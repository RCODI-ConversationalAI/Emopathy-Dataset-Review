title,authors,year,booktitle,doi,abstract,url,category,is_dataset,is_ml,is_ai
Estimating the Emotion of Disgust in {G}reek Parliament Records,"Lislevand, Vanessa  and
Pavlopoulos, John  and
Louridas, Panos  and
Dritsa, Konstantina",2024,Proceedings of the 8th Workshop on Online Abuse and Harms (WOAH 2024),10.18653/v1/2024.woah-1.9,"We present an analysis of the sentiment in Greek political speech, by focusing on the most frequently occurring emotion in electoral data, the emotion of {``}disgust{''}. We show that emotion classification is generally tough, but high accuracy can be achieved for that particular emotion. Using our best-performing model to classify political records of the Greek Parliament Corpus from 1989 to 2020, we studied the points in time when this emotion was frequently occurring and we ranked the Greek political parties based on their estimated score. We then devised an algorithm to investigate the emotional context shift of words that describe specific conditions and that can be used to stigmatise. Given that early detection of such word usage is essential for policy-making, we report two words we found being increasingly used in a negative emotional context, and one that is likely to be carrying stigma, in the studied parliamentary records.",https://aclanthology.org/2024.woah-1.9,emotion,Yes,Yes,No
Topic Bias in Emotion Classification,"Wegge, Maximilian  and
Klinger, Roman",2024,Proceedings of the Ninth Workshop on Noisy and User-generated Text (W-NUT 2024),,"Emotion corpora are typically sampled based on keyword/hashtag search or by asking study participants to generate textual instances. In any case, these corpora are not uniform samples representing the entirety of a domain. We hypothesize that this practice of data acquision leads to unrealistic correlations between overrepresented topics in these corpora that harm the generalizability of models. Such topic bias could lead to wrong predictions for instances like {``}I organized the service for my aunt{'}s funeral.{''} when funeral events are overpresented for instances labeled with sadness, despite the emotion of pride being more appropriate here. In this paper, we study this topic bias both from the data and the modeling perspective. We first label a set of emotion corpora automatically via topic modeling and show that emotions in fact correlate with specific topics. Further, we see that emotion classifiers are confounded by such topics. Finally, we show that the established debiasing method of adversarial correction via gradient reversal mitigates the issue. Our work points out issues with existing emotion corpora and that more representative resources are required for fair evaluation of models predicting affective concepts from text.",https://aclanthology.org/2024.wnut-1.9,emotion,Yes,Yes,No
{E}mo{M}ix-3{L}: A Code-Mixed Dataset for {B}angla-{E}nglish-{H}indi for Emotion Detection,"Raihan, Nishat  and
Goswami, Dhiman  and
Mahmud, Antara  and
Anastasopoulos, Antonios  and
Zampieri, Marcos",2024,Proceedings of the 7th Workshop on Indian Language Data: Resources and Evaluation,,"Code-mixing is a well-studied linguistic phenomenon that occurs when two or more languages are mixed in text or speech. Several studies have been conducted on building datasets and performing downstream NLP tasks on code-mixed data. Although it is not uncommon to observe code-mixing of three or more languages, most available datasets in this domain contain code-mixed data from only two languages. In this paper, we introduce EmoMix-3L, a novel multi-label emotion detection dataset containing code-mixed data from three different languages. We experiment with several models on EmoMix-3L and we report that MuRIL outperforms other models on this dataset.",https://aclanthology.org/2024.wildre-1.2,emotion,Yes,Yes,Yes
"Ice and Fire: Dataset on Sentiment, Emotions, Toxicity, Sarcasm, Hate speech, Sympathy and More in {I}celandic Blog Comments","Fri{\dh}riksd{\'o}ttir, Steinunn Rut  and
Simonsen, Annika  and
{\'A}smundsson, Atli Sn{\ae}r  and
Fri{\dh}j{\'o}nsd{\'o}ttir, Gu{\dh}r{\'u}n Lilja  and
Ingason, Anton Karl  and
Sn{\ae}bjarnarson, V{\'e}steinn  and
Einarsson, Hafsteinn",2024,"Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,"This study introduces {``}Ice and Fire,{''} a Multi-Task Learning (MTL) dataset tailored for sentiment analysis in the Icelandic language, encompassing a wide range of linguistic tasks, including sentiment and emotion detection, as well as identification of toxicity, hate speech, encouragement, sympathy, sarcasm/irony, and trolling. With 261 fully annotated blog comments and 1045 comments annotated in at least one task, this contribution marks a significant step forward in the field of Icelandic natural language processing. It provides a comprehensive dataset for understanding the nuances of online communication in Icelandic and an interface to expand the annotation effort. Despite the challenges inherent in subjective interpretation of text, our findings highlight the positive potential of this dataset to improve text analysis techniques and encourage more inclusive online discourse in Icelandic communities. With promising baseline performances, {``}Ice and Fire{''} sets the stage for future research to enhance automated text analysis and develop sophisticated language technologies, contributing to healthier online environments and advancing Icelandic language resources.",https://aclanthology.org/2024.trac-1.9,emotion,Yes,No,Yes
"Offensiveness, Hate, Emotion and {GPT}: Benchmarking {GPT}3.5 and {GPT}4 as Classifiers on {T}witter-specific Datasets","Bauer, Nikolaj  and
Preisig, Moritz  and
Volk, Martin",2024,"Proceedings of the Fourth Workshop on Threat, Aggression {\&} Cyberbullying @ LREC-COLING-2024",,"In this paper, we extend the work of benchmarking GPT by turning GPT models into classifiers and applying them on three different Twitter datasets on Hate-Speech Detection, Offensive Language Detection, and Emotion Classification. We use a Zero-Shot and Few-Shot approach to evaluate the classification capabilities of the GPT models. Our results show that GPT models do not always beat fine-tuned models on the tested benchmarks. However, in Hate-Speech and Emotion Detection, using a Few-Shot approach, state-of-the-art performance can be achieved. The results also reveal that GPT-4 is more sensitive to the examples given in a Few-Shot prompt, highlighting the importance of choosing fitting examples for inference and prompt formulation.",https://aclanthology.org/2024.trac-1.14,emotion,No,Yes,No
Identifying Emotional and Polar Concepts via Synset Translation,"Woudstra, Logan  and
Dawodu, Moyo  and
Igwe, Frances  and
Li, Senyu  and
Shi, Ning  and
Hauer, Bradley  and
Kondrak, Grzegorz",2024,Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024),10.18653/v1/2024.starsem-1.12,"Emotion identification and polarity classification seek to determine the sentiment expressed by a writer. Sentiment lexicons that provide classifications at the word level fail to distinguish between different senses of polysemous words. To address this problem, we propose a translation-based method for labeling each individual lexical concept and word sense. Specifically, we translate synsets into 20 different languages and verify the sentiment of these translations in multilingual sentiment lexicons. By applying our method to all WordNet synsets, we produce SentiSynset, a synset-level sentiment resource containing 12,429 emotional synsets and 15,567 polar synsets, which is significantly larger than previous resources. Experimental evaluation shows that our method outperforms prior automated methods that classify word senses, in addition to outperforming ChatGPT. We make the resulting resource publicly available on GitHub.",https://aclanthology.org/2024.starsem-1.12,emotion,No,Yes,No
Disambiguating Emotional Connotations of Words Using Contextualized Word Representations,"Hosseini, Akram Sadat  and
Staab, Steffen",2024,Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024),10.18653/v1/2024.starsem-1.21,"Understanding emotional nuances in written content is crucial for effective communication; however, the context-dependent nature of language poses challenges in precisely discerning emotions in text. This study contributes to the understanding of how the emotional connotations of a word are influenced by the sentence context in which it appears. Leveraging the contextual understanding embedded in contextualized word representations, we conduct an empirical investigation to (i) evaluate the varying abilities of these representations in distinguishing the diverse emotional connotations evoked by the same word across different contexts, (ii) explore potential biases in these representations toward specific emotions of a word, and (iii) assess the capability of these representations in estimating the number of emotional connotations evoked by a word in diverse contexts. Our experiments, utilizing four popular models{---}BERT, RoBERTa, XLNet, and GPT-2{---}and drawing on the GoEmotions and SemEval 2018 datasets, demonstrate that these models effectively discern emotional connotations of words. RoBERTa, in particular, shows superior performance and greater resilience against biases. Our further analysis reveals that disambiguating the emotional connotations of words significantly enhances emotion identification at the sentence level.",https://aclanthology.org/2024.starsem-1.21,emotion,No,Yes,No
{P}ersian{E}mo: Enhancing {F}arsi-{D}ari Emotion Analysis with a Hybrid Transformer and Recurrent Neural Network Model,"Hussiny, Mohammad Ali  and
Payenda, Mohammad Arif  and
{\O}vrelid, Lilja",2024,Proceedings of the 3rd Annual Meeting of the Special Interest Group on Under-resourced Languages @ LREC-COLING 2024,,"Emotion analysis is a critical research domain within the field of natural language processing (NLP). While substantial progress has been made in this area for the Persian language, there is still a need for more precise models and larger datasets specifically focusing on the Farsi and Dari dialects. In this research, we introduce {``}LearnArmanEmo{''} as a new dataset and a superior ensemble approach for Persian text emotion classification. Our proposed model, which combines XLM-RoBERTa-large and BiGRU, undergoes evaluation on LetHerLearn for the Dari dialect, ARMANEMO for the Farsi dialect, and LearnArmanEmo for both Dari and Farsi dialects. The empirical results substantiate the efficacy of our approach with the combined model demonstrating superior performance. Specifically, our model achieves an F1 score of 72.9{\%} on LetHerLearn, an F1 score of 77.1{\%} on ARMANEMO, and an F1 score of 78.8{\%} on the LearnArmanEmo dataset, establishing it as a better ensemble model for these datasets. These findings underscore the potential of this hybrid model as a useful tool for enhancing the performance of emotion analysis in Persian language processing.",https://aclanthology.org/2024.sigul-1.31,emotion,Yes,Yes,Yes
Sociolinguistically Informed Interpretability: A Case Study on {H}inglish Emotion Classification,"Tatariya, Kushal  and
Lent, Heather  and
Bjerva, Johannes  and
de Lhoneux, Miryam",2024,Proceedings of the 6th Workshop on Research in Computational Linguistic Typology and Multilingual NLP,,"Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression,especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply.",https://aclanthology.org/2024.sigtyp-1.9,emotion,Yes,Yes,Yes
nicolay-r at {S}em{E}val-2024 Task 3: Using Flan-T5 for Reasoning Emotion Cause in Conversations with Chain-of-Thought on Emotion States,"Rusnachenko, Nicolay  and
Liang, Huizhi",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.4,"Emotion expression is one of the essential traits of conversations. It may be self-related or caused by another speaker. The variety of reasons may serve as a source of the further emotion causes: conversation history, speaker{'}s emotional state, etc. Inspired by the most recent advances in Chain-of-Thought, in this work, we exploit the existing three-hop reasoning approach (THOR) to perform large language model instruction-tuning for answering: emotion states (THOR-state), and emotion caused by one speaker to the other (THOR-cause). We equip THORcause with the reasoning revision (RR) for devising a reasoning path in fine-tuning. In particular, we rely on the annotated speaker emotion states to revise reasoning path. Our final submission, based on Flan-T5-base (250M) and the rule-based span correction technique, preliminary tuned with THOR-state and fine-tuned with THOR-cause-rr on competition training data, results in 3rd and 4th places (F1-proportional) and 5th place (F1-strict) among 15 participating teams. Our THOR implementation fork is publicly available: https://github.com/nicolay-r/THOR-ECAC",https://aclanthology.org/2024.semeval-1.4,emotion,Yes,Yes,Yes
{NCL} Team at {S}em{E}val-2024 Task 3: Fusing Multimodal Pre-training Embeddings for Emotion Cause Prediction in Conversations,"Li, Shu  and
Liao, Zicen  and
Liang, Huizhi",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.44,"In this study, we introduce an MLP approach for extracting multimodal cause utterances in conversations, utilizing the multimodal conversational emotion causes from the ECF dataset. Our research focuses on evaluating a bi-modal framework that integrates video and audio embeddings to analyze emotional expressions within dialogues. The core of our methodology involves the extraction of embeddings from pre-trained models for each modality, followed by their concatenation and subsequent classification via an MLP network. We compared the accuracy performances across different modality combinations including text-audio-video, video-audio, and audio only.",https://aclanthology.org/2024.semeval-1.44,emotion,Yes,Yes,No
{T}rans{M}istral at {S}em{E}val-2024 Task 10: Using Mistral 7{B} for Emotion Discovery and Reasoning its Flip in Conversation,"Siino, Marco",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.46,"The EDiReF shared task at SemEval 2024 comprises three subtasks: Emotion Recognition in Conversation (ERC) in Hindi-English code-mixed conversations, Emotion Flip Reasoning (EFR) in Hindi-English code-mixed conversations, and EFR in English conversations. The objectives for the ERC and EFR tasks are defined as follows: 1) Emotion Recognition in Conversation (ERC): In this task, participants are tasked with assigning an emotion to each utterance within a dialogue from a predefined set of possible emotions. The goal is to accurately recognize and label the emotions expressed in the conversation; 2) Emotion Flip Reasoning (EFR): This task involves identifying the trigger utterance(s) for an emotion-flip within a multi-party conversation dialogue. Participants are required to pinpoint the specific utterance(s) that serve as catalysts for a change in emotion during the conversation. In this paper we only address the first subtask (ERC) making use of an online translation strategy followed by the application of a Mistral 7B model together with a few-shot prompt strategy. Our approach obtains an F1 of 0.36, eventually exhibiting further room for improvements.",https://aclanthology.org/2024.semeval-1.46,emotion,No,Yes,No
{TW}-{NLP} at {S}em{E}val-2024 Task10: Emotion Recognition and Emotion Reversal Inference in Multi-Party Dialogues.,"Tian, Wei  and
Ji, Peiyu  and
Zhang, Lei  and
Jian, Yue",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.48,"In multidimensional dialogues, emotions serve not only as crucial mediators of emotional exchanges but also carry rich information. Therefore, accurately identifying the emotions of interlocutors and understanding the triggering factors of emotional changes are paramount. This study focuses on the tasks of multilingual dialogue emotion recognition and emotion reversal reasoning based on provocateurs, aiming to enhance the accuracy and depth of emotional understanding in dialogues. To achieve this goal, we propose a novel model, MBERT-TextRCNN-PL, designed to effectively capture emotional information of interlocutors. Additionally, we introduce XGBoost-EC (Emotion Capturer) to identify emotion provocateurs, thereby delving deeper into the causal relationships behind emotional changes. By comparing with state-of-the-art models, our approach demonstrates significant improvements in recognizing dialogue emotions and provocateurs, offering new insights and methodologies for multilingual dialogue emotion understanding and emotion reversal research.",https://aclanthology.org/2024.semeval-1.48,emotion,No,Yes,Yes
{UWBA} at {S}em{E}val-2024 Task 3: Dialogue Representation and Multimodal Fusion for Emotion Cause Analysis,"Baloun, Josef  and
Martinek, Jiri  and
Lenc, Ladislav  and
Kral, Pavel  and
Zeman, Mat{\v{e}}j  and
Vl{\v{c}}ek, Luk{\'a}{\v{s}}",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.49,"In this paper, we present an approach for solving SemEval-2024 Task 3: The Competition of Multimodal Emotion Cause Analysis in Conversations. The task includes two subtasks that focus on emotion-cause pair extraction using text, video, and audio modalities. Our approach is composed of encoding all modalities (MFCC and Wav2Vec for audio, 3D-CNN for video, and transformer-based models for text) and combining them in an utterance-level fusion module. The model is then optimized for link and emotion prediction simultaneously. Our approach achieved 6th place in both subtasks. The full leaderboard can be found at https://codalab.lisn.upsaclay.fr/competitions/16141{\#}results",https://aclanthology.org/2024.semeval-1.49,emotion,No,Yes,No
{GAV}x at {S}em{E}val-2024 Task 10: Emotion Flip Reasoning via Stacked Instruction Finetuning of {LLM}s,"Nguyen, Vy  and
Zhang, Xiuzhen",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.50,"The Emotion Flip Reasoning task at SemEval 2024 aims at identifying the utterance(s) that trigger a speaker to shift from an emotion to another in a multi-party conversation. The spontaneous, informal, and occasionally multilingual dynamics of conversations make the task challenging. In this paper, we propose a supervised stacked instruction-based framework to finetune large language models to tackle this task. Utilising the annotated datasets provided, we curate multiple instruction sets involving chain-of-thoughts, feedback, and self-evaluation instructions, for a multi-step finetuning pipeline. We utilise the self-consistency inference strategy to enhance prediction consistency. Experimental results reveal commendable performance, achieving mean F1 scores of 0.77 and 0.76 for triggers in the Hindi-English and English-only tracks respectively. This led to us earning the second highest ranking in both tracks.",https://aclanthology.org/2024.semeval-1.50,emotion,Yes,Yes,Yes
{QFNU}{\_}{CS} at {S}em{E}val-2024 Task 3: A Hybrid Pre-trained Model based Approach for Multimodal Emotion-Cause Pair Extraction Task,"Wang, Zining  and
Zhao, Yanchao  and
Han, Guanghui  and
Song, Yang",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.53,"This article presents the solution of Qufu Normal University for the Multimodal Sentiment Cause Analysis competition in SemEval2024 Task 3.The competition aims to extract emotion-cause pairs from dialogues containing text, audio, and video modalities. To cope with this task, we employ a hybrid pre-train model based approach. Specifically, we first extract and fusion features from dialogues based on BERT, BiLSTM, openSMILE and C3D. Then, we adopt BiLSTM and Transformer to extract the candidate emotion-cause pairs. Finally, we design a filter to identify the correct emotion-cause pairs. The evaluation results show that, we achieve a weighted average F1 score of 0.1786 and an F1 score of 0.1882 on CodaLab.",https://aclanthology.org/2024.semeval-1.53,emotion,No,Yes,No
Hidetsune at {S}em{E}val-2024 Task 3: A Simple Textual Approach to Emotion Classification and Emotion Cause Analysis in Conversations Using Machine Learning and Next Sentence Prediction,"Takahashi, Hidetsune",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.55,"In this system paper for SemEval-2024 Task3 subtask 2, I present my simple textual approach to emotion classification and emotioncause analysis in conversations using machinelearning and next sentence prediction. I train aSpaCy model for emotion classification and usenext sentence prediction with BERT for emotion cause analysis. While speaker names andaudio-visual clips are given in addition to textof the conversations, my approach uses textualdata only to test my methodology to combinemachine learning with next sentence prediction.This paper reveals both strengths and weaknesses of my trial, suggesting a direction offuture studies to improve my introductory solution.",https://aclanthology.org/2024.semeval-1.55,emotion,No,Yes,No
{CLT}eam1 at {S}em{E}val-2024 Task 10: Large Language Model based ensemble for Emotion Detection in {H}inglish,"Vaidya, Ankit  and
Gokhale, Aditya  and
Desai, Arnav  and
Shukla, Ishaan  and
Sonawane, Sheetal",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.56,"This paper outlines our approach for the ERC subtask of the SemEval 2024 EdiREF Shared Task. In this sub-task, an emotion had to be assigned to an utterance which was the part of a dialogue. The utterance had to be classified into one of the following classes- disgust, contempt, anger, neutral, joy, sadness, fear, surprise. Our proposed system makes use of an ensemble of language specific RoBERTA and BERT models to tackle the problem. A weighted F1-score of 44{\%} was achieved by our system in this task. We conducted comprehensive ablations and suggested directions of future work. Our codebase is available publicly.",https://aclanthology.org/2024.semeval-1.56,emotion,No,Yes,Yes
Hidetsune at {S}em{E}val-2024 Task 10: An {E}nglish Based Approach to Emotion Recognition in {H}indi-{E}nglish code-mixed Conversations Using Machine Learning and Machine Translation,"Takahashi, Hidetsune",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.58,"In this system paper for SemEval-2024 Task10 subtask 1 (ERC), I present my approach torecognizing emotions in Hindi-English codemixed conversations. I train a SpaCy modelwith English translated data and classify emotions behind Hindi-English code-mixed utterances by using the model and translating theminto English. I use machine translation to translate all the data in Hindi-English mixed language into English due to an easy access to existing data for emotion recognition in English.Some additional data in English are used to enhance my model. This English based approachdemonstrates a fundamental possibility and potential of simplifying code-mixed language intoone major language for emotion recognition.",https://aclanthology.org/2024.semeval-1.58,emotion,No,Yes,No
{L}inguis{T}ech at {S}em{E}val-2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversation,"Alexandru, Mihaela  and
Ciocoiu, C{\u{a}}lina  and
M{\u{a}}niga, Ioana  and
Ungureanu, Octavian  and
G{\^\i}fu, Daniela  and
Trand{\u{a}}b{\u{a}}{\textcommabelow{t}}, Diana",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.64,"The {``}Emotion Discovery and Reasoning Its Flip in Conversation{''} task at the SemEval 2024 competition focuses on the automatic recognition of emotion flips, triggered within multi-party textual conversations. This paper proposes a novel approach that draws a parallel between a mixed strategy and a comparative strategy, contrasting a Rule-Based Function with Named Entity Recognition (NER){---}an approach that shows promise in understanding speaker-specific emotional dynamics. Furthermore, this method surpasses the performance of both DistilBERT and RoBERTa models, demonstrating competitive effectiveness in detecting emotion flips triggered in multi-party textual conversations, achieving a 70{\%} F1-score. This system was ranked 6th in the SemEval 2024 competition for Subtask 3.",https://aclanthology.org/2024.semeval-1.64,emotion,No,Yes,No
{S}amsung Research {C}hina-{B}eijing at {S}em{E}val-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations,"Zhang, Shen  and
Zhang, Haojie  and
Zhang, Jing  and
Zhang, Xudong  and
Zhuang, Yimeng  and
Wu, Jinting",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.81,"In human-computer interaction, it is crucial for agents to respond to human by understanding their emotions. unraveling the causes of emotions is more challenging. A new task named Multimodal Emotion-Cause Pair Extraction in Conversations is responsible for recognizing emotion and identifying causal expressions. In this study, we propose a multi-stage framework to generate emotion and extract the emotion causal pairs given the target emotion. In the first stage, LLaMA2-based InstructERC is utilized to extract the emotion category of each utterance in a conversation. After emotion recognition, a two-stream attention model is employed to extract the emotion causal pairs given the target emotion for subtask 2 while MuTEC is employed to extract causal span for subtask 1. Our approach achieved first place for both of the two subtasks in the competition.",https://aclanthology.org/2024.semeval-1.81,emotion,No,Yes,No
{SSN}{\_}{S}emeval10 at {S}em{E}val-2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversations,"Rajesh, Antony  and
Abirami, Supriya  and
Chandrabose, Aravindan  and
Kumar, Senthil",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.83,"This paper presents a transformer-based model for recognizing emotions in Hindi-English code-mixed conversations, adhering to the SemEval task constraints. Leveraging BERT-based transformers, we fine-tune pre-trained models on the dataset, incorporating tokenization and attention mechanisms. Our approach achieves competitive performance (weighted F1-score of 0.4), showcasing the effectiveness of BERT in nuanced emotion analysis tasks within code-mixed conversational contexts.",https://aclanthology.org/2024.semeval-1.83,emotion,Yes,Yes,No
Innovators at {S}em{E}val-2024 Task 10: Revolutionizing Emotion Recognition and Flip Analysis in Code-Mixed Texts,"Shanbhag, Abhay  and
Jadhav, Suramya  and
Rathi, Shashank  and
Pande, Siddhesh  and
Kadam, Dipali",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.93,"In this paper, we introduce our system for all three tracks of the SemEval 2024 EDiReF Shared Task 10, which focuses on Emotion Recognition in Conversation (ERC) and Emotion Flip Reasoning (EFR) within the domain of conversational analysis. Task-Track 1 (ERC) aims to assign an emotion to each utterance in the Hinglish language from a predefined set of possible emotions. Tracks 2 (EFR) and 3 (EFR) aim to identify the trigger utterance(s) for an emotion flip in a multi-party conversation dialogue in Hinglish and English text, respectively. For Track 1, our study spans both traditional machine learning ensemble techniques, including Decision Trees, SVM, Logistic Regression, and Multinomial NB models, as well as advanced transformer-based models like XLM-Roberta (XLMR), DistilRoberta, and T5 from Hugging Face{'}s transformer library. In the EFR competition, we developed and proposed two innovative algorithms to tackle the challenges presented in Tracks 2 and 3. Specifically, our team, Innovators, developed a standout algorithm that propelled us to secure the 2nd rank in Track 2, achieving an impressive F1 score of 0.79, and the 7th rank in Track 3, with an F1 score of 0.68.",https://aclanthology.org/2024.semeval-1.93,emotion,No,Yes,No
{ISDS}-{NLP} at {S}em{E}val-2024 Task 10: Transformer based neural networks for emotion recognition in conversations,"Creanga, Claudiu  and
Dinu, Liviu P.",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.95,"This paper outlines the approach of the ISDS-NLP team in the SemEval 2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). For Subtask 1 we obtained a weighted F1 score of 0.43 and placed 12 in the leaderboard. We investigate two distinct approaches: Masked Language Modeling (MLM) and Causal Language Modeling (CLM). For MLM, we employ pre-trained BERT-like models in a multilingual setting, fine-tuning them with a classifier to predict emotions. Experiments with varying input lengths, classifier architectures, and fine-tuning strategies demonstrate the effectiveness of this approach. Additionally, we utilize Mistral 7B Instruct V0.2, a state-of-the-art model, applying zero-shot and few-shot prompting techniques. Our findings indicate that while Mistral shows promise, MLMs currently outperform them in sentence-level emotion classification.",https://aclanthology.org/2024.semeval-1.95,emotion,No,Yes,Yes
{MIPS} at {S}em{E}val-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in Conversations with Multimodal Language Models,"Cheng, Zebang  and
Niu, Fuqiang  and
Lin, Yuxiang  and
Cheng, Zhi-qi  and
Peng, Xiaojiang  and
Zhang, Bowen",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.97,"This paper presents our winning submission to Subtask 2 of SemEval 2024 Task 3 on multimodal emotion cause analysis in conversations. We propose a novel Multimodal Emotion Recognition and Multimodal Emotion Cause Extraction (MER-MCE) framework that integrates text, audio, and visual modalities using specialized emotion encoders. Our approach sets itself apart from top-performing teams by leveraging modality-specific features for enhanced emotion understanding and causality inference. Experimental evaluation demonstrates the advantages of our multimodal approach, with our submission achieving a competitive weighted F1 score of 0.3435, ranking third with a margin of only 0.0339 behind the 1st team and 0.0025 behind the 2nd team.",https://aclanthology.org/2024.semeval-1.97,emotion,No,Yes,Yes
{UMUT}eam at {S}em{E}val-2024 Task 10: Discovering and Reasoning about Emotions in Conversation using Transformers,"Pan, Ronghao  and
Garc{\'\i}a-d{\'\i}az, Jos{\'e} Antonio  and
Rold{\'a}n, Diego  and
Valencia-garc{\'\i}a, Rafael",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.101,"These notes describe the participation of the UMUTeam in EDiReF, the 10th shared task of SemEval 2024. The goal is to develop systems for detecting and inferring emotional changes in the conversation. The task was divided into three related subtasks: (i) Emotion Recognition in Conversation (ERC) in Hindi-English code-mixed conversations, (ii) Emotion Flip Reasoning (EFR) in Hindi-English code-mixed conversations, and (iii) EFR in English conversations. We were involved in all three and our approach is based on a fine-tuning approach with different pre-trained models. After evaluation, we found BERT to be the best model for ERC and EFR and with this model we achieved the thirteenth best result with an F1 score of 43{\%} in Subtask 1, the sixth best in Subtask 2 with an F1 score of 26{\%} and the fifteenth best in Subtask 3 with an F1 score of 22{\%}.",https://aclanthology.org/2024.semeval-1.101,emotion,No,Yes,No
{SSN}{\_}{ARMM} at {S}em{E}val-2024 Task 10: Emotion Detection in Multilingual Code-Mixed Conversations using {L}inear{SVC} and {TF}-{IDF},"Arumugam, Rohith  and
Deborah, Angel  and
Sivanaiah, Rajalakshmi  and
R S, Milton  and
Thankanadar, Mirnalinee",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.105,"Our paper explores a task involving the analysis of emotions and triggers within dialogues. We annotate each utterance with an emotion and identify triggers, focusing on binary labeling. We emphasize clear guidelines for replicability and conduct thorough analyses, including multiple system runs and experiments to highlight effective techniques. By simplifying the complexities and detailing clear methodologies, our study contributes to advancing emotion analysis and trigger identification within dialogue systems.",https://aclanthology.org/2024.semeval-1.105,emotion,Yes,No,No
{F}eed{F}orward at {S}em{E}val-2024 Task 10: Trigger and sentext-height enriched emotion analysis in multi-party conversations,"Shaik, Zuhair Hasan  and
Prasanna, Dhivya  and
Jahnavi, Enduri  and
Thippireddy, Rishi  and
Madhav, Vamsi  and
Saumya, Sunil  and
Biradar, Shankar",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.107,"This paper reports on an innovative approach to Emotion Recognition in Conversation and Emotion Flip Reasoning for the SemEval-2024 competition with a specific focus on analyzing Hindi-English code-mixed language. By integrating Large Language Models (LLMs) with Instruction-based Fine-tuning and Quantized Low-Rank Adaptation (QLoRA), this study introduces innovative techniques like Sentext-height and advanced prompting strategies to navigate the intricacies of emotional analysis in code-mixed conversational data. The results of the proposed work effectively demonstrate its ability to overcome label bias and the complexities of code-mixed languages. Our team achieved ranks of 5, 3, and 3 in tasks 1, 2, and 3 respectively. This study contributes valuable insights and methods for enhancing emotion recognition models, underscoring the importance of continuous research in this field.",https://aclanthology.org/2024.semeval-1.107,emotion,No,Yes,Yes
{TECHSSN} at {S}em{E}val-2024 Task 10: {LSTM}-based Approach for Emotion Detection in Multilingual Code-Mixed Conversations,"V, Ravindran  and
Babu G, Shreejith  and
Jetti, Aashika  and
Sivanaiah, Rajalakshmi  and
Deborah, Angel  and
Thankanadar, Mirnalinee  and
R S, Milton",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.109,"Emotion Recognition in Conversation (ERC) in the context of code-mixed Hindi-English interactions is a subtask addressed in SemEval-2024 as Task 10. We made our maiden attempt to solve the problem using natural language processing, machine learning and deep learning techniques, that perform well in properly assigning emotions to individual utterances from a predefined collection. The use of well-proven classifier such as Long Short Term Memory networks improve the model{'}s efficacy than the BERT and Glove based models. How-ever, difficulties develop in the subtle arena of emotion-flip reasoning in multi-party discussions, emphasizing the importance of specialized methodologies. Our findings shed light on the intricacies of emotion dynamics in code-mixed languages, pointing to potential areas for further research and refinement in multilingual understanding.",https://aclanthology.org/2024.semeval-1.109,emotion,Yes,Yes,Yes
{UIR}-{ISC} at {S}em{E}val-2024 Task 3: Textual Emotion-Cause Pair Extraction in Conversations,"Guo, Hongyu  and
Zhang, Xueyao  and
Chen, Yiyang  and
Deng, Lin  and
Li, Binyang",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.110,"The goal of Emotion Cause Pair Extraction (ECPE) is to explore the causes of emotion changes and what causes a certain emotion. This paper proposes a three-step learning approach for the task of Textual Emotion-Cause Pair Extraction in Conversations in SemEval-2024 Task 3, named ECSP. We firstly perform data preprocessing operations on the original dataset to construct negative samples. Secondly, we use a pre-trained model to construct token sequence representations with contextual information to obtain emotion prediction. Thirdly, we regard the textual emotion-cause pair extraction task as a machine reading comprehension task, and fine-tune two pre-trained models, RoBERTa and SpanBERT. Our results have achieved good results in the official rankings, ranking 3rd under the strict match with the Strict F1-score of 15.18{\%}, which further shows that our system has a robust performance.",https://aclanthology.org/2024.semeval-1.110,emotion,Yes,Yes,No
{YNU}-{HPCC} at {S}em{E}val-2024 Task10: Pre-trained Language Model for Emotion Discovery and Reasoning its Flip in Conversation,"Liang, Chenyi  and
Wang, Jin  and
Zhang, Xuejie",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.111,"This paper describes the application of fine-tuning pre-trained models for SemEval-2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF), which requires the prediction of emotions for each utterance in a conversation and the identification of sentences where an emotional flip occurs. This model is built on the DeBERTa transformer model and enhanced for emotion detection and flip reasoning in conversations. It employs specific separators for utterance processing and utilizes specific padding to handle variable-length inputs. Methods such as R-drop, back translation, and focalloss are also employed in the training of my model. The model achieved specific results on the competition{'}s official leaderboard. The code of this paper is available athttps://github.com/jiaowoobjiuhao/SemEval-2024-task10.",https://aclanthology.org/2024.semeval-1.111,emotion,No,Yes,Yes
{BITS} Pilani at {S}em{E}val-2024 Task 10: Fine-tuning {BERT} and Llama 2 for Emotion Recognition in Conversation,"Venkatesh, Dilip  and
Prasanjith, Pasunti  and
Sharma, Yashvardhan",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.115,"Emotion Recognition in Conversation (ERC)aims to assign an emotion to a dialogue in aconversation between people. The first subtaskof EDiReF shared task aims to assign an emo-tions to a Hindi-English code mixed conversa-tion. For this, our team proposes a system toidentify the emotion based on fine-tuning largelanguage models on the MaSaC dataset. Forour study we have fine tuned 2 LLMs BERTand Llama 2 to perform sequence classificationto identify the emotion of the text.",https://aclanthology.org/2024.semeval-1.115,emotion,Yes,Yes,No
{TECHSSN}1 at {S}em{E}val-2024 Task 10: Emotion Classification in {H}indi-{E}nglish Code-Mixed Dialogue using Transformer-based Models,"Yenumulapalli, Venkatasai Ojus  and
Premnath, Pooja  and
Mohankumar, Parthiban  and
Sivanaiah, Rajalakshmi  and
Deborah, Angel",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.119,"The increase in the popularity of code mixed languages has resulted in the need to engineer language models for the same . Unlike pure languages, code-mixed languages lack clear grammatical structures, leading to ambiguous sentence constructions. This ambiguity presents significant challenges for natural language processing tasks, including syntactic parsing, word sense disambiguation, and language identification. This paper focuses on emotion recognition of conversations in Hinglish, a mix of Hindi and English, as part of Task 10 of SemEval 2024. The proposed approach explores the usage of standard machine learning models like SVM, MNB and RF, and also BERT-based models for Hindi-English code-mixed data- namely, HingBERT, Hing mBERT and HingRoBERTa for subtask A.",https://aclanthology.org/2024.semeval-1.119,emotion,No,Yes,Yes
{RACAI} at {S}em{E}val-2024 Task 10: Combining algorithms for code-mixed Emotion Recognition in Conversation,"Ni{\textcommabelow{t}}{\u{a}}, Sara  and
P{\u{a}}i{\textcommabelow{s}}, Vasile",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.149,Code-mixed emotion recognition constitutes a challenge for NLP research due to the text{'}s deviation from the traditional grammatical structure of the original languages. This paper describes the system submitted by the RACAI Team for the SemEval 2024 Task 10 - EDiReF subtasks 1: Emotion Recognition in Conversation (ERC) in Hindi-English code-mixed conversations. We propose a system that combines a transformer-based model with two simple neural networks.,https://aclanthology.org/2024.semeval-1.149,emotion,No,Yes,Yes
{PWEITINLP} at {S}em{E}val-2024 Task 3: Two Step Emotion Cause Analysis,"Levchenko, Sofiia  and
Wolert, Rafa{\l}  and
Andruszkiewicz, Piotr",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.159,ECPE (emotion cause pair extraction) task was introduced to solve the shortcomings of ECE (emotion cause extraction). Models with sequential data processing abilities or complex architecture can be utilized to solve this task. Our contribution to solving Subtask 1: Textual Emotion-Cause Pair Extraction in Conversations defined in the SemEval-2024 Task 3: The Competition of Multimodal Emotion Cause Analysis in Conversations is to create a two-step solution to the ECPE task utilizing GPT-3 for emotion classification and SpanBERT for extracting the cause utterances.,https://aclanthology.org/2024.semeval-1.159,emotion,No,Yes,No
{P}et{K}az at {S}em{E}val-2024 Task 3: Advancing Emotion Classification with an {LLM} for Emotion-Cause Pair Extraction in Conversations,"Kazakov, Roman  and
Petukhova, Kseniia  and
Kochmar, Ekaterina",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.164,"In this paper, we present our submission to the SemEval-2023 Task 3 {``}The Competition of Multimodal Emotion Cause Analysis in Conversations{''}, focusing on extracting emotion-cause pairs from dialogs. Specifically, our approach relies on combining fine-tuned GPT-3.5 for emotion classification and using a BiLSTM-based neural network to detect causes. We score 2nd in the ranking for Subtask 1, demonstrating the effectiveness of our approach through one of the highest weighted-average proportional F1 scores recorded at 0.264.",https://aclanthology.org/2024.semeval-1.164,emotion,No,Yes,No
{L}ast{R}esort at {S}em{E}val-2024 Task 3: Exploring Multimodal Emotion Cause Pair Extraction as Sequence Labelling Task,"Mathur, Suyash Vardhan  and
Jindal, Akshett  and
Mittal, Hardik  and
Shrivastava, Manish",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.175,"Conversation is the most natural form of human communication, where each utterance can range over a variety of possible emotions. While significant work has been done towards the detection of emotions in text, relatively little work has been done towards finding the cause of the said emotions, especially in multimodal settings. SemEval 2024 introduces the task of Multimodal Emotion Cause Analysis in Conversations, which aims to extract emotions reflected in individual utterances in a conversation involving multiple modalities (textual, audio, and visual modalities) along with the corresponding utterances that were the cause for the emotion. In this paper, we propose models that tackle this task as an utterance labeling and a sequence labeling problem and perform a comparative study of these models, involving baselines using different encoders, using BiLSTM for adding contextual information of the conversation, and finally adding a CRF layer to try to model the inter-dependencies between adjacent utterances more effectively. In the official leaderboard for the task, our architecture was ranked 8th, achieving an F1-score of 0.1759 on the leaderboard.",https://aclanthology.org/2024.semeval-1.175,emotion,No,Yes,No
{M}orphing{M}inds at {S}em{E}val-2024 Task 10: Emotion Recognition in Conversation in {H}indi-{E}nglish Code-Mixed Conversations,"Vyas, Monika",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.177,"The research focuses on emotion detection in multilingual conversations, particularly in Romanized Hindi and English, with applications in sentiment analysis and mental health assessments. The study employs Machine learning, deep learning techniques, including Transformer-based models like XLM-RoBERTa, for feature extraction and emotion classification. Various experiments are conducted to evaluate model performance, including fine-tuning, data augmentation, and addressing dataset imbalances. The findings highlight challenges and opportunities in emotion detection across languages and emphasize culturally sensitive approaches. The study contributes to advancing emotion analysis in multilingual contexts and provides practical guidance for developing more accurate emotion detection systems.",https://aclanthology.org/2024.semeval-1.177,emotion,Yes,Yes,No
{IASBS} at {S}em{E}val-2024 Task 10: Delving into Emotion Discovery and Reasoning in Code-Mixed Conversations,"Tareh, Mehrzad  and
Mohandesi, Aydin  and
Ansari, Ebrahim",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.179,"In this paper, we detail the IASBS team{'}s approach and findings from participating in SemEval-2024 Task 10, {``}Emotion Discovery and Reasoning in Hindi-English Code-mixed Conversations (EDiReF).{''} This task encompasses three critical subtasks: Emotion Recognition in Conversation (ERC), and Emotion Flip Reasoning (EFR) in both Hindi-English code-mixed and English dialogues. Our methodology integrates advanced NLP and machine learning techniques, focusing on the unique challenges of code-mixing, such as linguistic diversity and shifts in emotional context. By implementing a robust framework that includes data preprocessing, and feature engineering using models like GPT-4 and DistilBERT, we extend our analysis beyond mere emotion identification to explore the triggers behind emotion flips. This endeavor not only achieved third place on the leaderboard, demonstrating a high proficiency in emotion and flip detection with an F1-Score of 0.70 but also significantly contributed to the advancement of emotional AI. Our findings offer valuable insights into the complex interplay of emotions in communication, showcasing the potential for enhancing applications across various domains, from social media analytics to healthcare, and underscore the importance of understanding emotional dynamics in code-mixed conversations for future research and practical applications.",https://aclanthology.org/2024.semeval-1.179,emotion,No,Yes,Yes
{L}y{S} at {S}em{E}val-2024 Task 3: An Early Prototype for End-to-End Multimodal Emotion Linking as Graph-Based Parsing,"Ezquerro, Ana  and
Vilares, David",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.182,"This paper describes our participation in SemEval 2024 Task 3, which focused on Multimodal Emotion Cause Analysis in Conversations. We developed an early prototype for an end-to-end system that uses graph-based methods from dependency parsing to identify causal emotion relations in multi-party conversations. Our model comprises a neural transformer-based encoder for contextualizing multimodal conversation data and a graph-based decoder for generating the adjacency matrix scores of the causal graph. We ranked 7th out of 15 valid and official submissions for Subtask 1, using textual inputs only. We also discuss our participation in Subtask 2 during post-evaluation using multi-modal inputs.",https://aclanthology.org/2024.semeval-1.182,emotion,No,Yes,No
{V}erba{N}ex{AI} Lab at {S}em{E}val-2024 Task 10: Emotion recognition and reasoning in mixed-coded conversations based on an {NRC} {VAD} approach,"Garcia, Santiago  and
Martinez, Elizabeth  and
Cuadrado, Juan  and
Martinez-santos, Juan  and
Puertas, Edwin",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.192,"This study introduces an innovative approach to emotion recognition and reasoning about emotional shifts in code-mixed conversations, leveraging the NRC VAD Lexicon and computational models such as Transformer and GRU. Our methodology systematically identifies and categorizes emotional triggers, employing Emotion Flip Reasoning (EFR) and Emotion Recognition in Conversation (ERC). Through experiments with the MELD and MaSaC datasets, we demonstrate the model{'}s precision in accurately identifying emotional shift triggers and classifying emotions, evidenced by a significant improvement in accuracy as shown by an increase in the F1 score when including VAD analysis. These results underscore the importance of incorporating complex emotional dimensions into conversation analysis, paving new pathways for understanding emotional dynamics in code-mixed texts.",https://aclanthology.org/2024.semeval-1.192,emotion,No,Yes,No
{V}erba{N}ex{AI} Lab at {S}em{E}val-2024 Task 3: Deciphering emotional causality in conversations using multimodal analysis approach,"Pacheco, Victor  and
Martinez, Elizabeth  and
Cuadrado, Juan  and
Martinez Santos, Juan Carlos  and
Puertas, Edwin",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.193,"This study delineates our participation in the SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations, focusing on developing and applying an innovative methodology for emotion detection and cause analysis in conversational contexts. Leveraging logistic regression, we analyzed conversational utterances to identify emotions per utterance. Subsequently, we employed a dependency analysis pipeline, utilizing SpaCy to extract significant chunk features, including object, subject, adjectival modifiers, and adverbial clause modifiers. These features were analyzed within a graph-like framework, conceptualizing the dependency relationships as edges connecting emotional causes (tails) to their corresponding emotions (heads). Despite the novelty of our approach, the preliminary results were unexpectedly humbling, with a consistent score of 0.0 across all evaluated metrics. This paper presents our methodology, the challenges encountered, and an analysis of the potential factors contributing to these outcomes, offering insights into the complexities of emotion-cause analysis in multimodal conversational data.",https://aclanthology.org/2024.semeval-1.193,emotion,No,No,No
{UIC} {NLP} {GRADS} at {S}em{E}val-2024 Task 3: Two-Step Disjoint Modeling for Emotion-Cause Pair Extraction,"Chandakacherla, Sharad  and
Bhargava, Vaibhav  and
Parde, Natalie",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.198,"Disentangling underlying factors contributing to the expression of emotion in multimodal data is challenging but may accelerate progress toward many real-world applications. In this paper we describe our approach for solving SemEval-2024 Task {\#}3, Sub-Task {\#}1, focused on identifying utterance-level emotions and their causes using the text available from the multimodal F.R.I.E.N.D.S. television series dataset. We propose to disjointly model emotion detection and causal span detection, borrowing a paradigm popular in question answering (QA) to train our model. Through our experiments we find that (a) contextual utterances before and after the target utterance play a crucial role in emotion classification; and (b) once the emotion is established, detecting the causal spans resulting in that emotion using our QA-based technique yields promising results.",https://aclanthology.org/2024.semeval-1.198,emotion,Yes,Yes,Yes
{UCSC} {NLP} at {S}em{E}val-2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversation ({ED}i{R}e{F}),"Wan, Neng  and
Au, Steven  and
Ubale, Esha  and
Krogh, Decker",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.214,"We describe SemEval-2024 Task 10: EDiReF consisting of three sub-tasks involving emotion in conversation across Hinglish code-mixed and English datasets. Subtasks include classification of speaker emotion in multiparty conversations (Emotion Recognition in Conversation) and reasoning around shifts in speaker emotion state (Emotion Flip Reasoning). We deployed a BERT model for emotion recognition and two GRU-based models for emotion flip. Our model achieved F1 scores of 0.45, 0.79, and 0.68 for subtasks 1, 2, and 3, respectively.",https://aclanthology.org/2024.semeval-1.214,emotion,No,Yes,Yes
{NUS}-Emo at {S}em{E}val-2024 Task 3: Instruction-Tuning {LLM} for Multimodal Emotion-Cause Analysis in Conversations,"Luo, Meng  and
Zhang, Han  and
Wu, Shengqiong  and
Li, Bobo  and
Han, Hong  and
Fei, Hao",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.226,"This paper describes the architecture of our system developed for participation in Task 3 of SemEval-2024: Multimodal Emotion-Cause Analysis in Conversations. Our project targets the challenges of subtask 2, dedicated to Multimodal Emotion-Cause Pair Extraction with Emotion Category (MECPE-Cat), and constructs a dual-component system tailored to the unique challenges of this task. We divide the task into two subtasks: emotion recognition in conversation (ERC) and emotion-cause pair extraction (ECPE). To address these subtasks, we capitalize on the abilities of Large Language Models (LLMs), which have consistently demonstrated state-of-the-art performance across various natural language processing tasks and domains. Most importantly, we design an approach of emotion-cause-aware instruction-tuning for LLMs, to enhance the perception of the emotions with their corresponding causal rationales. Our method enables us to adeptly navigate the complexities of MECPE-Cat, achieving an average 34.71{\%} F1 score of the task, and securing the 2nd rank on the leaderboard. The code and metadata to reproduce our experiments are all made publicly available.",https://aclanthology.org/2024.semeval-1.226,emotion,No,Yes,Yes
{AIMA} at {S}em{E}val-2024 Task 3: Simple Yet Powerful Emotion Cause Pair Analysis,"Ghahramani Kure, Alireza  and
Dehghani, Mahshid  and
Abootorabi, Mohammad Mahdi  and
Ghazizadeh, Nona  and
Dalili, Seyed Arshan  and
Asgari, Ehsaneddin",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.243,"The SemEval-2024 Task 3 presents two subtasks focusing on emotion-cause pair extraction within conversational contexts. Subtask 1 revolves around the extraction of textual emotion-cause pairs, where causes are defined and annotated as textual spans within the conversation. Conversely, Subtask 2 extends the analysis to encompass multimodal cues, including language, audio, and vision, acknowledging instances where causes may not be exclusively represented in the textual data. Our proposed model for emotion-cause analysis is meticulously structured into three core segments: (i) embedding extraction, (ii) cause-pair extraction {\&} emotion classification, and (iii) cause extraction using QA after finding pairs. Leveraging state-of-the-art techniques and fine-tuning on task-specific datasets, our model effectively unravels the intricate web of conversational dynamics and extracts subtle cues signifying causality in emotional expressions. Our team, AIMA, demonstrated strong performance in the SemEval-2024 Task 3 competition. We ranked as the 10th in subtask 1 and the 6th in subtask 2 out of 23 teams.",https://aclanthology.org/2024.semeval-1.243,emotion,Yes,Yes,No
{AIMA} at {S}em{E}val-2024 Task 10: History-Based Emotion Recognition in {H}indi-{E}nglish Code-Mixed Conversations,"Abootorabi, Mohammad Mahdi  and
Ghazizadeh, Nona  and
Dalili, Seyed Arshan  and
Ghahramani Kure, Alireza  and
Dehghani, Mahshid  and
Asgari, Ehsaneddin",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.244,"In this study, we introduce a solution to the SemEval 2024 Task 10 on subtask 1, dedicated to Emotion Recognition in Conversation (ERC) in code-mixed Hindi-English conversations. ERC in code-mixed conversations presents unique challenges, as existing models are typically trained on monolingual datasets and may not perform well on code-mixed data. To address this, we propose a series of models that incorporate both the previous and future context of the current utterance, as well as the sequential information of the conversation. To facilitate the processing of code-mixed data, we developed a Hinglish-to-English translation pipeline to translate the code-mixed conversations into English. We designed four different base models, each utilizing powerful pre-trained encoders to extract features from the input but with varying architectures. By ensembling all of these models, we developed a final model that outperforms all other baselines.",https://aclanthology.org/2024.semeval-1.244,emotion,No,Yes,No
{D}eep{P}avlov at {S}em{E}val-2024 Task 3: Multimodal Large Language Models in Emotion Reasoning,"Belikova, Julia  and
Kosenko, Dmitrii",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.249,"This paper presents the solution of the DeepPavlov team for the Multimodal Sentiment Cause Analysis competition in SemEval-2024 Task 3, Subtask 2 (Wang et al., 2024). In the evaluation leaderboard, our approach ranks 7th with an F1-score of 0.2132. Large Language Models (LLMs) are transformative in their ability to comprehend and generate human-like text. With recent advancements, Multimodal Large Language Models (MLLMs) have expanded LLM capabilities, integrating different modalities such as audio, vision, and language. Our work delves into the state-of-the-art MLLM Video-LLaMA, its associated modalities, and its application to the emotion reasoning downstream task, Multimodal Emotion Cause Analysis in Conversations (MECAC). We investigate the model{'}s performance in several modes: zero-shot, few-shot, individual embeddings, and fine-tuned, providing insights into their limits and potential enhancements for emotion understanding.",https://aclanthology.org/2024.semeval-1.249,emotion,No,Yes,Yes
{IITK} at {S}em{E}val-2024 Task 10: Who is the speaker? Improving Emotion Recognition and Flip Reasoning in Conversations via Speaker Embeddings,"Patel, Shubham  and
Shukla, Divyaksh  and
Modi, Ashutosh",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.256,"This paper presents our approach for the SemEval-2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversations. We propose a transformer-based speaker-centric model for the Emotion Flip Reasoning (EFR) task and a masked-memory network along with a speaker participation vector for the Emotion Recognition in Conversations (ERC) task. We propose a Probable Trigger Zone, which is more likely to contain the utterances causing the emotion of a speaker to flip. In EFR, sub-task 3, the proposed approach archives a 5.9 (F1 score) improvement over the provided task baseline. The ablation study results highlight the significance of various design choices in the proposed method.",https://aclanthology.org/2024.semeval-1.256,emotion,No,Yes,No
{S}em{E}val 2024 - Task 10: Emotion Discovery and Reasoning its Flip in Conversation ({ED}i{R}e{F}),"Kumar, Shivani  and
Akhtar, Md. Shad  and
Cambria, Erik  and
Chakraborty, Tanmoy",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.270,"We present SemEval-2024 Task 10, a shared task centred on identifying emotions and finding the rationale behind their flips within monolingual English and Hindi-English code-mixed dialogues. This task comprises three distinct subtasks {--} emotion recognition in conversation for code-mixed dialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip reasoning for English dialogues. Participating systems were tasked to automatically execute one or more of these subtasks. The datasets for these tasks comprise manually annotated conversations focusing on emotions and triggers for emotion shifts.1 A total of 84 participants engaged in this task, with the most adept systems attaining F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper summarises the results and findings from 24 teams alongside their system descriptions.",https://aclanthology.org/2024.semeval-1.270,emotion,Yes,No,No
{S}em{E}val-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations,"Wang, Fanfan  and
Ma, Heqing  and
Xia, Rui  and
Yu, Jianfei  and
Cambria, Erik",2024,Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024),10.18653/v1/2024.semeval-1.277,"The ability to understand emotions is an essential component of human-like artificial intelligence, as emotions greatly influence human cognition, decision making, and social interactions. In addition to emotion recognition in conversations, the task of identifying the potential causes behind an individual{'}s emotional state in conversations, is of great importance in many application scenarios. We organize SemEval-2024 Task 3, named Multimodal Emotion Cause Analysis in Conversations, which aims at extracting all pairs of emotions and their corresponding causes from conversations. Under different modality settings, it consists of two subtasks: Textual Emotion-Cause Pair Extraction in Conversations (TECPE) and Multimodal Emotion-Cause Pair Extraction in Conversations (MECPE). The shared task has attracted 143 registrations and 216 successful submissions.In this paper, we introduce the task, dataset and evaluation settings, summarize the systems of the top teams, and discuss the findings of the participants.",https://aclanthology.org/2024.semeval-1.277,emotion,Yes,No,Yes
{S}arc{E}mp - Fine-tuning {D}ialo{GPT} for Sarcasm and Empathy,"Rizwan, Mohammed",2024,Proceedings of the 1st Workshop on Simulating Conversational Intelligence in Chat (SCI-CHAT 2024),,"Conversational models often face challenges such as a lack of emotional temperament and a limited sense of humor when interacting with users. To address these issues, we have selected relevant data and fine-tuned the model to (i) humanize the chatbot based on the user{'}s emotional response and the context of the conversation using a dataset based on empathy and (ii) enhanced conversations while incorporating humor/sarcasm for better user engagement. We aspire to achieve more personalized and enhanced user-computer interactions with the help of varied datasets involving sarcasm together with empathy on top of already available state-of-the-art conversational systems.",https://aclanthology.org/2024.scichat-1.6,empathy,Yes,Yes,No
Emo-Gen {BART} - A Multitask Emotion-Informed Dialogue Generation Framework,"Debnath, Alok  and
Graham, Yvette  and
Conlan, Owen",2024,Proceedings of the 1st Workshop on Simulating Conversational Intelligence in Chat (SCI-CHAT 2024),,"This paper is the model description for the Emo-Gen BART dialogue generation architecture, as submitted to the SCI-CHAT 2024 Shared Task. The Emotion-Informed Dialogue Generation model is a multi-task BARTbased model which performs dimensional and categorical emotion detection and uses that information to augment the input to the generation models. Our implementation is trained and validated against the IEMOCAP dataset, and compared against contemporary architectures in both dialogue emotion classification and dialogue generation. We show that certain loss function ablations are competitive against the state-of-the-art single-task models.",https://aclanthology.org/2024.scichat-1.7,emotion,Yes,Yes,No
"Multi-Dimensional Insights: Annotated Dataset of Stance, Sentiment, and Emotion in {F}acebook Comments on {T}unisia{'}s {J}uly 25 Measures","Laabar, Sanaa  and
Zaghouani, Wajdi",2024,Proceedings of the Second Workshop on Natural Language Processing for Political Sciences @ LREC-COLING 2024,,"On July 25, 2021, Tunisian President Kais Saied announced the suspension of parliament and dismissal of Prime Minister Hichem Mechichi, a move that sparked intense public debate. This study investigates Tunisian public opinion regarding these events by analyzing a corpus of 7,535 Facebook comments collected from the official Tunisian presidency page, specifically the post announcing the July 25 measures. A team of three annotators labeled a subset of 5,000 comments, categorizing each comment{'}s political stance (supportive, opposing, or neutral), sentiment (positive, negative, or neutral), emotions, presence of hate speech, aggressive tone, and racism. The inter-annotator agreement, measured by Cohen{'}s kappa, was 0.61, indicating substantial consensus. The analysis reveals that a majority of commenters supported President Saied{'}s actions, outnumbering those who opposed or took a neutral stance. Moreover, the overall sentiment expressed in the comments was predominantly positive. This study provides valuable insights into the complex landscape of public opinion in Tunisia during a crucial moment in the country{'}s ongoing political transformation, highlighting the role of social media as a platform for political discourse and engagement.",https://aclanthology.org/2024.politicalnlp-1.3,emotion,Yes,No,No
Automated Emotion Annotation of {F}innish Parliamentary Speeches Using {GPT}-4,"Tarkka, Otto  and
Koljonen, Jaakko  and
Korhonen, Markus  and
Laine, Juuso  and
Martiskainen, Kristian  and
Elo, Kimmo  and
Laippala, Veronika",2024,"Proceedings of the IV Workshop on Creating, Analysing, and Increasing Accessibility of Parliamentary Corpora (ParlaCLARIN) @ LREC-COLING 2024",,"In this paper, we test the efficacy of using GPT-4 to annotate a dataset that is the used to train a BERT classifier for emotion analysis. Manual data annotation is often a laborious and expensive task and emotion annotation, specifically, has proved difficult even for expert annotators. We show that using GPT-4 can produce equally good results as doing data annotation manually while saving a lot of time and money. We train a BERT classifier on our automatically annotated dataset and get results that outperform a BERT classifier that is trained on machine translated data. Our paper shows how Large Language Models can be used to work with and analyse parliamentary corpora.",https://aclanthology.org/2024.parlaclarin-1.11,emotion,Yes,Yes,Yes
Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion,"Singh, Smriti  and
Caragea, Cornelia  and
Li, Junyi Jessy",2024,Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers),10.18653/v1/2024.naacl-short.51,"Situations and events evoke emotions in humans, but to what extent do they inform the prediction of emotion detection models? This work investigates how well human-annotated emotion triggers correlate with features that models deemed salient in their prediction of emotions. First, we introduce a novel dataset EmoTrigger, consisting of 900 social media posts sourced from three different datasets; these were annotated by experts for emotion triggers with high agreement. Using EmoTrigger, we evaluate the ability of large language models (LLMs) to identify emotion triggers, and conduct a comparative analysis of the features considered important for these tasks between LLMs and fine-tuned models. Our analysis reveals that emotion triggers are largely not considered salient features for emotion prediction models, instead there is intricate interplay between various features and the task of emotion detection.",https://aclanthology.org/2024.naacl-short.51,emotion,Yes,Yes,Yes
Improved Text Emotion Prediction Using Combined Valence and Arousal Ordinal Classification,"Mitsios, Michail  and
Vamvoukakis, Georgios  and
Maniati, Georgia  and
Ellinas, Nikolaos  and
Dimitriou, Georgios  and
Markopoulos, Konstantinos  and
Kakoulidis, Panos  and
Vioni, Alexandra  and
Christidou, Myrsini  and
Oh, Junkwang  and
Jho, Gunu  and
Hwang, Inchul  and
Vardaxoglou, Georgios  and
Chalamandaris, Aimilios  and
Tsiakoulis, Pirros  and
Raptis, Spyros",2024,Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers),10.18653/v1/2024.naacl-short.72,"Emotion detection in textual data has received growing interest in recent years, as it is pivotal for developing empathetic human-computer interaction systems.This paper introduces a method for categorizing emotions from text, which acknowledges and differentiates between the diversified similarities and distinctions of various emotions.Initially, we establish a baseline by training a transformer-based model for standard emotion classification, achieving state-of-the-art performance. We argue that not all misclassifications are of the same importance, as there are perceptual similarities among emotional classes.We thus redefine the emotion labeling problem by shifting it from a traditional classification model to an ordinal classification one, where discrete emotions are arranged in a sequential order according to their valence levels.Finally, we propose a method that performs ordinal classification in the two-dimensional emotion space, considering both valence and arousal scales.The results show that our approach not only preserves high accuracy in emotion prediction but also significantly reduces the magnitude of errors in cases of misclassification.",https://aclanthology.org/2024.naacl-short.72,emotion,No,Yes,No
{T}el{ME}: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation,"Yun, Taeyang  and
Lim, Hyunkuk  and
Lee, Jeonghwan  and
Song, Min",2024,Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),10.18653/v1/2024.naacl-long.5,"Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue sys- tems to effectively respond to user requests. The emotions in a conversation can be identi- fied by the representations from various modal- ities, such as audio, visual, and text. How- ever, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a lan- guage model acting as the teacher to the non- verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multi- modal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effec- tiveness of our components through additional experiments.",https://aclanthology.org/2024.naacl-long.5,emotion,Yes,Yes,No
The Colorful Future of {LLM}s: Evaluating and Improving {LLM}s as Emotional Supporters for Queer Youth,"Lissak, Shir  and
Calderon, Nitay  and
Shenkman, Geva  and
Ophir, Yaakov  and
Fruchter, Eyal  and
Brunstein Klomek, Anat  and
Reichart, Roi",2024,Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),10.18653/v1/2024.naacl-long.113,"Queer youth face increased mental health risks, such as depression, anxiety, and suicidal ideation. Hindered by negative stigma, they often avoid seeking help and rely on online resources, which may provide incompatible information. Although access to a supportive environment and reliable information is invaluable, many queer youth worldwide have no access to such support. However, this could soon change due to the rapid adoption of Large Language Models (LLMs) such as ChatGPT. This paper aims to comprehensively explore the potential of LLMs to revolutionize emotional support for queers. To this end, we conduct a qualitative and quantitative analysis of LLM{'}s interactions with queer-related content. To evaluate response quality, we develop a novel ten-question scale that is inspired by psychological standards and expert input. We apply this scale to score several LLMs and human comments to posts where queer youth seek advice and share experiences. We find that LLM responses are supportive and inclusive, outscoring humans. However, they tend to be generic, not empathetic enough, and lack personalization, resulting in nonreliable and potentially harmful advice. We discuss these challenges, demonstrate that a dedicated prompt can improve the performance, and propose a blueprint of an LLM-supporter that actively (but sensitively) seeks user context to provide personalized, empathetic, and reliable responses. Our annotated dataset is available for further research.*https://github.com/nitaytech/LGBTeenDataset",https://aclanthology.org/2024.naacl-long.113,emotion,Yes,Yes,Yes
My Heart Skipped a Beat! Recognizing Expressions of Embodied Emotion in Natural Language,"Zhuang, Yuan  and
Jiang, Tianyu  and
Riloff, Ellen",2024,Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),10.18653/v1/2024.naacl-long.193,"Humans frequently experience emotions. When emotions arise, they affect not only our mental state but can also change our physical state. For example, we often open our eyes wide when we are surprised, or clap our hands when we feel excited. Physical manifestations of emotions are referred to as embodied emotion in the psychology literature. From an NLP perspective, recognizing descriptions of physical movements or physiological responses associated with emotions is a type of implicit emotion recognition. Our work introduces a new task of recognizing expressions of embodied emotion in natural language. We create a dataset of sentences that contains 7,300 body part mentions with human annotations for embodied emotion. We develop a classification model for this task and present two methods to acquire weakly labeled instances of embodied emotion by extracting emotional manner expressions and by prompting a language model. Our experiments show that the weakly labeled data can train an effective classification model without gold data, and can also improve performance when combined with gold data. Our dataset is publicly available at https://github.com/yyzhuang1991/Embodied-Emotions.",https://aclanthology.org/2024.naacl-long.193,emotion,Yes,Yes,Yes
{``}You are an expert annotator{''}: Automatic Best{--}Worst-Scaling Annotations for Emotion Intensity Modeling,"Bagdon, Christopher  and
Karmalkar, Prathamesh  and
Gurulingappa, Harsha  and
Klinger, Roman",2024,Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers),10.18653/v1/2024.naacl-long.439,"Labeling corpora constitutes a bottleneck to create models for new tasks or domains. Large language models mitigate the issue with automatic corpus labeling methods, particularly for categorical annotations. Some NLP tasks such as emotion intensity prediction, however, require text regression, but there is no work on automating annotations for continuous label assignments. Regression is considered more challenging than classification: The fact that humans perform worse when tasked to choose values from a rating scale lead to comparative annotation methods, including best{--}worst scaling. This raises the question if large language model-based annotation methods show similar patterns, namely that they perform worse on rating scale annotation tasks than on comparative annotation tasks. To study this, we automate emotion intensity predictions and compare direct rating scale predictions, pairwise comparisons and best{--}worst scaling. We find that the latter shows the highest reliability. A transformer regressor fine-tuned on these data performs nearly on par with a model trained on the original manual annotations.",https://aclanthology.org/2024.naacl-long.439,emotion,Yes,Yes,Yes
Fluid Dynamics-Inspired Emotional Analysis in {S}hakespearean Tragedies: A Novel Computational Linguistics Methodology,"Picca, Davide",2024,Proceedings of the 2nd Workshop on Mathematical Natural Language Processing @ LREC-COLING 2024,,"This study introduces an innovative method for analyzing emotions in texts, drawing inspiration from the principles of fluid dynamics, particularly the Navier-Stokes equations. It applies this framework to analyze Shakespeare{'}s tragedies {``}Hamlet{''} and {``}Romeo and Juliet{''}, treating emotional expressions as entities akin to fluids. By mapping linguistic characteristics onto fluid dynamics components, this approach provides a dynamic perspective on how emotions are expressed and evolve in narrative texts. The results, when compared with conventional sentiment analysis methods, reveal a more detailed and subtle grasp of the emotional arcs within these works. This interdisciplinary strategy not only enriches emotion analysis in computational linguistics but also paves the way for potential integrations with machine learning in NLP.",https://aclanthology.org/2024.mathnlp-1.2,emotion,No,Yes,Yes
How to Annotate Emotions in Historical {I}talian Novels: A Case Study on {I} Promessi Sposi,"Sprugnoli, Rachele  and
Redaelli, Arianna",2024,Proceedings of the Third Workshop on Language Technologies for Historical and Ancient Languages (LT4HALA) @ LREC-COLING-2024,,"This paper describes the annotation of a chapter taken from I Promessi Sposi, the most famous Italian novel of the 19th century written by Alessandro Manzoni, following 3 emotion classifications. The aim of this methodological paper is to understand: i) how the annotation procedure changes depending on the granularity of the classification, ii) how the different granularities impact the inter-annotator agreement, iii) which granularity allows good coverage of emotions, iv) if the chosen classifications are missing emotions that are important for historical literary texts. The opinion of non-experts is integrated in the present study through an online questionnaire. In addition, preliminary experiments are carried out using the new dataset as a test set to evaluate the performances of different approaches for emotion polarity detection and emotion classification respectively. Annotated data are released both as aggregated gold standard and with non-aggregated labels (that is labels before reconciliation between annotators) so to align with the perspectivist approach, that is an established practice in the Humanities and, more recently, also in NLP.",https://aclanthology.org/2024.lt4hala-1.13,emotion,Yes,Yes,Yes
Early {M}odern {D}utch Comedies and Farces in the Spotlight: Introducing {E}m{DC}om{F} and Its Emotion Framework,"Debaene, Florian  and
van der Haven, Kornee  and
Hoste, Veronique",2024,Proceedings of the Third Workshop on Language Technologies for Historical and Ancient Languages (LT4HALA) @ LREC-COLING-2024,,"As computational drama studies are developing rapidly, the Dutch dramatic tradition is in need of centralisation still before it can benefit from state-of-the-art methodologies. This paper presents and evaluates EmDComF, a historical corpus of both manually curated and automatically digitised early modern Dutch comedies and farces authored between 1650 and 1725, and describes the refinement of a historically motivated annotation framework exploring sentiment and emotions in these two dramatic subgenres. Originating from Lodewijk Meyer{'}s philosophical writings on passions in the dramatic genre ({\mbox{$\pm$}}1670), published in Naauwkeurig onderwys in de tooneel-po{\""e}zy (Thorough instruction in the Poetics of Drama) by the literary society Nil Volentibus Arduum in 1765, a historical and genre-specific emotion framework is tested and operationalised for annotating emotions in the domain of early modern Dutch comedies and farces. Based on a frequency and cluster analysis of 782 annotated sentences by 2 expert annotators, the initial 38 emotion labels were restructured to a hierarchical label set of the 5 emotions Hatred, Anxiety, Sadness, Joy and Desire.",https://aclanthology.org/2024.lt4hala-1.17,emotion,Yes,No,No
{T}artu{NLP} at {E}va{L}atin 2024: Emotion Polarity Detection,"Dorkin, Aleksei  and
Sirts, Kairit",2024,Proceedings of the Third Workshop on Language Technologies for Historical and Ancient Languages (LT4HALA) @ LREC-COLING-2024,,The technical report for our submission at EvaLatin 2024 shared task. We apply knowledge transfer techniques and two distinct approaches to data annotation: based on heuristics and based on LLMs.,https://aclanthology.org/2024.lt4hala-1.26,emotion,No,No,Yes
{A}cn{E}mpathize: A Dataset for Understanding Empathy in Dermatology Conversations,"Lee, Gyeongeun  and
Parde, Natalie",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Empathy is critical for effective communication and mental health support, and in many online health communities people anonymously engage in conversations to seek and provide empathetic support. The ability to automatically recognize and detect empathy contributes to the understanding of human emotions expressed in text, therefore advancing natural language understanding across various domains. Existing empathy and mental health-related corpora focus on broader contexts and lack domain specificity, but similarly to other tasks (e.g., learning distinct patterns associated with COVID-19 versus skin allergies in clinical notes), observing empathy within different domains is crucial to providing tailored support. To address this need, we introduce AcnEmpathize, a dataset that captures empathy expressed in acne-related discussions from forum posts focused on its emotional and psychological effects. We find that transformer-based models trained on our dataset demonstrate excellent performance at empathy classification. Our dataset is publicly released to facilitate analysis of domain-specific empathy in online conversations and advance research in this challenging and intriguing domain.",https://aclanthology.org/2024.lrec-main.13,empathy,Yes,Yes,No
Appraisal Framework for Clinical Empathy: A Novel Application to Breaking Bad News Conversations,"Lahnala, Allison Claire  and
Neuendorf, B{\'e}la  and
Thomin, Alexander  and
Welch, Charles  and
Stibane, Tina  and
Flek, Lucie",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Empathy is essential in healthcare communication. We introduce an annotation approach that draws on well-established frameworks for \textit{clinical empathy} and \textit{breaking bad news} (BBN) conversations for considering the interactive dynamics of discourse relations. We construct Empathy in BBNs, a span-relation task dataset of simulated BBN conversations in German, using our annotation scheme, in collaboration with a large medical school to support research on educational tools for medical didactics. The annotation is based on 1) Pounds (2011){'}s appraisal framework for clinical empathy, which is grounded in systemic functional linguistics, and 2) the SPIKES protocol for breaking bad news (Baile et al., 2000), commonly taught in medical didactics training. This approach presents novel opportunities to study clinical empathic behavior and enables the training of models to detect causal relations involving empathy, a highly desirable feature of systems that can provide feedback to medical professionals in training. We present illustrative examples, discuss applications of the annotation scheme, and insights we can draw from the framework.",https://aclanthology.org/2024.lrec-main.124,empathy,Yes,Yes,No
{ASEM}: Enhancing Empathy in Chatbot through Attention-based Sentiment and Emotion Modeling,"Hamad, Omama  and
Shaban, Khaled  and
Hamdi, Ali",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Effective feature representations play a critical role in enhancing the performance of text generation models that rely on deep neural networks. However, current approaches suffer from several drawbacks, such as the inability to capture the deep semantics of language and sensitivity to minor input variations, resulting in significant changes in the generated text. In this paper, we present a novel solution to these challenges by employing a mixture of experts, multiple encoders, to offer distinct perspectives on the emotional state of the user{'}s utterance while simultaneously enhancing performance. We propose an end-to-end model architecture called ASEM that performs emotion analysis on top of sentiment analysis for open-domain chatbots, enabling the generation of empathetic responses that are fluent and relevant. In contrast to traditional attention mechanisms, the proposed model employs a specialized attention strategy that uniquely zeroes in on sentiment and emotion nuances within the user{'}s utterance. This ensures the generation of context-rich representations tailored to the underlying emotional tone and sentiment intricacies of the text. Our approach outperforms existing methods for generating empathetic embeddings, providing empathetic and diverse responses. The performance of our proposed model significantly exceeds that of existing models, enhancing emotion detection accuracy by 6.2{\%} and lexical diversity by 1.4{\%}. ASEM code is released at https://github.com/MIRAH-Official/Empathetic-Chatbot-ASEM.git",https://aclanthology.org/2024.lrec-main.140,emotion_and_empathy,No,Yes,No
Beyond Linguistic Cues: Fine-grained Conversational Emotion Recognition via Belief-Desire Modelling,"Xu, Bo  and
Li, Longjiao  and
Luo, Wei  and
Naseriparsa, Mehdi  and
Zhao, Zhehuan  and
Lin, Hongfei  and
Xia, Feng",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion recognition in conversation (ERC) is essential for dialogue systems to identify the emotions expressed by speakers. Although previous studies have made significant progress, accurate recognition and interpretation of similar fine-grained emotion properly accounting for individual variability remains a challenge. One particular under-explored area is the role of individual beliefs and desires in modelling emotion. Inspired by the Belief-Desire Theory of Emotion, we propose a novel method for conversational emotion recognition that incorporates both belief and desire to accurately identify emotions. We extract emotion-eliciting events from utterances and construct graphs that represent beliefs and desires in conversations. By applying message passing between nodes, our graph effectively models the utterance context, speaker{'}s global state, and the interaction between emotional beliefs, desires, and utterances. We evaluate our model{'}s performance by conducting extensive experiments on four popular ERC datasets and comparing it with multiple state-of-the-art models. The experimental results demonstrate the superiority of our proposed model and validate the effectiveness of each module in the model.",https://aclanthology.org/2024.lrec-main.207,emotion,No,Yes,No
{CEPT}: A Contrast-Enhanced Prompt-Tuning Framework for Emotion Recognition in Conversation,"Gao, Qingqing  and
Cao, Jiuxin  and
Cao, Biwei  and
Guan, Xin  and
Liu, Bo",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion Recognition in Conversation (ERC) has attracted increasing attention due to its wide applications in public opinion analysis, empathetic conversation generation, and so on. However, ERC research suffers from the problems of data imbalance and the presence of similar linguistic expressions for different emotions. These issues can result in limited learning for minority emotions, biased predictions for common emotions, and the misclassification of different emotions with similar linguistic expressions. To alleviate these problems, we propose a Contrast-Enhanced Prompt-Tuning (CEPT) framework for ERC. We transform the ERC task into a Masked Language Modeling (MLM) generation task and generate the emotion for each utterance in the conversation based on the prompt-tuning of the Pre-trained Language Model (PLM), where a novel mixed prompt template and a label mapping strategy are introduced for better context and emotion feature modeling. Moreover, Supervised Contrastive Learning (SCL) is employed to help the PLM mine more information from the labels and learn a more discriminative representation space for utterances with different emotions. We conduct extensive experiments and the results demonstrate that CEPT outperforms the state-of-the-art methods on all three benchmark datasets and excels in recognizing minority emotions.",https://aclanthology.org/2024.lrec-main.263,emotion,Yes,Yes,Yes
{CTSM}: Combining Trait and State Emotions for Empathetic Response Model,"Wang, Yufeng  and
Chen, Chao  and
Yang, Zhou  and
Wang, Shuhui  and
Liao, Xiangwen",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Empathetic response generation endeavors to empower dialogue systems to perceive speakers{'} emotions and generate empathetic responses accordingly. Psychological research demonstrates that emotion, as an essential factor in empathy, encompasses trait emotions, which are static and context-independent, and state emotions, which are dynamic and context-dependent. However, previous studies treat them in isolation, leading to insufficient emotional perception of the context, and subsequently, less effective empathetic expression. To address this problem, we propose Combining Trait and State emotions for Empathetic Response Model (CTSM). Specifically, to sufficiently perceive emotions in dialogue, we first construct and encode trait and state emotion embeddings, and then we further enhance emotional perception capability through an emotion guidance module that guides emotion representation. In addition, we propose a cross-contrastive learning decoder to enhance the model{'}s empathetic expression capability by aligning trait and state emotions between generated responses and contexts. Both automatic and manual evaluation results demonstrate that CTSM outperforms state-of-the-art baselines and can generate more empathetic responses. Our code is available at https://github.com/wangyufeng-empty/CTSM",https://aclanthology.org/2024.lrec-main.376,emotion,No,Yes,No
Curriculum Learning Meets Directed Acyclic Graph for Multimodal Emotion Recognition,"Nguyen, Cam-Van Thi  and
Nguyen, Cao-Bach  and
Le, Duc-Trong  and
Ha, Quang-Thuy",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion recognition in conversation (ERC) is a crucial task in natural language processing and affective computing. This paper proposes MultiDAG+CL, a novel approach for Multimodal Emotion Recognition in Conversation (ERC) that employs Directed Acyclic Graph (DAG) to integrate textual, acoustic, and visual features within a unified framework. The model is enhanced by Curriculum Learning (CL) to address challenges related to emotional shifts and data imbalance. Curriculum learning facilitates the learning process by gradually presenting training samples in a meaningful order, thereby improving the model{'}s performance in handling emotional variations and data imbalance. Experimental results on the IEMOCAP and MELD datasets demonstrate that the MultiDAG+CL models outperform baseline models. We release the code for and experiments: \url{https://github.com/vanntc711/MultiDAG-CL}.",https://aclanthology.org/2024.lrec-main.380,emotion,No,Yes,Yes
Deciphering Emotional Landscapes in the {I}liad: A Novel {F}rench-Annotated Dataset for Emotion Recognition,"Picca, Davide  and
Pavlopoulos, John",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"One of the most significant pieces of ancient Greek literature, the Iliad, is part of humanity{'}s collective cultural heritage. This work aims to provide the scientific community with an emotion-labeled dataset for classical literature and Western mythology in particular. To model the emotions of the poem, we use a multi-variate time series. We also evaluated the dataset by means of two methods. We compare the manual classification against a dictionary-based benchmark as well as employ a state-of-the-art deep learning masked language model that has been tuned using our data. Both evaluations return encouraging results (MSE and MAE Macro Avg 0.101 and 0.188 respectively) and highlight some interesting phenomena.",https://aclanthology.org/2024.lrec-main.399,emotion,Yes,Yes,Yes
{E}mo{P}rogress: Cumulated Emotion Progression Analysis in Dreams and Customer Service Dialogues,"Wemmer, Eileen  and
Labat, Sofie  and
Klinger, Roman",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion analysis often involves the categorization of isolated textual units, but these are parts of longer discourses, like dialogues or stories. This leads to two different established emotion classification setups: (1) Classification of a longer text into one or multiple emotion categories. (2) Classification of the parts of a longer text (sentences or utterances), either (2a) with or (2b) without consideration of the context. None of these settings, does, however, enable to answer the question which emotion is presumably experienced at a specific moment in time. For instance, a customer{'}s request of {``}My computer broke.{''} would be annotated with anger. This emotion persists in a potential follow-up reply {``}It is out of warranty.{''} which would also correspond to the global emotion label. An alternative reply {``}We will send you a new one.{''} might, in contrast, lead to relief. Modeling these label relations requires classification of textual parts under consideration of the past, but without access to the future. Consequently, we propose a novel annotation setup for emotion categorization corpora, in which the annotations reflect the emotion up to the annotated sentence. We ensure this by uncovering the textual parts step-by-step to the annotator, asking for a label in each step. This perspective is important to understand the final, global emotion, while having access to the individual sentence{'}s emotion contributions to this final emotion. In modeling experiments, we use these data to check if the context is indeed required to automatically predict such cumulative emotion progressions.",https://aclanthology.org/2024.lrec-main.503,emotion,Yes,Yes,No
{E}mo{P}rompt-{ECPE}: Emotion Knowledge-aware Prompt-tuning for Emotion-Cause Pair Extraction,"Gu, Xue  and
Zhou, Zhihan  and
Meng, Ziyao  and
Li, Jian  and
Gomes, Tiago  and
Tavares, Adriano  and
Xu, Hao",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion-cause pair extraction (ECPE) main focus is on extracting all potential emotion clauses and corresponding cause clauses from unannotated documents. Existing methods achieve promising results with the help of fine-tuning and prompt paradigms, but they present three downsides. First, most approaches cannot distinguish between the emotion-cause pairs that belong to different types of emotions, limiting the existing approaches{'} applicability. Second, existing prompt methods utilize a one-to-one mapping relation to achieve label words to category mapping, which brings considerable bias to the results. Third, existing methods achieve the cause extraction task supported by explicit semantic understanding or basic prompt templates, ignoring the implicit information contained in the cause clauses themselves. To solve these issues, we propose an Emotion knowledge-aware Prompt-tuning for Emotion-Cause Pair Extraction (EmoPrompt-ECPE) method, which integrate the knowledge of emotion categories in the ECPE task and mine the implicit knowledge of cause clauses. Specifically, we inject the latent knowledge of the cause clauses and the emotion types into the prompt template. Besides, we extend the emotion labels for many-to-one mapping of label words to categories with an external emotion word base. Furthermore, we utilize the cosine similarity filtering of the label word base to reduce the noise caused by knowledge introduction. Experiments on both Chinese and English benchmark datasets show that our approach can achieve state-of-the-art results. Our code and data can be found at: https://github.com/xy-xiaotudou/EmoPrompt-ECPE.",https://aclanthology.org/2024.lrec-main.504,emotion,Yes,No,No
"Emotion Analysis in {NLP}: Trends, Gaps and Roadmap for Future Directions","Plaza-del-Arco, Flor Miriam  and
Cercas Curry, Alba A.  and
Cercas Curry, Amanda  and
Hovy, Dirk",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotions are a central aspect of communication. Consequently, emotion analysis (EA) is a rapidly growing field in natural language processing (NLP). However, there is no consensus on scope, direction, or methods. In this paper, we conduct a thorough review of 154 relevant NLP publications from the last decade. Based on this review, we address four different questions: (1) How are EA tasks defined in NLP? (2) What are the most prominent emotion frameworks and which emotions are modeled? (3) Is the subjectivity of emotions considered in terms of demographics and cultural factors? and (4) What are the primary NLP applications for EA? We take stock of trends in EA and tasks, emotion frameworks used, existing datasets, methods, and applications. We then discuss four lacunae: (1) the absence of demographic and cultural aspects does not account for the variation in how emotions are perceived, but instead assumes they are universally experienced in the same manner; (2) the poor fit of emotion categories from the two main emotion theories to the task; (3) the lack of standardized EA terminology hinders gap identification, comparison, and future goals; and (4) the absence of interdisciplinary research isolates EA from insights in other fields. Our work will enable more focused research into EA and a more holistic approach to modeling emotions in NLP.",https://aclanthology.org/2024.lrec-main.506,emotion,No,Yes,Yes
Emotion Recognition in Conversation via Dynamic Personality,"Wang, Yan  and
Wang, Bo  and
Zhao, Yachao  and
Zhao, Dongming  and
Jin, Xiaojia  and
Zhang, Jijun  and
He, Ruifang  and
Hou, Yuexian",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion recognition in conversation (ERC) is a field that aims to classify the emotion of each utterance within conversational contexts. This presents significant challenges, particularly in handling emotional ambiguity across various speakers and contextual factors. Existing ERC approaches have primarily focused on modeling conversational contexts while incorporating only superficial speaker attributes such as names, memories, and interactions. Recent works introduce personality as an essential deep speaker factor for emotion recognition, but relies on static personality, overlooking dynamic variability during conversations. Advances in personality psychology conceptualize personality as dynamic, proposing that personality states can change across situations. In this paper, we introduce ERC-DP, a novel model considering the dynamic personality of speakers during conversations. ERC-DP accounts for past utterances from the same speaker as situation impacting dynamic personality. It combines personality modeling with prompt design and fine-grained classification modules. Through a series of comprehensive experiments, ERC-DP demonstrates superior performance on three benchmark conversational datasets.",https://aclanthology.org/2024.lrec-main.507,emotion,Yes,Yes,No
{E}mo{T}rans: Emotional Transition-based Model for Emotion Recognition in Conversation,"Jian, Zhongquan  and
Wang, Ante  and
Su, Jinsong  and
Yao, Junfeng  and
Wang, Meihong  and
Wu, Qingqiang",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"In an emotional conversation, emotions are causally transmitted among communication participants, constituting a fundamental conversational feature that can facilitate the comprehension of intricate changes in emotional states during the conversation and contribute to neutralizing emotional semantic bias in utterance caused by the absence of modality information. Therefore, emotional transition (ET) plays a crucial role in the task of Emotion Recognition in Conversation (ERC) that has not received sufficient attention in current research. In light of this, an Emotional Transition-based Emotion Recognizer (EmoTrans) is proposed in this paper. Specifically, we concatenate the most recent utterances with their corresponding speakers to construct the model input, known as samples, each with several placeholders to implicitly express the emotions of contextual utterances. Based on these placeholders, two components are developed to make the model sensitive to emotions and effectively capture the ET features in the sample. Furthermore, an ET-based Contrastive Learning (CL) is developed to compact the representation space, making the model achieve more robust sample representations. We conducted exhaustive experiments on four widely used datasets and obtained competitive experimental results, especially, new state-of-the-art results obtained on MELD and IEMOCAP, demonstrating the superiority of EmoTrans.",https://aclanthology.org/2024.lrec-main.508,emotion,No,Yes,No
Emstremo: Adapting Emotional Support Response with Enhanced Emotion-Strategy Integrated Selection,"Li, Junlin  and
Peng, Bo  and
Hsu, Yu-Yin",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"To provide effective support, it is essential for a skilled supporter to emotionally resonate with the help-seeker{'}s current emotional state. In conversational interactions, this emotional alignment is further influenced by the comforting strategies employed by the supporter. Different strategies guide the interlocutors to align their emotions in nuanced patterns. However, the incorporation of strategy into emotional alignment in the context of emotional support agents remains underexplored. To address this limitation, we propose an improved emotional support agent called Emstremo. Emstremo aims to achieve strategic control of emotional alignment by perceiving and responding to the user{'}s emotions. Our system{'}s state-of-the-art performance emphasizes the importance of integrating emotions and strategies in modeling conversations that provide emotional support.",https://aclanthology.org/2024.lrec-main.514,emotion,No,Yes,No
Enhancing Emotion Prediction in News Headlines: Insights from {C}hat{GPT} and {S}eq2{S}eq Models for Free-Text Generation,"Gao, Ge  and
Kim, Jongin  and
Paik, Sejin  and
Novozhilova, Ekaterina  and
Liu, Yi  and
Bonna, Sarah T.  and
Betke, Margrit  and
Wijaya, Derry Tanti",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Predicting emotions elicited by news headlines can be challenging as the task is largely influenced by the varying nature of people{'}s interpretations and backgrounds. Previous works have explored classifying discrete emotions directly from news headlines. We provide a different approach to tackling this problem by utilizing people{'}s explanations of their emotion, written in free-text, on how they feel after reading a news headline. Using the dataset BU-NEmo+ (Gao et al., 2022), we found that for emotion classification, the free-text explanations have a strong correlation with the dominant emotion elicited by the headlines. The free-text explanations also contain more sentimental context than the news headlines alone and can serve as a better input to emotion classification models. Therefore, in this work we explored generating emotion explanations from headlines by training a sequence-to-sequence transformer model and by using pretrained large language model, ChatGPT (GPT-4). We then used the generated emotion explanations for emotion classification. In addition, we also experimented with training the pretrained T5 model for the intermediate task of explanation generation before fine-tuning it for emotion classification. Using McNemar{'}s significance test, methods that incorporate GPT-generated free-text emotion explanations demonstrated significant improvement (P-value {\textless} 0.05) in emotion classification from headlines, compared to methods that only use headlines. This underscores the value of using intermediate free-text explanations for emotion prediction tasks with headlines.",https://aclanthology.org/2024.lrec-main.526,emotion,Yes,Yes,Yes
{ESCP}: Enhancing Emotion Recognition in Conversation with Speech and Contextual Prefixes,"Xu, Xiujuan  and
Shi, Xiaoxiao  and
Zhao, Zhehuan  and
Liu, Yu",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion Recognition in Conversation (ERC) aims to analyze the speaker{'}s emotional state in a conversation. Fully mining the information in multimodal and historical utterances plays a crucial role in the performance of the model. However, recent works in ERC focus on historical utterances modeling and generally concatenate the multimodal features directly, which neglects mining deep multimodal information and brings redundancy at the same time. To address the shortcomings of existing models, we propose a novel model, termed Enhancing Emotion Recognition in Conversation with Speech and Contextual Prefixes (ESCP). ESCP employs a directed acyclic graph (DAG) to model historical utterances in a conversation and incorporates a contextual prefix containing the sentiment and semantics of historical utterances. By adding speech and contextual prefixes, the inter- and intra-modal emotion information is efficiently modeled using the prior knowledge of the large-scale pre-trained model. Experiments conducted on several public benchmarks demonstrate that the proposed approach achieves state-of-the-art (SOTA) performances. These results affirm the effectiveness of the novel ESCP model and underscore the significance of incorporating speech and contextual prefixes to guide the pre-trained model.",https://aclanthology.org/2024.lrec-main.555,emotion,No,Yes,No
Exploring the Emotional Dimension of {F}rench Online Toxic Content,"Dragos, Valentina  and
Battistelli, Delphine  and
Sow, Fatou  and
Etienne, Aline",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"One of the biggest hurdles for the effective analysis of data collected on social platforms is the need for deeper insights on the content and meaning of this data. Emotion annotation can bring new perspectives on this issue and can enable the identification of content{--}specific features. This study aims at investigating the ways in which variation in online content can be explored through emotion annotation and corpus-based analysis. The paper describes the emotion annotation of three data sets in French composed of extremist, sexist and hateful messages respectively. To this end, first a fine-grained, corpus annotation scheme was used to annotate the data sets and then several empirical studies were carried out to characterize the content in the light of emotional categories. Results suggest that emotion annotations can provide new insights for online content analysis and stronger empirical background for automatic content detection.",https://aclanthology.org/2024.lrec-main.608,emotion,Yes,No,No
{FUSE} - {F}r{U}stration and Surprise Expressions: A Subtle Emotional Multimodal Language Corpus,"Titung, Rajesh  and
Alm, Cecilia Ovesdotter",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"This study introduces a novel multimodal corpus for expressive task-based spoken language and dialogue, focused on language use under frustration and surprise, elicited from three tasks motivated by prior research and collected in an IRB-approved experiment. The resource is unique both because these are understudied affect states for emotion modeling in language, and also because it provides both individual and dyadic multimodally grounded language. The study includes a detailed analysis of annotations and performance results for multimodal emotion inference in language use.",https://aclanthology.org/2024.lrec-main.666,emotion,Yes,Yes,No
{IDEM}: The {ID}ioms with {EM}otions Dataset for Emotion Recognition,"Prochnow, Alexander  and
Bendler, Johannes E.  and
Lange, Caroline  and
Tzavellos, Foivos Ioannis  and
G{\""o}ritzer, Bas Marco  and
ten Thij, Marijn  and
Batista-Navarro, Riza",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Idiomatic expressions are used in everyday language and typically convey affect, i.e., emotion. However, very little work investigating the extent to which automated methods can recognise emotions expressed in idiom-containing text has been undertaken. This can be attributed to the lack of emotion-labelled datasets that support the development and evaluation of such methods. In this paper, we present the IDioms with EMotions (IDEM) dataset consisting of a total of 9685 idiom-containing sentences that were generated and labelled with any one of 36 emotion types, with the help of the GPT-4 generative language model. Human validation by two independent annotators showed that more than 51{\%} of the generated sentences are ideal examples, with the annotators reaching an agreement rate of 62{\%} measured in terms of Cohen{'}s Kappa coefficient. To establish baseline performance on IDEM, various transformer-based emotion recognition approaches were implemented and evaluated. Results show that a RoBERTa model fine-tuned as a sequence classifier obtains a weighted F1-score of 58.73{\%}, when the sequence provided as input specifies the idiom contained in a given sentence, together with its definition. Since this input configuration is based on the assumption that the idiom contained in the given sentence is already known, we also sought to assess the feasibility of automatically identifying the idioms contained in IDEM sentences. To this end, a hybrid idiom identification approach combining a rule-based method and a deep learning-based model was developed, whose performance on IDEM was determined to be 84.99{\%} in terms of F1-score.",https://aclanthology.org/2024.lrec-main.752,emotion,Yes,Yes,Yes
Integrating Representation Subspace Mapping with Unimodal Auxiliary Loss for Attention-based Multimodal Emotion Recognition,"Du, Xulong  and
Zhang, Xingnan  and
Wang, Dandan  and
Xu, Yingying  and
Wu, Zhiyuan  and
Zhang, Shiqing  and
Zhao, Xiaoming  and
Yu, Jun  and
Lou, Liangliang",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Multimodal emotion recognition (MER) aims to identify emotions by utilizing affective information from multiple modalities. Due to the inherent disparities among these heterogeneous modalities, there is a large modality gap in their representations, leading to the challenge of fusing multiple modalities for MER. To address this issue, this work proposes a novel attention-based MER framework by integrating representation subspace mapping with unimodal auxiliary loss for enhancing multimodal fusion capabilities. Initially, a representation subspace mapping module is proposed to map each modality into two distinct subspaces. One is modality-public, enabling the acquisition of common representations and reducing the discrepancies across modalities. The other is modality-unique, retaining the unique characteristics of each modality while eliminating redundant inter-modal attributes. Then, a cross-modality attention is leveraged to bridge the modality gap in unique representations and facilitate modality adaptation. Additionally, our method designs an unimodal auxiliary loss to remove the noise unrelated to emotion classification, resulting in robust and meaningful representations for MER. Comprehensive experiments are conducted on the IEMOCAP and MSP-Improv datasets, and experiment results show that our method achieves superior performance to state-of-the-art MER methods. Keywords: Multimodal emotion recognition, representation subspace mapping, cross-modality attention, unimodal auxiliary loss, fusion",https://aclanthology.org/2024.lrec-main.799,emotion,No,Yes,No
{K}az{E}mo{TTS}: A Dataset for {K}azakh Emotional Text-to-Speech Synthesis,"Abilbekov, Adal  and
Mussakhojayeva, Saida  and
Yeshpanov, Rustem  and
Varol, Huseyin Atakan",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"This study focuses on the creation of the KazEmoTTS dataset, designed for emotional Kazakh text-to-speech (TTS) applications. KazEmoTTS is a collection of 54,760 audio-text pairs, with a total duration of 74.85 hours, featuring 34.23 hours delivered by a female narrator and 40.62 hours by two male narrators. The list of the emotions considered include {``}neutral{''}, {``}angry{''}, {``}happy{''}, {``}sad{''}, {``}scared{''}, and {``}surprised{''}. We also developed a TTS model trained on the KazEmoTTS dataset. Objective and subjective evaluations were employed to assess the quality of synthesized speech, yielding an MCD score within the range of 6.02 to 7.67, alongside a MOS that spanned from 3.51 to 3.57. To facilitate reproducibility and inspire further research, we have made our code, pre-trained model, and dataset accessible in our GitHub repository.",https://aclanthology.org/2024.lrec-main.841,emotion,Yes,Yes,No
{L}ead{E}mpathy: An Expert Annotated {G}erman Dataset of Empathy in Written Leadership Communication,"Sedefoglu, Didem  and
Lahnala, Allison Claire  and
Wagner, Jasmin  and
Flek, Lucie  and
Ohly, Sandra",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Empathetic leadership communication plays a pivotal role in modern workplaces as it is associated with a wide range of positive individual and organizational outcomes. This paper introduces LeadEmpathy, an innovative expert-annotated German dataset for modeling empathy in written leadership communication. It features a novel theory-based coding scheme to model cognitive and affective empathy in asynchronous communication. The final dataset comprises 770 annotated emails from 385 participants who were allowed to rewrite their emails after receiving recommendations for increasing empathy in an online experiment. Two independent annotators achieved substantial inter-annotator agreement of {\textgreater}= .79 for all categories, indicating that the annotation scheme can be applied to produce high-quality, multidimensional empathy ratings in current and future applications. Beyond outlining the dataset{'}s development procedures, we present a case study on automatic empathy detection, establishing baseline models for predicting empathy scores in a range of ten possible scores that achieve a Pearson correlation of 0.816 and a mean squared error of 0.883. Our dataset is available at https://github.com/caisa-lab/LEAD-empathy-dataset.",https://aclanthology.org/2024.lrec-main.894,empathy,Yes,Yes,No
Mitigating Linguistic Artifacts in Emotion Recognition for Conversations from {TV} Scripts to Daily Conversations,"Ong, Donovan  and
Sun, Shuo  and
Su, Jian  and
Chen, Bin",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotion Recognition in Conversations (ERC) is a well-studied task with numerous potential real-world applications. However, existing ERC models trained on the MELD dataset derived from TV series, struggle when applied to daily conversation datasets. A closer examination of the datasets unveils the prevalence of linguistic artifacts such as repetitions and interjections in TV scripts, which ERC models may exploit when making predictions. To address this issue, we explore two techniques aimed at reducing the reliance of ERC models on these artifacts: 1) using contrastive learning to prioritize emotional features over dataset-specific linguistic style and 2) refining emotion predictions with pseudo-emotion intensity score. Our experiment results show that reducing reliance on the linguistic style found in TV transcripts could enhance model{'}s robustness and accuracy in diverse conversational contexts.",https://aclanthology.org/2024.lrec-main.989,emotion,Yes,Yes,No
Multi-stream Information Fusion Framework for Emotional Support Conversation,"Bao, Yinan  and
Hu, Dou  and
Wei, Lingwei  and
Wei, Shuchong  and
Zhou, Wei  and
Hu, Songlin",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Emotional support conversation (ESC) task aims to relieve the emotional distress of users who have high-intensity of negative emotions. However, due to the ignorance of emotion intensity modelling which is essential for ESC, previous methods fail to capture the transition of emotion intensity effectively. To this end, we propose a Multi-stream information Fusion Framework (MFF-ESC) to thoroughly fuse three streams (text semantics stream, emotion intensity stream, and feedback stream) for the modelling of emotion intensity, based on a designed multi-stream fusion unit. As the difficulty of modelling subtle transitions of emotion intensity and the strong emotion intensity-feedback correlations, we use the KL divergence between feedback distribution and emotion intensity distribution to further guide the learning of emotion intensities. Experimental results on automatic and human evaluations indicate the effectiveness of our method.",https://aclanthology.org/2024.lrec-main.1046,emotion,No,No,No
n{EMO}: Dataset of Emotional Speech in {P}olish,"Christop, Iwona",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Speech emotion recognition has become increasingly important in recent years due to its potential applications in healthcare, customer service, and personalization of dialogue systems. However, a major issue in this field is the lack of datasets that adequately represent basic emotional states across various language families. As datasets covering Slavic languages are rare, there is a need to address this research gap. This paper presents the development of nEMO, a novel corpus of emotional speech in Polish. The dataset comprises over 3 hours of samples recorded with the participation of nine actors portraying six emotional states: anger, fear, happiness, sadness, surprise, and a neutral state. The text material used was carefully selected to represent the phonetics of the Polish language adequately. The corpus is freely available under the terms of a Creative Commons license (CC BY-NC-SA 4.0).",https://aclanthology.org/2024.lrec-main.1059,emotion,Yes,No,No
Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives,"Cortal, Gustave",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"The study of dreams has been central to understanding human (un)consciousness, cognition, and culture for centuries. Analyzing dreams quantitatively depends on labor-intensive, manual annotation of dream narratives. We automate this process through a natural language sequence-to-sequence generation framework. This paper presents the first study on character and emotion detection in the English portion of the open DreamBank corpus of dream narratives. Our results show that language models can effectively address this complex task. To get insight into prediction performance, we evaluate the impact of model size, prediction order of characters, and the consideration of proper names and character traits. We compare our approach with a large language model using in-context learning. Our supervised models perform better while having 28 times fewer parameters. Our model and its generated annotations are made publicly available.",https://aclanthology.org/2024.lrec-main.1282,emotion,Yes,Yes,Yes
"{SM}-{FEEL}-{BG} - the First {B}ulgarian Datasets and Classifiers for Detecting Feelings, Emotions, and Sentiments of {B}ulgarian Social Media Text","Temnikova, Irina  and
Marinova, Iva  and
Gargova, Silvia  and
Margova, Ruslana  and
Komarov, Alexander  and
Stefanova, Tsvetelina  and
Kireva, Veneta  and
Vyatrova, Dimana  and
Grigorova, Nevena  and
Mandevski, Yordan  and
Minkov, Stefan",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"This article introduces SM-FEEL-BG {--} the first Bulgarian-language package, containing 6 datasets with Social Media (SM) texts with emotion, feeling, and sentiment labels and 4 classifiers trained on them. All but one dataset from these are freely accessible for research purposes. The largest dataset contains 6000 Twitter, Telegram, and Facebook texts, manually annotated with 21 fine-grained emotion/feeling categories. The fine-grained labels are automatically merged into three coarse-grained sentiment categories, producing a dataset with two parallel sets of labels. Several classification experiments are run on different subsets of the fine-grained categories and their respective sentiment labels with a Bulgarian fine-tuned BERT. The highest Acc. reached was 0.61 for 16 emotions and 0.70 for 11 emotions (incl. 310 ChatGPT 4-generated texts). The sentiments Acc. of the 11 emotions dataset was also the highest (0.79). As Facebook posts cannot be shared, we ran experiments on the Twitter and Telegram subset of the 11 emotions dataset, obtaining 0.73 Acc. for emotions and 0.80 for sentiments. The article describes the annotation procedures, guidelines, experiments, and results. We believe that this package will be of significant benefit to researchers working on emotion detection and sentiment analysis in Bulgarian.",https://aclanthology.org/2024.lrec-main.1301,emotion,Yes,Yes,No
Social Convos: Capturing Agendas and Emotions on Social Media,"Bhaumik, Ankita  and
Sa, Ning  and
Katsios, Gregorios  and
Strzalkowski, Tomek",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Social media platforms are popular tools for disseminating targeted information during major public events like elections or pandemics. Systematic analysis of the message traffic can provide valuable insights into prevailing opinions and social dynamics among different segments of the population. We are specifically interested in influence spread, and in particular whether more deliberate influence operations can be detected. However, filtering out the essential messages with telltale influence indicators from the extensive and often chaotic social media traffic is a major challenge.In this paper we present a novel approach to extract influence indicators from messages circulating among groups of users discussing particular topics. We build upon the the concept of a convo to identify influential authors who are actively promoting some particular agenda around that topic within the group. We focus on two influence indicators: the (control of) agenda and the use of emotional language.",https://aclanthology.org/2024.lrec-main.1303,emotion,No,No,No
{T}opic{D}iff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection,"Luo, Jiamin  and
Wang, Jingjing  and
Zhou, Guodong",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of TopicDiff in capturing such information. Furthermore, we observe an interesting finding that the topic information in acoustic and vision is more discriminative and robust compared to the language.",https://aclanthology.org/2024.lrec-main.1417,emotion,No,Yes,No
User Guide for {KOTE}: {K}orean Online That-gul Emotions Dataset,"Jeon, Duyoung  and
Lee, Junho  and
Kim, Cheongtag",2024,"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",,"Despite the lack of comprehensive exploration of emotional connotations, sentiment analysis, which categorizes data as positive or negative, has been widely employed to identify emotional aspects in texts. Recently, corpora labeled with more than just valence or polarity have been built to surpass this limitation. However, most Korean emotion corpora are limited by their small size and narrow range of emotions covered. In this paper, we introduce the KOTE dataset. The KOTE dataset comprises 50,000 Korean online comments, totaling 250,000 cases, each manually labeled for 43 emotions and NO EMOTION through crowdsourcing. The taxonomy for the 43 emotions was systematically derived through cluster analysis of Korean emotion concepts within the word embedding space. After detailing the development of KOTE, we further discuss the results of fine-tuning, as well as analysis for social discrimination within the corpus.",https://aclanthology.org/2024.lrec-main.1499,emotion,Yes,Yes,No
Emotional Toll and Coping Strategies: Navigating the Effects of Annotating Hate Speech Data,"AlEmadi, Maryam M.  and
Zaghouani, Wajdi",2024,Proceedings of the Workshop on Legal and Ethical Issues in Human Language Technologies @ LREC-COLING 2024,,"Freedom of speech on online social media platforms, often comes with the cost of hate speech production. Hate speech can be very harmful to the peace and development of societies as they bring about conflict and encourage crime. To regulate the hate speech content, moderators and annotators are employed. In our research, we look at the effects of prolonged exposure to hate speech on the mental and physical health of these annotators, as well as researchers with work revolving around the topic of hate speech. Through the methodology of analyzing literature, we found that prolonged exposure to hate speech does mentally and physically impact annotators and researchers in this field. We also propose solutions to reduce these negative impacts such as providing mental health services, fair labor practices, psychological assessments and interventions, as well as developing AI to assist in the process of hate speech detection.",https://aclanthology.org/2024.legal-1.10,emotion,No,No,No
A Mapping on Current Classifying Categories of Emotions Used in Multimodal Models for Emotion Recognition,"Gong, Ziwei  and
Yao, Muyin  and
Hu, Xinyi  and
Zhu, Xiaoning  and
Hirschberg, Julia",2024,Proceedings of The 18th Linguistic Annotation Workshop (LAW-XVIII),,"In Emotion Detection within Natural Language Processing and related multimodal research, the growth of datasets and models has led to a challenge: disparities in emotion classification methods. The lack of commonly agreed upon conventions on the classification of emotions creates boundaries for model comparisons and dataset adaptation. In this paper, we compare the current classification methods in recent models and datasets and propose a valid method to combine different emotion categories. Our proposal arises from experiments across models, psychological theories, and human evaluations, and we examined the effect of proposed mapping on models.",https://aclanthology.org/2024.law-1.3,emotion,Yes,Yes,Yes
"{E}motion{A}rcs: Emotion Arcs for 9,000 Literary Texts","Ohman, Emily  and
Bizzoni, Yuri  and
Feldkamp Moreira, Pascale  and
Nielbo, Kristoffer",2024,"Proceedings of the 8th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature (LaTeCH-CLfL 2024)",,"We introduce EmotionArcs, a dataset comprising emotional arcs from over 9,000 English novels, assembled to understand the dynamics of emotions represented in text and how these emotions may influence a novel s reception and perceived quality. We evaluate emotion arcs manually, by comparing them to human annotation and against other similar emotion modeling systems to show that our system produces coherent emotion arcs that correspond to human interpretation. We present and make this resource available for further studies of a large collection of emotion arcs and present one application, exploring these arcs for modeling reader appreciation. Using information-theoretic measures to analyze the impact of emotions on literary quality, we find that emotional entropy, as well as the skewness and steepness of emotion arcs correlate with two proxies of literary reception. Our findings may offer insights into how quality assessments relate to emotional complexity and could help with the study of affect in literary novels.",https://aclanthology.org/2024.latechclfl-1.7,emotion,Yes,Yes,No
Emotion-Anchored Contrastive Learning Framework for Emotion Recognition in Conversation,"Yu, Fangxu  and
Guo, Junjie  and
Wu, Zhen  and
Dai, Xinyu",2024,Findings of the Association for Computational Linguistics: NAACL 2024,10.18653/v1/2024.findings-naacl.282,"Emotion Recognition in Conversation (ERC) involves detecting the underlying emotion behind each utterance within a conversation. Effectively generating representations for utterances remains a significant challenge in this task. Recent works propose various models to address this issue, but they still struggle with differentiating similar emotions such as excitement and happiness. To alleviate this problem, We propose an Emotion-Anchored Contrastive Learning (EACL) framework that can generate more distinguishable utterance representations for similar emotions. To achieve this, we utilize label encodings as anchors to guide the learning of utterance representations and design an auxiliary loss to ensure the effective separation of anchors for similar emotions. Moreover, an additional adaptation process is proposed to adapt anchors to serve as effective classifiers to improve classification performance. Across extensive experiments, our proposed EACL achieves state-of-the-art emotion recognition performance and exhibits superior performance on similar emotions. Our code is available at https://github.com/Yu-Fangxu/EACL.",https://aclanthology.org/2024.findings-naacl.282,emotion,No,Yes,No
{LLM}-{GE}m: Large Language Model-Guided Prediction of People{'}s Empathy Levels towards Newspaper Article,"Hasan, Md Rakibul  and
Hossain, Md Zakir  and
Gedeon, Tom  and
Rahman, Shafin",2024,Findings of the Association for Computational Linguistics: EACL 2024,,"Empathy {--} encompassing the understanding and supporting others{'} emotions and perspectives {--} strengthens various social interactions, including written communication in healthcare, education and journalism. Detecting empathy using AI models by relying on self-assessed ground truth through crowdsourcing is challenging due to the inherent noise in such annotations. To this end, we propose a novel system, named Large Language Model-Guided Empathy {\_}(LLM-GEm){\_} prediction system. It rectifies annotation errors based on our defined annotation selection threshold and makes the annotations reliable for conventional empathy prediction models, e.g., BERT-based pre-trained language models (PLMs). Previously, demographic information was often integrated numerically into empathy detection models. In contrast, our {\_}LLM-GEm{\_} leverages GPT-3.5 LLM to convert numerical data into semantically meaningful textual sequences, enabling seamless integration into PLMs. We experiment with three {\_}NewsEmpathy{\_} datasets involving people{'}s empathy levels towards newspaper articles and achieve state-of-the-art test performance using a RoBERTa-based PLM. Code and evaluations are publicly available at [https://github.com/hasan-rakibul/LLM-GEm](https://github.com/hasan-rakibul/LLM-GEm).",https://aclanthology.org/2024.findings-eacl.147,empathy,No,Yes,Yes
Thesis Proposal: Detecting Empathy Using Multimodal Language Model,"Hasan, Md Rakibul  and
Hossain, Md Zakir  and
Krishna, Aneesh  and
Rahman, Shafin  and
Gedeon, Tom",2024,Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop,,"Empathy is crucial in numerous social interactions, including human-robot, patient-doctor, teacher-student, and customer-call centre conversations. Despite its importance, empathy detection in videos continues to be a challenging task because of the subjective nature of empathy and often remains under-explored. Existing studies have relied on scripted or semi-scripted interactions in text-, audio-, or video-only settings that fail to capture the complexities and nuances of real-life interactions. This PhD research aims to fill these gaps by developing a multimodal language model (MMLM) that detects empathy in audiovisual data. In addition to leveraging existing datasets, the proposed study involves collecting real-life interaction video and audio. This study will leverage optimisation techniques like neural architecture search to deliver an optimised small-scale MMLM. Successful implementation of this project has significant implications in enhancing the quality of social interactions as it enables real-time measurement of empathy and thus provides potential avenues for training for better empathy in interactions.",https://aclanthology.org/2024.eacl-srw.27,empathy,No,Yes,Yes
Predicting Client Emotions and Therapist Interventions in Psychotherapy Dialogues,"Mayer, Tobias  and
Warikoo, Neha  and
Eliassaf, Amir  and
Atzil-Slonim, Dana  and
Gurevych, Iryna",2024,Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers),,"Natural Language Processing (NLP) can advance psychotherapy research by scaling up therapy dialogue analysis as well as by allowing researchers to examine client-therapist interactions in detail. Previous studies have mainly either explored the clients{'} behavior or the therapists{'} intervention in dialogues. Yet, modelling conversations from both dialogue participants is crucial to understanding the therapeutic interaction. This study explores speaker contribution-based dialogue acts at the utterance-level; i.e, the therapist - Intervention Prediction (IP) and the client - Emotion Recognition (ER) in psychotherapy using a pan-theoretical schema. We perform experiments with fine-tuned language models and light-weight adapter solutions on a Hebrew dataset. We deploy the results from our ER model predictions in investigating the coherence between client self-reports on emotion and the utterance-level emotions. Our best adapters achieved on-par performance with fully fine-tuned models, at 0.64 and 0.66 micro F1 for IP and ER, respectively. In addition, our analysis identifies ambiguities within categorical clinical coding, which can be used to fine-tune the coding schema. Finally, our results indicate a positive correlation between client self-reports and utterance-level emotions.",https://aclanthology.org/2024.eacl-long.88,emotion,Yes,Yes,Yes
Improving Contrastive Learning in Emotion Recognition in Conversation via Data Augmentation and Decoupled Neutral Emotion,"Kang, Yujin  and
Cho, Yoon-Sik",2024,Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers),,"Emotion recognition in conversation (ERC) has attracted much attention due to its wide applications. While consistent improvement is being made in this area, inevitable challenge comes from the dataset. The ERC dataset exhibits significantly imbalanced emotion distribution. While the utterances with neutral emotion predominate the data, this emotion label is always treated the same as other emotion labels in current approaches. To address the problem caused by the dataset, we propose a supervised contrastive learning specifically oriented for ERC task. We employ a novel data augmentation method emulating the emotion dynamics in a conversation and formulate supervised contrastive learning method tailored for ERC addressing the predominance and the ambiguity of neutral emotion. Experimental results on four benchmark datasets demonstrate the effectiveness of our approach.",https://aclanthology.org/2024.eacl-long.134,emotion,Yes,Yes,No
{S}ensory{T}5: Infusing Sensorimotor Norms into T5 for Enhanced Fine-grained Emotion Classification,"Xia, Yuhan  and
Zhao, Qingqing  and
Long, Yunfei  and
Xu, Ge  and
Wang, Jia",2024,Proceedings of the Workshop on Cognitive Aspects of the Lexicon @ LREC-COLING 2024,,"In traditional research approaches, sensory perception and emotion classification have traditionally been considered separate domains. Yet, the significant influence of sensory experiences on emotional responses is undeniable. The natural language processing (NLP) community has often missed the opportunity to merge sensory knowledge with emotion classification. To address this gap, we propose SensoryT5, a neurocognitive approach that integrates sensory information into the T5 (Text-to-Text Transfer Transformer) model, designed specifically for fine-grained emotion classification. This methodology incorporates sensory cues into the T5{'}s attention mechanism, enabling a harmonious balance between contextual understanding and sensory awareness. The resulting model amplifies the richness of emotional representations. In rigorous tests across various detailed emotion classification datasets, SensoryT5 showcases improved performance, surpassing both the foundational T5 model and current state-of-the-art works. Notably, SensoryT5{'}s success signifies a pivotal change in the NLP domain, highlighting the potential influence of neurocognitive data in refining machine learning models{'} emotional sensitivity.",https://aclanthology.org/2024.cogalex-1.19,emotion,No,Yes,Yes
Automatic Annotation of Dream Report{'}s Emotional Content with Large Language Models,"Bertolini, Lorenzo  and
Elce, Valentina  and
Michalak, Adriana  and
Widhoelzl, Hanna-Sophia  and
Bernardi, Giulio  and
Weeds, Julie",2024,Proceedings of the 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024),,"In the field of dream research, the study of dream content typically relies on the analysis of verbal reports provided by dreamers upon awakening from their sleep. This task is classically performed through manual scoring provided by trained annotators, at a great time expense. While a consistent body of work suggests that natural language processing (NLP) tools can support the automatic analysis of dream reports, proposed methods lacked the ability to reason over a report{'}s full context and required extensive data pre-processing. Furthermore, in most cases, these methods were not validated against standard manual scoring approaches. In this work, we address these limitations by adopting large language models (LLMs) to study and replicate the manual annotation of dream reports, using a mixture of off-the-shelf and bespoke approaches, with a focus on references to reports{'} emotions. Our results show that the off-the-shelf method achieves a low performance probably in light of inherent linguistic differences between reports collected in different (groups of) individuals. On the other hand, the proposed bespoke text classification method achieves a high performance, which is robust against potential biases. Overall, these observations indicate that our approach could find application in the analysis of large dream datasets and may favour reproducibility and comparability of results across studies.",https://aclanthology.org/2024.clpsych-1.7,emotion,No,Yes,Yes
Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study,"Rizwan, Muhammad  and
Dem{\v{s}}ar, Jure",2024,Proceedings of the 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024),,"Social anxiety represents a prevalent challenge in modern society, affecting individuals across personal and professional spheres. Left unaddressed, this condition can yield substantial negative consequences, impacting social interactions and performance. Further understanding its diverse physical and emotional symptoms becomes pivotal for comprehensive diagnosis and tailored therapeutic interventions. This study analyze prev lance and frequency of social anxiety symptoms taken from Mayo Clinic, exploring diverse human experiences from utilizing a large Reddit dataset dedicated to this issue. Leveraging these platforms, the research aims to extract insights and examine a spectrum of physical and emotional symptoms linked to social anxiety disorder. Upholding ethical considerations, the study maintains strict user anonymity within the dataset. By employing a novel approach, the research utilizes BART-based multi-label zero-shot classification to identify and measure symptom prevalence and significance in the form of probability score for each symptom under consideration. Results uncover distinctive patterns: {``}Trembling{''} emerges as a prevalent physical symptom, while emotional symptoms like {``}Fear of being judged negatively{''} exhibit high frequencies. These findings offer insights into the multifaceted nature of social anxiety, aiding clinical practices and interventions tailored to its diverse expressions.",https://aclanthology.org/2024.clpsych-1.11,emotion,Yes,Yes,No
Annotating Emotions in Acquired Brain Injury Patients{'} Narratives,"Klein, Salom{\'e}  and
Todirascu, Amalia  and
Vassiliadou, H{\'e}l{\`e}ne  and
Kuppelin, Marie  and
Becart, Joffrey  and
Briand, Thalassio  and
Coridon, Clara  and
Gerhard-Krait, Francine  and
Laroche, Jo{\'e}  and
Ulrich, Jean  and
Krasny-Pacini, Agata",2024,Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024,,"In this article, we aim to measure the patients{'} progress in recognizing and naming emotions by capturing a variety of phenomena that express emotion in discourse. To do so, we introduce an emotion annotation scheme adapted for Acquired Brain Injury (ABI) patients{'} narratives. We draw on recent research outcomes in line with linguistic and psychological theories of emotion in the development of French resources for Natural Language Processing (NLP). From this perspective and following Battistelli et al. (2022) guidelines, our protocol considers several means of expressing emotions, including prototypical expressions as well as implicit means. Its originality lies on the methodology adopted for its creation, as we combined, adapted, and tested several previous annotation schemes to create a tool tailored to our spoken clinical French corpus and its unique characteristics and challenges.",https://aclanthology.org/2024.cl4health-1.4,emotion,Yes,No,Yes
Analysing Emotions in Cancer Narratives: A Corpus-Driven Approach,"Lal, Daisy Monika  and
Rayson, Paul  and
Payne, Sheila A.  and
Liu, Yufeng",2024,Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024,,"Cancer not only affects a patient{'}s physical health, but it can also elicit a wide spectrum of intense emotions in patients, friends, and family members. People with cancer and their carers (family member, partner, or friend) are increasingly turning to the web for information and support. Despite the expansion of sentiment analysis in the context of social media and healthcare, there is relatively less research on patient narratives, which are longer, more complex texts, and difficult to assess. In this exploratory work, we examine how patients and carers express their feelings about various aspects of cancer (treatments and stages). The objective of this paper is to illustrate with examples the nature of language in the clinical domain, as well as the complexities of language when performing automatic sentiment and emotion analysis. We perform a linguistic analysis of a corpus of cancer narratives collected from Reddit. We examine the performance of five state-of-the-art models (T5, DistilBERT, Roberta, RobertaGo, and NRCLex) to see how well they match with human comparisons separated by linguistic and medical background. The corpus yielded several surprising results that could be useful to sentiment analysis NLP experts. The linguistic issues encountered were classified into four categories: statements expressing a variety of emotions, ambiguous or conflicting statements with contradictory emotions, statements requiring additional context, and statements in which sentiment and emotions can be inferred but are not explicitly mentioned.",https://aclanthology.org/2024.cl4health-1.9,emotion,Yes,Yes,Yes
Modelling Emotions in Task-Oriented Dialogue,"Feng, Shutong",2023,Proceedings of the 19th Annual Meeting of the Young Reseachers' Roundtable on Spoken Dialogue Systems,,"My research interests lie in the area of modelling natural and human-like conversations, with a special focus on emotions in task-oriented dialogue (ToD) systems. ToD systems need to produce semantically and grammatically correct responses to fulfil the user{'}s goal. Being able to perceive and express emotions pushes them one more step towards achieving human-likeness. To begin with, I constructed a dataset with meaningful emotion labels as well as a wide coverage of emotions and linguistic features in ToDs. Then, I improved emotion recognition in conversations (ERC) in the task-oriented domain by exploiting key characteristics of ToDs. Currently, I am working towards enhancing ToD systems with emotions.",https://aclanthology.org/2023.yrrsds-1.20,emotion,Yes,No,No
Causality Reasoning for Empathy-Enriched and Personality-Conditioned Spoken Dialogue System,"Fu, Yahui",2023,Proceedings of the 19th Annual Meeting of the Young Reseachers' Roundtable on Spoken Dialogue Systems,,"The author{'}s objective centers around developing a spoken dialogue system (SDS) that can emulate the cognitive and conversational qualities of a human friend. Key attributes such as empathy, knowledge/causality reasoning, and personality are integral components of human interaction. The proposed approach involves the creation of an \textbf{Empathy-enriched SDS}, capable of comprehending human emotions and circumstances, thus providing companionship and assistance akin to a trusted friend. Additionally, the \textbf{Causality-reasoning for SDS} aims to ground the system in commonsense knowledge and equip it with the ability to reason about causalities, such as predicting user desires/reactions and system intentions/reactions, thereby enhancing the system{'}s intelligence and human-like behavior. Finally, the concept of a \textbf{Personality-conditioned SDS} involves enabling systems to exhibit distinct personalities, further enhancing the naturalness of human-robot interaction.",https://aclanthology.org/2023.yrrsds-1.23,empathy,No,No,No
Emotion and Modifier in Henry Rider Haggard{'}s Novels,"Sazzed, Salim",2023,Proceedings of the 5th Workshop on Narrative Understanding,10.18653/v1/2023.wnu-1.2,"In recent years, there has been a growing scholarly interest in employing quantitative methods to analyze literary texts, as they offer unique insights, theories, and interpretations. In light of this, the current study employs quantitative analysis to examine the fiction written by the renowned British adventure novelist, Sir Henry Rider Haggard. Specifically, the study aims to investigate the affective content and prevalence of distinctive linguistic features in six of Haggard{'}s most distinguished works. We evaluate dominant emotional states at the sentence level as well as investigate the deployment of specific linguistic features such as modifiers and deontic modals, and collocated terms. Through sentence-level emotion analysis the findings reveal a notable prevalence of {``}joy{''}-related emotions across the novels. Furthermore, the study observes that intensifiers are employed more commonly than the mitigators as modifiers and the collocated terms of modifiers exhibit high similarity across the novels. By integrating quantitative analyses with qualitative assessments, this study presents a novel perspective on the patterns of emotion and specialized grammatical features in some of Haggard{'}s most celebrated literary works.",https://aclanthology.org/2023.wnu-1.2,emotion,No,No,No
Emotion and Sentiment Guided Paraphrasing,"Xie, Justin  and
Agrawal, Ameeta",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.7,"Paraphrase generation, a.k.a. paraphrasing, is a common and important task in natural language processing. Emotional paraphrasing, which changes the emotion embodied in a piece of text while preserving its meaning, has many potential applications, including moderating online dialogues and preventing cyberbullying. We introduce a new task of fine-grained emotional paraphrasing along emotion gradients, that is, altering the emotional intensities of the paraphrases in fine-grained settings following smooth variations in affective dimensions while preserving the meaning of the original text. We reconstruct several widely used paraphrasing datasets by augmenting the input and target texts with their fine-grained emotion labels. Then, we propose a framework for emotion and sentiment guided paraphrasing by leveraging pre-trained language models for conditioned text generation. Extensive evaluation of the fine-tuned models suggests that including fine-grained emotion labels in the paraphrase task significantly improves the likelihood of obtaining high-quality paraphrases that reflect the desired emotions while achieving consistently better scores in paraphrase metrics such as BLEU, ROUGE, and METEOR.",https://aclanthology.org/2023.wassa-1.7,emotion,No,Yes,Yes
Emotions in Spoken Language - Do we need acoustics?,"Probol, Nadine  and
Mieskes, Margot",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.8,"Work on emotion detection is often focused on textual data from i.e. Social Media. If multimodal data (i.e. speech) is analysed, the focus again is often placed on the transcription. This paper takes a closer look at how crucial acoustic information actually is for the recognition of emotions from multimodal data. To this end we use the IEMOCAP data, which is one of the larger data sets that provides transcriptions, audio recordings and manual emotion categorization. We build models for emotion classification using text-only, acoustics-only and combining both modalities in order to examine the influence of the various modalities on the final categorization. Our results indicate that using text-only models outperform acoustics-only models. But combining text-only and acoustic-only models improves the results. Additionally, we perform a qualitative analysis and find that a range of misclassifications are due to factors not related to the model, but to the data such as, recording quality, a challenging classification task and misclassifications that are unsurprising for humans.",https://aclanthology.org/2023.wassa-1.8,emotion,No,Yes,No
Understanding Emotion Valence is a Joint Deep Learning Task,"Roccabruna, Gabriel  and
Mousavi, Seyed Mahed  and
Riccardi, Giuseppe",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.9,"The valence analysis of speakers{'} utterances or written posts helps to understand the activation and variations of the emotional state throughout the conversation. More recently, the concept of Emotion Carriers (EC) has been introduced to explain the emotion felt by the speaker and its manifestations. In this work, we investigate the natural inter-dependency of valence and ECs via a multi-task learning approach. We experiment with Pre-trained Language Models (PLM) for single-task, two-step, and joint settings for the valence and EC prediction tasks. We compare and evaluate the performance of generative (GPT-2) and discriminative (BERT) architectures in each setting. We observed that providing the ground truth label of one task improves the prediction performance of the models in the other task. We further observed that the discriminative model achieves the best trade-off of valence and EC prediction tasks in the joint prediction setting. As a result, we attain a single model that performs both tasks, thus, saving computation resources at training and inference times.",https://aclanthology.org/2023.wassa-1.9,emotion,No,Yes,Yes
Multilingual Language Models are not Multicultural: A Case Study in Emotion,"Havaldar, Shreya  and
Singhal, Bhumika  and
Rai, Sunny  and
Liu, Langchen  and
Guntuku, Sharath Chandra  and
Ungar, Lyle",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.19,"Emotions are experienced and expressed differently across the world. In order to use Large Language Models (LMs) for multilingual tasks that require emotional sensitivity, LMs must reflect this cultural variation in emotion. In this study, we investigate whether the widely-used multilingual LMs in 2023 reflect differences in emotional expressions across cultures and languages. We find that embeddings obtained from LMs (e.g., XLM-RoBERTa) are Anglocentric, and generative LMs (e.g., ChatGPT) reflect Western norms, even when responding to prompts in other languages. Our results show that multilingual LMs do not successfully learn the culturally appropriate nuances of emotion and we highlight possible research directions towards correcting this.",https://aclanthology.org/2023.wassa-1.19,emotion,No,Yes,Yes
Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations,"Pereira, Patr{\'\i}cia  and
Moniz, Helena  and
Dias, Isabel  and
Carvalho, Joao Paulo",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.21,"Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the utterance to be classified as input to the RoBERTa encoder, to which we append a simple classification module, thus discarding the need to deal with context after obtaining the embeddings since these constitute already an efficient representation of such context. We also investigate how the number of introduced conversational turns influences our model performance. The effectiveness of our approach is validated on the open-domain DailyDialog dataset and on the task-oriented EmoWOZ dataset.",https://aclanthology.org/2023.wassa-1.21,emotion,Yes,Yes,Yes
Emotion Analysis of Tweets Banning Education in {A}fghanistan,"Hussiny, Mohammad Ali  and
{\O}vrelid, Lilja",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.24,"This paper introduces the first emotion-annotated dataset for the Dari variant of Persian spoken in Afghanistan. The LetHerLearn dataset contains 7,600 tweets posted in reaction to the Taliban{'}s ban of women{'}s rights to education in 2022 and has been manually annotated according to Ekman{'}s emotion categories. We here detail the data collection and annotation process, present relevant dataset statistics as well as initial experiments on the resulting dataset, benchmarking a number of different neural architectures for the task of Dari emotion classification.",https://aclanthology.org/2023.wassa-1.24,emotion,Yes,Yes,No
Sentiment and Emotion Classification in Low-resource Settings,"Barnes, Jeremy",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.26,"The popularity of sentiment and emotion analysis has lead to an explosion of datasets, approaches, and papers. However, these are often tested in optimal settings, where plentiful training and development data are available, and compared mainly with recent state-of-the-art models that have been similarly evaluated. In this paper, we instead present a systematic comparison of sentiment and emotion classification methods, ranging from rule- and dictionary-based methods to recently proposed few-shot and prompting methods with large language models. We test these methods in-domain, out-of-domain, and in cross-lingual settings and find that in low-resource settings, rule- and dictionary-based methods perform as well or better than few-shot and prompting methods, especially for emotion classification. Zero-shot cross-lingual approaches, however, still outperform in-language dictionary induction.",https://aclanthology.org/2023.wassa-1.26,emotion,No,Yes,Yes
Transformer-based Prediction of Emotional Reactions to Online Social Network Posts,"Benedetto, Irene  and
La Quatra, Moreno  and
Cagliero, Luca  and
Vassio, Luca  and
Trevisan, Martino",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.31,"Emotional reactions to Online Social Network posts have recently gained importance in the study of the online ecosystem. Prior to post publication, the number of received reactions can be predicted based on either the textual content of the post or the related metadata. However, existing approaches suffer from both the lack of semantic-aware language understanding models and the limited explainability of the prediction models. To overcome these issues, we present a new transformer-based method to predict the number of emotional reactions of different types to social posts. It leverages the attention mechanism to capture arbitrary semantic textual relations neglected by prior works. Furthermore, it also provides end-users with textual explanations of the predictions. The results achieved on a large collection of Facebook posts confirm the applicability of the presented methodology.",https://aclanthology.org/2023.wassa-1.31,emotion,Yes,Yes,No
Utterance Emotion Dynamics in Children{'}s Poems: Emotional Changes Across Age,"Teodorescu, Daniela  and
Fyshe, Alona  and
Mohammad, Saif",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.35,"Emerging psychopathology studies are showing that patterns of changes in emotional state {---} emotion dynamics {---} are associated with overall well-being and mental health. More recently, there has been some work in tracking emotion dynamics through one{'}s utterances, allowing for data to be collected on a larger scale across time and people. However, several questions about how emotion dynamics change with age, especially in children, and when determined through children{'}s writing, remain unanswered. In this work, we use both a lexicon and a machine learning based approach to quantify characteristics of emotion dynamics determined from poems written by children of various ages. We show that both approaches point to similar trends: consistent increasing intensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and dominance) with age and a consistent decreasing valence with age. We also find increasing emotional variability, rise rates (i.e., emotional reactivity), and recovery rates (i.e., emotional regulation) with age. These results act as a useful baselines for further research in how patterns of emotions expressed by children change with age, and their association with mental health.",https://aclanthology.org/2023.wassa-1.35,emotion,No,Yes,No
Adapting Emotion Detection to Analyze Influence Campaigns on Social Media,"Bhaumik, Ankita  and
Bernhardt, Andy  and
Katsios, Gregorios  and
Sa, Ning  and
Strzalkowski, Tomek",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.38,"Social media is an extremely potent tool for influencing public opinion, particularly during important events such as elections, pandemics, and national conflicts. Emotions are a crucial aspect of this influence, but detecting them accurately in the political domain is a significant challenge due to the lack of suitable emotion labels and training datasets. In this paper, we present a generalized approach to emotion detection that can be adapted to the political domain with minimal performance sacrifice. Our approach is designed to be easily integrated into existing models without the need for additional training or fine-tuning. We demonstrate the zero-shot and few-shot performance of our model on the 2017 French presidential elections and propose efficient emotion groupings that would aid in effectively analyzing influence campaigns and agendas on social media.",https://aclanthology.org/2023.wassa-1.38,emotion,No,Yes,No
The Paradox of Multilingual Emotion Detection,"De Bruyne, Luna",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.40,"The dominance of English is a well-known issue in NLP research. In this position paper, I turn to state-of-the-art psychological insights to explain why this problem is especially persistent in research on automatic emotion detection, and why the seemingly promising approach of using multilingual models to include lower-resourced languages might not be the desired solution. Instead, I campaign for the use of models that acknowledge linguistic and cultural differences in emotion conceptualization and verbalization. Moreover, I see much potential in NLP to better understand emotions and emotional language use across different languages.",https://aclanthology.org/2023.wassa-1.40,emotion,No,Yes,Yes
"Findings of {WASSA} 2023 Shared Task on Empathy, Emotion and Personality Detection in Conversation and Reactions to News Articles","Barriere, Valentin  and
Sedoc, Jo{\~a}o  and
Tafreshi, Shabnam  and
Giorgi, Salvatore",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.44,"This paper presents the results of the WASSA 2023 shared task on predicting empathy, emotion, and personality in conversations and reactions to news articles. Participating teams were given access to a new dataset from Omitaomu et al. (2022) comprising empathic and emotional reactions to news articles. The dataset included formal and informal text, self-report data, and third-party annotations. Specifically, the dataset contained news articles (where harm is done to a person, group, or other) and crowd-sourced essays written in reaction to the article. After reacting via essays, crowd workers engaged in conversations about the news articles. Finally, the crowd workers self-reported their empathic concern and distress, personality (using the Big Five), and multi-dimensional empathy (via the Interpersonal Reactivity Index). A third-party annotated both the conversational turns (for empathy, emotion polarity, and emotion intensity) and essays (for multi-label emotions). Thus, the dataset contained outcomes (self-reported or third-party annotated) at the turn level (within conversations) and the essay level. Participation was encouraged in five tracks: (i) predicting turn-level empathy, emotion polarity, and emotion intensity in conversations, (ii) predicting state empathy and distress scores, (iii) predicting emotion categories, (iv) predicting personality, and (v) predicting multi-dimensional trait empathy. In total, 21 teams participated in the shared task. We summarize the methods and resources used by the participating teams.",https://aclanthology.org/2023.wassa-1.44,emotion_and_empathy,Yes,No,No
{YNU}-{HPCC} at {WASSA}-2023 Shared Task 1: Large-scale Language Model with {L}o{RA} Fine-Tuning for Empathy Detection and Emotion Classification,"Wang, Yukun  and
Wang, Jin  and
Zhang, Xuejie",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.45,"This paper describes the system for the YNU-HPCC team in WASSA-2023 Shared Task 1: Empathy Detection and Emotion Classification. This task needs to predict the empathy, emotion, and personality of the empathic reactions. This system is mainly based on the Decoding-enhanced BERT with disentangled attention (DeBERTa) model with parameter-efficient fine-tuning (PEFT) and the Robustly Optimized BERT Pretraining Approach (RoBERTa). Low-Rank Adaptation (LoRA) fine-tuning in PEFT is used to reduce the training parameters of large language models. Moreover, back translation is introduced to augment the training dataset. This system achieved relatively good results on the competition{'}s official leaderboard. The code of this system is available here.",https://aclanthology.org/2023.wassa-1.45,emotion_and_empathy,Yes,Yes,Yes
"{A}ditya{P}atkar at {WASSA} 2023 Empathy, Emotion, and Personality Shared Task: {R}o{BERT}a-Based Emotion Classification of Essays, Improving Performance on Imbalanced Data","Patkar, Aditya  and
Chandrashekhar, Suraj  and
Kadiyala, Ram Mohan Rao",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.46,"This paper presents a study on using the RoBERTa language model for emotion classification of essays as part of the {`}Shared Task on Empathy Detection, Emotion Classification and Personality Detection in Interactions{'} organized as part of {`}WASSA 2023{'} at {`}ACL 2023{'}. Emotion classification is a challenging task in natural language processing, and imbalanced datasets further exacerbate this challenge. In this study, we explore the use of various data balancing techniques in combination with RoBERTa to improve the classification performance. We evaluate the performance of our approach (denoted by adityapatkar on Codalab) on a benchmark multi-label dataset of essays annotated with eight emotion categories, provided by the Shared Task organizers. Our results show that the proposed approach achieves the best macro F1 score in the competition{'}s training and evaluation phase. Our study provides insights into the potential of RoBERTa for handling imbalanced data in emotion classification. The results can have implications for the natural language processing tasks related to emotion classification.",https://aclanthology.org/2023.wassa-1.46,emotion_and_empathy,Yes,Yes,Yes
"Curtin {OCAI} at {WASSA} 2023 Empathy, Emotion and Personality Shared Task: Demographic-Aware Prediction Using Multiple Transformers","Hasan, Md Rakibul  and
Hossain, Md Zakir  and
Gedeon, Tom  and
Soon, Susannah  and
Rahman, Shafin",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.47,"The WASSA 2023 shared task on predicting empathy, emotion and other personality traits consists of essays, conversations and articles in textual form and participants{'} demographic information in numerical form. To address the tasks, our contributions include (1) converting numerical information into meaningful text information using appropriate templates, (2) summarising lengthy articles, and (3) augmenting training data by paraphrasing. To achieve these contributions, we leveraged two separate T5-based pre-trained transformers. We then fine-tuned pre-trained BERT, DistilBERT and ALBERT for predicting empathy and personality traits. We used the Optuna hyperparameter optimisation framework to fine-tune learning rates, batch sizes and weight initialisation. Our proposed system achieved its highest performance {--} a Pearson correlation coefficient of 0.750 {--} on the onversation-level empathy prediction task1 . The system implementation is publicly available at https: //github.com/hasan-rakibul/WASSA23-empathy-emotion.",https://aclanthology.org/2023.wassa-1.47,emotion_and_empathy,No,Yes,No
"{T}eam{\_}{H}awk at {WASSA} 2023 Empathy, Emotion, and Personality Shared Task: Multi-tasking Multi-encoder based transformers for Empathy and Emotion Prediction in Conversations","Srinivas, Addepalli Sai  and
Barua, Nabarun  and
Pal, Santanu",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.48,"In this paper, we present Team Hawk{'}s participation in Track 1 of the WASSA 2023 shared task. The objective of the task is to understand the empathy that emerges between individuals during their conversations. In our study, we developed a multi-tasking framework that is capable of automatically assessing empathy, intensity of emotion, and polarity of emotion within participants{'} conversations. Our proposed core model extends the transformer architecture, utilizing two separate RoBERTa-based encoders to encode both the articles and conversations. Subsequently, a sequence of self-attention, position-wise feed-forward, and dense layers are employed to predict the regression scores for the three sub-tasks: empathy, intensity of emotion, and polarity of emotion. Our best model achieved average Pearson{'}s correlation of 0.7710 (Empathy: 0.7843, Emotion Polarity: 0.7917, Emotion Intensity: 0.7381) on the released development set and 0.7250 (Empathy: 0.8090, Emotion Polarity: 0.7010, Emotion Intensity: 0.6650) on the released test set. These results earned us the 3rd position in the test set evaluation phase of Track 1.",https://aclanthology.org/2023.wassa-1.48,emotion_and_empathy,No,Yes,No
{NCUEE}-{NLP} at {WASSA} 2023 Shared Task 1: Empathy and Emotion Prediction Using Sentiment-Enhanced {R}o{BERT}a Transformers,"Lin, Tzu-Mi  and
Chang, Jung-Ying  and
Lee, Lung-Hao",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.49,"This paper describes our proposed system design for the WASSA 2023 shared task 1. We propose a unified architecture of ensemble neural networks to integrate the original RoBERTa transformer with two sentiment-enhanced RoBERTa-Twitter and EmoBERTa models. For Track 1 at the speech-turn level, our best submission achieved an average Pearson correlation score of 0.7236, ranking fourth for empathy, emotion polarity and emotion intensity prediction. For Track 2 at the essay-level, our best submission obtained an average Pearson correlation score of 0.4178 for predicting empathy and distress scores, ranked first among all nine submissions.",https://aclanthology.org/2023.wassa-1.49,emotion_and_empathy,No,Yes,Yes
"Domain Transfer for Empathy, Distress, and Personality Prediction","Gruschka, Fabio  and
Lahnala, Allison  and
Welch, Charles  and
Flek, Lucie",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.50,"This research contributes to the task of predicting empathy and personality traits within dialogue, an important aspect of natural language processing, as part of our experimental work for the WASSA 2023 Empathy and Emotion Shared Task. For predicting empathy, emotion polarity, and emotion intensity on turns within a dialogue, we employ adapters trained on social media interactions labeled with empathy ratings in a stacked composition with the target task adapters. Furthermore, we embed demographic information to predict Interpersonal Reactivity Index (IRI) subscales and Big Five Personality Traits utilizing BERT-based models. The results from our study provide valuable insights, contributing to advancements in understanding human behavior and interaction through text. Our team ranked 2nd on the personality and empathy prediction tasks, 4th on the interpersonal reactivity index, and 6th on the conversational task.",https://aclanthology.org/2023.wassa-1.50,empathy,Yes,Yes,Yes
"Converge at {WASSA} 2023 Empathy, Emotion and Personality Shared Task: A Transformer-based Approach for Multi-Label Emotion Classification","Paranjape, Aditya  and
Kolhatkar, Gaurav  and
Patwardhan, Yash  and
Gokhale, Omkar  and
Dharmadhikari, Shweta",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.51,"In this paper, we highlight our approach for the {``}WASSA 2023 Shared-Task 1: Empathy Detection and Emotion Classification{''}. By accurately identifying emotions from textual sources of data, deep learning models can be trained to understand and interpret human emotions more effectively. The classification of emotions facilitates the creation of more emotionally intelligent systems that can better understand and respond to human emotions. We compared multiple transformer-based models for multi-label classification. Ensembling and oversampling were used to improve the performance of the system. A threshold-based voting mechanism performed on three models (Longformer, BERT, BigBird) yields the highest overall macro F1-score of 0.6605.",https://aclanthology.org/2023.wassa-1.51,emotion_and_empathy,No,Yes,No
"{PICT}-{CLRL} at {WASSA} 2023 Empathy, Emotion and Personality Shared Task: Empathy and Distress Detection using Ensembles of Transformer Models","Chavan, Tanmay  and
Deshpande, Kshitij  and
Sonawane, Sheetal",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.52,"This paper presents our approach for the WASSA 2023 Empathy, Emotion and Personality Shared Task. Empathy and distress are human feelings that are implicitly expressed in natural discourses. Empathy and distress detection are crucial challenges in Natural Language Processing that can aid our understanding of conversations. The provided dataset consists of several long-text examples in the English language, with each example associated with a numeric score for empathy and distress. We experiment with several BERT-based models as a part of our approach. We also try various ensemble methods. Our final submission has a Pearson{'}s r score of 0.346, placing us third in the empathy and distress detection subtask.",https://aclanthology.org/2023.wassa-1.52,emotion_and_empathy,Yes,Yes,Yes
"Team Bias Busters at {WASSA} 2023 Empathy, Emotion and Personality Shared Task: Emotion Detection with Generative Pretrained Transformers","Nedilko, Andrew  and
Chu, Yi",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.53,"This paper describes the approach that we used to take part in the multi-label multi-class emotion classification as Track 3 of the WASSA 2023 Empathy, Emotion and Personality Shared Task at ACL 2023. The overall goal of this track is to build models that can predict 8 classes (7 emotions + neutral) based on short English essays written in response to news article that talked about events perceived as harmful to people. We used OpenAI generative pretrained transformers with full-scale APIs for the emotion prediction task by fine-tuning a GPT-3 model and doing prompt engineering for zero-shot / few-shot learning with ChatGPT and GPT-4 models based on multiple experiments on the dev set. The most efficient method was fine-tuning a GPT-3 model which allowed us to beat our baseline character-based XGBoost Classifier and rank 2nd among all other participants by achieving a macro F1 score of 0.65 and a micro F1 score of 0.7 on the final blind test set.",https://aclanthology.org/2023.wassa-1.53,emotion_and_empathy,No,Yes,No
{HIT}-{SCIR} at {WASSA} 2023: Empathy and Emotion Analysis at the Utterance-Level and the Essay-Level,"Lu, Xin  and
Li, Zhuojun  and
Tong, Yanpeng  and
Zhao, Yanyan  and
Qin, Bing",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.54,"This paper introduces the participation of team HIT-SCIR to the WASSA 2023 Shared Task on Empathy Detection and Emotion Classification and Personality Detection in Interactions. We focus on three tracks: Track 1 (Empathy and Emotion Prediction in Conversations, CONV), Track 2 (Empathy Prediction, EMP) and Track 3 (Emotion Classification, EMO), and designed three different models to address them separately. For Track 1, we designed a direct fine-tuning DeBERTa model for three regression tasks at the utterance-level. For Track 2, we designed a multi-task learning RoBERTa model for two regression tasks at the essay-level. For Track 3, we designed a RoBERTa model with data augmentation for the classification task at the essay-level. Finally, our team ranked 1st in the Track 1 (CONV), 5th in the Track 2 (EMP) and 3rd in the Track 3 (EMO) in the evaluation phase.",https://aclanthology.org/2023.wassa-1.54,emotion_and_empathy,No,Yes,No
{VISU} at {WASSA} 2023 Shared Task: Detecting Emotions in Reaction to News Stories Using Transformers and Stacked Embeddings,"Kumar, Vivek  and
Tiwari, Prayag  and
Singh, Sushmita",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.55,"Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion Classification from essays written in reaction to news articles. Emotion detection from complex dialogues is challenging and often requires context/domain understanding. Therefore in this research, we have focused on developing deep learning (DL) models using the combination of word embedding representations with tailored prepossessing strategies to capture the nuances of emotions expressed. Our experiments used static and contextual embeddings (individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and Transformer based models. We occupied rank tenth in the emotion detection task by scoring a Macro F1-Score of 0.2717, validating the efficacy of our implemented approaches for small and imbalanced datasets with mixed categories of target emotions.",https://aclanthology.org/2023.wassa-1.55,emotion,No,Yes,No
[RETRACTED] Findings of {WASSA} 2023 Shared Task: Multi-Label and Multi-Class Emotion Classification on Code-Mixed Text Messages,"Ameer, Iqra  and
B{\""o}l{\""u}c{\""u}, Necva  and
Xu, Hua  and
Al Bataineh, Ali",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.56,"We present the results of the WASSA 2023 Shared-Task 2: Emotion Classification on code-mixed text messages (Roman Urdu + English), which included two tracks for emotion classification: multi-label and multi-class. The participants were provided with a dataset of code-mixed SMS messages in English and Roman Urdu labeled with 12 emotions for both tracks. A total of 5 teams (19 team members) participated in the shared task. We summarized the methods, resources, and tools used by the participating teams. We also made the data freely available for further improvements to the task.",https://aclanthology.org/2023.wassa-1.56,emotion,Yes,Yes,No
Emotion classification on code-mixed text messages via soft prompt tuning,"Zhang, Jinghui  and
Yang, Dongming  and
Bao, Siyu  and
Cao, Lina  and
Fan, Shunguo",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.57,"Emotion classification on code-mixed text messages is challenging due to the multilingual languages and non-literal cues (i.e., emoticons). To solve these problems, we propose an innovative soft prompt tuning method, which is lightweight and effective to release potential abilities of the pre-trained language models and improve the classification results. Firstly, we transform emoticons into textual information to utilize their rich emotional information. Then, variety of innovative templates and verbalizers are applied to promote emotion classification. Extensive experiments show that transforming emoticons and employing prompt tuning both benefit the performance. Finally, as a part of WASSA 2023, we obtain the accuracy of 0.972 in track MLEC and 0.892 in track MCEC, yielding the second place in both two tracks.",https://aclanthology.org/2023.wassa-1.57,emotion,No,Yes,Yes
{P}recog{IIITH}@{WASSA}2023: Emotion Detection for {U}rdu-{E}nglish Code-mixed Text,"Vedula, Bhaskara Hanuma  and
Kodali, Prashant  and
Shrivastava, Manish  and
Kumaraguru, Ponnurangam",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.58,"Code-mixing refers to the phenomenon of using two or more languages interchangeably within a speech or discourse context. This practice is particularly prevalent on social media platforms, and determining the embedded affects in a code-mixed sentence remains as a challenging problem. In this submission we describe our system for WASSA 2023 Shared Task on Emotion Detection in English-Urdu code-mixed text. In our system we implement a multiclass emotion detection model with label space of 11 emotions. Samples are code-mixed English-Urdu text, where Urdu is written in romanised form. Our submission is limited to one of the subtasks - Multi Class classification and we leverage transformer-based Multilingual Large Language Models (MLLMs), XLM-RoBERTa and Indic-BERT. We fine-tune MLLMs on the released data splits, with and without pre-processing steps (translation to english), for classifying texts into the appropriate emotion category. Our methods did not surpass the baseline, and our submission is ranked sixth overall.",https://aclanthology.org/2023.wassa-1.58,emotion,No,Yes,Yes
{B}p{H}igh at {WASSA} 2023: Using Contrastive Learning to build Sentence Transformer models for Multi-Class Emotion Classification in Code-mixed {U}rdu,"Pahwa, Bhavish",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.59,"In this era of digital communication and social media, texting and chatting among individuals occur mainly through code-mixed or Romanized versions of the native language prevalent in the region. The presence of Romanized and code-mixed language develops the need to build NLP systems in these domains to leverage the digital content for various use cases. This paper describes our contribution to the subtask MCEC of the shared task WASSA 2023:Shared Task on Multi-Label and Multi-Class Emotion Classification on Code-Mixed Text Messages. We explore how one can build sentence transformers models for low-resource languages using unsupervised data by leveraging contrastive learning techniques described in the SIMCSE paper and using the sentence transformer developed to build classification models using the SetFit approach. Additionally, we{'}ll publish our code and models on GitHub and HuggingFace, two open-source hosting services.",https://aclanthology.org/2023.wassa-1.59,emotion,No,Yes,Yes
{YNU}-{HPCC} at {WASSA} 2023: Using Text-Mixed Data Augmentation for Emotion Classification on Code-Mixed Text Message,"Ran, Xuqiao  and
Zhang, You  and
Wang, Jin  and
Xu, Dan  and
Zhang, Xuejie",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.60,"Emotion classification on code-mixed texts has been widely used in real-world applications. In this paper, we build a system that participates in the WASSA 2023 Shared Task 2 for emotion classification on code-mixed text messages from Roman Urdu and English. The main goal of the proposed method is to adopt a text-mixed data augmentation for robust code-mixed text representation. We mix texts with both multi-label (track 1) and multi-class (track 2) annotations in a unified multilingual pre-trained model, i.e., XLM-RoBERTa, for both subtasks. Our results show that the proposed text-mixed method performs competitively, ranking first in both tracks, achieving an average Macro F1 score of 0.9782 on the multi-label track and of 0.9329 on the multi-class track.",https://aclanthology.org/2023.wassa-1.60,emotion,No,Yes,No
Generative Pretrained Transformers for Emotion Detection in a Code-Switching Setting,"Nedilko, Andrew",2023,"Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",10.18653/v1/2023.wassa-1.61,"This paper describes the approach that we utilized to participate in the shared task for multi-label and multi-class emotion classification organized as part of WASSA 2023 at ACL 2023. The objective was to build mod- els that can predict 11 classes of emotions, or the lack thereof (neutral class) based on code- mixed Roman Urdu and English SMS text messages. We participated in Track 2 of this task - multi-class emotion classification (MCEC). We used generative pretrained transformers, namely ChatGPT because it has a commercially available full-scale API, for the emotion detec- tion task by leveraging the prompt engineer- ing and zero-shot / few-shot learning method- ologies based on multiple experiments on the dev set. Although this was the first time we used a GPT model for the purpose, this ap- proach allowed us to beat our own baseline character-based XGBClassifier, as well as the baseline model trained by the organizers (bert- base-multilingual-cased). We ranked 4th and achieved the macro F1 score of 0.7038 and the accuracy of 0.7313 on the blind test set.",https://aclanthology.org/2023.wassa-1.61,emotion,No,Yes,No
Emotion-Conditioned Text Generation through Automatic Prompt Optimization,"Resendiz, Yarik Menchaca  and
Klinger, Roman",2023,Proceedings of the 1st Workshop on Taming Large Language Models: Controllability in the era of Interactive Assistants!,,"Conditional natural language generation methods often require either expensive fine-tuning or training a large language model from scratch. Both are unlikely to lead to good results without a substantial amount of data and computational resources. Prompt learning without changing the parameters of a large language model presents a promising alternative. It is a cost-effective approach, while still achieving competitive results. While this procedure is now established for zero- and few-shot text classification and structured prediction, it has received limited attention in conditional text generation. We present the first automatic prompt optimization approach for emotion-conditioned text generation with instruction-fine-tuned models. Our method uses an iterative optimization procedure that changes the prompt by adding, removing, or replacing tokens. As objective function, we only require a text classifier that measures the realization of the conditional variable in the generated text. We evaluate the method on emotion-conditioned text generation with a focus on event reports and compare it to manually designed prompts that also act as the seed for the optimization procedure. The optimized prompts achieve 0.75 macro-average F1 to fulfill the emotion condition in contrast to manually designed seed prompts with only 0.22 macro-average F1.",https://aclanthology.org/2023.tllm-1.3,emotion,No,Yes,Yes
Modeling Emotion Dynamics in Song Lyrics with State Space Models,"Song, Yingjin  and
Beck, Daniel",2023,,10.1162/tacl_a_00541,"Most previous work in music emotion recognition assumes a single or a few song-level labels for the whole song. While it is known that different emotions can vary in intensity within a song, annotated data for this setup is scarce and difficult to obtain. In this work, we propose a method to predict emotion dynamics in song lyrics without song-level supervision. We frame each song as a time series and employ a State Space Model (SSM), combining a sentence-level emotion predictor with an Expectation-Maximization (EM) procedure to generate the full emotion dynamics. Our experiments show that applying our method consistently improves the performance of sentence-level baselines without requiring any annotated songs, making it ideal for limited training data scenarios. Further analysis through case studies shows the benefits of our method while also indicating the limitations and pointing to future directions.",https://aclanthology.org/2023.tacl-1.10,emotion,Yes,Yes,No
{F}eeling{B}lue: A Corpus for Understanding the Emotional Connotation of Color in Context,"Ananthram, Amith  and
Winn, Olivia  and
Muresan, Smaranda",2023,,10.1162/tacl_a_00540,"While the link between color and emotion has been widely studied, how context-based changes in color impact the intensity of perceived emotions is not well understood. In this work, we present a new multimodal dataset for exploring the emotional connotation of color as mediated by line, stroke, texture, shape, and language. Our dataset, FeelingBlue, is a collection of 19,788 4-tuples of abstract art ranked by annotators according to their evoked emotions and paired with rationales for those annotations. Using this corpus, we present a baseline for a new task: Justified Affect Transformation. Given an image I, the task is to 1) recolor I to enhance a specified emotion e and 2) provide a textual justification for the change in e. Our model is an ensemble of deep neural networks which takes I, generates an emotionally transformed color palette p conditioned on I, applies p to I, and then justifies the color transformation in text via a visual-linguistic model. Experimental results shed light on the emotional connotation of color in context, demonstrating both the promise of our approach on this challenging task and the considerable potential for future investigations enabled by our corpus.1",https://aclanthology.org/2023.tacl-1.11,emotion,Yes,Yes,No
Learning More from Mixed Emotions: A Label Refinement Method for Emotion Recognition in Conversations,"Wen, Jintao  and
Tu, Geng  and
Li, Rui  and
Jiang, Dazhi  and
Zhu, Wenhua",2023,,10.1162/tacl_a_00614,"One-hot labels are commonly employed as ground truth in Emotion Recognition in Conversations (ERC). However, this approach may not fully encompass all the emotions conveyed in a single utterance, leading to suboptimal performance. Regrettably, current ERC datasets lack comprehensive emotionally distributed labels. To address this issue, we propose the Emotion Label Refinement (EmoLR) method, which utilizes context- and speaker-sensitive information to infer mixed emotional labels. EmoLR comprises an Emotion Predictor (EP) module and a Label Refinement (LR) module. The EP module recognizes emotions and provides context/speaker states for the LR module. Subsequently, the LR module calculates the similarity between these states and ground-truth labels, generating a refined label distribution (RLD). The RLD captures a more comprehensive range of emotions than the original one-hot labels. These refined labels are then used for model training in place of the one-hot labels. Experimental results on three public conversational datasets demonstrate that our EmoLR achieves state-of-the-art performance.",https://aclanthology.org/2023.tacl-1.84,emotion,No,Yes,No
From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-oriented Dialogue,"Feng, Shutong  and
Lubis, Nurul  and
Ruppik, Benjamin  and
Geishauser, Christian  and
Heck, Michael  and
Lin, Hsien-chin  and
van Niekerk, Carel  and
Vukovic, Renato  and
Gasic, Milica",2023,Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue,10.18653/v1/2023.sigdial-1.8,"Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.",https://aclanthology.org/2023.sigdial-1.8,emotion,Yes,Yes,No
Eliciting Rich Positive Emotions in Dialogue Generation,"Gong, Ziwei  and
Min, Qingkai  and
Zhang, Yue",2023,Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023),10.18653/v1/2023.sicon-1.1,"Positive emotion elicitation aims at evoking positive emotion states in human users in open-domain dialogue generation. However, most work focuses on inducing a single-dimension of positive sentiment using human annotated datasets, which limits the scale of the training dataset. In this paper, we propose to model various emotions in large unannotated conversations, such as joy, trust and anticipation, by leveraging a latent variable to control the emotional intention of the response. Our proposed emotion-eliciting-Conditional-Variational-AutoEncoder (EE-CVAE) model generates more diverse and emotionally-intelligent responses compared to single-dimension baseline models in human evaluation.",https://aclanthology.org/2023.sicon-1.1,emotion,Yes,Yes,No
"{SINAI} at {S}em{E}val-2023 Task 10: Leveraging Emotions, Sentiments, and Irony Knowledge for Explainable Detection of Online Sexism","Vallecillo Rodrguez, Mar{\'\i}a Estrella  and
Plaza Del Arco, Flor Miriam  and
Ure{\~n}a L{\'o}pez, L. Alfonso  and
Mart{\'\i}n Valdivia, M. Teresa",2023,Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023),10.18653/v1/2023.semeval-1.136,"This paper describes the participation of SINAI research team in the Explainable Detection of Online Sexism (EDOS) Shared Task at SemEval 2023. Specifically, we participate in subtask A (binary sexism detection), subtask B (category of sexism), and subtask C (fine-grained vector of sexism). For the three subtasks, we propose a system that integrates information related to emotions, sentiments, and irony in order to check whether these features help detect sexism content. Our team ranked 46th in subtask A, 37th in subtask B, and 29th in subtask C, achieving 0.8245, 0.6043, and 0.4376 of macro f1-score, respectively, among the participants.",https://aclanthology.org/2023.semeval-1.136,emotion,No,No,No
Impact of Emojis on Automatic Analysis of Individual Emotion Categories,"Arreerard, Ratchakrit  and
Piao, Scott",2023,Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing,,"Automatic emotion analysis is a highly challenging task for Natural Language Processing, which has so far mainly relied on textual contents to determine the emotion of text. However, words are not the only media that carry emotional information. In social media, people also use emojis to convey their feelings. Recently, researchers have studied emotional aspects of emojis, and use emoji information to improve the emotion detection and classification, but many issues remain to be addressed. In this study, we examine the impact of emoji embedding on emotion classification and intensity prediction on four individual emotion categories, including anger, fear, joy, and sadness, in order to investigate how emojis affect the automatic analysis of individual emotion categories and intensity. We conducted a comparative study by testing five machine learning models with and without emoji embeddings involved. Our experiment demonstrates that emojis have varying impact on different emotion categories, and there is potential that emojis can be used to enhance emotion information processing.",https://aclanthology.org/2023.ranlp-1.14,emotion,No,Yes,Yes
Emotion-based Morality in {T}agalog and {E}nglish Scenarios ({EM}o{TES}-3{K}): A Parallel Corpus for Explaining (Im)morality of Actions,"Catapang, Jasper Kyle  and
Visperas, Moses",2023,Proceedings of the Joint 3rd International Conference on Natural Language Processing for Digital Humanities and 8th International Workshop on Computational Linguistics for Uralic Languages,,"Grasping morality is vital in AI systems, particularly as they become more prevalent in human-focused applications. Yet, research is scarce on this topic. This study presents the Emotion-based Morality in Tagalog and English Scenarios (EMoTES-3K), a collection that shows commonsense morality in both Filipino and English. This dataset is instrumental for analyzing moral decisions in various situations and their justifications. Our tests show that EMoTES-3K is effective for moral text categorization, with the fine-tuned RoBERTa model scoring 94.95{\%} accuracy in English and 88.53{\%} in Filipino. The dataset also excels in text generation tasks, as shown by fine-tuning the FLAN-T5 model to produce clear moral explanations. However, the model faces challenges when dealing with actions that have mixed moral implications. This work not only bridges the gap in moral reasoning datasets for languages like Filipino but also sets the stage for future research in commonsense moral reasoning in artificial intelligence.",https://aclanthology.org/2023.nlp4dh-1.1,emotion,Yes,Yes,Yes
Challenges of Human vs Machine Translation of Emotion-Loaded {C}hinese Microblog Texts,"Qian, Shenbin  and
Or{\u{a}}san, Constantin  and
do Carmo, F{\'e}lix  and
Kanojia, Diptesh",2023,"Proceedings of Machine Translation Summit XIX, Vol. 2: Users Track",,"This paper attempts to identify challenges professional translators face when translating emotion-loaded texts as well as errors machine translation (MT) makes when translating this content. We invited ten Chinese-English translators to translate thirty posts of a Chinese microblog, and interviewed them about the challenges encountered during translation and the problems they believe MT might have. Further, we analysed more than five-thousand automatic translations of microblog posts to observe problems in MT outputs. We establish that the most challenging problem for human translators is emotion-carrying words, which translators also consider as a problem for MT. Analysis of MT outputs shows that this is also the most common source of MT errors. We also find that what is challenging for MT, such as non-standard writing, is not necessarily an issue for humans. Our work contributes to a better understanding of the challenges for the translation of microblog posts by humans and MT, caused by different forms of expression of emotion.",https://aclanthology.org/2023.mtsummit-users.21,emotion,No,No,No
Emotion Recognition based on Psychological Components in Guided Narratives for Emotion Regulation,"Cortal, Gustave  and
Finkel, Alain  and
Paroubek, Patrick  and
Ye, Lina",2023,"Proceedings of the 7th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",10.18653/v1/2023.latechclfl-1.8,"Emotion regulation is a crucial element in dealing with emotional events and has positive effects on mental health. This paper aims to provide a more comprehensive understanding of emotional events by introducing a new French corpus of emotional narratives collected using a questionnaire for emotion regulation. We follow the theoretical framework of the Component Process Model which considers emotions as dynamic processes composed of four interrelated components (behavior, feeling, thinking and territory). Each narrative is related to a discrete emotion and is structured based on all emotion components by the writers. We study the interaction of components and their impact on emotion classification with machine learning methods and pre-trained language models. Our results show that each component improves prediction performance, and that the best results are achieved by jointly considering all components. Our results also show the effectiveness of pre-trained language models in predicting discrete emotion from certain components, which reveal differences in how emotion components are expressed.",https://aclanthology.org/2023.latechclfl-1.8,emotion,Yes,Yes,Yes
Transformer-based {B}engali Textual Emotion Recognition,"Atabuzzaman, Md.  and
Maksuda Bilkis, Baby  and
Shajalal, Md.",2023,Proceedings of the 20th International Conference on Natural Language Processing (ICON),,"Emotion recognition for high-resource languages has progressed significantly. However, resource-constrained languages such as Bengali have not advanced notably due to the lack of large benchmark datasets. Besides this, the need for more Bengali language processing tools makes the emotion recognition task more challenging and complicated. Therefore, we developed the largest dataset in this paper, consisting of almost 12k Bengali texts with six basic emotions. Then, we conducted experiments on our dataset to establish the baseline performance applying machine learning, deep learning, and transformer-based models as emotion classifiers. The experimental results demonstrate that the models achieved promising performance in Bengali emotion recognition.",https://aclanthology.org/2023.icon-1.55,emotion,Yes,Yes,No
"Leveraging Empathy, Distress, and Emotion for Accurate Personality Subtyping from Complex Human Textual Responses","Soumitra, Ghosh  and
Tanisha, Tiwari  and
Chetna, Painkra  and
Gopendra Vikram, Singh  and
Asif, Ekbal",2023,Proceedings of the 20th International Conference on Natural Language Processing (ICON),,"Automated personality subtyping is a crucial area of research with diverse applications in psychology, healthcare, and marketing. However, current studies face challenges such as insufficient data, noisy text data, and difficulty in capturing complex personality traits. To address these issues, including empathy, distress, and emotion as auxiliary tasks in automated personality subtyping may enhance accuracy and robustness. This study introduces a Multi-input Multi-task Framework for Personality, Empathy, Distress, and Emotion Detection (MultiPEDE). This framework harnesses the complementary information from empathy, distress, and emotion tasks (auxiliary tasks) to enhance the accuracy and generalizability of automated personality subtyping (the primary task). The model uses a novel deep-learning architecture that captures the interdependencies between these constructs, is end-to-end trainable, and does not rely on ensemble strategies, making it practical for real-world applications. Performance evaluation involves labeled examples of five personality traits, two classes each for personality, empathy, and distress detection, and seven classes for emotion detection. This approach has diverse applications, including mental health diagnosis, improving online services, and aiding job candidate selection.",https://aclanthology.org/2023.icon-1.68,emotion_and_empathy,Yes,Yes,No
Unlocking Emotions in Text: A Fusion of Word Embeddings and Lexical Knowledge for Emotion Classification,"Anjali, Bhardwaj  and
Nesar Ahmad, Wasi  and
Muhammad, Abulaish",2023,Proceedings of the 20th International Conference on Natural Language Processing (ICON),,"This paper introduces an improved method for emotion classification through the integration of emotion lexicons and pre-trained word embeddings. The proposed method utilizes semantically similar features to reconcile the semantic gap between words and emotions. The proposed approach is compared against three baselines for predicting Ekman{'}s emotions at the document level on the GoEmotions dataset. The effectiveness of the proposed approach is assessed using standard evaluation metrics, which show at least a 5{\%} gain in performance over baselines.",https://aclanthology.org/2023.icon-1.78,emotion,Yes,Yes,No
Dialogue Quality and Emotion Annotations for Customer Support Conversations,"Mendonca, John  and
Pereira, Patr{\'\i}cia  and
Menezes, Miguel  and
Cabarr{\~a}o, Vera  and
Farinha, Ana C  and
Moniz, Helena  and
Lavie, Alon  and
Trancoso, Isabel",2023,"Proceedings of the Third Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)",,"Task-oriented conversational datasets often lack topic variability and linguistic diversity. However, with the advent of Large Language Models (LLMs) pretrained on extensive, multilingual and diverse text data, these limitations seem overcome. Nevertheless, their generalisability to different languages and domains in dialogue applications remains uncertain without benchmarking datasets. This paper presents a holistic annotation approach for emotion and conversational quality in the context of bilingual customer support conversations. By performing annotations that take into consideration the complete instances that compose a conversation, one can form a broader perspective of the dialogue as a whole. Furthermore, it provides a unique and valuable resource for the development of text classification models. To this end, we present benchmarks for Emotion Recognition and Dialogue Quality Estimation and show that further research is needed to leverage these models in a production setting.",https://aclanthology.org/2023.gem-1.2,emotion,No,Yes,Yes
"{S}oul{C}hat: Improving {LLM}s{'} Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations","Chen, Yirong  and
Xing, Xiaofen  and
Lin, Jingkai  and
Zheng, Huimin  and
Wang, Zhenyu  and
Liu, Qi  and
Xu, Xiangmin",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.83,"Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.",https://aclanthology.org/2023.findings-emnlp.83,empathy,Yes,Yes,Yes
The {PEACE}-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis,"Yeo, Gerard  and
Jaidka, Kokil",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.186,"Cognitive appraisal plays a pivotal role in deciphering emotions. Recent studies have delved into its significance, yet the interplay between various forms of cognitive appraisal and specific emotions, such as joy and anger, remains an area of exploration in consumption contexts. Our research introduces the PEACE-Reviews dataset, a unique compilation of annotated autobiographical accounts where individuals detail their emotional and appraisal experiences during interactions with personally significant products or services. Focusing on the inherent variability in consumer experiences, this dataset offers an in-depth analysis of participants{'} psychological traits, their evaluative feedback on purchases, and the resultant emotions. Notably, the PEACE-Reviews dataset encompasses emotion, cognition, individual traits, and demographic data. We also introduce preliminary models that predict certain features based on the autobiographical narratives.",https://aclanthology.org/2023.findings-emnlp.186,emotion,Yes,Yes,No
Generative Emotion Cause Triplet Extraction in Conversations with Commonsense Knowledge,"Wang, Fanfan  and
Yu, Jianfei  and
Xia, Rui",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.260,"Emotion Cause Triplet Extraction in Conversations (ECTEC) aims to simultaneously extract emotion utterances, emotion categories, and cause utterances from conversations. However, existing studies mainly decompose the ECTEC task into multiple subtasks and solve them in a pipeline manner. Moreover, since conversations tend to contain many informal and implicit expressions, it often requires external knowledge and reasoning-based inference to accurately identify emotional and causal clues implicitly mentioned in the context, which are ignored by previous work. To address these limitations, in this paper, we propose a commonSense knowledge-enHanced generAtive fRameworK named SHARK, which formulates the ECTEC task as an index generation problem and generates the emotion-cause-category triplets in an end-to-end manner with a sequence-to-sequence model. Furthermore, we propose to incorporate both retrieved and generated commonsense knowledge into the generative model via a dual-view gate mechanism and a graph attention layer. Experimental results show that our SHARK model consistently outperforms several competitive systems on two benchmark datasets. Our source codes are publicly released at https://github.com/NUSTM/SHARK.",https://aclanthology.org/2023.findings-emnlp.260,emotion,Yes,Yes,No
Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis,"Teodorescu, Daniela  and
Mohammad, Saif",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.271,"Emotion arcs capture how an individual (or a population) feels over time. They are widely used in industry and research; however, there is little work on evaluating the automatically generated arcs. This is because of the difficulty of establishing the true (gold) emotion arc. Our work, for the first time, systematically and quantitatively evaluates automatically generated emotion arcs. We also compare two common ways of generating emotion arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. By running experiments on 18 diverse datasets in 9 languages, we show that despite being markedly poor at instance level emotion classification, LexO methods are highly accurate at generating emotion arcs when aggregating information from hundreds of instances. We also show, through experiments on six indigenous African languages, as well as Arabic, and Spanish, that automatic translations of English emotion lexicons can be used to generate high-quality emotion arcs in less-resource languages. This opens up avenues for work on emotions in languages from around the world; which is crucial for commerce, public policy, and health research in service of speakers often left behind. Code and resources: https://github.com/dteodore/EmotionArcs",https://aclanthology.org/2023.findings-emnlp.271,emotion,No,Yes,No
Exploiting Emotion-Semantic Correlations for Empathetic Response Generation,"Yang, Zhou  and
Ren, Zhaochun  and
Yufeng, Wang  and
Zhu, Xiaofei  and
Chen, Zhihao  and
Cai, Tiecheng  and
Yunbing, Wu  and
Su, Yisong  and
Ju, Sibo  and
Liao, Xiangwen",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.320,"Empathetic response generation aims to generate empathetic responses by understanding the speaker{'}s emotional feelings from the language of dialogue. Recent methods capture emotional words in the language of communicators and construct them as static vectors to perceive nuanced emotions. However, linguistic research has shown that emotional words in language are dynamic and have correlations with other grammar semantic roles, i.e., words with semantic meanings, in grammar. Previous methods overlook these two characteristics, which easily lead to misunderstandings of emotions and neglect of key semantics. To address this issue, we propose a dynamical Emotion-Semantic Correlation Model (ESCM) for empathetic dialogue generation tasks. ESCM constructs dynamic emotion-semantic vectors through the interaction of context and emotions. We introduce dependency trees to reflect the correlations between emotions and semantics. Based on dynamic emotion-semantic vectors and dependency trees, we propose a dynamic correlation graph convolutional network to guide the model in learning context meanings in dialogue and generating empathetic responses. Experimental results on the EMPATHETIC-DIALOGUES dataset show that ESCM understands semantics and emotions more accurately and expresses fluent and informative empathetic responses. Our analysis results also indicate that the correlations between emotions and semantics are frequently used in dialogues, which is of great significance for empathetic perception and expression.",https://aclanthology.org/2023.findings-emnlp.320,emotion,Yes,Yes,No
Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition,"Slaughter, Isaac  and
Greenberg, Craig  and
Schwartz, Reva  and
Caliskan, Aylin",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.602,"Previous work has established that a person{'}s demographics and speech style affect how well speech processing models perform for them. But where does this bias come from? In this work, we present the Speech Embedding Association Test (SpEAT), a method for detecting bias in one type of model used for many speech tasks: pre-trained models. The SpEAT is inspired by word embedding association tests in natural language processing, which quantify intrinsic bias in a model{'}s representations of different concepts, such as race or valence{---}something{'}s pleasantness or unpleasantness{---}and capture the extent to which a model trained on large-scale socio-cultural data has learned human-like biases. Using the SpEAT, we test for six types of bias in 16 English speech models (including 4 models also trained on multilingual data), which come from the wav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more models reveal positive valence (pleasantness) associations with abled people over disabled people, with European-Americans over African-Americans, with females over males, with U.S. accented speakers over non-U.S. accented speakers, and with younger people over older people. Beyond establishing that pre-trained speech models contain these biases, we also show that they can have real world effects. We compare biases found in pre-trained models to biases in downstream models adapted to the task of Speech Emotion Recognition (SER) and find that in 66 of the 96 tests performed (69{\%}), the group that is more associated with positive valence as indicated by the SpEAT also tends to be predicted as speaking with higher valence by the downstream model. Our work provides evidence that, like text and image-based models, pre-trained speech based-models frequently learn human-like biases when trained on large-scale socio-cultural datasets. Our work also shows that bias found in pre-trained models can propagate to the downstream task of SER.",https://aclanthology.org/2023.findings-emnlp.602,emotion,No,Yes,Yes
Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition,"Cowap, Alan  and
Graham, Yvette  and
Foster, Jennifer",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.665,"Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth",https://aclanthology.org/2023.findings-emnlp.665,emotion,No,Yes,Yes
{EMO}-{KNOW}: A Large Scale Dataset on Emotion-Cause,"Nguyen, Mia  and
Samaradivakara, Yasith  and
Sasikumar, Prasanth  and
Gupta, Chitralekha  and
Nanayakkara, Suranga",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.737,"Emotion-Cause analysis has attracted the attention of researchers in recent years. However, most existing datasets are limited in size and number of emotion categories. They often focus on extracting parts of the document that contain the emotion cause and fail to provide more abstractive, generalizable root cause. To bridge this gap, we introduce a large-scale dataset of emotion causes, derived from 9.8 million cleaned tweets over 15 years. We describe our curation process, which includes a comprehensive pipeline for data gathering, cleaning, labeling, and validation, ensuring the dataset{'}s reliability and richness. We extract emotion labels and provide abstractive summarization of the events causing emotions. The final dataset comprises over 700,000 tweets with corresponding emotion-cause pairs spanning 48 emotion classes, validated by human evaluators. The novelty of our dataset stems from its broad spectrum of emotion classes and the abstractive emotion cause that facilitates the development of an emotion-cause knowledge graph for nuanced reasoning. Our dataset will enable the design of emotion-aware systems that account for the diverse emotional responses of different people for the same event.",https://aclanthology.org/2023.findings-emnlp.737,emotion,Yes,No,No
Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition,"Xu, Yige  and
Zeng, Zhiwei  and
Shen, Zhiqi",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.780,"Emotion Recognition in Conversation (ERC) has been widely studied due to its importance in developing emotion-aware empathetic machines. The rise of pre-trained language models (PLMs) has further pushed the limit of ERC performance. However, most recent works on ERC using PLMs are heavily data-driven, and requires fine-tuning the entire PLMs. To improve both sample and computational efficiency, we propose a derivative-free optimization method called Cross-Task Prompt Tuning (CTPT) for few-shot conversational emotion recognition. Unlike existing methods that learn independent knowledge from individual tasks, CTPT leverages sharable cross-task knowledge by exploiting external knowledge from other source tasks to improve learning performance under the few-shot setting. Moreover, CTPT only needs to optimize a vector under the low intrinsic dimensionality without gradient, which is highly parameter-efficient compared with existing approaches. Experiments on five different contextual conversation datasets demonstrate that our CTPT method has superior results on both few-shot scenarios and zero-shot transfers.",https://aclanthology.org/2023.findings-emnlp.780,emotion,No,Yes,Yes
An Empirical Study on Multiple Knowledge from {C}hat{GPT} for Emotion Recognition in Conversations,"Tu, Geng  and
Liang, Bin  and
Qin, Bing  and
Wong, Kam-Fai  and
Xu, Ruifeng",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.813,"Multiple knowledge (e.g., co-reference, topics, emotional causes, etc) has been demonstrated effective for emotion detection. However, exploring this knowledge in Emotion Recognition in Conversations (ERC) is currently a blank slate due to the lack of annotated data and the high cost involved in obtaining such knowledge. Fortunately, the emergence of Large Language Models (LLMs) holds promise in filling this void. Therefore, we propose a Multiple Knowledge Fusion Model (MKFM) to effectively integrate such knowledge generated by LLMs for ERC and empirically study its impact on the model. Experimental results on three public datasets have demonstrated the effectiveness of multiple knowledge for ERC. Furthermore, we conduct a detailed analysis of the contribution and complementarity of this knowledge.",https://aclanthology.org/2023.findings-emnlp.813,emotion,Yes,Yes,Yes
Enhancing Emotion Recognition in Conversation via Multi-view Feature Alignment and Memorization,"Hou, Guiyang  and
Shen, Yongliang  and
Zhang, Wenqi  and
Xue, Wei  and
Lu, Weiming",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.842,"Emotion recognition in conversation (ERC) has attracted increasing attention in natural language processing community. Previous work commonly first extract semantic-view features via fine-tuning PLMs, then models context-view features based on the obtained semantic-view features by various graph neural networks. However, it is difficult to fully model interaction between utterances simply through a graph neural network and the features at semantic-view and context-view are not well aligned. Moreover, the previous parametric learning paradigm struggle to learn the patterns of tail class given fewer instances. To this end, we treat the pre-trained conversation model as a prior knowledge base and from which we elicit correlations between utterances by a probing procedure. And we adopt supervised contrastive learning to align semantic-view and context-view features, these two views of features work together in a complementary manner, contributing to ERC from distinct perspectives. Meanwhile, we propose a new semi-parametric paradigm of inferencing through memorization to solve the recognition problem of tail class samples. We consistently achieve state-of-the-art results on four widely used benchmarks. Extensive experiments demonstrate the effectiveness of our proposed multi-view feature alignment and memorization.",https://aclanthology.org/2023.findings-emnlp.842,emotion,No,Yes,Yes
Misery Loves Complexity: Exploring Linguistic Complexity in the Context of Emotion Detection,"Singh, Pranaydeep  and
De Bruyne, Luna  and
De Clercq, Orph{\'e}e  and
Lefever, Els",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.857,"Given the omnipresence of social media in our society, thoughts and opinions are being shared online in an unprecedented manner. This means that both positive and negative emotions can be equally and freely expressed. However, the negativity bias posits that human beings are inherently drawn to and more moved by negativity and, as a consequence, negative emotions get more traffic. Correspondingly, when writing about emotions this negativity bias could lead to expressions of negative emotions that are linguistically more complex. In this paper, we attempt to use readability and linguistic complexity metrics to better understand the manifestation of emotions on social media platforms like Reddit based on the widely-used GoEmotions dataset. We demonstrate that according to most metrics, negative emotions indeed tend to generate more complex text than positive emotions. In addition, we examine whether a higher complexity hampers the automatic identification of emotions. To answer this question, we fine-tuned three state-of-the-art transformers (BERT, RoBERTa, and SpanBERT) on the same emotion detection dataset. We demonstrate that these models often fail to predict emotions for the more complex texts. More advanced LLMs like RoBERTa and SpanBERT also fail to improve by significant margins on complex samples. This calls for a more nuanced interpretation of the emotion detection performance of transformer models. We make the automatically annotated data available for further research at: https://huggingface.co/datasets/pranaydeeps/CAMEO",https://aclanthology.org/2023.findings-emnlp.857,emotion,Yes,Yes,No
Conditioning on Dialog Acts improves Empathy Style Transfer,"Qu, Renyi  and
Ungar, Lyle  and
Sedoc, Jo{\~a}o",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.884,"We explore the role of dialog acts in style transfer, specifically empathy style transfer {--} rewriting a sentence to make it more empathetic without changing its meaning. Specifically, we use two novel few-shot prompting strategies: target prompting, which only uses examples of the target style (unlike traditional prompting with source/target pairs), and dialog-act-conditioned prompting, which first estimates the dialog act of the source sentence and then makes it more empathetic using few-shot examples of the same dialog act. Our study yields two key findings: (1) Target prompting typically improves empathy more effectively while maintaining the same level of semantic similarity; (2) Dialog acts matter. Dialog-act-conditioned prompting enhances empathy while preserving both semantics and the dialog-act type. Different dialog acts benefit differently from different prompting methods, highlighting the need for further investigation of the role of dialog acts in style transfer.",https://aclanthology.org/2023.findings-emnlp.884,empathy,No,No,No
Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models,"Zhan, Hongli  and
Ong, Desmond  and
Li, Junyi Jessy",2023,Findings of the Association for Computational Linguistics: EMNLP 2023,10.18653/v1/2023.findings-emnlp.962,"The emotions we experience involve complex processes; besides physiological aspects, research in psychology has studied cognitive appraisals where people assess their situations subjectively, according to their own values (Scherer, 2005). Thus, the same situation can often result in different emotional experiences. While the detection of emotion is a well-established task, there is very limited work so far on the automatic prediction of cognitive appraisals. This work fills the gap by presenting CovidET-Appraisals, the most comprehensive dataset to-date that assesses 24 appraisal dimensions, each with a natural language rationale, across 241 Reddit posts. CovidET-Appraisals presents an ideal testbed to evaluate the ability of large language models {---} excelling at a wide range of NLP tasks {---} to automatically assess and explain cognitive appraisals. We found that while the best models are performant, open-sourced LLMs fall short at this task, presenting a new challenge in the future development of emotionally intelligent models. We release our dataset at https://github.com/honglizhan/CovidET-Appraisals-Public.",https://aclanthology.org/2023.findings-emnlp.962,emotion,Yes,Yes,Yes
Best Practices in the Creation and Use of Emotion Lexicons,"Mohammad, Saif",2023,Findings of the Association for Computational Linguistics: EACL 2023,10.18653/v1/2023.findings-eacl.136,"Words play a central role in how we express ourselves. Lexicons of word{--}emotion associations are widely used in research and real-world applications for sentiment analysis, tracking emotions associated with products and policies, studying health disorders, tracking emotional arcs of stories, and so on. However, inappropriate and incorrect use of these lexicons can lead to not just sub-optimal results, but also inferences that are directly harmful to people. This paper brings together ideas from Affective Computing and AI Ethics to present, some of the practical and ethical considerations involved in the creation and use of emotion lexicons {--} best practices. The goal is to provide a comprehensive set of relevant considerations, so that readers (especially those new to work with emotions) can find relevant information in one place. We hope this work will facilitate more thoughtfulness when one is deciding on what emotions to work on, how to create an emotion lexicon, how to use an emotion lexicon, how to draw meaningful inferences, and how to judge success.",https://aclanthology.org/2023.findings-eacl.136,emotion,No,No,No
Global-Local Modeling with Prompt-Based Knowledge Enhancement for Emotion Inference in Conversation,"Wang, Renxi  and
Feng, Shi",2023,Findings of the Association for Computational Linguistics: EACL 2023,10.18653/v1/2023.findings-eacl.158,"The ability to recognize emotions in conversations is necessary and important for the online chatbot to do tasks such as empathetic response generation and emotional support. Present researches mainly focus on recognizing emotions through a speaker{'}s utterance, while research on emotion inference predicts emotions of addressees through previous utterances. Because of the lack of the addressee{'}s utterance, emotion inference is more challenging than emotion recognition. In this paper, we propose a global-local modeling method based on recurrent neural networks (RNN) and pre-trained language models (PLM) to do emotion inference, which utilizes the sequence modeling ability of RNNs and abundant knowledge from PLMs. Moreover, we take the whole dialogue history as input of PLM to generate knowledge by in-context learning. Experimental results show that our model with knoledge enhancement achieves state-of-the-art performance on all three datasets.",https://aclanthology.org/2023.findings-eacl.158,emotion,No,Yes,Yes
{PAL}: Persona-Augmented Emotional Support Conversation Generation,"Cheng, Jiale  and
Sabour, Sahand  and
Sun, Hao  and
Chen, Zhuang  and
Huang, Minlie",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.34,"Due to the lack of human resources for mental health support, there is an increasing demand for employing conversational agents for support. Recent work has demonstrated the effectiveness of dialogue models in providing emotional support. As previous studies have demonstrated that seekers{'} persona is an important factor for effective support, we investigate whether there are benefits to modeling such information in dialogue models for support. In this paper, our empirical analysis verifies that persona has an important impact on emotional support. Therefore, we propose a framework for dynamically inferring and modeling seekers{'} persona. We first train a model for inferring the seeker{'}s persona from the conversation history. Accordingly, we propose PAL, a model that leverages persona information and, in conjunction with our strategy-based controllable generation method, provides personalized emotional support. Automatic and manual evaluations demonstrate that PAL achieves state-of-the-art results, outperforming the baselines on the studied benchmark. Our code and data are publicly available at \url{https://github.com/chengjl19/PAL}.",https://aclanthology.org/2023.findings-acl.34,emotion,Yes,Yes,No
Emotion Cause Extraction on Social Media without Human Annotation,"Xiao, Debin  and
Xia, Rui  and
Yu, Jianfei",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.94,"In social media, there is a vast amount of information pertaining to people{'}s emotions and the corresponding causes. The emotion cause extraction (ECE) from social media data is an important research area that has not been thoroughly explored due to the lack of fine-grained annotations. Early studies referred to either unsupervised rule-based methods or supervised machine learning methods using a number of manually annotated data in specific domains. However, the former suffers from limitations in extraction performance, while the latter is constrained by the availability of fine-grained annotations and struggles to generalize to diverse domains. To address these issues, this paper proposes a new ECE framework on Chinese social media that achieves high extraction performance and generalizability without relying on human annotation. Specifically, we design a more dedicated rule-based system based on constituency parsing tree to discover causal patterns in social media. This system enables us to acquire large amounts of fine-grained annotated data. Next, we train a neural model on the rule-annotated dataset with a specific training strategy to further improve the model{'}s generalizability. Extensive experiments demonstrate the superiority of our approach over other methods in unsupervised and weakly-supervised settings.",https://aclanthology.org/2023.findings-acl.94,emotion,Yes,Yes,No
{A}ug{ESC}: Dialogue Augmentation with Large Language Models for Emotional Support Conversation,"Zheng, Chujie  and
Sabour, Sahand  and
Wen, Jiaxin  and
Zhang, Zheng  and
Huang, Minlie",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.99,"Crowdsourced dialogue corpora are usually limited in scale and topic coverage due to the expensive cost of data curation. This would hinder the generalization of downstream dialogue models to open-domain topics. In this work, we leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). By treating dialogue augmentation as a dialogue completion task, we prompt a fine-tuned language model to complete full dialogues from available dialogue posts of various topics, which are then postprocessed based on heuristics. Applying this approach, we construct AugESC, an augmented dataset for the ESC task, which largely extends the scale and topic coverage of the crowdsourced ESConv corpus. Through comprehensive human evaluation, we demonstrate that our approach is superior to strong baselines of dialogue augmentation and that AugESC has comparable dialogue quality to the crowdsourced corpus. We also conduct human interactive evaluation and prove that post-training on AugESC improves downstream dialogue models{'} generalization ability to open-domain topics. These results suggest the utility of AugESC and highlight the potential of large language models in improving data-scarce dialogue generation tasks.",https://aclanthology.org/2023.findings-acl.99,emotion,Yes,Yes,Yes
Topic and Style-aware Transformer for Multimodal Emotion Recognition,"Qiu, Shuwen  and
Sekhar, Nitesh  and
Singhal, Prateek",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.130,"Understanding emotion expressions in multimodal signals is key for machines to have a better understanding of human communication. While language, visual and acoustic modalities can provide clues from different perspectives, the visual modality is shown to make minimal contribution to the performance in the emotion recognition field due to its high dimensionality. Therefore, we first leverage the strong multimodality backbone VATT to project the visual signal to the common space with language and acoustic signals. Also, we propose content-oriented features Topic and Speaking style on top of it to approach the subjectivity issues. Experiments conducted on the benchmark dataset MOSEI show our model can outperform SOTA results and effectively incorporate visual signals and handle subjectivity issues by serving as content {``}normalization{''}.",https://aclanthology.org/2023.findings-acl.130,emotion,Yes,Yes,No
Semi-Supervised Domain Adaptation for Emotion-Related Tasks,"Hosseini, Mahshid  and
Caragea, Cornelia",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.333,"Semi-supervised domain adaptation (SSDA) adopts a model trained from a label-rich source domain to a new but related domain with a few labels of target data. It is shown that, in an SSDA setting, a simple combination of domain adaptation (DA) with semi-supervised learning (SSL) techniques often fails to effectively utilize the target supervision and cannot address distribution shifts across different domains due to the training data bias toward the source-labeled samples. In this paper, inspired by the co-learning of multiple classifiers for the computer vision tasks, we propose to decompose the SSDA framework for emotion-related tasks into two subcomponents of unsupervised domain adaptation (UDA) from the source to the target domain and semi-supervised learning (SSL) in the target domain where the two models iteratively teach each other by interchanging their high confident predictions. We further propose a novel data cartography-based regularization technique for pseudo-label denoising that employs training dynamics to further hone our models{'} performance. We publicly release our code.",https://aclanthology.org/2023.findings-acl.333,emotion,Yes,Yes,No
Self-adaptive Context and Modal-interaction Modeling For Multimodal Emotion Recognition,"Yang, Haozhe  and
Gao, Xianqiang  and
Wu, Jianlong  and
Gan, Tian  and
Ding, Ning  and
Jiang, Feijun  and
Nie, Liqiang",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.390,"The multimodal emotion recognition in conversation task aims to predict the emotion label for a given utterance with its context and multiple modalities. Existing approaches achieve good results but also suffer from the following two limitations: 1) lacking modeling of diverse dependency ranges, i.e., long, short, and independent context-specific representations and without consideration of the different recognition difficulty for each utterance; 2) consistent treatment of the contribution for various modalities. To address the above challenges, we propose the Self-adaptive Context and Modal-interaction Modeling (SCMM) framework. We first design the context representation module, which consists of three submodules to model multiple contextual representations. Thereafter, we propose the modal-interaction module, including three interaction submodules to make full use of each modality. Finally, we come up with a self-adaptive path selection module to select an appropriate path in each module and integrate the features to obtain the final representation. Extensive experiments under four settings on three multimodal datasets, including IEMOCAP, MELD, and MOSEI, demonstrate that our proposed method outperforms the state-of-the-art approaches.",https://aclanthology.org/2023.findings-acl.390,emotion,No,Yes,No
{T}rans{ESC}: Smoothing Emotional Support Conversation via Turn-Level State Transition,"Zhao, Weixiang  and
Zhao, Yanyan  and
Wang, Shilong  and
Qin, Bing",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.420,"Emotion Support Conversation (ESC) is an emerging and challenging task with the goal of reducing the emotional distress of people. Previous attempts fail to maintain smooth transitions between utterances in ESC because they ignoring to grasp the fine-grained transition information at each dialogue turn. To solve this problem, we propose to take into account turn-level state Transitions of ESC (TransESC) from three perspectives, including semantics transition, strategy transition and emotion transition, to drive the conversation in a smooth and natural way. Specifically, we construct the state transition graph with a two-step way, named transit-then-interact, to grasp such three types of turn-level transition information. Finally, they are injected into the transition aware decoder to generate more engaging responses. Both automatic and human evaluations on the benchmark dataset demonstrate the superiority of TransESC to generate more smooth and effective supportive responses. Our source code will be publicly available.",https://aclanthology.org/2023.findings-acl.420,emotion,Yes,No,No
Towards Distribution-shift Robust Text Classification of Emotional Content,"Bulla, Luana  and
Gangemi, Aldo  and
Mongiovi{'}, Misael",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.524,"Supervised models based on Transformers have been shown to achieve impressive performances in many natural language processing tasks. However, besides requiring a large amount of costly manually annotated data, supervised models tend to adapt to the characteristics of the training dataset, which are usually created ad-hoc and whose data distribution often differs from the one in real applications, showing significant performance degradation in real-world scenarios. We perform an extensive assessment of the out-of-distribution performances of supervised models for classification in the emotion and hate-speech detection tasks and show that NLI-based zero-shot models often outperform them, making task-specific annotation useless when the characteristics of final-user data are not known in advance. To benefit from both supervised and zero-shot approaches, we propose to fine-tune an NLI-based model on the task-specific dataset. The resulting model often outperforms all available supervised models both in distribution and out of distribution, with only a few thousand training samples.",https://aclanthology.org/2023.findings-acl.524,emotion,Yes,Yes,Yes
What to Fuse and How to Fuse: Exploring Emotion and Personality Fusion Strategies for Explainable Mental Disorder Detection,"Zanwar, Sourabh  and
Li, Xiaofei  and
Wiechmann, Daniel  and
Qiao, Yu  and
Kerz, Elma",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.568,"Mental health disorders (MHD) are increasingly prevalent worldwide and constitute one of the greatest challenges facing our healthcare systems and modern societies in general. In response to this societal challenge, there has been a surge in digital mental health research geared towards the development of new techniques for unobtrusive and efficient automatic detection of MHD. Within this area of research, natural language processing techniques are playing an increasingly important role, showing promising detection results from a variety of textual data. Recently, there has been a growing interest in improving mental illness detection from textual data by way of leveraging emotions: {`}Emotion fusion{'} refers to the process of integrating emotion information with general textual information to obtain enhanced information for decision-making. However, while the available research has shown that MHD prediction can be improved through a variety of different fusion strategies, previous works have been confined to a particular fusion strategy applied to a specific dataset, and so is limited by the lack of meaningful comparability. In this work, we integrate and extend this research by conducting extensive experiments with three types of deep learning-based fusion strategies: (i) feature-level fusion, where a pre-trained masked language model for mental health detection (MentalRoBERTa) was infused with a comprehensive set of engineered features, (ii) model fusion, where the MentalRoBERTa model was infused with hidden representations of other language models and (iii) task fusion, where a multi-task framework was leveraged to learn the features for auxiliary tasks. In addition to exploring the role of different fusion strategies, we expand on previous work by broadening the information infusion to include a second domain related to mental health, namely personality. We evaluate algorithm performance on data from two benchmark datasets, encompassing five mental health conditions: attention deficit hyperactivity disorder, anxiety, bipolar disorder, depression and psychological stress.",https://aclanthology.org/2023.findings-acl.568,emotion,Yes,Yes,Yes
{QAP}: A Quantum-Inspired Adaptive-Priority-Learning Model for Multimodal Emotion Recognition,"Li, Ziming  and
Zhou, Yan  and
Liu, Yaxin  and
Zhu, Fuqing  and
Yang, Chuanpeng  and
Hu, Songlin",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.772,"Multimodal emotion recognition for video has gained considerable attention in recent years, in which three modalities (\textit{i.e.,} textual, visual and acoustic) are involved. Due to the diverse levels of informational content related to emotion, three modalities typically possess varying degrees of contribution to emotion recognition. More seriously, there might be inconsistencies between the emotion of individual modality and the video. The challenges mentioned above are caused by the inherent uncertainty of emotion. Inspired by the recent advances of quantum theory in modeling uncertainty, we make an initial attempt to design a quantum-inspired adaptive-priority-learning model (QAP) to address the challenges. Specifically, the quantum state is introduced to model modal features, which allows each modality to retain all emotional tendencies until the final classification. Additionally, we design Q-attention to orderly integrate three modalities, and then QAP learns modal priority adaptively so that modalities can provide different amounts of information based on priority. Experimental results on the IEMOCAP and MOSEI datasets show that QAP establishes new state-of-the-art results.",https://aclanthology.org/2023.findings-acl.772,emotion,No,Yes,No
Context or Knowledge is Not Always Necessary: A Contrastive Learning Framework for Emotion Recognition in Conversations,"Tu, Geng  and
Liang, Bin  and
Mao, Ruibin  and
Yang, Min  and
Xu, Ruifeng",2023,Findings of the Association for Computational Linguistics: ACL 2023,10.18653/v1/2023.findings-acl.883,"Emotion recognition in conversations (ERC) aims to detect the emotion of utterances in conversations. Existing efforts generally focus on modeling context- and knowledge-sensitive dependencies. However, it is observed that the emotions of many utterances can be correctly detected without context or external knowledge. In such cases, blindly leveraging the context and external knowledge may impede model training. Based on this, we propose a novel framework based on contrastive learning (CL), called CKCL (including the contrastive learning scenarios among Context and Knowledge), to distinguish the above utterances for better vector representations. The CKCL framework defines context- and knowledge-independent utterances, as the positive sample, whose predicted results are unchanged even masking context and knowledge representations, otherwise, the negative sample. This can obtain a latent feature reflecting the impact degree of context and external knowledge on predicted results, thus effectively denoising irrelevant context and knowledge during training. Experimental results on four datasets show the performance of CKCL-based models is significantly boosted and outperforms state-of-the-art methods.",https://aclanthology.org/2023.findings-acl.883,emotion,No,Yes,No
Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers,"Teodorescu, Daniela  and
Cheng, Tiffany  and
Fyshe, Alona  and
Mohammad, Saif",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.188,"Research in psychopathology has shown that, at an aggregate level, the patterns of emotional change over time{---}emotion dynamics{---}are indicators of one{'}s mental health. One{'}s patterns of emotion change have traditionally been determined through self-reports of emotions; however, there are known issues with accuracy, bias, and convenience. Recent approaches to determining emotion dynamics from one{'}s everyday utterances, addresses many of these concerns, but it is not yet known whether these measures of utterance emotion dynamics (UED) correlate with mental health diagnoses. Here, for the first time, we study the relationship between tweet emotion dynamics and mental health disorders. We find that each of the UED metrics studied varied by the user{'}s self-disclosed diagnosis. For example: average valence was significantly higher (i.e., more positive text) in the control group compared to users with ADHD, MDD, and PTSD. Valence variability was significantly lower in the control group compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but not PPD. Rise and recovery rates of valence also exhibited significant differences from the control. This work provides important early evidence for how linguistic cues pertaining to emotion dynamics can play a crucial role as biosocial markers for mental illnesses and aid in the understanding, diagnosis, and management of mental health disorders.",https://aclanthology.org/2023.emnlp-main.188,emotion,No,No,No
Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning,"Shah, Sapan  and
Reddy, Sreedhar  and
Bhattacharyya, Pushpak",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.222,"We present a novel retrofitting method to induce emotion aspects into pre-trained language models (PLMs) such as BERT and RoBERTa. Our method updates pre-trained network weights using contrastive learning so that the text fragments exhibiting similar emotions are encoded nearby in the representation space, and the fragments with different emotion content are pushed apart. While doing so, it also ensures that the linguistic knowledge already present in PLMs is not inadvertently perturbed. The language models retrofitted by our method, i.e., BERTEmo and RoBERTaEmo, produce emotion-aware text representations, as evaluated through different clustering and retrieval metrics. For the downstream tasks on sentiment analysis and sarcasm detection, they perform better than their pre-trained counterparts (about 1{\%} improvement in F1-score) and other existing approaches. Additionally, a more significant boost in performance is observed for the retrofitted models over pre-trained ones in few-shot learning setting.",https://aclanthology.org/2023.emnlp-main.222,emotion,No,Yes,Yes
Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction ({DICE}) in Multimodal Online Posts,"Singh, Gopendra  and
Ghosh, Soumitra  and
Verma, Atul  and
Painkra, Chetna  and
Ekbal, Asif",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.275,"Due to its growing impact on public opinion, hate speech on social media has garnered increased attention. While automated methods for identifying hate speech have been presented in the past, they have mostly been limited to analyzing textual content. The interpretability of such models has received very little attention, despite the social and legal consequences of erroneous predictions. In this work, we present a novel problem of \textit{Distress Identification and Cause Extraction (DICE)} from multimodal online posts. We develop a multi-task deep framework for the simultaneous detection of distress content and identify connected causal phrases from the text using emotional information. The emotional information is incorporated into the training process using a zero-shot strategy, and a novel mechanism is devised to fuse the features from the multimodal inputs. Furthermore, we introduce the first-of-its-kind \textit{Distress and Cause annotated Multimodal (DCaM)} dataset of 20,764 social media posts. We thoroughly evaluate our proposed method by comparing it to several existing benchmarks. Empirical assessment and comprehensive qualitative analysis demonstrate that our proposed method works well on distress detection and cause extraction tasks, improving F1 and ROS scores by 1.95{\%} and 3{\%}, respectively, relative to the best-performing baseline. The code and the dataset can be accessed from the following link: \url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html\#DICE}.",https://aclanthology.org/2023.emnlp-main.275,emotion,Yes,Yes,Yes
Modeling Empathic Similarity in Personal Narratives,"Shen, Jocelyn  and
Sap, Maarten  and
Colon-Hernandez, Pedro  and
Park, Hae  and
Breazeal, Cynthia",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.383,"The most meaningful connections between people are often fostered through expression of shared vulnerability and emotional experiences in personal narratives. We introduce a new task of identifying similarity in personal stories based on empathic resonance, i.e., the extent to which two people empathize with each others{'} experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP. Using insights from social psychology, we craft a framework that operationalizes empathic similarity in terms of three key features of stories: main events, emotional trajectories, and overall morals or takeaways. We create EmpathicStories, a dataset of 1,500 personal stories annotated with our empathic similarity features, and 2,000 pairs of stories annotated with empathic similarity scores. Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics. Through a user study with 150 participants, we also assess the effect our model has on retrieving stories that users empathize with, compared to naive semantic similarity-based retrieval, and find that participants empathized significantly more with stories retrieved by our model. Our work has strong implications for the use of empathy-aware models to foster human connection and empathy between people.",https://aclanthology.org/2023.emnlp-main.383,empathy,Yes,Yes,Yes
Empathy Intent Drives Empathy Detection,"Jiang, Liting  and
Wu, Di  and
Mao, Bohui  and
Li, Yanbing  and
Slamu, Wushour",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.386,"Empathy plays an important role in the human dialogue. Detecting the empathetic direction expressed by the user is necessary for empathetic dialogue systems because it is highly relevant to understanding the user{'}s needs. Several studies have shown that empathy intent information improves the ability to response capacity of empathetic dialogue. However, the interaction between empathy detection and empathy intent recognition has not been explored. To this end, we invite 3 experts to manually annotate the healthy empathy detection datasets IEMPATHIZE and TwittEmp with 8 empathy intent labels, and perform joint training for the two tasks. Empirical study has shown that the introduction of empathy intent recognition task can improve the accuracy of empathy detection task, and we analyze possible reasons for this improvement. To make joint training of the two tasks more challenging, we propose a novel framework, Cascaded Label Signal Network, which uses the cascaded interactive attention module and the label signal enhancement module to capture feature exchange information between empathy and empathy intent representations. Experimental results show that our framework outperforms all baselines under both settings on the two datasets.",https://aclanthology.org/2023.emnlp-main.386,empathy,Yes,Yes,No
From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues,"Kumar, Shivani  and
S, Ramaneswaran  and
Akhtar, Md  and
Chakraborty, Tanmoy",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.598,"Understanding emotions during conversation is a fundamental aspect of human communication, driving NLP research for Emotion Recognition in Conversation (ERC). While considerable research has focused on discerning emotions of individual speakers in monolingual dialogues, understanding the emotional dynamics in code-mixed conversations has received relatively less attention. This motivates our undertaking of ERC for code-mixed conversations in this study. Recognizing that emotional intelligence encompasses a comprehension of worldly knowledge, we propose an innovative approach that integrates commonsense information with dialogue context to facilitate a deeper understanding of emotions. To achieve this, we devise an efficient pipeline that extracts relevant commonsense from existing knowledge graphs based on the code-mixed input. Subsequently, we develop an advanced fusion technique that seamlessly combines the acquired commonsense information with the dialogue representation obtained from a dedicated dialogue understanding module. Our comprehensive experimentation showcases the substantial performance improvement obtained through the systematic incorporation of commonsense in ERC. Both quantitative assessments and qualitative analyses further corroborate the validity of our hypothesis, reaffirming the pivotal role of commonsense integration in enhancing ERC.",https://aclanthology.org/2023.emnlp-main.598,emotion,No,No,Yes
{E}-{CORE}: Emotion Correlation Enhanced Empathetic Dialogue Generation,"Fu, Fengyi  and
Zhang, Lei  and
Wang, Quan  and
Mao, Zhendong",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.653,"Achieving empathy is a crucial step toward humanized dialogue systems. Current approaches for empathetic dialogue generation mainly perceive an emotional label to generate an empathetic response conditioned on it, which simply treat emotions independently, but ignore the intrinsic emotion correlation in dialogues, resulting in inaccurate emotion perception and unsuitable response generation. In this paper, we propose a novel emotion correlation enhanced empathetic dialogue generation framework, which comprehensively realizes emotion correlation learning, utilization, and supervising. Specifically, a multi-resolution emotion graph is devised to capture context-based emotion interactions from different resolutions, further modeling emotion correlation. Then we propose an emotion correlation enhanced decoder, with a novel correlation-aware aggregation and soft/hard strategy, respectively improving the emotion perception and response generation. Experimental results on the benchmark dataset demonstrate the superiority of our model in both empathetic perception and expression.",https://aclanthology.org/2023.emnlp-main.653,emotion,Yes,Yes,No
Countering Misinformation via Emotional Response Generation,"Russo, Daniel  and
Kaszefski-Yaschuk, Shane  and
Staiano, Jacopo  and
Guerini, Marco",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.703,"The proliferation of misinformation on social media platforms (SMPs) poses a significant danger to public health, social cohesion and ultimately democracy. Previous research has shown how social correction can be an effective way to curb misinformation, by engaging directly in a constructive dialogue with users who spread {--} often in good faith {--} misleading messages. Although professional fact-checkers are crucial to debunking viral claims, they usually do not engage in conversations on social media. Thereby, significant effort has been made to automate the use of fact-checker material in social correction; however, no previous work has tried to integrate it with the style and pragmatics that are commonly employed in social media communication. To fill this gap, we present VerMouth, the first large-scale dataset comprising roughly 12 thousand claim-response pairs (linked to debunking articles), accounting for both SMP-style and basic emotions, two factors which have a significant role in misinformation credibility and spreading. To collect this dataset we used a technique based on an author-reviewer pipeline, which efficiently combines LLMs and human annotators to obtain high-quality data. We also provide comprehensive experiments showing how models trained on our proposed dataset have significant improvements in terms of output quality and generalization capabilities.",https://aclanthology.org/2023.emnlp-main.703,emotion,Yes,Yes,No
A Training-Free Debiasing Framework with Counterfactual Reasoning for Conversational Emotion Detection,"Tu, Geng  and
Jing, Ran  and
Liang, Bin  and
Yang, Min  and
Wong, Kam-Fai  and
Xu, Ruifeng",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.967,"Unintended dataset biases typically exist in existing Emotion Recognition in Conversations (ERC) datasets, including label bias, where models favor the majority class due to imbalanced training data, as well as the speaker and neutral word bias, where models make unfair predictions because of excessive correlations between specific neutral words or speakers and classes. However, previous studies in ERC generally focus on capturing context-sensitive and speaker-sensitive dependencies, ignoring the unintended dataset biases of data, which hampers the generalization and fairness in ERC. To address this issue, we propose a Training-Free Debiasing framework (TFD) that operates during prediction without additional training. To ensure compatibility with various ERC models, it does not balance data or modify the model structure. Instead, TFD extracts biases from the model by generating counterfactual utterances and contexts and mitigates them using simple yet empirically robust element-wise subtraction operations. Extensive experiments on three public datasets demonstrate that TFD effectively improves generalization ability and fairness across different ERC models.",https://aclanthology.org/2023.emnlp-main.967,emotion,Yes,Yes,No
Joyful: Joint Modality Fusion and Graph Contrastive Learning for Multimoda Emotion Recognition,"Li, Dongyuan  and
Wang, Yusong  and
Funakoshi, Kotaro  and
Okumura, Manabu",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.996,"Multimodal emotion recognition aims to recognize emotions for each utterance from multiple modalities, which has received increasing attention for its application in human-machine interaction. Current graph-based methods fail to simultaneously depict global contextual features and local diverse uni-modal features in a dialogue. Furthermore, with the number of graph layers increasing, they easily fall into over-smoothing. In this paper, we propose a method for joint modality fusion and graph contrastive learning for multimodal emotion recognition (Joyful), where multimodality fusion, contrastive learning, and emotion recognition are jointly optimized. Specifically, we first design a new multimodal fusion mechanism that can provide deep interaction and fusion between the global contextual and uni-modal specific features. Then, we introduce a graph contrastive learning framework with inter- and intra-view contrastive losses to learn more distinguishable representations for samples with different sentiments. Extensive experiments on three benchmark datasets indicate that Joyful achieved state-of-the-art (SOTA) performance compared with all baselines. Code is released on Github (https://anonymous.4open.science/r/MERC-7F88).",https://aclanthology.org/2023.emnlp-main.996,emotion,Yes,No,No
Federated Meta-Learning for Emotion and Sentiment Aware Multi-modal Complaint Identification,"Singh, Apoorva  and
Chandrasekar, Siddarth  and
Saha, Sriparna  and
Sen, Tanmay",2023,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2023.emnlp-main.999,"Automatic detection of consumers{'} complaints about items or services they buy can be critical for organizations and online merchants. Previous studies on complaint identification are limited to text. Images along with the reviews can provide cues to identify complaints better, thus emphasizing the importance of incorporating multi-modal inputs into the process. Generally, the customer{'}s emotional state significantly impacts the complaint expression; thus, the effect of emotion and sentiment on complaint identification must also be investigated. Furthermore, different organizations are usually not allowed to share their privacy-sensitive records due to data security and privacy concerns. Due to these issues, traditional models find it hard to understand and identify complaint patterns, particularly in the financial and healthcare sectors. In this work, we created a new dataset - Multi-modal Complaint Dataset (MCD), a collection of reviews and images of the products posted on the website of the retail giant Amazon. We propose a federated meta-learning-based multi-modal multi-task framework for identifying complaints considering emotion recognition and sentiment analysis as two auxiliary tasks. Experimental results indicate that the proposed approach outperforms the baselines and the state-of-the-art approaches in centralized and federated meta-learning settings.",https://aclanthology.org/2023.emnlp-main.999,emotion,Yes,Yes,No
Evaluation of {C}hinese-{E}nglish Machine Translation of Emotion-Loaded Microblog Texts: A Human Annotated Dataset for the Quality Assessment of Emotion Translation,"Qian, Shenbin  and
Orasan, Constantin  and
Carmo, Felix Do  and
Li, Qiuliang  and
Kanojia, Diptesh",2023,Proceedings of the 24th Annual Conference of the European Association for Machine Translation,,"In this paper, we focus on how current Machine Translation (MT) engines perform on the translation of emotion-loaded texts by evaluating outputs from Google Translate according to a framework proposed in this paper. We propose this evaluation framework based on the Multidimensional Quality Metrics (MQM) and perform detailed error analyses of the MT outputs. From our analysis, we observe that about 50{\%} of MT outputs are erroneous in preserving emotions. After further analysis of the erroneous examples, we find that emotion carrying words and linguistic phenomena such as polysemous words, negation, abbreviation etc., are common causes for these translation errors.",https://aclanthology.org/2023.eamt-1.13,emotion,Yes,No,No
Analysing Mistranslation of Emotions in Multilingual Tweets by Online {MT} Tools,"Saadany, Hadeel  and
Orasan, Constantin  and
Quintana, Rocio Caro  and
Carmo, Felix Do  and
Zilio, Leonardo",2023,Proceedings of the 24th Annual Conference of the European Association for Machine Translation,,"It is common for websites that contain User-Generated Text (UGT) to provide an automatic translation option to reach out to their linguistically diverse users. In such scenarios, the process of translating the users{'} emotions is entirely automatic with no human intervention, neither for post-editing, nor for accuracy checking. In this paper, we assess whether automatic translation tools can be a successful real-life utility in transferring emotion in multilingual tweets. Our analysis shows that the mistranslation of the source tweet can lead to critical errors where the emotion is either completely lost or flipped to an opposite sentiment. We identify linguistic phenomena specific to Twitter data which pose a challenge in translation of emotions and show how frequent these features are in different language pairs. We also show that commonly-used quality metrics can lend false confidence in the performance of online MT tools specifically when the source emotion is distorted in telegraphic messages such as tweets.",https://aclanthology.org/2023.eamt-1.27,emotion,No,No,No
Emotion Analysis from Texts,"Stajner, Sanja  and
Klinger, Roman",2023,Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts,10.18653/v1/2023.eacl-tutorials.2,"Emotion analysis in text is an area of research that encompasses a set of various natural language processing (NLP) tasks, including classification and regression settings, as well as structured prediction tasks like role labelling or stimulus detection. In this tutorial, we provide an overview of research from emotion psychology which sets the ground for choosing adequate NLP methodology, and present existing resources and classification methods used for emotion analysis in texts. We further discuss appraisal theories and how events can be interpreted regarding their presumably caused emotion and briefly introduce emotion role labelling. In addition to these technical topics, we discuss the use cases of emotion analysis in text, their societal impact, ethical considerations, as well as the main challenges in the field.",https://aclanthology.org/2023.eacl-tutorials.2,emotion,No,Yes,Yes
A Unified Framework for Emotion Identification and Generation in Dialogues,"Madasu, Avinash  and
Firdaus, Mauajama  and
Ekbal, Asif",2023,Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop,10.18653/v1/2023.eacl-srw.7,"Social chatbots have gained immense popularity, and their appeal lies not just in their capacity to respond to the diverse requests from users, but also in the ability to develop an emotional connection with users. To further develop and promote social chatbots, we need to concentrate on increasing user interaction and take into account both the intellectual and emotional quotient in the conversational agents. In this paper, we propose a multi-task framework that jointly identifies the emotion of a given dialogue and generates response in accordance to the identified emotion. We employ a {BERT} based network for creating an empathetic system and use a mixed objective function that trains the end-to-end network with both the classification and generation loss. Experimental results show that our proposed framework outperforms current state-of-the-art models.",https://aclanthology.org/2023.eacl-srw.7,emotion,No,Yes,No
Empathy Identification Systems are not Accurately Accounting for Context,"Lee, Andrew  and
Kummerfeld, Jonathan K.  and
An, Larry  and
Mihalcea, Rada",2023,Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics,10.18653/v1/2023.eacl-main.123,"Understanding empathy in text dialogue data is a difficult, yet critical, skill for effective human-machine interaction. In this work, we ask whether systems are making meaningful progress on this challenge. We consider a simple model that checks if an input utterance is similar to a small set of empathetic examples. Crucially, the model does not look at what the utterance is a response to, i.e., the dialogue context. This model performs comparably to other work on standard benchmarks and even outperforms state-of-the-art models for empathetic rationale extraction by 16.7 points on T-F1 and 4.3 on IOU-F1. This indicates that current systems rely on the surface form of the response, rather than whether it is suitable in context. To confirm this, we create examples with dialogue contexts that change the interpretation of the response and show that current systems continue to label utterances as empathetic. We discuss the implications of our findings, including improvements for empathetic benchmarks and how our model can be an informative baseline.",https://aclanthology.org/2023.eacl-main.123,empathy,No,Yes,No
How people talk about each other: Modeling Generalized Intergroup Bias and Emotion,"Govindarajan, Venkata Subrahmanyan  and
Atwell, Katherine  and
Sinno, Barea  and
Alikhani, Malihe  and
Beaver, David I.  and
Li, Junyi Jessy",2023,Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics,10.18653/v1/2023.eacl-main.183,"Current studies of bias in NLP rely mainly on identifying (unwanted or negative) bias towards a specific demographic group. While this has led to progress recognizing and mitigating negative bias, and having a clear notion of the targeted group is necessary, it is not always practical. In this work we extrapolate to a broader notion of bias, rooted in social science and psychology literature. We move towards predicting interpersonal group relationship (IGR) - modeling the relationship between the speaker and the target in an utterance - using fine-grained interpersonal emotions as an anchor. We build and release a dataset of English tweets by US Congress members annotated for interpersonal emotion - the first of its kind, and {`}found supervision{'} for IGR labels; our analyses show that subtle emotional signals are indicative of different biases. While humans can perform better than chance at identifying IGR given an utterance, we show that neural models perform much better; furthermore, a shared encoding between IGR and interpersonal perceived emotion enabled performance gains in both tasks.",https://aclanthology.org/2023.eacl-main.183,emotion,Yes,Yes,Yes
Conversational Emotion-Cause Pair Extraction with Guided Mixture of Experts,"Jeong, DongJin  and
Bak, JinYeong",2023,Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics,10.18653/v1/2023.eacl-main.240,"Emotion-Cause Pair Extraction (ECPE) task aims to pair all emotions and corresponding causes in documents.ECPE is an important task for developing human-like responses. However, previous ECPE research is conducted based on news articles, which has different characteristics compared to dialogues. To address this issue, we propose a Pair-Relationship Guided Mixture-of-Experts (PRG-MoE) model, which considers dialogue features (e.g., speaker information).PRG-MoE automatically learns relationship between utterances and advises a gating network to incorporate dialogue features in the evaluation, yielding substantial performance improvement. We employ a new ECPE dataset, which is an English dialogue dataset, with more emotion-cause pairs in documents than news articles. We also propose Cause Type Classification that classifies emotion-cause pairs according to the types of the cause of a detected emotion. For reproducing the results, we make available all our code and data.",https://aclanthology.org/2023.eacl-main.240,emotion,Yes,Yes,No
Social Media Data Analysis for {M}alayalam {Y}ou{T}ube Comments: Sentiment Analysis and Emotion Detection using {ML} and {DL} Models,"V P, Abeera  and
Kumar, Dr. Sachin  and
K P, Dr. Soman",2023,Proceedings of the Third Workshop on Speech and Language Technologies for Dravidian Languages,,"In this paper, we present a study on social media data analysis of Malayalam YouTube comments, specifically focusing on sentiment analysis and emotion detection. Our research aims to investigate the effectiveness of various machine learning (ML) and deep learning (DL) models in addressing these two tasks. For sentiment analysis, we collected a dataset consisting of 3064 comments, while for two-class emotion detection, we used a dataset of 817 comments. In the sentiment analysis phase, we explored multiple ML and DL models, including traditional algorithms such as Support Vector Machines (SVM), Na{\""\i}ve Bayes, K-Nearest Neighbors (KNN), MLP Classifier, Decision Tree, and Random Forests. Additionally, we utilized DL models such as Recurrent Neural Networks (RNN), LSTM, and GRU. To enhance the performance of these models, we preprocessed the Malayalam YouTube comments by tokenizing and removing stop words. Experimental results revealed that DL models achieved higher accuracy compared to ML models, indicating their ability to capture the complex patterns and nuances in the Malayalam language. Furthermore, we extended our analysis to emotion detection, which involved dealing with limited annotated data. This task is closely related to social media data analysis. For emotion detection, we employed the same ML models used in the sentiment analysis phase. Our dataset of 817 comments was annotated with two emotions: Happy and Sad. We trained the models to classify the comments into these emotion classes and analyzed the accuracy of the different models.",https://aclanthology.org/2023.dravidianlangtech-1.6,emotion,Yes,Yes,No
Investigating Stylistic Profiles for the Task of Empathy Classification in Medical Narrative Essays,"Dey, Priyanka  and
Girju, Roxana",2023,"Proceedings of the First International Workshop on Construction Grammars and NLP (CxGs+NLP, GURT/SyntaxFest 2023)",,"One important aspect of language is how speakers generate utterances and texts to convey their intended meanings. In this paper, we bring various aspects of the Construction Grammar (CxG) and the Systemic Functional Grammar (SFG) theories in a deep learning computational framework to model empathic language. Our corpus consists of 440 essays written by premed students as narrated simulated patient{--}doctor interactions. We start with baseline classifiers (state-of-the-art recurrent neural networks and transformer models). Then, we enrich these models with a set of linguistic constructions proving the importance of this novel approach to the task of empathy classification for this dataset. Our results indicate the potential of such constructions to contribute to the overall empathy profile of first-person narrative essays.",https://aclanthology.org/2023.cxgsnlp-1.8,empathy,Yes,Yes,No
"Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus Creation, Annotation Reliability, and Prediction","Troiano, Enrica  and
Oberl{\""a}nder, Laura  and
Klinger, Roman",2023,,10.1162/coli_a_00461,"The most prominent tasks in emotion analysis are to assign emotions to texts and to understand how emotions manifest in language. An important observation for natural language processing is that emotions can be communicated implicitly by referring to events alone, appealing to an empathetic, intersubjective understanding of events, even without explicitly mentioning an emotion name. In psychology, the class of emotion theories known as appraisal theories aims at explaining the link between events and emotions. Appraisals can be formalized as variables that measure a cognitive evaluation by people living through an event that they consider relevant. They include the assessment if an event is novel, if the person considers themselves to be responsible, if it is in line with their own goals, and so forth. Such appraisals explain which emotions are developed based on an event, for example, that a novel situation can induce surprise or one with uncertain consequences could evoke fear. We analyze the suitability of appraisal theories for emotion analysis in text with the goal of understanding if appraisal concepts can reliably be reconstructed by annotators, if they can be predicted by text classifiers, and if appraisal concepts help to identify emotion categories. To achieve that, we compile a corpus by asking people to textually describe events that triggered particular emotions and to disclose their appraisals. Then, we ask readers to reconstruct emotions and appraisals from the text. This set-up allows us to measure if emotions and appraisals can be recovered purely from text and provides a human baseline to judge a model{'}s performance measures. Our comparison of text classification methods to human annotators shows that both can reliably detect emotions and appraisals with similar performance. Therefore, appraisals constitute an alternative computational emotion analysis paradigm and further improve the categorization of emotions in text with joint models.",https://aclanthology.org/2023.cl-1.1,emotion,Yes,Yes,Yes
(Multimodal Emotion Recognition in Conversation with Mutual Information Maximization and Contrastive Loss),"Li, Qianer  and
Huang, Peijie  and
Chen, Jiawei  and
Wu, Jialin  and
Xu, Yuhong  and
Lin, Peiyuan",2023,Proceedings of the 22nd Chinese National Conference on Computational Linguistics,,"{``}(emotion recognition in conversation,ERC),,,,MMIC(mutual information),,(supervised contrastive learning),,,,,{''}",https://aclanthology.org/2023.ccl-1.24,emotion,No,Yes,No
Where are We in Event-centric Emotion Analysis? Bridging Emotion Role Labeling and Appraisal-based Approaches,"Klinger, Roman",2023,Proceedings of the Big Picture Workshop,10.18653/v1/2023.bigpicture-1.1,"The term emotion analysis in text subsumes various natural language processing tasks which have in common the goal to enable computers to understand emotions. Most popular is emotion classification in which one or multiple emotions are assigned to a predefined textual unit. While such setting is appropriate for identifying the reader{'}s or author{'}s emotion, emotion role labeling adds the perspective of mentioned entities and extracts text spans that correspond to the emotion cause. The underlying emotion theories agree on one important point; that an emotion is caused by some internal or external event and comprises several subcomponents, including the subjective feeling and a cognitive evaluation. We therefore argue that emotions and events are related in two ways. (1) Emotions are events; and this perspective is the fundament in natural language processing for emotion role labeling. (2) Emotions are caused by events; a perspective that is made explicit with research how to incorporate psychological appraisal theories in NLP models to interpret events. These two research directions, role labeling and (event-focused) emotion classification, have by and large been tackled separately. In this paper, we contextualize both perspectives and discuss open research questions.",https://aclanthology.org/2023.bigpicture-1.1,emotion,No,Yes,Yes
{BE}mo{L}ex{BERT}: A Hybrid Model for Multilabel Textual Emotion Classification in {B}angla by Combining Transformers with Lexicon Features,"Kabir, Ahasan  and
Roy, Animesh  and
Taheri, Zaima",2023,Proceedings of the First Workshop on Bangla Language Processing (BLP-2023),10.18653/v1/2023.banglalp-1.7,"Multilevel textual emotion classification involves the extraction of emotions from text data, a task that has seen significant progress in high resource languages. However, resource-constrained languages like Bangla have received comparatively less attention in the field of emotion classification. Furthermore, the availability of a comprehensive and accurate emotion lexiconspecifically designed for the Bangla language is limited. In this paper, we present a hybrid model that combines lexicon features with transformers for multilabel emotion classification in the Bangla language. We have developed a comprehensive Bangla emotion lexicon consisting of 5336 carefully curated lexicons across nine emotion categories. We experimented with pre-trained transformers including mBERT, XLM-R, BanglishBERT, and BanglaBERT on the EmoNaBa (Islam et al.,2022) dataset. By integrating lexicon features from our emotion lexicon, we evaluate the performance of these transformers in emotion detection tasks. The results demonstrate that incorporating lexicon features significantly improves the performance of transformers. Among the evaluated models, our hybrid approach achieves the highest performance using BanglaBERT(large) (Bhattacharjee et al., 2022) as the pre-trained transformer along with our emotion lexicon, achieving an impressive weighted F1 score of 82.73{\%}. The emotion lexicon is publicly available at https://github.com/Ahasannn/BEmoLex-Bangla{\_}Emotion{\_}Lexicon",https://aclanthology.org/2023.banglalp-1.7,emotion,Yes,Yes,No
Predicting Empathic Accuracy from User-Designer Interviews,"Nguyen, Steven  and
Beck, Daniel  and
Holtta-Otto, Katja",2023,Proceedings of the 21st Annual Workshop of the Australasian Language Technology Association,,"Measuring empathy as a natural language processing task has often been limited to a subjective measure of how well individuals respond to each other in emotive situations. Cognitive empathy, or an individual{'}s ability to accurately assess another individual{'}s thoughts, remains a more novel task. In this paper, we explore natural language processing techniques to measure cognitive empathy using paired sentence data from design interviews. Our findings show that an unsupervised approach based on similarity of vectors from a Large Language Model is surprisingly promising, while adding supervision does not necessarily improve the performance. An analysis of the results highlights potential reasons for this behaviour and gives directions for future work in this space.",https://aclanthology.org/2023.alta-1.14,empathy,No,Yes,Yes
The uncivil empathy: Investigating the relation between empathy and toxicity in online mental health support forums,"Chen, Ming-Bin  and
Lau, Jey Han  and
Frermann, Lea",2023,Proceedings of the 21st Annual Workshop of the Australasian Language Technology Association,,"We explore the relationship between empathy and toxicity in the context of online mental health forums. Despite the common assumption of a negative correlation between these concepts, it has not been empirically examined. We augment the EPITOME mental health empathy dataset with toxicity labels using two widely employed toxic/harmful content detection APIs: Perspective API and OpenAI moderation API. We find a notable presence of toxic/harmful content (17.77{\%}) within empathetic responses, and only a very weak negative correlation between the two variables. Qualitative analysis revealed contributions labeled as empathetic often contain harmful content such as promotion of suicidal ideas. Our results highlight the need for reevaluating empathy independently from toxicity in future research and encourage a reconsideration of empathy{'}s role in natural language generation and evaluation.",https://aclanthology.org/2023.alta-1.16,empathy,Yes,No,No
Unveiling Emotional Landscapes in Plautus and Terentius Comedies: A Computational Approach for Qualitative Analysis,"Picca, Davide  and
Richard, Caroline",2023,Proceedings of the Ancient Language Processing Workshop,,"This ongoing study explores emotion recognition in Latin texts, specifically focusing on Latin comedies. Leveraging Natural Language Processing and classical philology insights, the project navigates the challenges of Latin{'}s intricate grammar and nuanced emotional expression. Despite initial challenges with lexicon translation and emotional alignment, the work provides a foundation for a more comprehensive analysis of emotions in Latin literature.",https://aclanthology.org/2023.alp-1.10,emotion,No,No,Yes
Using Word Embeddings for Identifying Emotions Relating to the Body in a {N}eo-{A}ssyrian Corpus,"Bennett, Ellie  and
Sahala, Aleksi",2023,Proceedings of the Ancient Language Processing Workshop,,"Research into emotions is a developing field within Assyriology, and NLP tools for Akkadian texts offers a new perspective on the data. In this submission, we use PMI-based word embeddings to explore the relationship between parts of the body and emotions. Using data downloaded from Oracc, we ask which parts of the body were semantically linked to emotions. We do this through examining which of the top 10 results for a body part could be used to express emotions. After identifying two words for the body that have the most emotion words in their results list (\textit{libbu} and \textit{kabattu}), we then examine whether the emotion words in their results lists were indeed used in this manner in the Neo-Assyrian textual corpus. The results indicate that of the two body parts, \textit{kabattu} was semantically linked to happiness and joy, and had a secondary emotional field of anger.",https://aclanthology.org/2023.alp-1.22,emotion,Yes,No,Yes
Layer-wise Fusion with Modality Independence Modeling for Multi-modal Emotion Recognition,"Sun, Jun  and
Han, Shoukang  and
Ruan, Yu-Ping  and
Zhang, Xiaoning  and
Zheng, Shu-Kai  and
Liu, Yulong  and
Huang, Yuxin  and
Li, Taihao",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.39,"Multi-modal emotion recognition has gained increasing attention in recent years due to its widespread applications and the advances in multi-modal learning approaches. However, previous studies primarily focus on developing models that exploit the unification of multiple modalities. In this paper, we propose that maintaining modality independence is beneficial for the model performance. According to this principle, we construct a dataset, and devise a multi-modal transformer model. The new dataset, CHinese Emotion Recognition dataset with Modality-wise Annotions, abbreviated as CHERMA, provides uni-modal labels for each individual modality, and multi-modal labels for all modalities jointly observed. The model consists of uni-modal transformer modules that learn representations for each modality, and a multi-modal transformer module that fuses all modalities. All the modules are supervised by their corresponding labels separately, and the forward information flow is uni-directionally from the uni-modal modules to the multi-modal module. The supervision strategy and the model architecture guarantee each individual modality learns its representation independently, and meanwhile the multi-modal module aggregates all information. Extensive empirical results demonstrate that our proposed scheme outperforms state-of-the-art alternatives, corroborating the importance of modality independence in multi-modal emotion recognition. The dataset and codes are availabel at \url{https://github.com/sunjunaimer/LFMIM}",https://aclanthology.org/2023.acl-long.39,emotion,Yes,Yes,No
Joint Constrained Learning with Boundary-adjusting for Emotion-Cause Pair Extraction,"Feng, Huawen  and
Liu, Junlong  and
Zheng, Junhao  and
Chen, Haibin  and
Shang, Xichen  and
Ma, Qianli",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.62,"Emotion-Cause Pair Extraction (ECPE) aims to identify the document{'}s emotion clauses and corresponding cause clauses. Like other relation extraction tasks, ECPE is closely associated with the relationship between sentences. Recent methods based on Graph Convolutional Networks focus on how to model the multiplex relations between clauses by constructing different edges. However, the data of emotions, causes, and pairs are extremely unbalanced, and current methods get their representation using the same graph structure. In this paper, we propose a **J**oint **C**onstrained Learning framework with **B**oundary-adjusting for Emotion-Cause Pair Extraction (**JCB**). Specifically, through constrained learning, we summarize the prior rules existing in the data and force the model to take them into consideration in optimization, which helps the model learn a better representation from unbalanced data. Furthermore, we adjust the decision boundary of classifiers according to the relations between subtasks, which have always been ignored. No longer working independently as in the previous framework, the classifiers corresponding to three subtasks cooperate under the relation constraints. Experimental results show that **JCB** obtains competitive results compared with state-of-the-art methods and prove its robustness on unbalanced data.",https://aclanthology.org/2023.acl-long.62,emotion,No,Yes,No
Facilitating Multi-turn Emotional Support Conversation with Positive Emotion Elicitation: A Reinforcement Learning Approach,"Zhou, Jinfeng  and
Chen, Zhuang  and
Wang, Bo  and
Huang, Minlie",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.96,"Emotional support conversation (ESC) aims to provide emotional support (ES) to improve one{'}s mental state. Existing works stay at fitting grounded responses and responding strategies (e.g., \textit{question}), which ignore the effect on ES and lack explicit goals to guide emotional positive transition. To this end, we introduce a new paradigm to formalize multi-turn ESC as a process of positive emotion elicitation. Addressing this task requires finely adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence. In this paper, we propose Supporter, a mixture-of-expert-based reinforcement learning model, and well design ES and dialogue coherence rewards to guide policy{'}s learning for responding. Experiments verify the superiority of Supporter in achieving positive emotion elicitation during responding while maintaining conversational goals including coherence.",https://aclanthology.org/2023.acl-long.96,emotion,No,Yes,No
Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations,"Deng, Yang  and
Zhang, Wenxuan  and
Yuan, Yifei  and
Lam, Wai",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.225,"Unlike empathetic dialogues, the system in emotional support conversations (ESC) is expected to not only convey empathy for comforting the help-seeker, but also proactively assist in exploring and addressing their problems during the conversation. In this work, we study the problem of mixed-initiative ESC where the user and system can both take the initiative in leading the conversation. Specifically, we conduct a novel analysis on mixed-initiative ESC systems with a tailor-designed schema that divides utterances into different types with speaker roles and initiative types. Four emotional support metrics are proposed to evaluate the mixed-initiative interactions. The analysis reveals the necessity and challenges of building mixed-initiative ESC systems. In the light of this, we propose a knowledge-enhanced mixed-initiative framework (KEMI) for ESC, which retrieves actual case knowledge from a large-scale mental health knowledge graph for generating mixed-initiative responses. Experimental results on two ESC datasets show the superiority of KEMI in both content-preserving evaluation and mixed initiative related analyses.",https://aclanthology.org/2023.acl-long.225,emotion,No,No,No
{D}ual{GAT}s: Dual Graph Attention Networks for Emotion Recognition in Conversations,"Zhang, Duzhen  and
Chen, Feilong  and
Chen, Xiuyi",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.408,"Capturing complex contextual dependencies plays a vital role in Emotion Recognition in Conversations (ERC). Previous studies have predominantly focused on speaker-aware context modeling, overlooking the discourse structure of the conversation. In this paper, we introduce Dual Graph ATtention networks (DualGATs) to concurrently consider the complementary aspects of discourse structure and speaker-aware context, aiming for more precise ERC. Specifically, we devise a Discourse-aware GAT (DisGAT) module to incorporate discourse structural information by analyzing the discourse dependencies between utterances. Additionally, we develop a Speaker-aware GAT (SpkGAT) module to incorporate speaker-aware contextual information by considering the speaker dependencies between utterances. Furthermore, we design an interaction module that facilitates the integration of the DisGAT and SpkGAT modules, enabling the effective interchange of relevant information between the two modules. We extensively evaluate our method on four datasets, and experimental results demonstrate that our proposed DualGATs surpass state-of-the-art baselines on the majority of the datasets.",https://aclanthology.org/2023.acl-long.408,emotion,No,Yes,No
Unsupervised Extractive Summarization of Emotion Triggers,"Sosea, Tiberiu  and
Zhan, Hongli  and
Li, Junyi Jessy  and
Caragea, Cornelia",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.531,"Understanding what leads to emotions during large-scale crises is important as it can provide groundings for expressed emotions and subsequently improve the understanding of ongoing disasters. Recent approaches trained supervised models to both detect emotions and explain emotion triggers (events and appraisals) via abstractive summarization. However, obtaining timely and qualitative abstractive summaries is expensive and extremely time-consuming, requiring highly-trained expert annotators. In time-sensitive, high-stake contexts, this can block necessary responses. We instead pursue unsupervised systems that extract triggers from text. First, we introduce CovidET-EXT, augmenting (Zhan et al., 2022){'}s abstractive dataset (in the context of the COVID-19 crisis) with extractive triggers. Second, we develop new unsupervised learning models that can jointly detect emotions and summarize their triggers. Our best approach, entitled Emotion-Aware Pagerank, incorporates emotion information from external sources combined with a language understanding module, and outperforms strong baselines. We release our data and code at \url{https://github.com/tsosea2/CovidET-EXT}.",https://aclanthology.org/2023.acl-long.531,emotion,Yes,Yes,No
Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations,"Hu, Dou  and
Bao, Yinan  and
Wei, Lingwei  and
Zhou, Wei  and
Hu, Songlin",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.606,"Extracting generalized and robust representations is a major challenge in emotion recognition in conversations (ERC). To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations in a supervised manner. SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model{'}s context robustness. Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC. Experiments on three datasets show that SACL-LSTM achieves state-of-the-art performance on ERC. Extended experiments prove the effectiveness of SACL and CAT.",https://aclanthology.org/2023.acl-long.606,emotion,No,Yes,No
Label-Aware Hyperbolic Embeddings for Fine-grained Emotion Classification,"Chen, Chih Yao  and
Hung, Tun Min  and
Hsu, Yi-Li  and
Ku, Lun-Wei",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.613,"Fine-grained emotion classification (FEC) is a challenging task. Specifically, FEC needs to handle subtle nuance between labels, which can be complex and confusing. Most existing models only address text classification problem in the euclidean space, which we believe may not be the optimal solution as labels of close semantic (e.g., afraid and terrified) may not be differentiated in such space, which harms the performance. In this paper, we propose HypEmo, a novel framework that can integrate hyperbolic embeddings to improve the FEC task. First, we learn label embeddings in the hyperbolic space to better capture their hierarchical structure, and then our model projects contextualized representations to the hyperbolic space to compute the distance between samples and labels. Experimental results show that incorporating such distance to weight cross entropy loss substantially improve the performance on two benchmark datasets, with around 3{\%} improvement compared to previous state-of-the-art, and could even improve up to 8.6{\%} when the labels are hard to distinguish. Code is available at \url{https://github.com/dinobby/HypEmo}.",https://aclanthology.org/2023.acl-long.613,emotion,Yes,Yes,No
{PAL} to Lend a Helping Hand: Towards Building an Emotion Adaptive Polite and Empathetic Counseling Conversational Agent,"Mishra, Kshitij  and
Priya, Priyanshu  and
Ekbal, Asif",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.685,"The World Health Organization (WHO) has significantly emphasized the need for mental health care. The social stigma associated with mental illness prevents individuals from addressing their issues and getting assistance. In such a scenario, the relevance of online counseling has increased dramatically. The feelings and attitudes that a client and a counselor express towards each other result in a higher or lower counseling experience. A counselor should be friendly and gain clients{'} trust to make them share their problems comfortably. Thus, it is essential for the counselor to adequately comprehend the client{'}s emotions and ensure client{'}s welfare, i.e. s/he should adapt and deal with the clients politely and empathetically to provide a pleasant, cordial and personalized experience. Motivated by this, in this work, we attempt to build a novel Polite and empAthetic counseLing conversational agent PAL to lay down the counseling support to substance addict and crime victims. To have client{'}s emotion-based polite and empathetic responses, two counseling datasets laying down the counseling support to substance addicts and crime victims are annotated. These annotated datasets are used to build PAL in a reinforcement learning framework. A novel reward function is formulated to ensure correct politeness and empathy preferences as per client{'}s emotions with naturalness and non-repetitiveness in responses. Thorough automatic and human evaluation showcase the usefulness and strength of the designed novel reward function. Our proposed system is scalable and can be easily modified with different modules of preference models as per need.",https://aclanthology.org/2023.acl-long.685,emotion,Yes,Yes,No
A Cross-Modality Context Fusion and Semantic Refinement Network for Emotion Recognition in Conversation,"Zhang, Xiaoheng  and
Li, Yang",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.732,"Emotion recognition in conversation (ERC) has attracted enormous attention for its applications in empathetic dialogue systems. However, most previous researches simply concatenate multimodal representations, leading to an accumulation of redundant information and a limited context interaction between modalities. Furthermore, they only consider simple contextual features ignoring semantic clues, resulting in an insufficient capture of the semantic coherence and consistency in conversations. To address these limitations, we propose a cross-modality context fusion and semantic refinement network (CMCF-SRNet). Specifically, we first design a cross-modal locality-constrained transformer to explore the multimodal interaction. Second, we investigate a graph-based semantic refinement transformer, which solves the limitation of insufficient semantic relationship information between utterances. Extensive experiments on two public benchmark datasets show the effectiveness of our proposed method compared with other state-of-the-art methods, indicating its potential application in emotion recognition. Our model will be available at \url{https://github.com/zxiaohen/CMCF-SRNet}.",https://aclanthology.org/2023.acl-long.732,emotion,Yes,Yes,No
{M}ulti{EMO}: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations,"Shi, Tao  and
Huang, Shao-Lun",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.824,"Emotion Recognition in Conversations (ERC) is an increasingly popular task in the Natural Language Processing community, which seeks to achieve accurate emotion classifications of utterances expressed by speakers during a conversation. Most existing approaches focus on modeling speaker and contextual information based on the textual modality, while the complementarity of multimodal information has not been well leveraged, few current methods have sufficiently captured the complex correlations and mapping relationships across different modalities. Furthermore, existing state-of-the-art ERC models have difficulty classifying minority and semantically similar emotion categories. To address these challenges, we propose a novel attention-based correlation-aware multimodal fusion framework named MultiEMO, which effectively integrates multimodal cues by capturing cross-modal mapping relationships across textual, audio and visual modalities based on bidirectional multi-head cross-attention layers. The difficulty of recognizing minority and semantically hard-to-distinguish emotion classes is alleviated by our proposed Sample-Weighted Focal Contrastive (SWFC) loss. Extensive experiments on two benchmark ERC datasets demonstrate that our MultiEMO framework consistently outperforms existing state-of-the-art approaches in all emotion categories on both datasets, the improvements in minority and semantically similar emotions are especially significant.",https://aclanthology.org/2023.acl-long.824,emotion,Yes,Yes,Yes
A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations,"Zheng, Wenjie  and
Yu, Jianfei  and
Xia, Rui  and
Wang, Shijin",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.861,"Multimodal Emotion Recognition in Multiparty Conversations (MERMC) has recently attracted considerable attention. Due to the complexity of visual scenes in multi-party conversations, most previous MERMC studies mainly focus on text and audio modalities while ignoring visual information. Recently, several works proposed to extract face sequences as visual features and have shown the importance of visual information in MERMC. However, given an utterance, the face sequence extracted by previous methods may contain multiple people{'}s faces, which will inevitably introduce noise to the emotion prediction of the real speaker. To tackle this issue, we propose a two-stage framework named Facial expressionaware Multimodal Multi-Task learning (FacialMMT). Specifically, a pipeline method is first designed to extract the face sequence of the real speaker of each utterance, which consists of multimodal face recognition, unsupervised face clustering, and face matching. With the extracted face sequences, we propose a multimodal facial expression-aware emotion recognition model, which leverages the frame-level facial emotion distributions to help improve utterance-level emotion recognition based on multi-task learning. Experiments demonstrate the effectiveness of the proposed FacialMMT framework on the benchmark MELD dataset. The source code is publicly released at \url{https://github.com/NUSTM/FacialMMT}.",https://aclanthology.org/2023.acl-long.861,emotion,Yes,Yes,No
Estimating the Uncertainty in Emotion Attributes using Deep Evidential Regression,"Wu, Wen  and
Zhang, Chao  and
Woodland, Philip",2023,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2023.acl-long.873,"In automatic emotion recognition (AER), labels assigned by different human annotators to the same utterance are often inconsistent due to the inherent complexity of emotion and the subjectivity of perception. Though deterministic labels generated by averaging or voting are often used as the ground truth, it ignores the intrinsic uncertainty revealed by the inconsistent labels. This paper proposes a Bayesian approach, deep evidential emotion regression (DEER), to estimate the uncertainty in emotion attributes. Treating the emotion attribute labels of an utterance as samples drawn from an unknown Gaussian distribution, DEER places an utterance-specific normal-inverse gamma prior over the Gaussian likelihood and predicts its hyper-parameters using a deep neural network model. It enables a joint estimation of emotion attributes along with the aleatoric and epistemic uncertainties. AER experiments on the widely used MSP-Podcast and IEMOCAP datasets showed DEER produced state-of-the-art results for both the mean values and the distribution of emotion attributes.",https://aclanthology.org/2023.acl-long.873,emotion,No,Yes,No
An Emotional Journey: Detecting Emotion Trajectories in {D}utch Customer Service Dialogues,"Labat, Sofie  and
Hadifar, Amir  and
Demeester, Thomas  and
Hoste, Veronique",2022,Proceedings of the Eighth Workshop on Noisy User-generated Text (W-NUT 2022),,"The ability to track fine-grained emotions in customer service dialogues has many real-world applications, but has not been studied extensively. This paper measures the potential of prediction models on that task, based on a real-world dataset of Dutch Twitter conversations in the domain of customer service. We find that modeling emotion trajectories has a small, but measurable benefit compared to predictions based on isolated turns. The models used in our study are shown to generalize well to different companies and economic sectors.",https://aclanthology.org/2022.wnut-1.12,emotion,Yes,Yes,No
Identifying Emotions in Code Mixed {H}indi-{E}nglish Tweets,"Sonu, Sanket  and
Haque, Rejwanul  and
Hasanuzzaman, Mohammed  and
Stynes, Paul  and
Pathak, Pramod",2022,Proceedings of the WILDRE-6 Workshop within the 13th Language Resources and Evaluation Conference,,"Emotion detection (ED) in tweets is a text classification problem that is of interest to Natural Language Processing (NLP) researchers. Code-mixing (CM) is a process of mixing linguistic units such as words of two different languages. The CM languages are characteristically different from the languages whose linguistic units are used for mixing. Whilst NLP has been shown to be successful for low-resource languages, it becomes challenging to perform NLP tasks on CM languages. As for ED, it has been rarely investigated on CM languages such as Hindi{---}English due to the lack of training data that is required for today{'}s data-driven classification algorithms. This research proposes a gold standard dataset for detecting emotions in CM Hindi{--}English tweets. This paper also presents our results about the investigation of the usefulness of our gold-standard dataset while testing a number of state-of-the-art classification algorithms. We found that the ED classifier built using SVM provided us the highest accuracy (75.17{\%}) on the hold-out test set. This research would benefit the NLP community in detecting emotions from social media platforms in multilingual societies.",https://aclanthology.org/2022.wildre-1.7,emotion,Yes,Yes,Yes
On the Complementarity of Images and Text for the Expression of Emotions in Social Media,"Khlyzova, Anna  and
Silberer, Carina  and
Klinger, Roman",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.1,"Authors of posts in social media communicate their emotions and what causes them with text and images. While there is work on emotion and stimulus detection for each modality separately, it is yet unknown if the modalities contain complementary emotion information in social media. We aim at filling this research gap and contribute a novel, annotated corpus of English multimodal Reddit posts. On this resource, we develop models to automatically detect the relation between image and text, an emotion stimulus category and the emotion class. We evaluate if these tasks require both modalities and find for the image{--}text relations, that text alone is sufficient for most categories (complementary, illustrative, opposing): the information in the text allows to predict if an image is required for emotion understanding. The emotions of anger and sadness are best predicted with a multimodal model, while text alone is sufficient for disgust, joy, and surprise. Stimuli depicted by objects, animals, food, or a person are best predicted by image-only models, while multimodal mod- els are most effective on art, events, memes, places, or screenshots.",https://aclanthology.org/2022.wassa-1.1,emotion,Yes,Yes,No
{``}splink{''} is happy and {``}phrouth{''} is scary: Emotion Intensity Analysis for Nonsense Words,"Sabbatino, Valentino  and
Troiano, Enrica  and
Schweitzer, Antje  and
Klinger, Roman",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.4,"People associate affective meanings to words - {``}death{''} is scary and sad while {``}party{''} is connotated with surprise and joy. This raises the question if the association is purely a product of the learned affective imports inherent to semantic meanings, or is also an effect of other features of words, e.g., morphological and phonological patterns. We approach this question with an annotation-based analysis leveraging nonsense words. Specifically, we conduct a best-worst scaling crowdsourcing study in which participants assign intensity scores for joy, sadness, anger, disgust, fear, and surprise to 272 non-sense words and, for comparison of the results to previous work, to 68 real words. Based on this resource, we develop character-level and phonology-based intensity regressors. We evaluate them on both nonsense words and real words (making use of the NRC emotion intensity lexicon of 7493 words), across six emotion categories. The analysis of our data reveals that some phonetic patterns show clear differences between emotion intensities. For instance, s as a first phoneme contributes to joy, sh to surprise, p as last phoneme more to disgust than to anger and fear. In the modelling experiments, a regressor trained on real words from the NRC emotion intensity lexicon shows a higher performance (r = 0.17) than regressors that aim at learning the emotion connotation purely from nonsense words. We conclude that humans do associate affective meaning to words based on surface patterns, but also based on similarities to existing words ({``}juy{''} to {``}joy{''}, or {``}flike{''} to {``}like{''}).",https://aclanthology.org/2022.wassa-1.4,emotion,No,Yes,No
{S}ent{EMO}: A Multilingual Adaptive Platform for Aspect-based Sentiment and Emotion Analysis,"De Geyndt, Ellen  and
De Clercq, Orphee  and
Van Hee, Cynthia  and
Lefever, Els  and
Singh, Pranaydeep  and
Parent, Olivier  and
Hoste, Veronique",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.5,"In this paper, we present the SentEMO platform, a tool that provides aspect-based sentiment analysis and emotion detection of unstructured text data such as reviews, emails and customer care conversations. Currently, models have been trained for five domains and one general domain and are implemented in a pipeline approach, where the output of one model serves as the input for the next. The results are presented in three dashboards, allowing companies to gain more insights into what stakeholders think of their products and services. The SentEMO platform is available at \url{https://sentemo.ugent.be}",https://aclanthology.org/2022.wassa-1.5,emotion,No,Yes,No
Can Emotion Carriers Explain Automatic Sentiment Prediction? A Study on Personal Narratives,"Mousavi, Seyed Mahed  and
Roccabruna, Gabriel  and
Tammewar, Aniruddha  and
Azzolin, Steve  and
Riccardi, Giuseppe",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.6,"Deep Neural Networks (DNN) models have achieved acceptable performance in sentiment prediction of written text. However, the output of these machine learning (ML) models cannot be natively interpreted. In this paper, we study how the sentiment polarity predictions by DNNs can be explained and compare them to humans{'} explanations. We crowdsource a corpus of Personal Narratives and ask human judges to annotate them with polarity and select the corresponding token chunks - the Emotion Carriers (EC) - that convey narrators{'} emotions in the text. The interpretations of ML neural models are carried out through Integrated Gradients method and we compare them with human annotators{'} interpretations. The results of our comparative analysis indicate that while the ML model mostly focuses on the explicit appearance of emotions-laden words (e.g. happy, frustrated), the human annotator predominantly focuses the attention on the manifestation of emotions through ECs that denote events, persons, and objects which activate narrator{'}s emotional state.",https://aclanthology.org/2022.wassa-1.6,emotion,Yes,Yes,No
Emotion Analysis of Writers and Readers of {J}apanese Tweets on Vaccinations,"Ramos, Patrick John  and
Ferawati, Kiki  and
Liew, Kongmeng  and
Aramaki, Eiji  and
Wakamiya, Shoko",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.10,"Public opinion in social media is increasingly becoming a critical factor in pandemic control. Understanding the emotions of a population towards vaccinations and COVID-19 may be valuable in convincing members to become vaccinated. We investigated the emotions of Japanese Twitter users towards Tweets related to COVID-19 vaccination. Using the WRIME dataset, which provides emotion ratings for Japanese Tweets sourced from writers (Tweet posters) and readers, we fine-tuned a BERT model to predict levels of emotional intensity. This model achieved a training accuracy of $MSE$ = 0.356. A separate dataset of 20,254 Japanese Tweets containing COVID-19 vaccine-related keywords was also collected, on which the fine-tuned BERT was used to perform emotion analysis. Afterwards, a correlation analysis between the extracted emotions and a set of vaccination measures in Japan was conducted.The results revealed that surprise and fear were the most intense emotions predicted by the model for writers and readers, respectively, on the vaccine-related Tweet dataset. The correlation analysis also showed that vaccinations were weakly positively correlated with predicted levels of writer joy, writer/reader anticipation, and writer/reader trust.",https://aclanthology.org/2022.wassa-1.10,emotion,Yes,Yes,No
{E}nglish-{M}alay Word Embeddings Alignment for Cross-lingual Emotion Classification with Hierarchical Attention Network,"Lim, Ying Hao  and
Liew, Jasy Suet Yan",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.12,"The main challenge in English-Malay cross-lingual emotion classification is that there are no Malay training emotion corpora. Given that machine translation could fall short in contextually complex tweets, we only limited machine translation to the word level. In this paper, we bridge the language gap between English and Malay through cross-lingual word embeddings constructed using singular value decomposition. We pre-trained our hierarchical attention model using English tweets and fine-tuned it using a set of gold standard Malay tweets. Our model uses significantly less computational resources compared to the language models. Experimental results show that the performance of our model is better than mBERT in zero-shot learning by 2.4{\%} and Malay BERT by 0.8{\%} when a limited number of Malay tweets is available. In exchange for 6 {--} 7 times less in computational time, our model only lags behind mBERT and XLM-RoBERTa by a margin of 0.9 {--} 4.3 {\%} in few-shot learning. Also, the word-level attention could be transferred to the Malay tweets accurately using the cross-lingual word embeddings.",https://aclanthology.org/2022.wassa-1.12,emotion,No,Yes,Yes
{XLM}-{EMO}: Multilingual Emotion Prediction in Social Media Text,"Bianchi, Federico  and
Nozza, Debora  and
Hovy, Dirk",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.18,"Detecting emotion in text allows social and computational scientists to study how people behave and react to online events. However, developing these tools for different languages requires data that is not always available. This paper collects the available emotion detection datasets across 19 languages. We train a multilingual emotion prediction model for social media data, XLM-EMO. The model shows competitive performance in a zero-shot setting, suggesting it is helpful in the context of low-resource languages. We release our model to the community so that interested researchers can directly use it.",https://aclanthology.org/2022.wassa-1.18,emotion,No,Yes,No
"{WASSA} 2022 Shared Task: Predicting Empathy, Emotion and Personality in Reaction to News Stories","Barriere, Valentin  and
Tafreshi, Shabnam  and
Sedoc, Jo{\~a}o  and
Alqahtani, Sawsan",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.20,"This paper presents the results that were obtained from WASSA 2022 shared task on predicting empathy, emotion, and personality in reaction to news stories. Participants were given access to a dataset comprising empathic reactions to news stories where harm is done to a person, group, or other. These reactions consist of essays and Batson{'}s empathic concern and personal distress scores. The dataset was further extended in WASSA 2021 shared task to include news articles, person-level demographic information (e.g. age, gender), personality information, and Ekman{'}s six basic emotions at essay level Participation was encouraged in four tracks: predicting empathy and distress scores, predicting emotion categories, predicting personality and predicting interpersonal reactivity. In total, 14 teams participated in the shared task. We summarize the methods and resources used by the participating teams.",https://aclanthology.org/2022.wassa-1.20,emotion_and_empathy,Yes,No,No
{IUCL} at {WASSA} 2022 Shared Task: A Text-only Approach to Empathy and Emotion Detection,"Chen, Yue  and
Ju, Yingnan  and
K{\""u}bler, Sandra",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.21,"Our system, IUCL, participated in the WASSA 2022 Shared Task on Empathy Detection and Emotion Classification. Our main goal in building this system is to investigate how the use of demographic attributes influences performance. Our (official) results show that our text-only systems perform very competitively, ranking first in the empathy detection task, reaching an average Pearson correlation of 0.54, and second in the emotion classification task, reaching a Macro-F of 0.572. Our systems that use both text and demographic data are less competitive.",https://aclanthology.org/2022.wassa-1.21,emotion_and_empathy,No,Yes,No
Continuing Pre-trained Model with Multiple Training Strategies for Emotional Classification,"Li, Bin  and
Weng, Yixuan  and
Song, Qiya  and
Sun, Bin  and
Li, Shutao",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.22,"Emotion is the essential attribute of human beings. Perceiving and understanding emotions in a human-like manner is the most central part of developing emotional intelligence. This paper describes the contribution of the LingJing team{'}s method to the Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis (WASSA) 2022 shared task on Emotion Classification. The participants are required to predict seven emotions from empathic responses to news or stories that caused harm to individuals, groups, or others. This paper describes the continual pre-training method for the masked language model (MLM) to enhance the DeBERTa pre-trained language model. Several training strategies are designed to further improve the final downstream performance including the data augmentation with the supervised transfer, child-tuning training, and the late fusion method. Extensive experiments on the emotional classification dataset show that the proposed method outperforms other state-of-the-art methods, demonstrating our method{'}s effectiveness. Moreover, our submission ranked Top-1 with all metrics in the evaluation phase for the Emotion Classification task.",https://aclanthology.org/2022.wassa-1.22,emotion,Yes,Yes,Yes
Empathy and Distress Prediction using Transformer Multi-output Regression and Emotion Analysis with an Ensemble of Supervised and Zero-Shot Learning Models,"Del Arco, Flor Miriam  and
Collado-Monta{\~n}ez, Jaime  and
Ure{\~n}a, L. Alfonso  and
Mart{\'\i}n-Valdivia, Mar{\'\i}a-Teresa",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.23,"This paper describes the participation of the SINAI research group at WASSA 2022 (Empathy and Personality Detection and Emotion Classification). Specifically, we participate in Track 1 (Empathy and Distress predictions) and Track 2 (Emotion classification). We conducted extensive experiments developing different machine learning solutions in line with the state of the art in Natural Language Processing. For Track 1, a Transformer multi-output regression model is proposed. For Track 2, we aim to explore recent techniques based on Zero-Shot Learning models including a Natural Language Inference model and GPT-3, using them in an ensemble manner with a fine-tune RoBERTa model. Our team ranked 2nd in the first track and 3rd in the second track.",https://aclanthology.org/2022.wassa-1.23,emotion_and_empathy,No,Yes,Yes
Leveraging Emotion-Specific features to improve Transformer performance for Emotion Classification,"Desai, Shaily  and
Kshirsagar, Atharva  and
Sidnerlikar, Aditi  and
Khodake, Nikhil  and
Marathe, Manisha",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.24,"This paper describes team PVG{'}s AI Club{'}s approach to the Emotion Classification shared task held at WASSA 2022. This Track 2 sub-task focuses on building models which can predict a multi-class emotion label based on essays from news articles where a person, group or another entity is affected. Baseline transformer models have been demonstrating good results on sequence classification tasks, and we aim to improve this performance with the help of ensembling techniques, and by leveraging two variations of emotion-specific representations. We observe better results than our baseline models and achieve an accuracy of 0.619 and a macro F1 score of 0.520 on the emotion classification task.",https://aclanthology.org/2022.wassa-1.24,emotion,No,Yes,No
Transformer based ensemble for emotion detection,"Kane, Aditya  and
Patankar, Shantanu  and
Khose, Sahil  and
Kirtane, Neeraja",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.25,"Detecting emotions in languages is important to accomplish a complete interaction between humans and machines. This paper describes our contribution to the WASSA 2022 shared task which handles this crucial task of emotion detection. We have to identify the following emotions: sadness, surprise, neutral, anger, fear, disgust, joy based on a given essay text. We are using an ensemble of ELECTRA and BERT models to tackle this problem achieving an F1 score of 62.76{\%}. Our codebase (\url{https://bit.ly/WASSA_shared_task}) and our WandB project (\url{https://wandb.ai/acl_wassa_pictxmanipal/acl_wassa}) is publicly available.",https://aclanthology.org/2022.wassa-1.25,emotion,No,Yes,No
"Team {IITP}-{AINLPML} at {WASSA} 2022: Empathy Detection, Emotion Classification and Personality Detection","Ghosh, Soumitra  and
Maurya, Dhirendra  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.26,"Computational comprehension and identifying emotional components in language have been critical in enhancing human-computer connection in recent years. The WASSA 2022 Shared Task introduced four tracks and released a dataset of news stories: Track-1 for Empathy and Distress Prediction, Track-2 for Emotion classification, Track-3 for Personality prediction, and Track-4 for Interpersonal Reactivity Index prediction at the essay level. This paper describes our participation in the WASSA 2022 shared task on the tasks mentioned above. We developed multi-task deep learning methods to address Tracks 1 and 2 and machine learning models for Track 3 and 4. Our developed systems achieved average Pearson scores of 0.483, 0.05, and 0.08 for Track 1, 3, and 4, respectively, and a macro F1 score of 0.524 for Track 2 on the test set. We ranked 8th, 11th, 2nd and 2nd for tracks 1, 2, 3, and 4 respectively.",https://aclanthology.org/2022.wassa-1.26,emotion_and_empathy,Yes,Yes,No
Transformer-based Architecture for Empathy Prediction and Emotion Classification,"Vasava, Himil  and
Uikey, Pramegh  and
Wasnik, Gaurav  and
Sharma, Raksha",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.27,"This paper describes the contribution of team PHG to the WASSA 2022 shared task on Empathy Prediction and Emotion Classification. The broad goal of this task was to model an empathy score, a distress score and the type of emotion associated with the person who had reacted to the essay written in response to a newspaper article. We have used the RoBERTa model for training and top of which few layers are added to finetune the transformer. We also use few machine learning techniques to augment as well as upsample the data. Our system achieves a Pearson Correlation Coefficient of 0.488 on Task 1 (Empathy - 0.470 and Distress - 0.506) and Macro F1-score of 0.531 on Task 2.",https://aclanthology.org/2022.wassa-1.27,emotion_and_empathy,No,Yes,No
"{SURREY}-{CTS}-{NLP} at {WASSA}2022: An Experiment of Discourse and Sentiment Analysis for the Prediction of Empathy, Distress and Emotion","Qian, Shenbin  and
Orasan, Constantin  and
Kanojia, Diptesh  and
Saadany, Hadeel  and
Do Carmo, F{\'e}lix",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.29,"This paper summarises the submissions our team, SURREY-CTS-NLP has made for the WASSA 2022 Shared Task for the prediction of empathy, distress and emotion. In this work, we tested different learning strategies, like ensemble learning and multi-task learning, as well as several large language models, but our primary focus was on analysing and extracting emotion-intensive features from both the essays in the training data and the news articles, to better predict empathy and distress scores from the perspective of discourse and sentiment analysis. We propose several text feature extraction schemes to compensate the small size of training examples for fine-tuning pretrained language models, including methods based on Rhetorical Structure Theory (RST) parsing, cosine similarity and sentiment score. Our best submissions achieve an average Pearson correlation score of 0.518 for the empathy prediction task and an F1 score of 0.571 for the emotion prediction task, indicating that using these schemes to extract emotion-intensive information can help improve model performance.",https://aclanthology.org/2022.wassa-1.29,emotion_and_empathy,No,Yes,Yes
An Ensemble Approach to Detect Emotions at an Essay Level,"Maheshwari, Himanshu  and
Varma, Vasudeva",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.30,"This paper describes our system (IREL, reffered as himanshu.1007 on Codalab) for Shared Task on Empathy Detection, Emotion Classification, and Personality Detection at 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis at ACL 2022. We participated in track 2 for predicting emotion at the essay level. We propose an ensemble approach that leverages the linguistic knowledge of the RoBERTa, BART-large, and RoBERTa model finetuned on the GoEmotions dataset. Each brings in its unique advantage, as we discuss in the paper. Our proposed system achieved a Macro F1 score of 0.585 and ranked one out of thirteen teams",https://aclanthology.org/2022.wassa-1.30,emotion,Yes,Yes,No
{CAISA} at {WASSA} 2022: Adapter-Tuning for Empathy Prediction,"Lahnala, Allison  and
Welch, Charles  and
Flek, Lucie",2022,"Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis",10.18653/v1/2022.wassa-1.31,"We build a system that leverages adapters, a light weight and efficient method for leveraging large language models to perform the task Em- pathy and Distress prediction tasks for WASSA 2022. In our experiments, we find that stacking our empathy and distress adapters on a pre-trained emotion lassification adapter performs best compared to full fine-tuning approaches and emotion feature concatenation. We make our experimental code publicly available",https://aclanthology.org/2022.wassa-1.31,empathy,No,Yes,Yes
"Baseline {E}nglish and {M}altese-{E}nglish Classification Models for Subjectivity Detection, Sentiment Analysis, Emotion Analysis, Sarcasm Detection, and Irony Detection","Cortis, Keith  and
Davis, Brian",2022,Proceedings of the 1st Annual Meeting of the ELRA/ISCA Special Interest Group on Under-Resourced Languages,,"This paper presents baseline classification models for subjectivity detection, sentiment analysis, emotion analysis, sarcasm detection, and irony detection. All models are trained on user-generated content gathered from newswires and social networking services, in three different languages: English {---}a high-resourced language, Maltese {---}a low-resourced language, and Maltese-English {---}a code-switched language. Traditional supervised algorithms namely, Support Vector Machines, Na{\""\i}ve Bayes, Logistic Regression, Decision Trees, and Random Forest, are used to build a baseline for each classification task, namely subjectivity, sentiment polarity, emotion, sarcasm, and irony. Baseline models are established at a monolingual (English) level and at a code-switched level (Maltese-English). Results obtained from all the classification models are presented.",https://aclanthology.org/2022.sigul-1.21,emotion,No,Yes,No
{YNU}-{HPCC} at {S}em{E}val-2022 Task 5: Multi-Modal and Multi-label Emotion Classification Based on {LXMERT},"Han, Chao  and
Wang, Jin  and
Zhang, Xuejie",2022,Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022),10.18653/v1/2022.semeval-1.104,"This paper describes our system used in the SemEval-2022 Task5 Multimedia Automatic Misogyny Identification (MAMI). This task is to use the provided text-image pairs to classify emotions. In this paper, We propose a multi-label emotion classification model based on pre-trained LXMERT. We use Faster-RCNN to extract visual representation and utilize LXMERT{'}s cross-attention for multi-modal alignment. Then we use the Bilinear-interaction layer to fuse these features. Our experimental results surpass the $F_1$ score of baseline. For Sub-task A, our $F_1$ score is 0.662 and Sub-task B{'}s $F_1$ score is 0.633. The code of this study is available on GitHub.",https://aclanthology.org/2022.semeval-1.104,emotion,No,Yes,No
Invited talk: From Data to Meaning in Representation of Emotions,"Fensel, Anna",2022,Proceedings of the 2nd Workshop on Sentiment Analysis and Linguistic Linked Data,,"Historically, now we have an unprecedentedly large amount of data available in various systems, and the growth of data volumes is rapid and continuous. The numbers of scientific papers published per year are higher than ever before. While it is desirable to have the context of the users of a social system known and represented in a machine-readable form, capturing this context is notoriously complex (as social context is more difficult to measure with simple sensors, unlike some physical characteristics). This complexity applies especially to the domain of emotions, but also to other context information relevant for social systems and social sciences (for example, in case of experimental study set up in sociology or marketing, detailed user profiles, exact background and experimental settings need to be recorded in a precise manner). Which data and scientific findings get shared, for which purposes, and how? How to address open and closed data, and reproducibility crisis? How to convert Big Data into Smart Data, which is interpretable by both machine and human? And how to make sure that the resulting Smart Data is trustworthy and appropriately handling biases? In my talk, I discuss these questions from the technical perspective, and give examples for relevant solutions implemented with Semantic Web technology, linked data, knowledge graphs and FAIR (Findable, Accessible, Interoperable, Reusable) data management. Specifically, I will be discussing experiences with combining machine learning and knowledge graphs for semantic representation of emotions. Further, I will talk about research data infrastructures and tools for social sciences that can facilitate semantic interoperability and bring more meaning with sharing semantic representation of context, such as one about emotions. Such semantic representations and infrastructures can serve as a basis for industrial applications, including recommender systems, personal assistants and chatbots, and also serve to improve research data management in social sciences.",https://aclanthology.org/2022.salld-1.1,emotion,No,Yes,No
Do Multimodal Emotion Recognition Models Tackle Ambiguity?,"Tran, H{\'e}l{\`e}ne  and
Falih, Issam  and
Goblet, Xavier  and
Mephu Nguifo, Engelbert",2022,"Proceedings of the 2nd Workshop on People in Vision, Language, and the Mind",,"Most databases used for emotion recognition assign a single emotion to data samples. This does not match with the complex nature of emotions: we can feel a wide range of emotions throughout our lives with varying degrees of intensity. We may even experience multiple emotions at once. Furthermore, each person physically expresses emotions differently, which makes emotion recognition even more challenging: we call this emotional ambiguity. This paper investigates the problem as a review of ambiguity in multimodal emotion recognition models. To lay the groundwork, the main representations of emotions along with solutions for incorporating ambiguity are described, followed by a brief overview of ambiguity representation in multimodal databases. Thereafter, only models trained on a database that incorporates ambiguity have been studied in this paper. We conclude that although databases provide annotations with ambiguity, most of these models do not fully exploit them, showing that there is still room for improvement in multimodal emotion recognition systems.",https://aclanthology.org/2022.pvlam-1.2,emotion,No,Yes,No
Emotions Running High? A Synopsis of the state of {T}urkish Politics through the {P}arla{M}int Corpus,"Kurto{\u{g}}lu Eski{\c{s}}ar, G{\""u}l M.  and
{\c{C}}{\""o}ltekin, {\c{C}}a{\u{g}}r{\i}",2022,Proceedings of the Workshop ParlaCLARIN III within the 13th Language Resources and Evaluation Conference,,"We present the initial results of our quantitative study on emotions (Anger, Disgust, Fear, Happiness, Sadness and Surprise) in Turkish parliament (2011{--}2021). We use machine learning models to assign emotion scores to all speeches delivered in the parliament during this period, and observe any changes to them in relation to major political and social events in Turkey. We highlight a number of interesting observations, such as anger being the dominant emotion in parliamentary speeches, and the ruling party showing more stable emotions compared to the political opposition, despite its depiction as a populist party in the literature.",https://aclanthology.org/2022.parlaclarin-1.10,emotion,Yes,Yes,No
{S}tud{E}mo: A Non-aggregated Review Dataset for Personalized Emotion Recognition,"Ngo, Anh  and
Candri, Agri  and
Ferdinan, Teddy  and
Kocon, Jan  and
Korczynski, Wojciech",2022,Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022,,"Humans{'} emotional perception is subjective by nature, in which each individual could express different emotions regarding the same textual content. Existing datasets for emotion analysis commonly depend on a single ground truth per data sample, derived from majority voting or averaging the opinions of all annotators. In this paper, we introduce a new non-aggregated dataset, namely StudEmo, that contains 5,182 customer reviews, each annotated by 25 people with intensities of eight emotions from Plutchik{'}s model, extended with valence and arousal. We also propose three personalized models that use not only textual content but also the individual human perspective, providing the model with different approaches to learning human representations. The experiments were carried out as a multitask classification on two datasets: our StudEmo dataset and GoEmotions dataset, which contains 28 emotional categories. The proposed personalized methods significantly improve prediction results, especially for emotions that have low inter-annotator agreement.",https://aclanthology.org/2022.nlperspectives-1.7,emotion,Yes,Yes,No
Variation in the Expression and Annotation of Emotions: A {W}izard of {O}z Pilot Study,"Labat, Sofie  and
Ackaert, Naomi  and
Demeester, Thomas  and
Hoste, Veronique",2022,Proceedings of the 1st Workshop on Perspectivist Approaches to NLP @LREC2022,,"This pilot study employs the Wizard of Oz technique to collect a corpus of written human-computer conversations in the domain of customer service. The resulting dataset contains 192 conversations and is used to test three hypotheses related to the expression and annotation of emotions. First, we hypothesize that there is a discrepancy between the emotion annotations of the participant (the experiencer) and the annotations of our external annotator (the observer). Furthermore, we hypothesize that the personality of the participants has an influence on the emotions they expressed, and on the way they evaluated (annotated) these emotions. We found that for an external, trained annotator, not all emotion labels were equally easy to work with. We also noticed that the trained annotator had a tendency to opt for emotion labels that were more centered in the valence-arousal space, while participants made more {`}extreme{'} annotations. For the second hypothesis, we discovered a positive correlation between the personality trait extraversion and the emotion dimensions valence and dominance in our sample. Finally, for the third premise, we observed a positive correlation between the internal-external agreement on emotion labels and the personality traits conscientiousness and extraversion. Our insights and findings will be used in future research to conduct a larger Wizard of Oz experiment.",https://aclanthology.org/2022.nlperspectives-1.9,emotion,Yes,Yes,No
Improving the Generalizability of Text-Based Emotion Detection by Leveraging Transformers with Psycholinguistic Features,"Zanwar, Sourabh  and
Wiechmann, Daniel  and
Qiao, Yu  and
Kerz, Elma",2022,Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS),10.18653/v1/2022.nlpcss-1.1,"recent years, there has been increased interest in building predictive models that harness natural language processing and machine learning techniques to detect emotions from various text sources, including social media posts, micro-blogs or news articles. Yet, deployment of such models in real-world sentiment and emotion applications faces challenges, in particular poor out-of-domain generalizability. This is likely due to domain-specific differences (e.g., topics, communicative goals, and annotation schemes) that make transfer between different models of emotion recognition difficult. In this work we propose approaches for text-based emotion detection that leverage transformer models (BERT and RoBERTa) in combination with Bidirectional Long Short-Term Memory (BiLSTM) networks trained on a comprehensive set of psycholinguistic features. First, we evaluate the performance of our models within-domain on two benchmark datasets GoEmotion (Demszky et al., 2020) and ISEAR (Scherer and Wallbott, 1994). Second, we conduct transfer learning experiments on six datasets from the Unified Emotion Dataset (Bostan and Klinger, 2018) to evaluate their out-of-domain robustness. We find that the proposed hybrid models improve the ability to generalize to out-of-distribution data compared to a standard transformer-based approach. Moreover, we observe that these models perform competitively on in-domain data.{'}",https://aclanthology.org/2022.nlpcss-1.1,emotion,Yes,Yes,Yes
Experiencer-Specific Emotion and Appraisal Prediction,"Wegge, Maximilian  and
Troiano, Enrica  and
Oberlaender, Laura Ana Maria  and
Klinger, Roman",2022,Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS),10.18653/v1/2022.nlpcss-1.3,"Emotion classification in NLP assigns emotions to texts, such as sentences or paragraphs. With texts like {``}I felt guilty when he cried{''}, focusing on the sentence level disregards the standpoint of each participant in the situation: the writer ({``}I{''}) and the other entity ({``}he{''}) could in fact have different affective states. The emotions of different entities have been considered only partially in emotion semantic role labeling, a task that relates semantic roles to emotion cue words. Proposing a related task, we narrow the focus on the experiencers of events, and assign an emotion (if any holds) to each of them. To this end, we represent each emotion both categorically and with appraisal variables, as a psychological access to explaining why a person develops a particular emotion. On an event description corpus, our experiencer-aware models of emotions and appraisals outperform the experiencer-agnostic baselines, showing that disregarding event participants is an oversimplification for the emotion detection task.",https://aclanthology.org/2022.nlpcss-1.3,emotion,Yes,Yes,Yes
Emotion Conditioned Creative Dialog Generation,"Alnajjar, Khalid  and
H{\""a}m{\""a}l{\""a}inen, Mika",2022,Proceedings of the 2nd International Workshop on Natural Language Processing for Digital Humanities,,"We present a DialGPT based model for generating creative dialog responses that are conditioned based on one of the following emotions: anger, disgust, fear, happiness, pain, sadness and surprise. Our model is capable of producing a contextually apt response given an input sentence and a desired emotion label. Our model is capable of expressing the desired emotion with an accuracy of 0.6. The best performing emotions are neutral, fear and disgust. When measuring the strength of the expressed emotion, we find that anger, fear and disgust are expressed in the most strong fashion by the model.",https://aclanthology.org/2022.nlp4dh-1.20,emotion,No,Yes,No
Static and Dynamic Speaker Modeling based on Graph Neural Network for Emotion Recognition in Conversation,"Saxena, Prakhar  and
Huang, Yin Jou  and
Kurohashi, Sadao",2022,Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop,10.18653/v1/2022.naacl-srw.31,"Each person has a unique personality which affects how they feel and convey emotions. Hence, speaker modeling is important for the task of emotion recognition in conversation (ERC). In this paper, we propose a novel graph-based ERC model which considers both conversational context and speaker personality. We model the internal state of the speaker (personality) as Static and Dynamic speaker state, where the Dynamic speaker state is modeled with a graph neural network based encoder. Experiments on benchmark dataset shows the effectiveness of our model. Our model outperforms baseline and other graph-based methods. Analysis of results also show the importance of explicit speaker modeling.",https://aclanthology.org/2022.naacl-srw.31,emotion,Yes,Yes,No
Empathic Machines: Using Intermediate Features as Levers to Emulate Emotions in Text-To-Speech Systems,"Kosgi, Saiteja  and
Sivaprasad, Sarath  and
Pedanekar, Niranjan  and
Nelakanti, Anil  and
Gandhi, Vineet",2022,Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2022.naacl-main.26,"We present a method to control the emotional prosody of Text to Speech (TTS) systems by using phoneme-level intermediate features (pitch, energy, and duration) as levers. As a key idea, we propose Differential Scaling (DS) to disentangle features relating to affective prosody from those arising due to acoustics conditions and speaker identity. With thorough experimental studies, we show that the proposed method improves over the prior art in accurately emulating the desired emotions while retaining the naturalness of speech. We extend the traditional evaluation of using individual sentences for a more complete evaluation of HCI systems. We present a novel experimental setup by replacing an actor with a TTS system in offline and live conversations. The emotion to be rendered is either predicted or manually assigned. The results show that the proposed method is strongly preferred over the state-of-the-art TTS system and adds the much-coveted {``}human touch{''} in machine dialogue. Audio samples from our experiments and the code are available at: \url{https://emtts.github.io/tts-demo/}",https://aclanthology.org/2022.naacl-main.26,emotion_and_empathy,No,No,No
Beyond Emotion: A Multi-Modal Dataset for Human Desire Understanding,"Jia, Ao  and
He, Yu  and
Zhang, Yazhou  and
Uprety, Sagar  and
Song, Dawei  and
Lioma, Christina",2022,Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2022.naacl-main.108,"Desire is a strong wish to do or have something, which involves not only a linguistic expression, but also underlying cognitive phenomena driving human feelings. As the most primitive and basic human instinct, conscious desire is often accompanied by a range of emotional responses. As a strikingly understudied task, it is difficult for machines to model and understand desire due to the unavailability of benchmarking datasets with desire and emotion labels. To bridge this gap, we present MSED, the first multi-modal and multi-task sentiment, emotion and desire dataset, which contains 9,190 text-image pairs, with English text. Each multi-modal sample is annotated with six desires, three sentiments and six emotions. We also propose the state-of-the-art baselines to evaluate the potential of MSED and show the importance of multi-task and multi-modal clues for desire understanding. We hope this study provides a benchmark for human desire analysis. MSED will be publicly available for research.",https://aclanthology.org/2022.naacl-main.108,emotion,Yes,Yes,No
{COGMEN}: {CO}ntextualized {GNN} based Multimodal Emotion recognitio{N},"Joshi, Abhinav  and
Bhat, Ashwani  and
Jain, Ayush  and
Singh, Atin  and
Modi, Ashutosh",2022,Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2022.naacl-main.306,"Emotions are an inherent part of human interactions, and consequently, it is imperative to develop AI systems that understand and recognize human emotions. During a conversation involving various people, a person{'}s emotions are influenced by the other speaker{'}s utterances and their own emotional state over the utterances. In this paper, we propose COntextualized Graph Neural Network based Multi- modal Emotion recognitioN (COGMEN) system that leverages local information (i.e., inter/intra dependency between speakers) and global information (context). The proposed model uses Graph Neural Network (GNN) based architecture to model the complex dependencies (local and global information) in a conversation. Our model gives state-of-the- art (SOTA) results on IEMOCAP and MOSEI datasets, and detailed ablation experiments show the importance of modeling information at both levels.",https://aclanthology.org/2022.naacl-main.306,emotion,No,Yes,No
Mitigating Toxic Degeneration with Empathetic Data: Exploring the Relationship Between Toxicity and Empathy,"Lahnala, Allison  and
Welch, Charles  and
Neuendorf, B{\'e}la  and
Flek, Lucie",2022,Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2022.naacl-main.363,"Large pre-trained neural language models have supported the effectiveness of many NLP tasks, yet are still prone to generating toxic language hindering the safety of their use. Using empathetic data, we improve over recent work on controllable text generation that aims to reduce the toxicity of generated text. We find we are able to dramatically reduce the size of fine-tuning data to 7.5-30k samples while at the same time making significant improvements over state-of-the-art toxicity mitigation of up to 3.4{\%} absolute reduction (26{\%} relative) from the original work on 2.3m samples, by strategically sampling data based on empathy scores. We observe that the degree of improvements is subject to specific communication components of empathy. In particular, the more cognitive components of empathy significantly beat the original dataset in almost all experiments, while emotional empathy was tied to less improvement and even underperforming random samples of the original data. This is a particularly implicative insight for NLP work concerning empathy as until recently the research and resources built for it have exclusively considered empathy as an emotional concept.",https://aclanthology.org/2022.naacl-main.363,empathy,Yes,Yes,Yes
{C}o{MPM}: Context Modeling with Speaker{'}s Pre-trained Memory Tracking for Emotion Recognition in Conversation,"Lee, Joosung  and
Lee, Wooin",2022,Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2022.naacl-main.416,"As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine-generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. Many recent approaches show performance improvement by combining knowledge into modules learned from external structured data. However, structured data is difficult to access in non-English languages, making it difficult to extend to other languages. Therefore, we extract the pre-trained memory using the pre-trained language model as an extractor of external knowledge. We introduce CoMPM, which combines the speaker{'}s pre-trained memory with the context model, and find that the pre-trained memory significantly improves the performance of the context model. CoMPM achieves the first or second performance on all data and is state-of-the-art among systems that do not leverage structured data. In addition, our method shows that it can be extended to other languages because structured knowledge is not required, unlike previous methods. Our code is available on github .",https://aclanthology.org/2022.naacl-main.416,emotion,No,Yes,Yes
How Language-Dependent is Emotion Detection? Evidence from Multilingual {BERT},"De Bruyne, Luna  and
Singh, Pranaydeep  and
De Clercq, Orphee  and
Lefever, Els  and
Hoste, Veronique",2022,Proceedings of the 2nd Workshop on Multi-lingual Representation Learning (MRL),10.18653/v1/2022.mrl-1.7,"As emotion analysis in text has gained a lot of attention in the field of natural language processing, differences in emotion expression across languages could have consequences for how emotion detection models work. We evaluate the language-dependence of an mBERT-based emotion detection model by comparing language identification performance before and after fine-tuning on emotion detection, and performing (adjusted) zero-shot experiments to assess whether emotion detection models rely on language-specific information. When dealing with typologically dissimilar languages, we found evidence for the language-dependence of emotion detection.",https://aclanthology.org/2022.mrl-1.7,emotion,No,Yes,Yes
Shapes of Emotions: Multimodal Emotion Recognition in Conversations via Emotion Shifts,"Bansal, Keshav  and
Agarwal, Harsh  and
Joshi, Abhinav  and
Modi, Ashutosh",2022,"Proceedings of the First Workshop on Performance and Interpretability Evaluations of Multimodal, Multipurpose, Massive-Scale Models",,"Emotion Recognition in Conversations (ERC) is an important and active research area. Recent work has shown the benefits of using multiple modalities (e.g., text, audio, and video) for the ERC task. In a conversation, participants tend to maintain a particular emotional state unless some stimuli evokes a change. There is a continuous ebb and flow of emotions in a conversation. Inspired by this observation, we propose a multimodal ERC model and augment it with an emotion-shift component that improves performance. The proposed emotion-shift component is modular and can be added to any existing multimodal ERC model (with a few modifications). We experiment with different variants of the model, and results show that the inclusion of emotion shift signal helps the model to outperform existing models for ERC on MOSEI and IEMOCAP datasets.",https://aclanthology.org/2022.mmmpie-1.6,emotion,No,Yes,No
Understanding the role of Emojis for emotion detection in {T}amil,"Rajalakshmi, Ratnavel  and
Mattins R, Faerie  and
Selvaraj, Srivarshan  and
Shibani, Antonette  and
Kumar M, Anand  and
Raja Chakravarthi, Bharathi",2022,Proceedings of the First Workshop on Multimodal Machine Learning in Low-resource Languages,,"of expressing relevant idea through social media platforms and forums. At the same time, these memes are trolled by a person who tries to get identified from the other internet users like social media users, chat rooms and blogs. The memes contain both textual and visual information. Based on the content of memes, they are trolled in online community. There is no restriction for language usage in online media. The present work focuses on whether memes are trolled or not trolled. The proposed multi modal approach achieved considerably better weighted average F1 score of 0.5437 compared to Unimodal approaches. The other performance metrics like precision, recall, accuracy and macro average have also been studied to observe the proposed system.",https://aclanthology.org/2022.mmlow-1.2,emotion,No,No,No
{BERT} 4{EVER}@{LT}-{EDI}-{ACL}2022-Detecting signs of Depression from Social Media:Detecting Depression in Social Media using Prompt-Learning and Word-Emotion Cluster,"Lin, Xiaotian  and
Fu, Yingwen  and
Yang, Ziyu  and
Lin, Nankai  and
Jiang, Shengyi",2022,"Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion",10.18653/v1/2022.ltedi-1.27,"In this paper, we report the solution of the team BERT 4EVER for the LT-EDI-2022 shared task2: Homophobia/Transphobia Detection in social media comments in ACL 2022, which aims to classify Youtube comments into one of the following categories: no,moderate, or severe depression. We model the problem as a text classification task and a text generation task and respectively propose two different models for the tasks. To combine the knowledge learned from these two different models, we softly fuse the predicted probabilities of the models above and then select the label with the highest probability as the final output. In addition, multiple augmentation strategies are leveraged to improve the model generalization capability, such as back translation and adversarial training. Experimental results demonstrate the effectiveness of the proposed models and two augmented strategies.",https://aclanthology.org/2022.ltedi-1.27,emotion,No,Yes,No
Angry or Sad ? Emotion Annotation for Extremist Content Characterisation,"Dragos, Valentina  and
Battistelli, Delphine  and
Etienne, Aline  and
Constable, Yol{\`e}ne",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"This paper examines the role of emotion annotations to characterize extremist content released on social platforms. The analysis of extremist content is important to identify user emotions towards some extremist ideas and to highlight the root cause of where emotions and extremist attitudes merge together. To address these issues our methodology combines knowledge from sociological and linguistic annotations to explore French extremist content collected online. For emotion linguistic analysis, the solution presented in this paper relies on a complex linguistic annotation scheme. The scheme was used to annotate extremist text corpora in French. Data sets were collected online by following semi-automatic procedures for content selection and validation. The paper describes the integrated annotation scheme, the annotation protocol that was set-up for French corpora annotation and the results, e.g. agreement measures and remarks on annotation disagreements. The aim of this work is twofold: first, to provide a characterization of extremist contents; second, to validate the annotation scheme and to test its capacity to capture and describe various aspects of emotions.",https://aclanthology.org/2022.lrec-1.21,emotion,Yes,No,No
Aspect-Based Emotion Analysis and Multimodal Coreference: A Case Study of Customer Comments on Adidas {I}nstagram Posts,"De Bruyne, Luna  and
Karimi, Akbar  and
De Clercq, Orphee  and
Prati, Andrea  and
Hoste, Veronique",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"While aspect-based sentiment analysis of user-generated content has received a lot of attention in the past years, emotion detection at the aspect level has been relatively unexplored. Moreover, given the rise of more visual content on social media platforms, we want to meet the ever-growing share of multimodal content. In this paper, we present a multimodal dataset for Aspect-Based Emotion Analysis (ABEA). Additionally, we take the first steps in investigating the utility of multimodal coreference resolution in an ABEA framework. The presented dataset consists of 4,900 comments on 175 images and is annotated with aspect and emotion categories and the emotional dimensions of valence and arousal. Our preliminary experiments suggest that ABEA does not benefit from multimodal coreference resolution, and that aspect and emotion classification only requires textual information. However, when more specific information about the aspects is desired, image recognition could be essential.",https://aclanthology.org/2022.lrec-1.61,emotion,Yes,Yes,No
A (Psycho-)Linguistically Motivated Scheme for Annotating and Exploring Emotions in a Genre-Diverse Corpus,"Etienne, Aline  and
Battistelli, Delphine  and
Lecorv{\'e}, Gw{\'e}nol{\'e}",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"This paper presents a scheme for emotion annotation and its manual application on a genre-diverse corpus of texts written in French. The methodology introduced here emphasizes the necessity of clarifying the main concepts implied by the analysis of emotions as they are expressed in texts, before conducting a manual annotation campaign. After explaining whatentails a deeply linguistic perspective on emotion expression modeling, we present a few NLP works that share some common points with this perspective and meticulously compare our approach with them. We then highlight some interesting quantitative results observed on our annotated corpus. The most notable interactions are on the one hand between emotion expression modes and genres of texts, and on the other hand between emotion expression modes and emotional categories. These observation corroborate and clarify some of the results already mentioned in other NLP works on emotion annotation.",https://aclanthology.org/2022.lrec-1.64,emotion,Yes,Yes,Yes
A Dataset for Speech Emotion Recognition in {G}reek Theatrical Plays,"Moutti, Maria  and
Eleftheriou, Sofia  and
Koromilas, Panagiotis  and
Giannakopoulos, Theodoros",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Machine learning methodologies can be adopted in cultural applications and propose new ways to distribute or even present the cultural content to the public. For instance, speech analytics can be adopted to automatically generate subtitles in theatrical plays, in order to (among other purposes) help people with hearing loss. Apart from a typical speech-to-text transcription with Automatic Speech Recognition (ASR), Speech Emotion Recognition (SER) can be used to automatically predict the underlying emotional content of speech dialogues in theatrical plays, and thus to provide a deeper understanding how the actors utter their lines. However, real-world datasets from theatrical plays are not available in the literature. In this work we present GreThE, the Greek Theatrical Emotion dataset, a new publicly available data collection for speech emotion recognition in Greek theatrical plays. The dataset contains utterances from various actors and plays, along with respective valence and arousal annotations. Towards this end, multiple annotators have been asked to provide their input for each speech recording and inter-annotator agreement is taken into account in the final ground truth generation. In addition, we discuss the results of some indicative experiments that have been conducted with machine and deep learning frameworks, using the dataset, along with some widely used databases in the field of speech emotion recognition.",https://aclanthology.org/2022.lrec-1.111,emotion,Yes,Yes,No
x-en{VENT}: A Corpus of Event Descriptions with Experiencer-specific Emotion and Appraisal Annotations,"Troiano, Enrica  and
Oberlaender, Laura Ana Maria  and
Wegge, Maximilian  and
Klinger, Roman",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Emotion classification is often formulated as the task to categorize texts into a predefined set of emotion classes. So far, this task has been the recognition of the emotion of writers and readers, as well as that of entities mentioned in the text. We argue that a classification setup for emotion analysis should be performed in an integrated manner, including the different semantic roles that participate in an emotion episode. Based on appraisal theories in psychology, which treat emotions as reactions to events, we compile an English corpus of written event descriptions. The descriptions depict emotion-eliciting circumstances, and they contain mentions of people who responded emotionally. We annotate all experiencers, including the original author, with the emotions they likely felt. In addition, we link them to the event they found salient (which can be different for different experiencers in a text) by annotating event properties, or appraisals (e.g., the perceived event undesirability, the uncertainty of its outcome). Our analysis reveals patterns in the co-occurrence of people{'}s emotions in interaction. Hence, this richly-annotated resource provides useful data to study emotions and event evaluations from the perspective of different roles, and it enables the development of experiencer-specific emotion and appraisal classification systems.",https://aclanthology.org/2022.lrec-1.146,emotion,Yes,Yes,No
{RED} v2: Enhancing {RED} Dataset for Multi-Label Emotion Detection,"Ciobotaru, Alexandra  and
Constantinescu, Mihai Vlad  and
Dinu, Liviu P.  and
Dumitrescu, Stefan",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"RED (Romanian Emotion Dataset) is a machine learning-based resource developed for the automatic detection of emotions in Romanian texts, containing single-label annotated tweets with one of the following emotions: joy, fear, sadness, anger and neutral. In this work, we propose REDv2, an open-source extension of RED by adding two more emotions, trust and surprise, and by widening the annotation schema so that the resulted novel dataset is multi-label. We show the overall reliability of our dataset by computing inter-annotator agreements per tweet using a formula suitable for our annotation setup and we aggregate all annotators{'} opinions into two variants of ground truth, one suitable for multi-label classification and the other suitable for text regression. We propose strong baselines with two transformer models, the Romanian BERT and the multilingual XLM-Roberta model, in both categorical and regression settings.",https://aclanthology.org/2022.lrec-1.149,emotion,Yes,Yes,No
A Comparative Cross Language View On Acted Databases Portraying Basic Emotions Utilising Machine Learning,"Burkhardt, Felix  and
Hacker, Anabell  and
Reichel, Uwe  and
Wierstorf, Hagen  and
Eyben, Florian  and
Schuller, Bj{\""o}rn",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Since several decades emotional databases have been recorded by various laboratories. Many of them contain acted portrays of Darwin{'}s famous {``}big four{''} basic emotions. In this paper, we investigate in how far a selection of them are comparable by two approaches: on the one hand modeling similarity as performance in cross database machine learning experiments and on the other by analyzing a manually picked set of four acoustic features that represent different phonetic areas. It is interesting to see in how far specific databases (we added a synthetic one) perform well as a training set for others while some do not. Generally speaking, we found indications for both similarity as well as specificiality across languages.",https://aclanthology.org/2022.lrec-1.204,emotion,No,Yes,No
A Study on the Ambiguity in Human Annotation of {G}erman Oral History Interviews for Perceived Emotion Recognition and Sentiment Analysis,"Gref, Michael  and
Matthiesen, Nike  and
Hikkal Venugopala, Sreenivasa  and
Satheesh, Shalaka  and
Vijayananth, Aswinkumar  and
Ha, Duc Bach  and
Behnke, Sven  and
K{\""o}hler, Joachim",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"For research in audiovisual interview archives often it is not only of interest what is said but also how. Sentiment analysis and emotion recognition can help capture, categorize and make these different facets searchable. In particular, for oral history archives, such indexing technologies can be of great interest. These technologies can help understand the role of emotions in historical remembering. However, humans often perceive sentiments and emotions ambiguously and subjectively. Moreover, oral history interviews have multi-layered levels of complex, sometimes contradictory, sometimes very subtle facets of emotions. Therefore, the question arises of the chance machines and humans have capturing and assigning these into predefined categories. This paper investigates the ambiguity in human perception of emotions and sentiment in German oral history interviews and the impact on machine learning systems. Our experiments reveal substantial differences in human perception for different emotions. Furthermore, we report from ongoing machine learning experiments with different modalities. We show that the human perceptual ambiguity and other challenges, such as class imbalance and lack of training data, currently limit the opportunities of these technologies for oral history archives. Nonetheless, our work uncovers promising observations and possibilities for further research.",https://aclanthology.org/2022.lrec-1.217,emotion,No,Yes,No
Conversational Analysis of Daily Dialog Data using Polite Emotional Dialogue Acts,"Bothe, Chandrakant  and
Wermter, Stefan",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Many socio-linguistic cues are used in conversational analysis, such as emotion, sentiment, and dialogue acts. One of the fundamental social cues is politeness, which linguistically possesses properties such as social manners useful in conversational analysis. This article presents findings of polite emotional dialogue act associations, where we can correlate the relationships between the socio-linguistic cues. We confirm our hypothesis that the utterances with the emotion classes Anger and Disgust are more likely to be impolite. At the same time, Happiness and Sadness are more likely to be polite. A less expectable phenomenon occurs with dialogue acts Inform and Commissive which contain more polite utterances than Question and Directive. Finally, we conclude on the future work of these findings to extend the learning of social behaviours using politeness.",https://aclanthology.org/2022.lrec-1.256,emotion,No,No,No
{E}mo{WOZ}: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems,"Feng, Shutong  and
Lubis, Nurul  and
Geishauser, Christian  and
Lin, Hsien-chin  and
Heck, Michael  and
van Niekerk, Carel  and
Gasic, Milica",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"The ability to recognise emotions lends a conversational artificial intelligence a human touch. While emotions in chit-chat dialogues have received substantial attention, emotions in task-oriented dialogues remain largely unaddressed. This is despite emotions and dialogue success having equally important roles in a natural system. Existing emotion-annotated task-oriented corpora are limited in size, label richness, and public availability, creating a bottleneck for downstream tasks. To lay a foundation for studies on emotions in task-oriented dialogues, we introduce EmoWOZ, a large-scale manually emotion-annotated corpus of task-oriented dialogues. EmoWOZ is based on MultiWOZ, a multi-domain task-oriented dialogue dataset. It contains more than 11K dialogues with more than 83K emotion annotations of user utterances. In addition to Wizard-of-Oz dialogues from MultiWOZ, we collect human-machine dialogues within the same set of domains to sufficiently cover the space of various emotions that can happen during the lifetime of a data-driven dialogue system. To the best of our knowledge, this is the first large-scale open-source corpus of its kind. We propose a novel emotion labelling scheme, which is tailored to task-oriented dialogues. We report a set of experimental results to show the usability of this corpus for emotion recognition and state tracking in task-oriented dialogues.",https://aclanthology.org/2022.lrec-1.436,emotion,Yes,No,Yes
{Tweet Emotion Dynamics}: Emotion Word Usage in Tweets from {US} and {C}anada,"Vishnubhotla, Krishnapriya  and
Mohammad, Saif M.",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Over the last decade, Twitter has emerged as one of the most influential forums for social, political, and health discourse. In this paper, we introduce a massive dataset of more than 45 million geo-located tweets posted between 2015 and 2021 from US and Canada (TUSC), especially curated for natural language analysis. We also introduce Tweet Emotion Dynamics (TED) {---} metrics to capture patterns of emotions associated with tweets over time. We use TED and TUSC to explore the use of emotion-associated words across US and Canada; across 2019 (pre-pandemic), 2020 (the year the pandemic hit), and 2021 (the second year of the pandemic); and across individual tweeters. We show that Canadian tweets tend to have higher valence, lower arousal, and higher dominance than the US tweets. Further, we show that the COVID-19 pandemic had a marked impact on the emotional signature of tweets posted in 2020, when compared to the adjoining years. Finally, we determine metrics of TED for 170,000 tweeters to benchmark characteristics of TED metrics at an aggregate level. TUSC and the metrics for TED will enable a wide variety of research on studying how we use language to express ourselves, persuade, communicate, and influence, with particularly promising applications in public health, affective science, social science, and psychology.",https://aclanthology.org/2022.lrec-1.442,emotion,Yes,No,No
{ELAL}: An Emotion Lexicon for the Analysis of {A}lsatian Theatre Plays,"Bernhard, Delphine  and
Ruiz Fabo, Pablo",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"In this work, we present a novel and manually corrected emotion lexicon for the Alsatian dialects, including graphical variants of Alsatian lexical items. These High German dialects are spoken in the North-East of France. They are used mainly orally, and thus lack a stable and consensual spelling convention. There has nevertheless been a continuous literary production since the middle of the 17th century and, in particular, theatre plays. A large sample of Alsatian theatre plays is currently being encoded according to the Text Encoding Initiative (TEI) Guidelines. The emotion lexicon will be used to perform automatic emotion analysis in this corpus of theatre plays. We used a graph-based approach to deriving emotion scores and translations, relying only on bilingual lexicons, cognates and spelling variants. The source lexicons for emotion scores are the NRC Valence Arousal and Dominance and NRC Emotion Intensity lexicons.",https://aclanthology.org/2022.lrec-1.534,emotion,Yes,No,No
{HADREB}: Human Appraisals and ({E}nglish) Descriptions of Robot Emotional Behaviors,"Torres-Fonseca, Josue  and
Kennington, Casey",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Humans sometimes anthropomorphize everyday objects, but especially robots that have human-like qualities and that are often able to interact with and respond to humans in ways that other objects cannot. Humans especially attribute emotion to robot behaviors, partly because humans often use and interpret emotions when interacting with other humans, and they apply that capability when interacting with robots. Moreover, emotions are a fundamental part of the human language system and emotions are used as scaffolding for language learning, making them an integral part of language learning and meaning. However, there are very few datasets that explore how humans perceive the emotional states of robots and how emotional behaviors relate to human language. To address this gap we have collected HADREB, a dataset of human appraisals and English descriptions of robot emotional behaviors collected from over 30 participants. These descriptions and human emotion appraisals are collected using the Mistyrobotics Misty II and the Digital Dream Labs Cozmo (formerly Anki) robots. The dataset contains English descriptions and emotion appraisals of more than 500 descriptions and graded valence labels of 8 emotion pairs for each behavior and each robot. In this paper we describe the process of collecting and cleaning the data, give a general analysis of the data, and evaluate the usefulness of the dataset in two experiments, one using a language model to map descriptions to emotions, the other maps robot behaviors to emotions.",https://aclanthology.org/2022.lrec-1.617,emotion,Yes,Yes,Yes
{E}mo{I}n{H}indi: A Multi-label Emotion and Intensity Annotated Dataset in {H}indi for Emotion Recognition in Dialogues,"Singh, Gopendra Vikram  and
Priya, Priyanshu  and
Firdaus, Mauajama  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"The long-standing goal of Artificial Intelligence (AI) has been to create human-like conversational systems. Such systems should have the ability to develop an emotional connection with the users, consequently, emotion recognition in dialogues has gained popularity. Emotion detection in dialogues is a challenging task because humans usually convey multiple emotions with varying degrees of intensities in a single utterance. Moreover, emotion in an utterance of a dialogue may be dependent on previous utterances making the task more complex. Recently, emotion recognition in low-resource languages like Hindi has been in great demand. However, most of the existing datasets for multi-label emotion and intensity detection in conversations are in English. To this end, we propose a large conversational dataset in Hindi named EmoInHindi for multi-label emotion and intensity recognition in conversations containing 1,814 dialogues with a total of 44,247 utterances. We prepare our dataset in a Wizard-of-Oz manner for mental health and legal counselling of crime victims. Each utterance of dialogue is annotated with one or more emotion categories from 16 emotion labels including neutral and their corresponding intensity. We further propose strong contextual baselines that can detect the emotion(s) and corresponding emotional intensity of an utterance given the conversational context.",https://aclanthology.org/2022.lrec-1.627,emotion,Yes,No,Yes
{RELATE}: Generating a linguistically inspired Knowledge Graph for fine-grained emotion classification,"Schoene, Annika Marie  and
Dethlefs, Nina  and
Ananiadou, Sophia",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Several existing resources are available for sentiment analysis (SA) tasks that are used for learning sentiment specific embedding (SSE) representations. These resources are either large, common-sense knowledge graphs (KG) that cover a limited amount of polarities/emotions or they are smaller in size (e.g.: lexicons), which require costly human annotation and cover fine-grained emotions. Therefore using knowledge resources to learn SSE representations is either limited by the low coverage of polarities/emotions or the overall size of a resource. In this paper, we first introduce a new directed KG called {`}RELATE{'}, which is built to overcome both the issue of low coverage of emotions and the issue of scalability. RELATE is the first KG of its size to cover Ekman{'}s six basic emotions that are directed towards entities. It is based on linguistic rules to incorporate the benefit of semantics without relying on costly human annotation. The performance of {`}RELATE{'} is evaluated by learning SSE representations using a Graph Convolutional Neural Network (GCN).",https://aclanthology.org/2022.lrec-1.679,emotion,No,Yes,No
{MMDAG}: Multimodal Directed Acyclic Graph Network for Emotion Recognition in Conversation,"Xu, Shuo  and
Jia, Yuxiang  and
Niu, Changyong  and
Zan, Hongying",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Emotion recognition in conversation is important for an empathetic dialogue system to understand the user{'}s emotion and then generate appropriate emotional responses. However, most previous researches focus on modeling conversational contexts primarily based on the textual modality or simply utilizing multimodal information through feature concatenation. In order to exploit multimodal information and contextual information more effectively, we propose a multimodal directed acyclic graph (MMDAG) network by injecting information flows inside modality and across modalities into the DAG architecture. Experiments on IEMOCAP and MELD show that our model outperforms other state-of-the-art models. Comparative studies validate the effectiveness of the proposed modality fusion method.",https://aclanthology.org/2022.lrec-1.733,emotion,No,Yes,No
Emotion analysis and detection during {COVID}-19,"Sosea, Tiberiu  and
Pham, Chau  and
Tekle, Alexander  and
Caragea, Cornelia  and
Li, Junyi Jessy",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Understanding emotions that people express during large-scale crises helps inform policy makers and first responders about the emotional states of the population as well as provide emotional support to those who need such support. We present CovidEmo, a dataset of {\textasciitilde}3,000 English tweets labeled with emotions and temporally distributed across 18 months. Our analyses reveal the emotional toll caused by COVID-19, and changes of the social narrative and associated emotions over time. Motivated by the time-sensitive nature of crises and the cost of large-scale annotation efforts, we examine how well large pre-trained language models generalize across domains and timeline in the task of perceived emotion prediction in the context of COVID-19. Our analyses suggest that cross-domain information transfers occur, yet there are still significant gaps. We propose semi-supervised learning as a way to bridge this gap, obtaining significantly better performance using unlabeled data from the target domain.",https://aclanthology.org/2022.lrec-1.750,emotion,Yes,Yes,Yes
Cross-lingual Emotion Detection,"Hassan, Sabit  and
Shaar, Shaden  and
Darwish, Kareem",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"Emotion detection can provide us with a window into understanding human behavior. Due to the complex dynamics of human emotions, however, constructing annotated datasets to train automated models can be expensive. Thus, we explore the efficacy of cross-lingual approaches that would use data from a source language to build models for emotion detection in a target language. We compare three approaches, namely: i) using inherently multilingual models; ii) translating training data into the target language; and iii) using an automatically tagged parallel corpus. In our study, we consider English as the source language with Arabic and Spanish as target languages. We study the effectiveness of different classification models such as BERT and SVMs trained with different features. Our BERT-based monolingual models that are trained on target language data surpass state-of-the-art (SOTA) by 4{\%} and 5{\%} absolute Jaccard score for Arabic and Spanish respectively. Next, we show that using cross-lingual approaches with English data alone, we can achieve more than 90{\%} and 80{\%} relative effectiveness of the Arabic and Spanish BERT models respectively. Lastly, we use LIME to analyze the challenges of training cross-lingual models for different language pairs.",https://aclanthology.org/2022.lrec-1.751,emotion,Yes,Yes,No
A Multimodal Corpus for Emotion Recognition in Sarcasm,"Ray, Anupama  and
Mishra, Shubham  and
Nunna, Apoorva  and
Bhattacharyya, Pushpak",2022,Proceedings of the Thirteenth Language Resources and Evaluation Conference,,"While sentiment and emotion analysis have been studied extensively, the relationship between sarcasm and emotion has largely remained unexplored. A sarcastic expression may have a variety of underlying emotions. For example, {``}I love being ignored{''} belies sadness, while {``}my mobile is fabulous with a battery backup of only 15 minutes!{''} expresses frustration. Detecting the emotion behind a sarcastic expression is non-trivial yet an important task. We undertake the task of detecting the emotion in a sarcastic statement, which to the best of our knowledge, is hitherto unexplored. We start with the recently released multimodal sarcasm detection dataset (MUStARD) pre-annotated with 9 emotions. We identify and correct 343 incorrect emotion labels (out of 690). We double the size of the dataset, label it with emotions along with valence and arousal which are important indicators of emotional intensity. Finally, we label each sarcastic utterance with one of the four sarcasm types-Propositional, Embedded, Likeprefixed and Illocutionary, with the goal of advancing sarcasm detection research. Exhaustive experimentation with multimodal (text, audio, and video) fusion models establishes a benchmark for exact emotion recognition in sarcasm and outperforms the state-of-art sarcasm detection. We release the dataset enriched with various annotations and the code for research purposes: \url{https://github.com/apoorva-nunna/MUStARD_Plus_Plus}",https://aclanthology.org/2022.lrec-1.756,emotion,Yes,Yes,No
Enriching Deep Learning with Frame Semantics for Empathy Classification in Medical Narrative Essays,"Dey, Priyanka  and
Girju, Roxana",2022,Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI),10.18653/v1/2022.louhi-1.23,"Empathy is a vital component of health care and plays a key role in the training of future doctors. Paying attention to medical students{'} self-reflective stories of their interactions with patients can encourage empathy and the formation of professional identities that embody desirable values such as integrity and respect. We present a computational approach and linguistic analysis of empathic language in a large corpus of 440 essays written by pre-med students as narrated simulated patient {--} doctor interactions. We analyze the discourse of three kinds of empathy: cognitive, affective, and prosocial as highlighted by expert annotators. We also present various experiments with state-of-the-art recurrent neural networks and transformer models for classifying these forms of empathy. To further improve over these results, we develop a novel system architecture that makes use of frame semantics to enrich our state-of-the-art models. We show that this novel framework leads to significant improvement on the empathy classification task for this dataset.",https://aclanthology.org/2022.louhi-1.23,empathy,Yes,Yes,No
Towards a contextualised spatial-diachronic history of literature: mapping emotional representations of the city and the country in {P}olish fiction from 1864 to 1939,"Karli{\'n}ska, Agnieszka  and
Rosi{\'n}ski, Cezary  and
Wieczorek, Jan  and
Hubar, Patryk  and
Koco{\'n}, Jan  and
Kubis, Marek  and
Wo{\'z}niak, Stanis{\l}aw  and
Margraf, Arkadiusz  and
Walentynowicz, Wiktor",2022,"Proceedings of the 6th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",,"In this article, we discuss the conditions surrounding the building of historical and literary corpora. We describe the assumptions and method of making the original corpus of the Polish novel (1864-1939). Then, we present the research procedure aimed at demonstrating the variability of the emotional value of the concept of {``}the city{''} and {``}the country{''} in the texts included in our corpus. The proposed method considers the complex socio-political nature of Central and Eastern Europe, especially the fact that there was no unified Polish state during this period. The method can be easily replicated in studies of the literature of countries with similar specificities.",https://aclanthology.org/2022.latechclfl-1.14,emotion,Yes,No,No
Plug-and-Play Controller for Story Completion: A Pilot Study toward Emotion-aware Story Writing Assistance,"Mori, Yusuke  and
Yamane, Hiroaki  and
Shimizu, Ryohei  and
Harada, Tatsuya",2022,Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing 2022),10.18653/v1/2022.in2writing-1.6,"Emotions are essential for storytelling and narrative generation, and as such, the relationship between stories and emotions has been extensively studied. The authors of this paper, including a professional novelist, have examined the use of natural language processing to address the problems of novelists from the perspective of practical creative writing. In particular, the story completion task, which requires understanding the existing unfinished context, was studied from the perspective of creative support for human writers, to generate appropriate content to complete the unfinished parts. It was found that unsupervised pre-trained large neural models of the sequence-to-sequence type are useful for this task. Furthermore, based on the plug-and-play module for controllable text generation using GPT-2, an additional module was implemented to consider emotions. Although this is a preliminary study, and the results leave room for improvement before incorporating the model into a practical system, this effort is an important step in complementing the emotional trajectory of the story.",https://aclanthology.org/2022.in2writing-1.6,emotion,No,Yes,Yes
Emotion-guided Cross-domain Fake News Detection using Adversarial Domain Adaptation,"Choudhry, Arjun  and
Khatri, Inder  and
Chakraborty, Arkajyoti  and
Vishwakarma, Dinesh  and
Prasad, Mukesh",2022,Proceedings of the 19th International Conference on Natural Language Processing (ICON),,"Recent works on fake news detection have shown the efficacy of using emotions as a feature or emotions-based features for improved performance. However, the impact of these emotion-guided features for fake news detection in cross-domain settings, where we face the problem of domain shift, is still largely unexplored. In this work, we evaluate the impact of emotion-guided features for cross-domain fake news detection, and further propose an emotion-guided, domain-adaptive approach using adversarial learning. We prove the efficacy of emotion-guided models in cross-domain settings for various combinations of source and target datasets from FakeNewsAMT, Celeb, Politifact and Gossipcop datasets.",https://aclanthology.org/2022.icon-main.10,emotion,No,Yes,No
Beyond calories: evaluating how tailored communication reduces emotional load in diet-coaching,"Balloccu, Simone  and
Reiter, Ehud",2022,Proceedings of the 2nd Workshop on Human Evaluation of NLP Systems (HumEval),10.18653/v1/2022.humeval-1.5,"Dieting is a behaviour change task that is difficult for many people to conduct successfully. This is due to many factors, including stress and cost. Mobile applications offer an alternative to traditional coaching. However, previous work on apps evaluation only focused on dietary outcomes, ignoring users{'} emotional state despite its influence on eating habits. In this work, we introduce a novel evaluation of the effects that tailored communication can have on the emotional load of dieting. We implement this by augmenting a traditional diet-app with affective NLG, text-tailoring and persuasive communication techniques. We then run a short 2-weeks experiment and check dietary outcomes, user feedback of produced text and, most importantly, its impact on emotional state, through PANAS questionnaire. Results show that tailored communication significantly improved users{'} emotional state, compared to an app-only control group.",https://aclanthology.org/2022.humeval-1.5,emotion,No,No,No
Design Considerations for an {NLP}-Driven Empathy and Emotion Interface for Clinician Training via Telemedicine,"Girju, Roxana  and
Girju, Marina",2022,Proceedings of the Second Workshop on Bridging Human--Computer Interaction and Natural Language Processing,10.18653/v1/2022.hcinlp-1.3,"As digital social platforms and mobile technologies become more prevalent and robust, the use of Artificial Intelligence (AI) in facilitating human communication will grow. This, in turn, will encourage development of intuitive, adaptive, and effective empathic AI interfaces that better address the needs of socially and culturally diverse communities. In this paper, we present several design considerations of an intelligent digital interface intended to guide the clinicians toward more empathetic communication. This approach allows various communities of practice to investigate how AI, on one side, and human communication and healthcare needs, on the other, can contribute to each other{'}s development.",https://aclanthology.org/2022.hcinlp-1.3,emotion_and_empathy,No,Yes,Yes
Teaching Interactively to Learn Emotions in Natural Language,"Titung, Rajesh  and
Alm, Cecilia",2022,Proceedings of the Second Workshop on Bridging Human--Computer Interaction and Natural Language Processing,10.18653/v1/2022.hcinlp-1.6,"Motivated by prior literature, we provide a proof of concept simulation study for an understudied interactive machine learning method, machine teaching (MT), for the text-based emotion prediction task. We compare this method experimentally against a more well-studied technique, active learning (AL). Results show the strengths of both approaches over more resource-intensive offline supervised learning. Additionally, applying AL and MT to fine-tune a pre-trained model offers further efficiency gain. We end by recommending research directions which aim to empower users in the learning process.",https://aclanthology.org/2022.hcinlp-1.6,emotion,No,Yes,No
The Secret of Metaphor on Expressing Stronger Emotion,"Li, Yucheng  and
Guerin, Frank  and
Lin, Chenghua",2022,Proceedings of the 3rd Workshop on Figurative Language Processing (FLP),10.18653/v1/2022.flp-1.6,"Metaphors are proven to have stronger emotional impact than literal expressions. Although this conclusion is shown to be promising in benefiting various NLP applications, the reasons behind this phenomenon are not well studied. This paper conducts the first study in exploring how metaphors convey stronger emotion than their literal counterparts. We find that metaphors are generally more specific than literal expressions. The more specific property of metaphor can be one of the reasons for metaphors{'} superiority in emotion expression. When we compare metaphors with literal expressions with the same specificity level, the gap of emotion expressing ability between both reduces significantly. In addition, we observe specificity is crucial in literal language as well, as literal language can express stronger emotion by making it more specific.",https://aclanthology.org/2022.flp-1.6,emotion,No,No,Yes
A Sentiment and Emotion Annotated Dataset for Bitcoin Price Forecasting Based on {R}eddit Posts,"Seroyizhko, Pavlo  and
Zhexenova, Zhanel  and
Shafiq, Muhammad Zohaib  and
Merizzi, Fabio  and
Galassi, Andrea  and
Ruggeri, Federico",2022,Proceedings of the Fourth Workshop on Financial Technology and Natural Language Processing (FinNLP),10.18653/v1/2022.finnlp-1.27,"Cryptocurrencies have gained enormous momentum in finance and are nowadays commonly adopted as a medium of exchange for online payments. After recent events during which GameStop{'}s stocks were believed to be influenced by WallStreetBets subReddit, Reddit has become a very hot topic on the cryptocurrency market. The influence of public opinions on cryptocurrency price trends has inspired researchers on exploring solutions that integrate such information in crypto price change forecasting. A popular integration technique regards representing social media opinions via sentiment features. However, this research direction is still in its infancy, where a limited number of publicly available datasets with sentiment annotations exists. We propose a novel Bitcoin Reddit Sentiment Dataset, a ready-to-use dataset annotated with state-of-the-art sentiment and emotion recognition. The dataset contains pre-processed Reddit posts and comments about Bitcoin from several domain-related subReddits along with Bitcoin{'}s financial data. We evaluate several widely adopted neural architectures for crypto price change forecasting. Our results show controversial benefits of sentiment and emotion features advocating for more sophisticated social media integration techniques. We make our dataset publicly available for research.",https://aclanthology.org/2022.finnlp-1.27,emotion,Yes,Yes,No
Empathetic Persuasion: Reinforcing Empathy and Persuasiveness in Dialogue Systems,"Samad, Azlaan Mustafa  and
Mishra, Kshitij  and
Firdaus, Mauajama  and
Ekbal, Asif",2022,Findings of the Association for Computational Linguistics: NAACL 2022,10.18653/v1/2022.findings-naacl.63,"Persuasion is an intricate process involving empathetic connection between two individuals. Plain persuasive responses may make a conversation non-engaging. Even the most well-intended and reasoned persuasive conversations can fall through in the absence of empathetic connection between the speaker and listener. In this paper, we propose a novel task of incorporating empathy when generating persuasive responses. We develop an empathetic persuasive dialogue system by fine-tuning a maximum likelihood Estimation (MLE)-based language model in a reinforcement learning (RL) framework. To design feedbacks for our RL-agent, we define an effective and efficient reward function considering consistency, repetitiveness, emotion and persuasion rewards to ensure consistency, non-repetitiveness, empathy and persuasiveness in the generated responses. Due to lack of emotion annotated persuasive data, we first annotate the existing Persuaion For Good dataset with emotions, then build transformer based classifiers to provide emotion based feedbacks to our RL agent. Experimental results confirm that our proposed model increases the rate of generating persuasive responses as compared to the available state-of-the-art dialogue models while making the dialogues empathetically more engaging and retaining the language quality in responses.",https://aclanthology.org/2022.findings-naacl.63,empathy,Yes,Yes,Yes
A Critical Reflection and Forward Perspective on Empathy and Natural Language Processing,"Lahnala, Allison  and
Welch, Charles  and
Jurgens, David  and
Flek, Lucie",2022,Findings of the Association for Computational Linguistics: EMNLP 2022,10.18653/v1/2022.findings-emnlp.157,"We review the state of research on empathy in natural language processing and identify the following issues: (1) empathy definitions are absent or abstract, which (2) leads to low construct validity and reproducibility. Moreover, (3) emotional empathy is overemphasized, skewing our focus to a narrow subset of simplified tasks. We believe these issues hinder research progress and argue that current directions will benefit from a clear conceptualization that includes operationalizing cognitive empathy components. Our main objectives are to provide insight and guidance on empathy conceptualization for NLP research objectives and to encourage researchers to pursue the overlooked opportunities in this area, highly relevant, e.g., for clinical and educational sectors.",https://aclanthology.org/2022.findings-emnlp.157,empathy,No,No,Yes
Empathetic Dialogue Generation via Sensitive Emotion Recognition and Sensible Knowledge Selection,"Wang, Lanrui  and
Li, Jiangnan  and
Lin, Zheng  and
Meng, Fandong  and
Yang, Chenxu  and
Wang, Weiping  and
Zhou, Jie",2022,Findings of the Association for Computational Linguistics: EMNLP 2022,10.18653/v1/2022.findings-emnlp.340,"Empathy, which is widely used in psychological counseling, is a key trait of everyday human conversations. Equipped with commonsense knowledge, current approaches to empathetic response generation focus on capturing implicit emotion within dialogue context, where the emotions are treated as a static variable throughout the conversations. However, emotions change dynamically between utterances, which makes previous works difficult to perceive the emotion flow and predict the correct emotion of the target response, leading to inappropriate response. Furthermore, simply importing commonsense knowledge without harmonization may trigger the conflicts between knowledge and emotion, which confuse the model to choose the correct information to guide the generation process. To address the above problems, we propose a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation. We use a fine-grained encoding strategy which is more sensitive to the emotion dynamics (emotion flow) in the conversations to predict the emotion-intent characteristic of response. Besides, we design a novel framework to model the interaction between knowledge and emotion to solve the conflicts generate more sensible response. Extensive experiments on the utterance-level annotated EMPATHETICDIALOGUES demonstrate that SEEK outperforms the strong baseline in both automatic and manual evaluations.",https://aclanthology.org/2022.findings-emnlp.340,emotion,Yes,Yes,No
Self-supervised Cross-modal Pretraining for Speech Emotion Recognition and Sentiment Analysis,"Chu, Iek-Heng  and
Chen, Ziyi  and
Yu, Xinlu  and
Han, Mei  and
Xiao, Jing  and
Chang, Peng",2022,Findings of the Association for Computational Linguistics: EMNLP 2022,10.18653/v1/2022.findings-emnlp.375,"Multimodal speech emotion recognition (SER) and sentiment analysis (SA) are important techniques for human-computer interaction. Most existing multimodal approaches utilize either shallow cross-modal fusion of pretrained features, or deep cross-modal fusion with raw features. Recently, attempts have been made to fuse pretrained feature representations in a deep fusion manner during fine-tuning stage. However those approaches have not led to improved results, partially due to their relatively simple fusion mechanisms and lack of proper cross-modal pretraining. In this work, leveraging single-modal pretrained models (RoBERTa and HuBERT), we propose a novel deeply-fused audio-text bi-modal transformer with carefully designed cross-modal fusion mechanism and a stage-wise cross-modal pretraining scheme to fully facilitate the cross-modal learning. Our experiment results show that the proposed method achieves state-of-the-art results on the public IEMOCAP emotion and CMU-MOSEI sentiment datasets, exceeding the previous benchmarks by a large margin.",https://aclanthology.org/2022.findings-emnlp.375,emotion,No,Yes,No
Empathetic and Emotionally Positive Conversation Systems with an Emotion-specific Query-Response Memory,"Tian, Zhiliang  and
Wang, Yinliang  and
Song, Yiping  and
Zhang, Chi  and
Lee, Dongkyu  and
Zhao, Yingxiu  and
Li, Dongsheng  and
Zhang, Nevin L.",2022,Findings of the Association for Computational Linguistics: EMNLP 2022,10.18653/v1/2022.findings-emnlp.475,"Emotional conversation systems generate responses for the input queries considering the speaker{'}s emotions in a conversation. Existing emotional conversation systems output emotional responses according to either a given emotion or the user{'}s emotion reflected in the input queries. Following a given emotion may lead to an emotional drift between the given emotion and the conversation state, and following only the user{'}s emotion may aggravate the user{'}s negative feelings if users suffer from a negative mood. In this paper, we propose to generate empathetic responses catering to the user{'}s emotions while leading the conversation to be emotionally positive. Particularly, by abstracting the conversation corpus, we extract and store the different responding strategies for different users{'} emotions and conversational topics into a memory. We encourage positive emotions in conversation via a sentiment evaluator. We model the memory outputs with a Gaussian mixture distribution and sample a final responding strategy from the distribution. The strategy acts as a condition to a transformer model to generate responses. The experiments verify our model surpasses the baseline methods in appropriateness, diversity, and generating emotionally positive responses.",https://aclanthology.org/2022.findings-emnlp.475,emotion,Yes,Yes,No
Multi-Granularity Semantic Aware Graph Model for Reducing Position Bias in Emotion Cause Pair Extraction,"Bao, Yinan  and
Ma, Qianwen  and
Wei, Lingwei  and
Zhou, Wei  and
Hu, Songlin",2022,Findings of the Association for Computational Linguistics: ACL 2022,10.18653/v1/2022.findings-acl.95,"The emotion cause pair extraction (ECPE) task aims to extract emotions and causes as pairs from documents. We observe that the relative distance distribution of emotions and causes is extremely imbalanced in the typical ECPE dataset. Existing methods have set a fixed size window to capture relations between neighboring clauses. However, they neglect the effective semantic connections between distant clauses, leading to poor generalization ability towards position-insensitive data. To alleviate the problem, we propose a novel $\textbf{M}$ulti-$\textbf{G}$ranularity $\textbf{S}$emantic $\textbf{A}$ware $\textbf{G}$raph model (MGSAG) to incorporate fine-grained and coarse-grained semantic features jointly, without regard to distance limitation. In particular, we first explore semantic dependencies between clauses and keywords extracted from the document that convey fine-grained semantic features, obtaining keywords enhanced clause representations. Besides, a clause graph is also established to model coarse-grained semantic relations between clauses. Experimental results indicate that MGSAG surpasses the existing state-of-the-art ECPE models. Especially, MGSAG outperforms other models significantly in the condition of position-insensitive data.",https://aclanthology.org/2022.findings-acl.95,emotion,Yes,Yes,No
{E}mo{C}aps: Emotion Capsule based Model for Conversational Emotion Recognition,"Li, Zaijing  and
Tang, Fengxiao  and
Zhao, Ming  and
Zhu, Yusen",2022,Findings of the Association for Computational Linguistics: ACL 2022,10.18653/v1/2022.findings-acl.126,"Emotion recognition in conversation (ERC) aims to analyze the speaker{'}s state and identify their emotion in the conversation. Recent works in ERC focus on context modeling but ignore the representation of contextual emotional tendency. In order to extract multi-modal information and the emotional tendency of the utterance effectively, we propose a new structure named Emoformer to extract multi-modal emotion vectors from different modalities and fuse them with sentence vector to be an emotion capsule. Furthermore, we design an end-to-end ERC model called EmoCaps, which extracts emotion vectors through the Emoformer structure and obtain the emotion classification results from a context analysis model. Through the experiments with two benchmark datasets, our model shows better performance than the existing state-of-the-art models.",https://aclanthology.org/2022.findings-acl.126,emotion,Yes,Yes,No
{MMM}: An Emotion and Novelty-aware Approach for Multilingual Multimodal Misinformation Detection,"Gupta, Vipin  and
Kumari, Rina  and
Ashok, Nischal  and
Ghosal, Tirthankar  and
Ekbal, Asif",2022,Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022,,"The growth of multilingual web content in low-resource languages is becoming an emerging challenge to detect misinformation. One particular hindrance to research on this problem is the non-availability of resources and tools. Majority of the earlier works in misinformation detection are based on English content which confines the applicability of the research to a specific language only. Increasing presence of multimedia content on the web has promoted misinformation in which real multimedia content (images, videos) are used in different but related contexts with manipulated texts to mislead the readers. Detecting this category of misleading information is almost impossible without any prior knowledge. Studies say that emotion-invoking and highly novel content accelerates the dissemination of false information. To counter this problem, here in this paper, we first introduce a novel multilingual multimodal misinformation dataset that includes background knowledge (from authentic sources) of the misleading articles. Second, we propose an effective neural model leveraging novelty detection and emotion recognition to detect fabricated information. We perform extensive experiments to justify that our proposed model outperforms the state-of-the-art (SOTA) on the concerned task.",https://aclanthology.org/2022.findings-aacl.43,emotion,Yes,Yes,No
Improving Multi-turn Emotional Support Dialogue Generation with Lookahead Strategy Planning,"Cheng, Yi  and
Liu, Wenge  and
Li, Wenjie  and
Wang, Jiashuo  and
Zhao, Ruihui  and
Liu, Bang  and
Liang, Xiaodan  and
Zheng, Yefeng",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.195,"Providing Emotional Support (ES) to soothe people in emotional distress is an essential capability in social interactions. Most existing researches on building ES conversation systems only considered single-turn interactions with users, which was over-simplified. In comparison, multi-turn ES conversation systems can provide ES more effectively, but face several new technical challenges, including: (1) how to adopt appropriate support strategies to achieve the long-term dialogue goal of comforting the user{'}s emotion; (2) how to dynamically model the user{'}s state. In this paper, we propose a novel system MultiESC to address these issues. For strategy planning, drawing inspiration from the A* search algorithm, we propose lookahead heuristics to estimate the future user feedback after using particular strategies, which helps to select strategies that can lead to the best long-term effects. For user state modeling, MultiESC focuses on capturing users{'} subtle emotional expressions and understanding their emotion causes. Extensive experiments show that MultiESC significantly outperforms competitive baselines in both dialogue generation and strategy planning.",https://aclanthology.org/2022.emnlp-main.195,emotion,No,Yes,No
Face-Sensitive Image-to-Emotional-Text Cross-modal Translation for Multimodal Aspect-based Sentiment Analysis,"Yang, Hao  and
Zhao, Yanyan  and
Qin, Bing",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.219,"Aspect-level multimodal sentiment analysis, which aims to identify the sentiment of the target aspect from multimodal data, recently has attracted extensive attention in the community of multimedia and natural language processing. Despite the recent success in textual aspect-based sentiment analysis, existing models mainly focused on utilizing the object-level semantic information in the image but ignore explicitly using the visual emotional cues, especially the facial emotions. How to distill visual emotional cues and align them with the textual content remains a key challenge to solve the problem. In this work, we introduce a face-sensitive image-to-emotional-text translation (FITE) method, which focuses on capturing visual sentiment cues through facial expressions and selectively matching and fusing with the target aspect in textual modality. To the best of our knowledge, we are the first that explicitly utilize the emotional information from images in the multimodal aspect-based sentiment analysis task. Experiment results show that our method achieves state-of-the-art results on the Twitter-2015 and Twitter-2017 datasets. The improvement demonstrates the superiority of our model in capturing aspect-level sentiment in multimodal data with facial expressions.",https://aclanthology.org/2022.emnlp-main.219,emotion,No,Yes,Yes
Efficient Nearest Neighbor Emotion Classification with {BERT}-whitening,"Yin, Wenbiao  and
Shang, Lin",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.312,"Retrieval-based methods have been proven effective in many NLP tasks. Previous methods use representations from the pre-trained model for similarity search directly. However, the sentence representations from the pre-trained model like BERT perform poorly in retrieving semantically similar sentences, resulting in poor performance of the retrieval-based methods. In this paper, we propose kNN-EC, a simple and efficient non-parametric emotion classification (EC) method using nearest neighbor retrieval. We use BERT-whitening to get better sentence semantics, ensuring that nearest neighbor retrieval works. Meanwhile, BERT-whitening can also reduce memory storage of datastore and accelerate retrieval speed, solving the efficiency problem of the previous methods. kNN-EC average improves the pre-trained model by 1.17 F1-macro on two emotion classification datasets.",https://aclanthology.org/2022.emnlp-main.312,emotion,No,Yes,Yes
Supervised Prototypical Contrastive Learning for Emotion Recognition in Conversation,"Song, Xiaohui  and
Huang, Longtao  and
Xue, Hui  and
Hu, Songlin",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.347,"Capturing emotions within a conversation plays an essential role in modern dialogue systems. However, the weak correlation between emotions and semantics brings many challenges to emotion recognition in conversation (ERC). Even semantically similar utterances, the emotion may vary drastically depending on contexts or speakers. In this paper, we propose a Supervised Prototypical Contrastive Learning (SPCL) loss for the ERC task. Leveraging the Prototypical Network, the SPCL targets at solving the imbalanced classification problem through contrastive learning and does not require a large batch size. Meanwhile, we design a difficulty measure function based on the distance between classes and introduce curriculum learning to alleviate the impact of extreme samples. We achieve state-of-the-art results on three widely used benchmarks. Further, we conduct analytical experiments to demonstrate the effectiveness of our proposed SPCL and curriculum learning strategy.",https://aclanthology.org/2022.emnlp-main.347,emotion,No,Yes,No
Pair-Based Joint Encoding with Relational Graph Convolutional Networks for Emotion-Cause Pair Extraction,"Liu, Junlong  and
Shang, Xichen  and
Ma, Qianli",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.358,"Emotion-cause pair extraction (ECPE) aims to extract emotion clauses and corresponding cause clauses, which have recently received growing attention. Previous methods sequentially encode features with a specified order. They first encode the emotion and cause features for clause extraction and then combine them for pair extraction. This lead to an imbalance in inter-task feature interaction where features extracted later have no direct contact with the former. To address this issue, we propose a novel **P**air-**B**ased **J**oint **E**ncoding (**PBJE**) network, which generates pairs and clauses features simultaneously in a joint feature encoding manner to model the causal relationship in clauses. PBJE can balance the information flow among emotion clauses, cause clauses and pairs. From a multi-relational perspective, we construct a heterogeneous undirected graph and apply the Relational Graph Convolutional Network (RGCN) to capture the multiplex relationship between clauses and the relationship between pairs and clauses. Experimental results show that PBJE achieves state-of-the-art performance on the Chinese benchmark corpus.",https://aclanthology.org/2022.emnlp-main.358,emotion,Yes,Yes,No
{U}ni{MSE}: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition,"Hu, Guimin  and
Lin, Ting-En  and
Zhao, Yi  and
Lu, Guangming  and
Wu, Yuchuan  and
Li, Yongbin",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.534,"Multimodal sentiment analysis (MSA) and emotion recognition in conversation (ERC) are key research topics for computers to understand human behaviors. From a psychological perspective, emotions are the expression of affect or feelings during a short period, while sentiments are formed and held for a longer period. However, most existing works study sentiment and emotion separately and do not fully exploit the complementary knowledge behind the two. In this paper, we propose a multimodal sentiment knowledge-sharing framework (UniMSE) that unifies MSA and ERC tasks from features, labels, and models. We perform modality fusion at the syntactic and semantic levels and introduce contrastive learning between modalities and samples to better capture the difference and consistency between sentiments and emotions. Experiments on four public benchmark datasets, MOSI, MOSEI, MELD, and IEMOCAP, demonstrate the effectiveness of the proposed method and achieve consistent improvements compared with state-of-the-art methods.",https://aclanthology.org/2022.emnlp-main.534,emotion,Yes,Yes,No
{A}rt{EL}ingo: A Million Emotion Annotations of {W}iki{A}rt with Emphasis on Diversity over Language and Culture,"Mohamed, Youssef  and
Abdelfattah, Mohamed  and
Alhuwaider, Shyma  and
Li, Feifan  and
Zhang, Xiangliang  and
Church, Kenneth  and
Elhoseiny, Mohamed",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.600,"This paper introduces ArtELingo, a new benchmark and dataset, designed to encourage work on diversity across languages and cultures. Following ArtEmis, a collection of 80k artworks from WikiArt with 0.45M emotion labels and English-only captions, ArtELingo adds another 0.79M annotations in Arabic and Chinese, plus 4.8K in Spanish to evaluate {``}cultural-transfer{''} performance. 51K artworks have 5 annotations or more in 3 languages. This diversity makes it possible to study similarities and differences across languages and cultures. Further, we investigate captioning tasks, and find diversity improves the performance of baseline models. ArtELingo is publicly available at {`}www.artelingo.org{`} with standard splits and baseline models. We hope our work will help ease future research on multilinguality and culturally-aware AI.",https://aclanthology.org/2022.emnlp-main.600,emotion,Yes,Yes,No
Calibrating Student Models for Emotion-related Tasks,"Hosseini, Mahshid  and
Caragea, Cornelia",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.629,"Knowledge Distillation (KD) is an effective method to transfer knowledge from one network (a.k.a. teacher) to another (a.k.a. student). In this paper, we study KD on the emotion-related tasks from a new perspective: calibration. We further explore the impact of the mixup data augmentation technique on the distillation objective and propose to use a simple yet effective mixup method informed by training dynamics for calibrating the student models. Underpinned by the regularization impact of the mixup process by providing better training signals to the student models using training dynamics, our proposed mixup strategy gradually enhances the student model{'}s calibration while effectively improving its performance. We evaluate the calibration of pre-trained language models through knowledge distillation over three tasks of emotion detection, sentiment analysis, and empathy detection. By conducting extensive experiments on different datasets, with both in-domain and out-of-domain test sets, we demonstrate that student models distilled from teacher models trained using our proposed mixup method obtained the lowest Expected Calibration Errors (ECEs) and best performance on both in-domain and out-of-domain test sets.",https://aclanthology.org/2022.emnlp-main.629,emotion,No,Yes,Yes
Why Do You Feel This Way? Summarizing Triggers of Emotions in Social Media Posts,"Zhan, Hongli  and
Sosea, Tiberiu  and
Caragea, Cornelia  and
Li, Junyi Jessy",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.642,"Crises such as the COVID-19 pandemic continuously threaten our world and emotionally affect billions of people worldwide in distinct ways. Understanding the triggers leading to people{'}s emotions is of crucial importance. Social media posts can be a good source of such analysis, yet these texts tend to be charged with multiple emotions, with triggers scattering across multiple sentences. This paper takes a novel angle, namely, emotion detection and trigger summarization, aiming to both detect perceived emotions in text, and summarize events and their appraisals that trigger each emotion. To support this goal, we introduce CovidET (Emotions and their Triggers during Covid-19), a dataset of {\textasciitilde}1,900 English Reddit posts related to COVID-19, which contains manual annotations of perceived emotions and abstractive summaries of their triggers described in the post. We develop strong baselines to jointly detect emotions and summarize emotion triggers. Our analyses show that CovidET presents new challenges in emotion-specific summarization, as well as multi-emotion detection in long social media posts.",https://aclanthology.org/2022.emnlp-main.642,emotion,Yes,No,No
Textless Speech Emotion Conversion using Discrete {\&} Decomposed Representations,"Kreuk, Felix  and
Polyak, Adam  and
Copet, Jade  and
Kharitonov, Eugene  and
Nguyen, Tu Anh  and
Rivi{\`e}re, Morgan  and
Hsu, Wei-Ning  and
Mohamed, Abdelrahman  and
Dupoux, Emmanuel  and
Adi, Yossi",2022,Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2022.emnlp-main.769,"Speech emotion conversion is the task of modifying the perceived emotion of a speech utterance while preserving the lexical content and speaker identity. In this study, we cast the problem of emotion conversion as a spoken language translation task. We use a decomposition of the speech signal into discrete learned representations, consisting of phonetic-content units, prosodic features, speaker, and emotion. First, we modify the speech content by translating the phonetic-content units to a target emotion, and then predict the prosodic features based on these units. Finally, the speech waveform is generated by feeding the predicted representations into a neural vocoder. Such a paradigm allows us to go beyond spectral and parametric changes of the signal, and model non-verbal vocalizations, such as laughter insertion, yawning removal, etc. We demonstrate objectively and subjectively that the proposed method is vastly superior to current approaches and even beats text-based systems in terms of perceived emotion and audio quality. We rigorously evaluate all components of such a complex system and conclude with an extensive model analysis and ablation study to better emphasize the architectural choices, strengths and weaknesses of the proposed method. Samples are available under the following link: https://speechbot.github.io/emotion",https://aclanthology.org/2022.emnlp-main.769,emotion,No,Yes,No
{UMUT}eam@{T}amil{NLP}-{ACL}2022: Emotional Analysis in {T}amil,"Garc{\'\i}a-D{\'\i}az, Jos{\'e}  and
Rodr{\'\i}guez Garc{\'\i}a, Miguel {\'A}ngel  and
Valencia-Garc{\'\i}a, Rafael",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.6,"This working notes summarises the participation of the UMUTeam on the TamilNLP (ACL 2022) shared task concerning emotion analysis in Tamil. We participated in the two multi-classification challenges proposed with a neural network that combines linguistic features with different feature sets based on contextual and non-contextual sentence embeddings. Our proposal achieved the 1st result for the second subtask, with an f1-score of 15.1{\%} discerning among 30 different emotions. However, our results for the first subtask were not recorded in the official leader board. Accordingly, we report our results for this subtask with the validation split, reaching a macro f1-score of 32.360{\%}.",https://aclanthology.org/2022.dravidianlangtech-1.6,emotion,No,Yes,Yes
{J}udith{J}eyafreeda{A}ndrew@{T}amil{NLP}-{ACL}2022:{CNN} for Emotion Analysis in {T}amil,"Andrew, Judith Jeyafreeda",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.9,"Using technology for analysis of human emotion is a relatively nascent research area. There are several types of data where emotion recognition can be employed, such as - text, images, audio and video. In this paper, the focus is on emotion recognition in text data. Emotion recognition in text can be performed from both written comments and from conversations. In this paper, the dataset used for emotion recognition is a list of comments. While extensive research is being performed in this area, the language of the text plays a very important role. In this work, the focus is on the Dravidian language of Tamil. The language and its script demands an extensive pre-processing. The paper contributes to this by adapting various pre-processing methods to the Dravidian Language of Tamil. A CNN method has been adopted for the task at hand. The proposed method has achieved a comparable result.",https://aclanthology.org/2022.dravidianlangtech-1.9,emotion,Yes,No,Yes
{GJG}@{T}amil{NLP}-{ACL}2022: Emotion Analysis and Classification in {T}amil using Transformers,"Prasad, Janvi  and
Prasad, Gaurang  and
C, Gunavathi",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.14,"This paper describes the systems built by our team for the {``}Emotion Analysis in Tamil{''} shared task at the Second Workshop on Speech and Language Technologies for Dravidian Languages at ACL 2022. There were two multi-class classification sub-tasks as a part of this shared task. The dataset for sub-task A contained 11 types of emotions while sub-task B was more fine-grained with 31 emotions. We fine-tuned an XLM-RoBERTa and DeBERTA base model for each sub-task. For sub-task A, the XLM-RoBERTa model achieved an accuracy of 0.46 and the DeBERTa model achieved an accuracy of 0.45. We had the best classification performance out of 11 teams for sub-task A. For sub-task B, the XLM-RoBERTa model{'}s accuracy was 0.33 and the DeBERTa model had an accuracy of 0.26. We ranked 2nd out of 7 teams for sub-task B.",https://aclanthology.org/2022.dravidianlangtech-1.14,emotion,Yes,Yes,Yes
{PANDAS}@{T}amil{NLP}-{ACL}2022: Emotion Analysis in {T}amil Text using Language Agnostic Embeddings,"K, Divyasri  and
G L, Gayathri  and
Swaminathan, Krithika  and
Durairaj, Thenmozhi  and
B, Bharathi  and
B, Senthil Kumar",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.17,"As the world around us continues to become increasingly digital, it has been acknowledged that there is a growing need for emotion analysis of social media content. The task of identifying the emotion in a given text has many practical applications ranging from screening public health to business and management. In this paper, we propose a language-agnostic model that focuses on emotion analysis in Tamil text. Our experiments yielded an F1-score of 0.010.",https://aclanthology.org/2022.dravidianlangtech-1.17,emotion,No,Yes,Yes
{SSNCSE}{\_}{NLP}@{T}amil{NLP}-{ACL}2022: Transformer based approach for Emotion analysis in {T}amil language,"B, Bharathi  and
Varsha, Josephine",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.20,"Emotion analysis is the process of identifying and analyzing the underlying emotions expressed in textual data. Identifying emotions from a textual conversation is a challenging task due to the absence of gestures, vocal intonation, and facial expressions. Once the chatbots and messengers detect and report the emotions of the user, a comfortable conversation can be carried out with no misunderstandings. Our task is to categorize text into a predefined notion of emotion. In this thesis, it is required to classify text into several emotional labels depending on the task. We have adopted the transformer model approach to identify the emotions present in the text sequence. Our task is to identify whether a given comment contains emotion, and the emotion it stands for. The datasets were provided to us by the LT-EDI organizers (CITATION) for two tasks, in the Tamil language. We have evaluated the datasets using the pretrained transformer models and we have obtained the micro-averaged F1 scores as 0.19 and 0.12 for Task1 and Task 2 respectively.",https://aclanthology.org/2022.dravidianlangtech-1.20,emotion,No,Yes,Yes
{MUCS}@{D}ravidian{L}ang{T}ech@{ACL}2022: Ensemble of Logistic Regression Penalties to Identify Emotions in {T}amil Text,"Hegde, Asha  and
Coelho, Sharal  and
Shashirekha, Hosahalli",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.23,"Emotion Analysis (EA) is the process of automatically analyzing and categorizing the input text into one of the predefined sets of emotions. In recent years, people have turned to social media to express their emotions, opinions or feelings about news, movies, products, services, and so on. These users{'} emotions may help the public, governments, business organizations, film producers, and others in devising strategies, making decisions, and so on. The increasing number of social media users and the increasing amount of user generated text containing emotions on social media demands automated tools for the analysis of such data as handling this data manually is labor intensive and error prone. Further, the characteristics of social media data makes the EA challenging. Most of the EA research works have focused on English language leaving several Indian languages including Tamil unexplored for this task. To address the challenges of EA in Tamil texts, in this paper, we - team MUCS, describe the model submitted to the shared task on Emotion Analysis in Tamil at DravidianLangTech@ACL 2022. Out of the two subtasks in this shared task, our team submitted the model only for Task a. The proposed model comprises of an Ensemble of Logistic Regression (LR) classifiers with three penalties, namely: L1, L2, and Elasticnet. This Ensemble model trained with Term Frequency - Inverse Document Frequency (TF-IDF) of character bigrams and trigrams secured 4th rank in Task a with a macro averaged F1-score of 0.04. The code to reproduce the proposed models is available in github1.",https://aclanthology.org/2022.dravidianlangtech-1.23,emotion,No,Yes,No
{V}arsini{\_}and{\_}{K}irthanna@{D}ravidian{L}ang{T}ech-{ACL}2022-Emotional Analysis in {T}amil,"S, Varsini  and
Rajan, Kirthanna  and
S, Angel  and
Sivanaiah, Rajalakshmi  and
Rajendram, Sakaya Milton  and
T T, Mirnalinee",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.26,"In this paper, we present our system for the task of Emotion analysis in Tamil. Over 3.96 million people use these platforms to send messages formed using texts, images, videos, audio or combinations of these to express their thoughts and feelings. Text communication on social media platforms is quite overwhelming due to its enormous quantity and simplicity. The data must be processed to understand the general feeling felt by the author. We present a lexicon-based approach for the extraction emotion in Tamil texts. We use dictionaries of words labelled with their respective emotions. The process of assigning an emotional label to each text, and then capture the main emotion expressed in it. Finally, the F1-score in the official test set is 0.0300 and our method ranks 5th.",https://aclanthology.org/2022.dravidianlangtech-1.26,emotion,No,No,No
{CUET}-{NLP}@{T}amil{NLP}-{ACL}2022: Multi-Class Textual Emotion Detection from Social Media using Transformer,"Mustakim, Nasehatul  and
Rabu, Rabeya  and
Md. Mursalin, Golam  and
Hossain, Eftekhar  and
Sharif, Omar  and
Hoque, Mohammed Moshiul",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.31,"Recently, emotion analysis has gained increased attention by NLP researchers due to its various applications in opinion mining, e-commerce, comprehensive search, healthcare, personalized recommendations and online education. Developing an intelligent emotion analysis model is challenging in resource-constrained languages like Tamil. Therefore a shared task is organized to identify the underlying emotion of a given comment expressed in the Tamil language. The paper presents our approach to classifying the textual emotion in Tamil into 11 classes: ambiguous, anger, anticipation, disgust, fear, joy, love, neutral, sadness, surprise and trust. We investigated various machine learning (LR, DT, MNB, SVM), deep learning (CNN, LSTM, BiLSTM) and transformer-based models (Multilingual-BERT, XLM-R). Results reveal that the XLM-R model outdoes all other models by acquiring the highest macro $f_1$-score (0.33).",https://aclanthology.org/2022.dravidianlangtech-1.31,emotion,No,Yes,Yes
{O}ptimize{\_}{P}rime@{D}ravidian{L}ang{T}ech-{ACL}2022: Emotion Analysis in {T}amil,"Gokhale, Omkar  and
Patankar, Shantanu  and
Litake, Onkar  and
Mandke, Aditya  and
Kadam, Dipali",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.35,"This paper aims to perform an emotion analysis of social media comments in Tamil. Emotion analysis is the process of identifying the emotional context of the text. In this paper, we present the findings obtained by Team Optimize{\_}Prime in the ACL 2022 shared task {``}Emotion Analysis in Tamil.{''} The task aimed to classify social media comments into categories of emotion like Joy, Anger, Trust, Disgust, etc. The task was further divided into two subtasks, one with 11 broad categories of emotions and the other with 31 specific categories of emotion. We implemented three different approaches to tackle this problem: transformer-based models, Recurrent Neural Networks (RNNs), and Ensemble models. XLM-RoBERTa performed the best on the first task with a macro-averaged f1 score of 0.27, while MuRIL provided the best results on the second task with a macro-averaged f1 score of 0.13.",https://aclanthology.org/2022.dravidianlangtech-1.35,emotion,No,Yes,No
Findings of the Shared Task on Emotion Analysis in {T}amil,"Sampath, Anbukkarasi  and
Durairaj, Thenmozhi  and
Chakravarthi, Bharathi Raja  and
Priyadharshini, Ruba  and
Cn, Subalalitha  and
Shanmugavadivel, Kogilavani  and
Thavareesan, Sajeetha  and
Thangasamy, Sathiyaraj  and
Krishnamurthy, Parameswari  and
Hande, Adeep  and
Benhur, Sean  and
Ponnusamy, Kishore  and
Pandiyan, Santhiya",2022,Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages,10.18653/v1/2022.dravidianlangtech-1.42,"This paper presents the overview of the shared task on emotional analysis in Tamil. The result of the shared task is presented at the workshop. This paper presents the dataset used in the shared task, task description, and the methodology used by the participants and the evaluation results of the submission. This task is organized as two Tasks. Task A is carried with 11 emotions annotated data for social media comments in Tamil and Task B is organized with 31 fine-grained emotion annotated data for social media comments in Tamil. For conducting experiments, training and development datasets were provided to the participants and results are evaluated for the unseen data. Totally we have received around 24 submissions from 13 teams. For evaluating the models, Precision, Recall, micro average metrics are used.",https://aclanthology.org/2022.dravidianlangtech-1.42,emotion,Yes,Yes,No
{S}ynt{A}ct: A Synthesized Database of Basic Emotions,"Burkhardt, Felix  and
Eyben, Florian  and
Schuller, Bj{\""o}rn",2022,Proceedings of the Workshop on Dataset Creation for Lower-Resourced Languages within the 13th Language Resources and Evaluation Conference,,"Speech emotion recognition is in the focus of research since several decades and has many applications. One problem is sparse data for supervised learning. One way to tackle this problem is the synthesis of data with emotion simulating speech synthesis approaches. We present a synthesized database of five basic emotions and neutral expression based on rule based manipulation for a diphone synthesizer which we release to the public. The database has been validated in several machine learning experiments as a training set to detect emotional expression from natural speech data. The scripts to generate such a database have been made open source and could be used to aid speech emotion recognition for a low resourced language, as MBROLA supports 35 languages",https://aclanthology.org/2022.dclrl-1.1,emotion,No,Yes,No
"{COMMA}: Modeling Relationship among Motivations, Emotions and Actions in Language-based Human Activities","Xie, Yuqiang  and
Hu, Yue  and
Peng, Wei  and
Bi, Guanqun  and
Xing, Luxi",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Motivations, emotions, and actions are inter-related essential factors in human activities. While motivations and emotions have long been considered at the core of exploring how people take actions in human activities, there has been relatively little research supporting analyzing the relationship between human mental states and actions. We present the first study that investigates the viability of modeling motivations, emotions, and actions in language-based human activities, named COMMA (Cognitive Framework of Human Activities). Guided by COMMA, we define three natural language processing tasks (emotion understanding, motivation understanding and conditioned action generation), and build a challenging dataset Hail through automatically extracting samples from Story Commonsense. Experimental results on NLP applications prove the effectiveness of modeling the relationship. Furthermore, our models inspired by COMMA can better reveal the essential relationship among motivations, emotions and actions than existing methods.",https://aclanthology.org/2022.coling-1.15,emotion,Yes,Yes,Yes
{D}ialogue{EIN}: Emotion Interaction Network for Dialogue Affective Analysis,"Liu, Yuchen  and
Zhao, Jinming  and
Hu, Jingwen  and
Li, Ruichen  and
Jin, Qin",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Emotion Recognition in Conversation (ERC) has attracted increasing attention in the affective computing research field. Previous works have mainly focused on modeling the semantic interactions in the dialogue and implicitly inferring the evolution of the speakers{'} emotional states. Few works have considered the emotional interactions, which directly reflect the emotional evolution of speakers in the dialogue. According to psychological and behavioral studies, the emotional inertia and emotional stimulus are important factors that affect the speaker{'}s emotional state in conversations. In this work, we propose a novel Dialogue Emotion Interaction Network, DialogueEIN, to explicitly model the intra-speaker, inter-speaker, global and local emotional interactions to respectively simulate the emotional inertia, emotional stimulus, global and local emotional evolution in dialogues. Extensive experiments on four ERC benchmark datasets, IEMOCAP, MELD, EmoryNLP and DailyDialog, show that our proposed DialogueEIN considering emotional interaction factors can achieve superior or competitive performance compared to state-of-the-art methods. Our codes and models are released.",https://aclanthology.org/2022.coling-1.57,emotion,Yes,Yes,No
Emotion Enriched Retrofitted Word Embeddings,"Shah, Sapan  and
Reddy, Sreedhar  and
Bhattacharyya, Pushpak",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Word embeddings learned using the distributional hypothesis (e.g., GloVe, Word2vec) are good at encoding various lexical-semantic relations. However, they do not capture the emotion aspects of words. We present a novel retrofitting method for updating the vectors of emotion bearing words like fun, offence, angry, etc. The retrofitted embeddings achieve better inter-cluster and intra-cluster distance for words having the same emotions, e.g., the joy cluster containing words like fun, happiness, etc., and the anger cluster with words like offence, rage, etc., as evaluated through different cluster quality metrics. For the downstream tasks on sentiment analysis and sarcasm detection, simple classification models, such as SVM and Attention Net, learned using our retrofitted embeddings perform better than their pre-trained counterparts (about 1.5 {\%} improvement in F1-score) as well as other benchmarks. Furthermore, the difference in performance is more pronounced in the limited data setting.",https://aclanthology.org/2022.coling-1.363,emotion,No,Yes,No
"{CHAE}: Fine-Grained Controllable Story Generation with Characters, Actions and Emotions","Wang, Xinpeng  and
Jiang, Han  and
Wei, Zhihua  and
Zhou, Shanlin",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Story generation has emerged as an interesting yet challenging NLP task in recent years. Some existing studies aim at generating fluent and coherent stories from keywords and outlines; while others attempt to control the global features of the story, such as emotion, style and topic. However, these works focus on coarse-grained control on the story, neglecting control on the details of the story, which is also crucial for the task. To fill the gap, this paper proposes a model for fine-grained control on the story, which allows the generation of customized stories with characters, corresponding actions and emotions arbitrarily assigned. Extensive experimental results on both automatic and human manual evaluations show the superiority of our method. It has strong controllability to generate stories according to the fine-grained personalized guidance, unveiling the effectiveness of our methodology. Our code is available at \url{https://github.com/victorup/CHAE}.",https://aclanthology.org/2022.coling-1.559,emotion,No,Yes,Yes
A Multi-turn Machine Reading Comprehension Framework with Rethink Mechanism for Emotion-Cause Pair Extraction,"Zhou, Changzhi  and
Song, Dandan  and
Xu, Jing  and
Wu, Zhijing",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Emotion-cause pair extraction (ECPE) is an emerging task in emotion cause analysis, which extracts potential emotion-cause pairs from an emotional document. Most recent studies use end-to-end methods to tackle the ECPE task. However, these methods either suffer from a label sparsity problem or fail to model complicated relations between emotions and causes. Furthermore, they all do not consider explicit semantic information of clauses. To this end, we transform the ECPE task into a document-level machine reading comprehension (MRC) task and propose a Multi-turn MRC framework with Rethink mechanism (MM-R). Our framework can model complicated relations between emotions and causes while avoiding generating the pairing matrix (the leading cause of the label sparsity problem). Besides, the multi-turn structure can fuse explicit semantic information flow between emotions and causes. Extensive experiments on the benchmark emotion cause corpus demonstrate the effectiveness of our proposed framework, which outperforms existing state-of-the-art methods.",https://aclanthology.org/2022.coling-1.584,emotion,Yes,Yes,No
A Sentiment and Emotion Aware Multimodal Multiparty Humor Recognition in Multilingual Conversational Setting,"Chauhan, Dushyant Singh  and
Singh, Gopendra Vikram  and
Arora, Aseem  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"In this paper, we hypothesize that humor is closely related to sentiment and emotions. Also, due to the tremendous growth in multilingual content, there is a great demand for building models and systems that support multilingual information access. To end this, we first extend the recently released Multimodal Multiparty Hindi Humor (M2H2) dataset by adding parallel English utterances corresponding to Hindi utterances and then annotating each utterance with sentiment and emotion classes. We name it Sentiment, Humor, and Emotion aware Multilingual Multimodal Multiparty Dataset (SHEMuD). Therefore, we propose a multitask framework wherein the primary task is humor detection, and the auxiliary tasks are sentiment and emotion identification. We design a multitasking framework wherein we first propose a Context Transformer to capture the deep contextual relationships with the input utterances. We then propose a Sentiment and Emotion aware Embedding (SE-Embedding) to get the overall representation of a particular emotion and sentiment w.r.t. the specific humor situation. Experimental results on the SHEMuD show the efficacy of our approach and shows that multitask learning offers an improvement over the single-task framework for both monolingual (4.86 points in Hindi and 5.9 points in English in F1-score) and multilingual (5.17 points in F1-score) setting.",https://aclanthology.org/2022.coling-1.587,emotion,Yes,Yes,No
{TSAM}: A Two-Stream Attention Model for Causal Emotion Entailment,"Zhang, Duzhen  and
Yang, Zhen  and
Meng, Fandong  and
Chen, Xiuyi  and
Zhou, Jie",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Causal Emotion Entailment (CEE) aims to discover the potential causes behind an emotion in a conversational utterance. Previous works formalize CEE as independent utterance pair classification problems, with emotion and speaker information neglected. From a new perspective, this paper considers CEE in a joint framework. We classify multiple utterances synchronously to capture the correlations between utterances in a global view and propose a Two-Stream Attention Model (TSAM) to effectively model the speaker{'}s emotional influences in the conversational history. Specifically, the TSAM comprises three modules: Emotion Attention Network (EAN), Speaker Attention Network (SAN), and interaction module. The EAN and SAN incorporate emotion and speaker information in parallel, and the subsequent interaction module effectively interchanges relevant information between the EAN and SAN via a mutual BiAffine transformation. Extensive experimental results demonstrate that our model achieves new State-Of-The-Art (SOTA) performance and outperforms baselines remarkably.",https://aclanthology.org/2022.coling-1.588,emotion,No,Yes,No
Natural Language Inference Prompts for Zero-shot Emotion Classification in Text across Corpora,"Plaza-del-Arco, Flor Miriam  and
Mart{\'\i}n-Valdivia, Mar{\'\i}a-Teresa  and
Klinger, Roman",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Within textual emotion classification, the set of relevant labels depends on the domain and application scenario and might not be known at the time of model development. This conflicts with the classical paradigm of supervised learning in which the labels need to be predefined. A solution to obtain a model with a flexible set of labels is to use the paradigm of zero-shot learning as a natural language inference task, which in addition adds the advantage of not needing any labeled training data. This raises the question how to prompt a natural language inference model for zero-shot learning emotion classification. Options for prompt formulations include the emotion name anger alone or the statement {``}This text expresses anger{''}. With this paper, we analyze how sensitive a natural language inference-based zero-shot-learning classifier is to such changes to the prompt under consideration of the corpus: How carefully does the prompt need to be selected? We perform experiments on an established set of emotion datasets presenting different language registers according to different sources (tweets, events, blogs) with three natural language inference models and show that indeed the choice of a particular prompt formulation needs to fit to the corpus. We show that this challenge can be tackled with combinations of multiple prompts. Such ensemble is more robust across corpora than individual prompts and shows nearly the same performance as the individual best prompt for a particular corpus.",https://aclanthology.org/2022.coling-1.592,emotion,Yes,Yes,No
Joint Alignment of Multi-Task Feature and Label Spaces for Emotion Cause Pair Extraction,"Chen, Shunjie  and
Shi, Xiaochuan  and
Li, Jingye  and
Wu, Shengqiong  and
Fei, Hao  and
Li, Fei  and
Ji, Donghong",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Emotion cause pair extraction (ECPE), as one of the derived subtasks of emotion cause analysis (ECA), shares rich inter-related features with emotion extraction (EE) and cause extraction (CE). Therefore EE and CE are frequently utilized as auxiliary tasks for better feature learning, modeled via multi-task learning (MTL) framework by prior works to achieve state-of-the-art (SoTA) ECPE results. However, existing MTL-based methods either fail to simultaneously model the specific features and the interactive feature in between, or suffer from the inconsistency of label prediction. In this work, we consider addressing the above challenges for improving ECPE by performing two alignment mechanisms with a novel A{\^{}}2Net model. We first propose a feature-task alignment to explicitly model the specific emotion-{\&}cause-specific features and the shared interactive feature. Besides, an inter-task alignment is implemented, in which the label distance between the ECPE and the combinations of EE{\&}CE are learned to be narrowed for better label consistency. Evaluations of benchmarks show that our methods outperform current best-performing systems on all ECA subtasks. Further analysis proves the importance of our proposed alignment mechanisms for the task.",https://aclanthology.org/2022.coling-1.606,emotion,No,Yes,No
{COMMA}-{DEER}: {CO}mmon-sense Aware Multimodal Multitask Approach for Detection of Emotion and Emotional Reasoning in Conversations,"Ghosh, Soumitra  and
Singh, Gopendra Vikram  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Mental health is a critical component of the United Nations{'} Sustainable Development Goals (SDGs), particularly Goal 3, which aims to provide {``}good health and well-being{''}. The present mental health treatment gap is exacerbated by stigma, lack of human resources, and lack of research capability for implementation and policy reform. We present and discuss a novel task of detecting emotional reasoning (ER) and accompanying emotions in conversations. In particular, we create a first-of-its-kind multimodal mental health conversational corpus that is manually annotated at the utterance level with emotional reasoning and related emotion. We develop a multimodal multitask framework with a novel multimodal feature fusion technique and a contextuality learning module to handle the two tasks. Leveraging multimodal sources of information, commonsense reasoning, and through a multitask framework, our proposed model produces strong results. We achieve performance gains of 6{\%} accuracy and 4.62{\%} F1 on the emotion detection task and 3.56{\%} accuracy and 3.31{\%} F1 on the ER detection task, when compared to the existing state-of-the-art model.",https://aclanthology.org/2022.coling-1.608,emotion,Yes,Yes,No
{E}mo{M}ent: An Emotion Annotated Mental Health Corpus from Two {S}outh {A}sian Countries,"Atapattu, Thushari  and
Herath, Mahen  and
Elvitigala, Charitha  and
de Zoysa, Piyanjali  and
Gunawardana, Kasun  and
Thilakaratne, Menasha  and
de Zoysa, Kasun  and
Falkner, Katrina",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"People often utilise online media (e.g., Facebook, Reddit) as a platform to express their psychological distress and seek support. State-of-the-art NLP techniques demonstrate strong potential to automatically detect mental health issues from text. Research suggests that mental health issues are reflected in emotions (e.g., sadness) indicated in a person{'}s choice of language. Therefore, we developed a novel emotion-annotated mental health corpus (EmoMent),consisting of 2802 Facebook posts (14845 sentences) extracted from two South Asian countries - Sri Lanka and India. Three clinical psychology postgraduates were involved in annotating these posts into eight categories, including {`}mental illness{'} (e.g., depression) and emotions (e.g., {`}sadness{'}, {`}anger{'}). EmoMent corpus achieved {`}very good{'} inter-annotator agreement of 98.3{\%} (i.e. {\%} with two or more agreement) and Fleiss{'} Kappa of 0.82. Our RoBERTa based models achieved an F1 score of 0.76 and a macro-averaged F1 score of 0.77 for the first task (i.e. predicting a mental health condition from a post) and the second task (i.e. extent of association of relevant posts with the categories defined in our taxonomy), respectively.",https://aclanthology.org/2022.coling-1.609,emotion,Yes,Yes,Yes
{M}u{CDN}: Mutual Conversational Detachment Network for Emotion Recognition in Multi-Party Conversations,"Zhao, Weixiang  and
Zhao, Yanyan  and
Qin, Bing",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"As an emerging research topic in natural language processing community, emotion recognition in multi-party conversations has attained increasing interest. Previous approaches that focus either on dyadic or multi-party scenarios exert much effort to cope with the challenge of emotional dynamics and achieve appealing results. However, since emotional interactions among speakers are often more complicated within the entangled multi-party conversations, these works are limited in capturing effective emotional clues in conversational context. In this work, we propose Mutual Conversational Detachment Network (MuCDN) to clearly and effectively understand the conversational context by separating conversations into detached threads. Specifically, two detachment ways are devised to perform context and speaker-specific modeling within detached threads and they are bridged through a mutual module. Experimental results on two datasets show that our model achieves better performance over the baseline models.",https://aclanthology.org/2022.coling-1.612,emotion,No,Yes,Yes
{UECA}-Prompt: Universal Prompt for Emotion Cause Analysis,"Zheng, Xiaopeng  and
Liu, Zhiyue  and
Zhang, Zizhen  and
Wang, Zhaoyang  and
Wang, Jiahai",2022,Proceedings of the 29th International Conference on Computational Linguistics,,"Emotion cause analysis (ECA) aims to extract emotion clauses and find the corresponding cause of the emotion. Existing methods adopt fine-tuning paradigm to solve certain types of ECA tasks. These task-specific methods have a deficiency of universality. And the relations among multiple objectives in one task are not explicitly modeled. Moreover, the relative position information introduced in most existing methods may make the model suffer from dataset bias. To address the first two problems, this paper proposes a universal prompt tuning method to solve different ECA tasks in the unified framework. As for the third problem, this paper designs a directional constraint module and a sequential learning module to ease the bias. Considering the commonalities among different tasks, this paper proposes a cross-task training method to further explore the capability of the model. The experimental results show that our method achieves competitive performance on the ECA datasets.",https://aclanthology.org/2022.coling-1.613,emotion,Yes,Yes,No
Comparing emotion feature extraction approaches for predicting depression and anxiety,"Burkhardt, Hannah  and
Pullmann, Michael  and
Hull, Thomas  and
Are{\'a}n, Patricia  and
Cohen, Trevor",2022,Proceedings of the Eighth Workshop on Computational Linguistics and Clinical Psychology,10.18653/v1/2022.clpsych-1.9,"The increasing adoption of message-based behavioral therapy enables new approaches to assessing mental health using linguistic analysis of patient-generated text. Word counting approaches have demonstrated utility for linguistic feature extraction, but deep learning methods hold additional promise given recent advances in this area. We evaluated the utility of emotion features extracted using a BERT-based model in comparison to emotions extracted using word counts as predictors of symptom severity in a large set of messages from text-based therapy sessions involving over 6,500 unique patients, accompanied by data from repeatedly administered symptom scale measurements. BERT-based emotion features explained more variance in regression models of symptom severity, and improved predictive modeling of scale-derived diagnostic categories. However, LIWC categories that are not directly related to emotions provided valuable and complementary information for modeling of symptom severity, indicating a role for both approaches in inferring the mental states underlying patient-generated language.",https://aclanthology.org/2022.clpsych-1.9,emotion,No,Yes,No
Ethics Sheet for Automatic Emotion Recognition and Sentiment Analysis,"Mohammad, Saif M.",2022,,10.1162/coli_a_00433,"The importance and pervasiveness of emotions in our lives makes affective computing a tremendously important and vibrant line of work. Systems for automatic emotion recognition (AER) and sentiment analysis can be facilitators of enormous progress (e.g., in improving public health and commerce) but also enablers of great harm (e.g., for suppressing dissidents and manipulating voters). Thus, it is imperative that the affective computing community actively engage with the ethical ramifications of their creations. In this article, I have synthesized and organized information from AI Ethics and Emotion Recognition literature to present fifty ethical considerations relevant to AER. Notably, this ethics sheet fleshes out assumptions hidden in how AER is commonly framed, and in the choices often made regarding the data, method, and evaluation. Special attention is paid to the implications of AER on privacy and social groups. Along the way, key recommendations are made for responsible AER. The objective of the ethics sheet is to facilitate and encourage more thoughtfulness on why to automate, how to automate, and how to judge success well before the building of AER systems. Additionally, the ethics sheet acts as a useful introductory document on emotion recognition (complementing survey articles).",https://aclanthology.org/2022.cl-2.1,emotion,No,No,No
(Negative Emotion Recognition Method Based on Rational Graph Attention Network and Broad Learning),"Peng, Sancheng  and
Chen, Guanghao  and
Cao, Lihong  and
Zeng, Rong  and
Zhou, Yongmei  and
Li, Xinguang",2022,Proceedings of the 21st Chinese National Conference on Computational Linguistics,,"{``},,,,(Rational Graph Attention Network, RGAT)(Broad Learning, BL),RGAT-BLRoBERTa;,Bi-LSTM,;RGAT,;BL,,weighted-F 1macroF 1{''}",https://aclanthology.org/2022.ccl-1.44,emotion,No,No,No
-(Emotion-Cause Pair Extraction Based on Knowledge-Transfer),"Zhao, Fengyuan  and
Liu, Dexi  and
Wan, Qizhi  and
Wan, Changxuan  and
Liu, Xiping  and
Liao, Guoqiong",2022,Proceedings of the 21st Chinese National Conference on Computational Linguistics,,"{``},;;,,,,,{''}",https://aclanthology.org/2022.ccl-1.45,emotion,No,No,No
Using Extracted Emotion Cause to Improve Content-Relevance for Empathetic Conversation Generation,"Minghui, Zou  and
Rui, Pan  and
Sai, Zhang  and
Xiaowang, Zhang",2022,Proceedings of the 21st Chinese National Conference on Computational Linguistics,,"{``}Empathetic conversation generation intends to endow the open-domain conversation model with the capability for understanding, interpreting, and expressing emotion. Humans express not only their emotional state but also the stimulus that caused the emotion, i.e., emotion cause, during a conversation. Most existing approaches focus on emotion modeling, emotion recognition and prediction, and emotion fusion generation, ignoring the critical aspect of the emotion cause, which results in generating responses with irrelevant content. Emotion cause can help the model understand the user{'}s emotion and make the generated responses more content-relevant. However, using the emotion cause to enhance empathetic conversation generation is challenging. Firstly, the model needs to accurately identify the emotion cause without large-scale labeled data. Second, the model needs to effectively integrate the emotion cause into the generation process. To this end, we present an emotion cause extractor using a semi-supervised training method and an empathetic conversation generator using a biased self-attention mechanism to overcome these two issues. Experimental results indicate that our proposed emotion cause extractor improves recall scores markedly compared to the baselines, and the proposed empathetic conversation generator has superior performance and improves the content-relevance of generated responses.{''}",https://aclanthology.org/2022.ccl-1.72,emotion,Yes,Yes,No
An Emotion-based {K}orean Multimodal Empathetic Dialogue System,"Jung, Minyoung  and
Lim, Yeongbeom  and
Kim, San  and
Jang, Jin Yea  and
Shin, Saim  and
Lee, Ki-Hoon",2022,Proceedings of the Second Workshop on When Creative AI Meets Conversational AI,,"We propose a Korean multimodal dialogue system targeting emotion-based empathetic dialogues because most research in this field has been conducted in a few languages such as English and Japanese and in certain circumstances. Our dialogue system consists of an emotion detector, an empathetic response generator, a monitoring interface, a voice activity detector, a speech recognizer, a speech synthesizer, a gesture classification, and several controllers to provide both multimodality and empathy during a conversation between a human and a machine. For comparisons across visual influence on users, our dialogue system contains two versions of the user interface, a cat face-based user interface and an avatar-based user interface. We evaluated our dialogue system by investigating the dialogues in text and the average mean opinion scores under three different visual conditions, no visual, the cat face-based, and the avatar-based expressions. The experimental results stand for the importance of adequate visual expressions according to user utterances.",https://aclanthology.org/2022.cai-1.3,emotion,No,Yes,No
Building a Dialogue Corpus Annotated with Expressed and Experienced Emotions,"Ide, Tatsuya  and
Kawahara, Daisuke",2022,Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,10.18653/v1/2022.acl-srw.3,"In communication, a human would recognize the emotion of an interlocutor and respond with an appropriate emotion, such as empathy and comfort. Toward developing a dialogue system with such a human-like ability, we propose a method to build a dialogue corpus annotated with two kinds of emotions. We collect dialogues from Twitter and annotate each utterance with the emotion that a speaker put into the utterance (expressed emotion) and the emotion that a listener felt after listening to the utterance (experienced emotion). We built a dialogue corpus in Japanese using this method, and its statistical analysis revealed the differences between expressed and experienced emotions. We conducted experiments on recognition of the two kinds of emotions. The experimental results indicated the difficulty in recognizing experienced emotions and the effectiveness of multi-task learning of the two kinds of emotions. We hope that the constructed corpus will facilitate the study on emotion recognition in a dialogue and emotion-aware dialogue response generation.",https://aclanthology.org/2022.acl-srw.3,emotion,Yes,No,No
{MISC}: A Mixed Strategy-Aware Model integrating {COMET} for Emotional Support Conversation,"Tu, Quan  and
Li, Yanran  and
Cui, Jianwei  and
Wang, Bin  and
Wen, Ji-Rong  and
Yan, Rui",2022,Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2022.acl-long.25,"Applying existing methods to emotional support conversation{---}which provides valuable assistance to people who are in need{---}has two major limitations: (a) they generally employ a conversation-level emotion label, which is too coarse-grained to capture user{'}s instant mental state; (b) most of them focus on expressing empathy in the response(s) rather than gradually reducing user{'}s distress. To address the problems, we propose a novel model $\textbf{MISC}$, which firstly infers the user{'}s fine-grained emotional status, and then responds skillfully using a mixture of strategy. Experimental results on the benchmark dataset demonstrate the effectiveness of our method and reveal the benefits of fine-grained emotion understanding as well as mixed-up strategy modeling.",https://aclanthology.org/2022.acl-long.25,emotion,Yes,Yes,No
{M}3{ED}: Multi-modal Multi-scene Multi-label Emotional Dialogue Database,"Zhao, Jinming  and
Zhang, Tenggan  and
Hu, Jingwen  and
Liu, Yuchen  and
Jin, Qin  and
Wang, Xinchao  and
Li, Haizhou",2022,Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/2022.acl-long.391,"The emotional state of a speaker can be influenced by many different factors in dialogues, such as dialogue scene, dialogue topic, and interlocutor stimulus. The currently available data resources to support such multimodal affective analysis in dialogues are however limited in scale and diversity. In this work, we propose a Multi-modal Multi-scene Multi-label Emotional Dialogue dataset, M$^3$ED, which contains 990 dyadic emotional dialogues from 56 different TV series, a total of 9,082 turns and 24,449 utterances. M$^3$ED is annotated with 7 emotion categories (happy, surprise, sad, disgust, anger, fear, and neutral) at utterance level, and encompasses acoustic, visual, and textual modalities. To the best of our knowledge, M$^3$ED is the first multimodal emotional dialogue dataset in Chinese.It is valuable for cross-culture emotion analysis and recognition. We apply several state-of-the-art methods on the M$^3$ED dataset to verify the validity and quality of the dataset. We also propose a general Multimodal Dialogue-aware Interaction framework, MDI, to model the dialogue context for emotion recognition, which achieves comparable performance to the state-of-the-art methods on the M$^3$ED. The full dataset and codes are available.",https://aclanthology.org/2022.acl-long.391,emotion,Yes,Yes,No
Emotional Intensity Estimation based on Writer{'}s Personality,"Suzuki, Haruya  and
Tarumoto, Sora  and
Kajiwara, Tomoyuki  and
Ninomiya, Takashi  and
Nakashima, Yuta  and
Nagahara, Hajime",2022,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: Student Research Workshop,,"We propose a method for personalized emotional intensity estimation based on a writer{'}s personality test for Japanese SNS posts. Existing emotion analysis models are difficult to accurately estimate the writer{'}s subjective emotions behind the text. We personalize the emotion analysis using not only the text but also the writer{'}s personality information. Experimental results show that personality information improves the performance of emotional intensity estimation. Furthermore, a hybrid model combining the existing personalized method with ours achieved state-of-the-art performance.",https://aclanthology.org/2022.aacl-srw.1,emotion,No,Yes,No
{E}mo{N}o{B}a: A Dataset for Analyzing Fine-Grained Emotions on Noisy {B}angla Texts,"Islam, Khondoker Ittehadul  and
Yuvraz, Tanvir  and
Islam, Md Saiful  and
Hassan, Enamul",2022,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),,"For low-resourced Bangla language, works on detecting emotions on textual data suffer from size and cross-domain adaptability. In our paper, we propose a manually annotated dataset of 22,698 Bangla public comments from social media sites covering 12 different domains such as Personal, Politics, and Health, labeled for 6 fine-grained emotion categories of the Junto Emotion Wheel. We invest efforts in the data preparation to 1) preserve the linguistic richness and 2) challenge any classification model. Our experiments to develop a benchmark classification system show that random baselines perform better than neural networks and pre-trained language models as hand-crafted features provide superior performance.",https://aclanthology.org/2022.aacl-short.17,emotion,Yes,Yes,Yes
{S}+{PAGE}: A Speaker and Position-Aware Graph Neural Network Model for Emotion Recognition in Conversation,"Liang, Chen  and
Xu, Jing  and
Lin, Yangkun  and
Yang, Chong  and
Wang, Yongliang",2022,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,"Emotion recognition in conversation (ERC) has attracted much attention in recent years for its necessity in widespread applications. With the development of graph neural network (GNN), recent state-of-the-art ERC models mostly use GNN to embed the intrinsic structure information of a conversation into the utterance features. In this paper, we propose a novel GNN-based model for ERC, namely S+PAGE, to better capture the speaker and position-aware conversation structure information. Specifically, we add the relative positional encoding and speaker dependency encoding in the representations of edge weights and edge types respectively to acquire a more reasonable aggregation algorithm for ERC. Besides, a two-stream conversational Transformer is presented to extract both the self and inter-speaker contextual features for each utterance. Extensive experiments are conducted on four ERC benchmarks with state-of-the-art models employed as baselines for comparison, whose results demonstrate the superiority of our model.",https://aclanthology.org/2022.aacl-main.12,emotion,No,Yes,No
Prediction of People{'}s Emotional Response towards Multi-modal News,"Gao, Ge  and
Paik, Sejin  and
Reardon, Carley  and
Zhao, Yanling  and
Guo, Lei  and
Ishwar, Prakash  and
Betke, Margrit  and
Wijaya, Derry Tanti",2022,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,"We aim to develop methods for understanding how multimedia news exposure can affect people{'}s emotional responses, and we especially focus on news content related to gun violence, a very important yet polarizing issue in the U.S. We created the dataset NEmo+ by significantly extending the U.S. gun violence news-to-emotions dataset, BU-NEmo, from 320 to 1,297 news headline and lead image pairings and collecting 38,910 annotations in a large crowdsourcing experiment. In curating the NEmo+ dataset, we developed methods to identify news items that will trigger similar versus divergent emotional responses. For news items that trigger similar emotional responses, we compiled them into the NEmo+-Consensus dataset. We benchmark models on this dataset that predict a person{'}s dominant emotional response toward the target news item (single-label prediction). On the full NEmo+ dataset, containing news items that would lead to both differing and similar emotional responses, we also benchmark models for the novel task of predicting the distribution of evoked emotional responses in humans when presented with multi-modal news content. Our single-label and multi-label prediction models outperform baselines by large margins across several metrics.",https://aclanthology.org/2022.aacl-main.29,emotion,Yes,Yes,No
Meta-Learning based Deferred Optimisation for Sentiment and Emotion aware Multi-modal Dialogue Act Classification,"Saha, Tulika  and
Patra, Aditya Prakash  and
Saha, Sriparna  and
Bhattacharyya, Pushpak",2022,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,"Dialogue Act Classification (DAC) that determines the communicative intention of an utterance has been investigated widely over the years as a standalone task. But the emotional state of the speaker has a considerable effect on its pragmatic content. Sentiment as a human behavior is also closely related to emotion and one aids in the better understanding of the other. Thus, their role in identification of DAs needs to be explored. As a first step, we extend the newly released multi-modal \textit{EMOTyDA} dataset to enclose sentiment tags for each utterance. In order to incorporate these multiple aspects, we propose a Dual Attention Mechanism (DAM) based multi-modal, multi-tasking conversational framework. The DAM module encompasses intra-modal and interactive inter-modal attentions with multiple loss optimization at various hierarchies to fuse multiple modalities efficiently and learn generalized features across all the tasks. Additionally, to counter the class-imbalance issue in dialogues, we introduce a 2-step Deferred Optimisation Schedule (DOS) that involves Meta-Net (MN) learning and deferred re-weighting where the former helps to learn an explicit weighting function from data automatically and the latter deploys a re-weighted multi-task loss with a smaller learning rate. Empirically, we establish that the joint optimisation of multi-modal DAC, SA and ER tasks along with the incorporation of 2-step DOS and MN learning produces better results compared to its different counterparts and outperforms state-of-the-art model.",https://aclanthology.org/2022.aacl-main.71,emotion,Yes,Yes,No
Hell Hath No Fury? Correcting Bias in the {NRC} Emotion Lexicon,"Zad, Samira  and
Jimenez, Joshuan  and
Finlayson, Mark",2021,Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021),10.18653/v1/2021.woah-1.11,"There have been several attempts to create an accurate and thorough emotion lexicon in English, which identifies the emotional content of words. Of the several commonly used resources, the NRC emotion lexicon (Mohammad and Turney, 2013b) has received the most attention due to its availability, size, and its choice of Plutchik{'}s expressive 8-class emotion model. In this paper we identify a large number of troubling entries in the NRC lexicon, where words that should in most contexts be emotionally neutral, with no affect (e.g., {`}lesbian{'}, {`}stone{'}, {`}mountain{'}), are associated with emotional labels that are inaccurate, nonsensical, pejorative, or, at best, highly contingent and context-dependent (e.g., {`}lesbian{'} labeled as Disgust and Sadness, {`}stone{'} as Anger, or {`}mountain{'} as Anticipation). We describe a procedure for semi-automatically correcting these problems in the NRC, which includes disambiguating POS categories and aligning NRC entries with other emotion lexicons to infer the accuracy of labels. We demonstrate via an experimental benchmark that the quality of the resources is thus improved. We release the revised resource and our code to enable other researchers to reproduce and build upon results.",https://aclanthology.org/2021.woah-1.11,emotion,Yes,Yes,No
"Emotion Ratings: How Intensity, Annotation Confidence and Agreements are Entangled","Troiano, Enrica  and
Pad{\'o}, Sebastian  and
Klinger, Roman",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"When humans judge the affective content of texts, they also implicitly assess the correctness of such judgment, that is, their confidence. We hypothesize that people{'}s (in)confidence that they performed well in an annotation task leads to (dis)agreements among each other. If this is true, confidence may serve as a diagnostic tool for systematic differences in annotations. To probe our assumption, we conduct a study on a subset of the Corpus of Contemporary American English, in which we ask raters to distinguish neutral sentences from emotion-bearing ones, while scoring the confidence of their answers. Confidence turns out to approximate inter-annotator disagreements. Further, we find that confidence is correlated to emotion intensity: perceiving stronger affect in text prompts annotators to more certain classification performances. This insight is relevant for modelling studies of intensity, as it opens the question wether automatic regressors or classifiers actually predict intensity, or rather human{'}s self-perceived confidence.",https://aclanthology.org/2021.wassa-1.5,emotion,Yes,Yes,No
Universal Joy A Data Set and Results for Classifying Emotions Across Languages,"Lamprinidis, Sotiris  and
Bianchi, Federico  and
Hardt, Daniel  and
Hovy, Dirk",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"While emotions are universal aspects of human psychology, they are expressed differently across different languages and cultures. We introduce a new data set of over 530k anonymized public Facebook posts across 18 languages, labeled with five different emotions. Using multilingual BERT embeddings, we show that emotions can be reliably inferred both within and across languages. Zero-shot learning produces promising results for low-resource languages. Following established theories of basic emotions, we provide a detailed analysis of the possibilities and limits of cross-lingual emotion classification. We find that structural and typological similarity between languages facilitates cross-lingual learning, as well as linguistic diversity of training data. Our results suggest that there are commonalities underlying the expression of emotion in different languages. We publicly release the anonymized data for future research.",https://aclanthology.org/2021.wassa-1.7,emotion,Yes,Yes,No
{FEEL}-{IT}: Emotion and Sentiment Classification for the {I}talian Language,"Bianchi, Federico  and
Nozza, Debora  and
Hovy, Dirk",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"While sentiment analysis is a popular task to understand people{'}s reactions online, we often need more nuanced information: is the post negative because the user is angry or sad? An abundance of approaches have been introduced for tackling these tasks, also for Italian, but they all treat only one of the tasks. We introduce FEEL-IT, a novel benchmark corpus of Italian Twitter posts annotated with four basic emotions: \textit{anger}, \textit{fear}, \textit{joy}, \textit{sadness}. By collapsing them, we can also do sentiment analysis. We evaluate our corpus on benchmark datasets for both emotion and sentiment classification, obtaining competitive results. We release an open-source Python library, so researchers can use a model trained on FEEL-IT for inferring both sentiments and emotions from Italian text.",https://aclanthology.org/2021.wassa-1.8,emotion,Yes,Yes,No
An End-to-End Network for Emotion-Cause Pair Extraction,"Singh, Aaditya  and
Hingane, Shreeshail  and
Wani, Saim  and
Modi, Ashutosh",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"The task of Emotion-Cause Pair Extraction (ECPE) aims to extract all potential clause-pairs of emotions and their corresponding causes in a document. Unlike the more well-studied task of Emotion Cause Extraction (ECE), ECPE does not require the emotion clauses to be provided as annotations. Previous works on ECPE have either followed a multi-stage approach where emotion extraction, cause extraction, and pairing are done independently or use complex architectures to resolve its limitations. In this paper, we propose an end-to-end model for the ECPE task. Due to the unavailability of an English language ECPE corpus, we adapt the NTCIR-13 ECE corpus and establish a baseline for the ECPE task on this dataset. On this dataset, the proposed method produces significant performance improvements ( 6.5{\%} increase in F1 score) over the multi-stage approach and achieves comparable performance to the state-of-the-art methods.",https://aclanthology.org/2021.wassa-1.9,emotion,Yes,Yes,No
{WASSA} 2021 Shared Task: Predicting Empathy and Emotion in Reaction to News Stories,"Tafreshi, Shabnam  and
De Clercq, Orphee  and
Barriere, Valentin  and
Buechel, Sven  and
Sedoc, Jo{\~a}o  and
Balahur, Alexandra",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"This paper presents the results that were obtained from the WASSA 2021 shared task on predicting empathy and emotions. The participants were given access to a dataset comprising empathic reactions to news stories where harm is done to a person, group, or other. These reactions consist of essays, Batson empathic concern, and personal distress scores, and the dataset was further extended with news articles, person-level demographic information (age, gender, ethnicity, income, education level), and personality information. Additionally, emotion labels, namely Ekman{'}s six basic emotions, were added to the essays at both the document and sentence level. Participation was encouraged in two tracks: predicting empathy and predicting emotion categories. In total five teams participated in the shared task. We summarize the methods and resources used by the participating teams.",https://aclanthology.org/2021.wassa-1.10,emotion_and_empathy,Yes,No,No
"{PVG} at {WASSA} 2021: A Multi-Input, Multi-Task, Transformer-Based Architecture for Empathy and Distress Prediction","Kulkarni, Atharva  and
Somwase, Sunanda  and
Rajput, Shivam  and
Marathe, Manisha",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"Active research pertaining to the affective phenomenon of empathy and distress is invaluable for improving human-machine interaction. Predicting intensities of such complex emotions from textual data is difficult, as these constructs are deeply rooted in the psychological theory. Consequently, for better prediction, it becomes imperative to take into account ancillary factors such as the psychological test scores, demographic features, underlying latent primitive emotions, along with the text{'}s undertone and its psychological complexity. This paper proffers team PVG{'}s solution to the WASSA 2021 Shared Task on Predicting Empathy and Emotion in Reaction to News Stories. Leveraging the textual data, demographic features, psychological test score, and the intrinsic interdependencies of primitive emotions and empathy, we propose a multi-input, multi-task framework for the task of empathy score prediction. Here, the empathy score prediction is considered the primary task, while emotion and empathy classification are considered secondary auxiliary tasks. For the distress score prediction task, the system is further boosted by the addition of lexical features. Our submission ranked 1st based on the average correlation (0.545) as well as the distress correlation (0.574), and 2nd for the empathy Pearson correlation (0.517).",https://aclanthology.org/2021.wassa-1.11,empathy,No,Yes,No
{WASSA}@{IITK} at {WASSA} 2021: Multi-task Learning and Transformer Finetuning for Emotion Classification and Empathy Prediction,"Mundra, Jay  and
Gupta, Rohan  and
Mukherjee, Sagnik",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"This paper describes our contribution to the WASSA 2021 shared task on Empathy Prediction and Emotion Classification. The broad goal of this task was to model an empathy score, a distress score and the overall level of emotion of an essay written in response to a newspaper article associated with harm to someone. We have used the ELECTRA model abundantly and also advanced deep learning approaches like multi-task learning. Additionally, we also leveraged standard machine learning techniques like ensembling. Our system achieves a Pearson Correlation Coefficient of 0.533 on sub-task I and a macro F1 score of 0.5528 on sub-task II. We ranked 1st in Emotion Classification sub-task and 3rd in Empathy Prediction sub-task.",https://aclanthology.org/2021.wassa-1.12,emotion_and_empathy,No,Yes,No
Exploring Stylometric and Emotion-Based Features for Multilingual Cross-Domain Hate Speech Detection,"Markov, Ilia  and
Ljube{\v{s}}i{\'c}, Nikola  and
Fi{\v{s}}er, Darja  and
Daelemans, Walter",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"In this paper, we describe experiments designed to evaluate the impact of stylometric and emotion-based features on hate speech detection: the task of classifying textual content into hate or non-hate speech classes. Our experiments are conducted for three languages {--} English, Slovene, and Dutch {--} both in in-domain and cross-domain setups, and aim to investigate hate speech using features that model two linguistic phenomena: the writing style of hateful social media content operationalized as function word usage on the one hand, and emotion expression in hateful messages on the other hand. The results of experiments with features that model different combinations of these phenomena support our hypothesis that stylometric and emotion-based features are robust indicators of hate speech. Their contribution remains persistent with respect to domain and language variation. We show that the combination of features that model the targeted phenomena outperforms words and character n-gram features under cross-domain conditions, and provides a significant boost to deep learning models, which currently obtain the best results, when combined with them in an ensemble.",https://aclanthology.org/2021.wassa-1.16,emotion,No,Yes,No
"Emotion-Aware, Emotion-Agnostic, or Automatic: Corpus Creation Strategies to Obtain Cognitive Event Appraisal Annotations","Hofmann, Jan  and
Troiano, Enrica  and
Klinger, Roman",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"Appraisal theories explain how the cognitive evaluation of an event leads to a particular emotion. In contrast to theories of basic emotions or affect (valence/arousal), this theory has not received a lot of attention in natural language processing. Yet, in psychology it has been proven powerful: Smith and Ellsworth (1985) showed that the appraisal dimensions attention, certainty, anticipated effort, pleasantness, responsibility/control and situational control discriminate between (at least) 15 emotion classes. We study different annotation strategies for these dimensions, based on the event-focused enISEAR corpus (Troiano et al., 2019). We analyze two manual annotation settings: (1) showing the text to annotate while masking the experienced emotion label; (2) revealing the emotion associated with the text. Setting 2 enables the annotators to develop a more realistic intuition of the described event, while Setting 1 is a more standard annotation procedure, purely relying on text. We evaluate these strategies in two ways: by measuring inter-annotator agreement and by fine- tuning RoBERTa to predict appraisal variables. Our results show that knowledge of the emotion increases annotators{'} reliability. Further, we evaluate a purely automatic rule-based labeling strategy (inferring appraisal from annotated emotion classes). Training on automatically assigned labels leads to a competitive performance of our classifier, even when tested on manual annotations. This is an indicator that it might be possible to automatically create appraisal corpora for every domain for which emotion corpora already exist.",https://aclanthology.org/2021.wassa-1.17,emotion,Yes,Yes,Yes
Towards Emotion Recognition in {H}indi-{E}nglish Code-Mixed Data: A Transformer Based Approach,"Wadhawan, Anshul  and
Aggarwal, Akshita",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"In the last few years, emotion detection in social-media text has become a popular problem due to its wide ranging application in better understanding the consumers, in psychology, in aiding human interaction with computers, designing smart systems etc. Because of the availability of huge amounts of data from social-media, which is regularly used for expressing sentiments and opinions, this problem has garnered great attention. In this paper, we present a Hinglish dataset labelled for emotion detection. We highlight a deep learning based approach for detecting emotions using bilingual word embeddings derived from FastText and Word2Vec approaches in Hindi-English code mixed tweets. We experiment with various deep learning models, including CNNs, LSTMs, Bi-directional LSTMs (with and without attention), along with transformers like BERT, RoBERTa, and ALBERT. The transformer based BERT model outperforms all current state-of-the-art models giving the best performance with an accuracy of 71.43{\%}.",https://aclanthology.org/2021.wassa-1.21,emotion,Yes,Yes,No
Nearest neighbour approaches for Emotion Detection in Tweets,"Kaminska, Olha  and
Cornelis, Chris  and
Hoste, Veronique",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"Emotion detection is an important task that can be applied to social media data to discover new knowledge. While the use of deep learning methods for this task has been prevalent, they are black-box models, making their decisions hard to interpret for a human operator. Therefore, in this paper, we propose an approach using weighted k Nearest Neighbours (kNN), a simple, easy to implement, and explainable machine learning model. These qualities can help to enhance results{'} reliability and guide error analysis. In particular, we apply the weighted kNN model to the shared emotion detection task in tweets from SemEval-2018. Tweets are represented using different text embedding methods and emotion lexicon vocabulary scores, and classification is done by an ensemble of weighted kNN models. Our best approaches obtain results competitive with state-of-the-art solutions and open up a promising alternative path to neural network methods.",https://aclanthology.org/2021.wassa-1.22,emotion,No,Yes,No
Multi-Emotion Classification for Song Lyrics,"Edmonds, Darren  and
Sedoc, Jo{\~a}o",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"Song lyrics convey a multitude of emotions to the listener and powerfully portray the emotional state of the writer or singer. This paper examines a variety of modeling approaches to the multi-emotion classification problem for songs. We introduce the Edmonds Dance dataset, a novel emotion-annotated lyrics dataset from the reader{'}s perspective, and annotate the dataset of Mihalcea and Strapparava (2012) at the song level. We find that models trained on relatively small song datasets achieve marginally better performance than BERT (Devlin et al., 2018) fine-tuned on large social media or dialog datasets.",https://aclanthology.org/2021.wassa-1.24,emotion,Yes,Yes,No
"Me, myself, and ire: Effects of automatic transcription quality on emotion, sarcasm, and personality detection","Culnan, John  and
Park, Seongjin  and
Krishnaswamy, Meghavarshini  and
Sharp, Rebecca",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"In deployment, systems that use speech as input must make use of automated transcriptions. Yet, typically when these systems are evaluated, gold transcriptions are assumed. We explicitly examine the impact of transcription errors on the downstream performance of a multi-modal system on three related tasks from three datasets: emotion, sarcasm, and personality detection. We include three separate transcription tools and show that while all automated transcriptions propagate errors that substantially impact downstream performance, the open-source tools fair worse than the paid tool, though not always straightforwardly, and word error rates do not correlate well with downstream performance. We further find that the inclusion of audio features partially mitigates transcription errors, but that a naive usage of a multi-task setup does not.",https://aclanthology.org/2021.wassa-1.26,emotion,No,No,No
Emotional {R}ob{BERT} and Insensitive {BERT}je: Combining Transformers and Affect Lexica for {D}utch Emotion Detection,"De Bruyne, Luna  and
De Clercq, Orphee  and
Hoste, Veronique",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"In a first step towards improving Dutch emotion detection, we try to combine the Dutch transformer models BERTje and RobBERT with lexicon-based methods. We propose two architectures: one in which lexicon information is directly injected into the transformer model and a meta-learning approach where predictions from transformers are combined with lexicon features. The models are tested on 1,000 Dutch tweets and 1,000 captions from TV-shows which have been manually annotated with emotion categories and dimensions. We find that RobBERT clearly outperforms BERTje, but that directly adding lexicon information to transformers does not improve performance. In the meta-learning approach, lexicon information does have a positive effect on BERTje, but not on RobBERT. This suggests that more emotional information is already contained within this latter language model.",https://aclanthology.org/2021.wassa-1.27,emotion,Yes,Yes,Yes
"{E}mp{N}a at {WASSA} 2021: A Lightweight Model for the Prediction of Empathy, Distress and Emotions from Reactions to News Stories","Vettigli, Giuseppe  and
Sorgente, Antonio",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"This paper describes our submission for the WASSA 2021 shared task regarding the prediction of empathy, distress and emotions from news stories. The solution is based on combining the frequency of words, lexicon-based information, demographics of the annotators and personality of the annotators into a linear model. The prediction of empathy and distress is performed using Linear Regression while the prediction of emotions is performed using Logistic Regression. Both tasks are performed using the same features. Our models rank 4th for the prediction of emotions and 2nd for the prediction of empathy and distress. These results are particularly interesting when considered that the computational requirements of the solution are minimal.",https://aclanthology.org/2021.wassa-1.28,emotion_and_empathy,No,Yes,No
Team Phoenix at {WASSA} 2021: Emotion Analysis on News Stories with Pre-Trained Language Models,"Butala, Yash  and
Singh, Kanishk  and
Kumar, Adarsh  and
Shrivastava, Shrey",2021,"Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",,"Emotion is fundamental to humanity. The ability to perceive, understand and respond to social interactions in a human-like manner is one of the most desired capabilities in artificial agents, particularly in social-media bots. Over the past few years, computational understanding and detection of emotional aspects in language have been vital in advancing human-computer interaction. The WASSA Shared Task 2021 released a dataset of news-stories across two tracks, Track-1 for Empathy and Distress Prediction and Track-2 for Multi-Dimension Emotion prediction at the essay-level. We describe our system entry for the WASSA 2021 Shared Task (for both Track-1 and Track-2), where we leveraged the information from Pre-trained language models for Track-specific Tasks. Our proposed models achieved an Average Pearson Score of 0.417, and a Macro-F1 Score of 0.502 in Track 1 and Track 2, respectively. In the Shared Task leaderboard, we secured the fourth rank in Track 1 and the second rank in Track 2.",https://aclanthology.org/2021.wassa-1.30,emotion,Yes,Yes,Yes
Classifying Emotional Utterances by Employing Multi-modal Speech Emotion Recognition,"Das, Dipankar",2021,Proceedings of the Workshop on Speech and Music Processing 2021,,"Deep learning methods are being applied to several speech processing problems in recent years. In the present work, we have explored different deep learning models for speech emotion recognition. We have employed normal deep feedforward neural network (FFNN) and convolutional neural network (CNN) to classify audio files according to their emotional content. Comparative study indicates that CNN model outperforms FFNN in case of emotions as well as gender classification. It was observed that the sole audio based models can capture the emotions up to a certain limit. Thus, we attempted a multi-modal framework by combining the benefits of the audio and text features and employed them into a recurrent encoder. Finally, the audio and text encoders are merged to provide the desired impact on various datasets. In addition, a database consists of emotional utterances of several words has also been developed as a part of this work. It contains same word in different emotional utterances. Though the size of the database is not that large but this database is ideally supposed to contain all the English words that exist in an English dictionary.",https://aclanthology.org/2021.smp-1.1,emotion,No,Yes,No
A Study on Using Transfer Learning to Improve {BERT} Model for Emotional Classification of {C}hinese Lyrics,"Liao, Jia-Yi  and
Lin, Ya-Hsuan  and
Lin, Kuan-Cheng  and
Chang, Jia-Wei",2021,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),,"The explosive growth of music libraries has made music information retrieval and recommendation a critical issue. Recommendation systems based on music emotion recognition are gradually gaining attention. Most of the studies focus on audio data rather than lyrics to build models of music emotion classification. In addition, because of the richness of English language resources, most of the existing studies are focused on English lyrics but rarely on Chinese. For this reason, We propose an approach that uses the BERT pretraining model and Transfer learning to improve the emotion classification task of Chinese lyrics. The following approaches were used without any specific training for the Chinese lyrics emotional classification task: (a) Using BERT, only can reach 50{\%} of the classification accuracy. (b) Using BERT with transfer learning of CVAW, CVAP, and CVAT datasets can achieve 71{\%} classification accuracy.",https://aclanthology.org/2021.rocling-1.2,emotion,No,Yes,No
Speech Emotion Recognition Based on {CNN}+{LSTM} Model,"Mou, Wei  and
Shen, Pei-Hsuan  and
Chu, Chu-Yun  and
Chiu, Yu-Cheng  and
Yang, Tsung-Hsien  and
Su, Ming-Hsiang",2021,Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing (ROCLING 2021),,"Due to the popularity of intelligent dialogue assistant services, speech emotion recognition has become more and more important. In the communication between humans and machines, emotion recognition and emotion analysis can enhance the interaction between machines and humans. This study uses the CNN+LSTM model to implement speech emotion recognition (SER) processing and prediction. From the experimental results, it is known that using the CNN+LSTM model achieves better performance than using the traditional NN model.",https://aclanthology.org/2021.rocling-1.6,emotion,No,Yes,No
{E}mo{P}ars: A Collection of 30{K} Emotion-Annotated {P}ersian Social Media Texts,"Sabri, Nazanin  and
Akhavan, Reyhane  and
Bahrak, Behnam",2021,Proceedings of the Student Research Workshop Associated with RANLP 2021,,"The wide reach of social media platforms, such as Twitter, have enabled many users to share their thoughts, opinions and emotions on various topics online. The ability to detect these emotions automatically would allow social scientists, as well as, businesses to better understand responses from nations and costumers. In this study we introduce a dataset of 30,000 Persian Tweets labeled with Ekman{'}s six basic emotions (Anger, Fear, Happiness, Sadness, Hatred, and Wonder). This is the first publicly available emotion dataset in the Persian language. In this paper, we explain the data collection and labeling scheme used for the creation of this dataset. We also analyze the created dataset, showing the different features and characteristics of the data. Among other things, we investigate co-occurrence of different emotions in the dataset, and the relationship between sentiment and emotion of textual instances. The dataset is publicly available at \url{https://github.com/nazaninsbr/Persian-Emotion-Detection}.",https://aclanthology.org/2021.ranlp-srw.23,emotion,Yes,No,No
Probabilistic Ensembles of Zero- and Few-Shot Learning Models for Emotion Classification,"Basile, Angelo  and
P{\'e}rez-Torr{\'o}, Guillermo  and
Franco-Salvador, Marc",2021,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021),,"Emotion Classification is the task of automatically associating a text with a human emotion. State-of-the-art models are usually learned using annotated corpora or rely on hand-crafted affective lexicons. We present an emotion classification model that does not require a large annotated corpus to be competitive. We experiment with pretrained language models in both a zero-shot and few-shot configuration. We build several of such models and consider them as biased, noisy annotators, whose individual performance is poor. We aggregate the predictions of these models using a Bayesian method originally developed for modelling crowdsourced annotations. Next, we show that the resulting system performs better than the strongest individual model. Finally, we show that when trained on few labelled data, our systems outperform fully-supervised models.",https://aclanthology.org/2021.ranlp-1.16,emotion,Yes,Yes,Yes
{RED}: A Novel Dataset for {R}omanian Emotion Detection from Tweets,"Ciobotaru, Alexandra  and
Dinu, Liviu P.",2021,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021),,"In Romanian language there are some resources for automatic text comprehension, but for Emotion Detection, not lexicon-based, there are none. To cover this gap, we extracted data from Twitter and created the first dataset containing tweets annotated with five types of emotions: joy, fear, sadness, anger and neutral, with the intent of being used for opinion mining and analysis tasks. In this article we present some features of our novel dataset, and create a benchmark to achieve the first supervised machine learning model for automatic Emotion Detection in Romanian short texts. We investigate the performance of four classical machine learning models: Multinomial Naive Bayes, Logistic Regression, Support Vector Classification and Linear Support Vector Classification. We also investigate more modern approaches like fastText, which makes use of subword information. Lastly, we fine-tune the Romanian BERT for text classification and our experiments show that the BERT-based model has the best performance for the task of Emotion Detection from Romanian tweets. Keywords: Emotion Detection, Twitter, Romanian, Supervised Machine Learning",https://aclanthology.org/2021.ranlp-1.34,emotion,Yes,Yes,No
Exploring Reliability of Gold Labels for Emotion Detection in {T}witter,"Stajner, Sanja",2021,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021),,"Emotion detection from social media posts has attracted noticeable attention from natural language processing (NLP) community in recent years. The ways for obtaining gold labels for training and testing of the systems for automatic emotion detection differ significantly from one study to another, and pose the question of reliability of gold labels and obtained classification results. This study systematically explores several ways for obtaining gold labels for Ekman{'}s emotion model on Twitter data and the influence of the chosen strategy on the manual classification results.",https://aclanthology.org/2021.ranlp-1.151,emotion,No,Yes,Yes
Empathy and Hope: Resource Transfer to Model Inter-country Social Media Dynamics,"Yoo, Clay H.  and
Palakodety, Shriphani  and
Sarkar, Rupak  and
KhudaBukhsh, Ashiqur",2021,Proceedings of the 1st Workshop on NLP for Positive Impact,10.18653/v1/2021.nlp4posimpact-1.14,"The ongoing COVID-19 pandemic resulted in significant ramifications for international relations ranging from travel restrictions, global ceasefires, and international vaccine production and sharing agreements. Amidst a wave of infections in India that resulted in a systemic breakdown of healthcare infrastructure, a social welfare organization based in Pakistan offered to procure medical-grade oxygen to assist India - a nation which was involved in four wars with Pakistan in the past few decades. In this paper, we focus on Pakistani Twitter users{'} response to the ongoing healthcare crisis in India. While {\#}IndiaNeedsOxygen and {\#}PakistanStandsWithIndia featured among the top-trending hashtags in Pakistan, divisive hashtags such as {\#}EndiaSaySorryToKashmir simultaneously started trending. Against the backdrop of a contentious history including four wars, divisive content of this nature, especially when a country is facing an unprecedented healthcare crisis, fuels further deterioration of relations. In this paper, we define a new task of detecting \textit{supportive} content and demonstrate that existing \textit{NLP for social impact} tools can be effectively harnessed for such tasks within a quick turnaround time. We also release the first publicly available data set at the intersection of geopolitical relations and a raging pandemic in the context of India and Pakistan.",https://aclanthology.org/2021.nlp4posimpact-1.14,empathy,No,Yes,Yes
Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation,"Ide, Tatsuya  and
Kawahara, Daisuke",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop,10.18653/v1/2021.naacl-srw.15,"For a computer to naturally interact with a human, it needs to be human-like. In this paper, we propose a neural response generation model with multi-task learning of generation and classification, focusing on emotion. Our model based on BART (Lewis et al., 2020), a pre-trained transformer encoder-decoder model, is trained to generate responses and recognize emotions simultaneously. Furthermore, we weight the losses for the tasks to control the update of parameters. Automatic evaluations and crowdsourced manual evaluations show that the proposed model makes generated responses more emotionally aware.",https://aclanthology.org/2021.naacl-srw.15,emotion,No,Yes,No
Emotion Classification in a Resource Constrained Language Using Transformer-based Approach,"Das, Avishek  and
Sharif, Omar  and
Hoque, Mohammed Moshiul  and
Sarker, Iqbal H.",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop,10.18653/v1/2021.naacl-srw.19,"Although research on emotion classification has significantly progressed in high-resource languages, it is still infancy for resource-constrained languages like Bengali. However, unavailability of necessary language processing tools and deficiency of benchmark corpora makes the emotion classification task in Bengali more challenging and complicated. This work proposes a transformer-based technique to classify the Bengali text into one of the six basic emotions: anger, fear, disgust, sadness, joy, and surprise. A Bengali emotion corpus consists of 6243 texts is developed for the classification task. Experimentation carried out using various machine learning (LR, RF, MNB, SVM), deep neural networks (CNN, BiLSTM, CNN+BiLSTM) and transformer (Bangla-BERT, m-BERT, XLM-R) based approaches. Experimental outcomes indicate that XLM-R outdoes all other techniques by achieving the highest weighted f{\_}1-score of 69.73{\%} on the test data.",https://aclanthology.org/2021.naacl-srw.19,emotion,Yes,Yes,No
{WRIME}: A New Dataset for Emotional Intensity Estimation with Subjective and Objective Annotations,"Kajiwara, Tomoyuki  and
Chu, Chenhui  and
Takemura, Noriko  and
Nakashima, Yuta  and
Nagahara, Hajime",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2021.naacl-main.169,"We annotate 17,000 SNS posts with both the writer{'}s subjective emotional intensity and the reader{'}s objective one to construct a Japanese emotion analysis dataset. In this study, we explore the difference between the emotional intensity of the writer and that of the readers with this dataset. We found that the reader cannot fully detect the emotions of the writer, especially anger and trust. In addition, experimental results in estimating the emotional intensity show that it is more difficult to estimate the writer{'}s subjective labels than the readers{'}. The large gap between the subjective and objective emotions imply the complexity of the mapping from a post to the subjective emotion intensities, which also leads to a lower performance with machine learning models.",https://aclanthology.org/2021.naacl-main.169,emotion,Yes,Yes,No
{MUSER}: {MU}ltimodal Stress detection using Emotion Recognition as an Auxiliary Task,"Yao, Yiqun  and
Papakostas, Michalis  and
Burzo, Mihai  and
Abouelenien, Mohamed  and
Mihalcea, Rada",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2021.naacl-main.216,"The capability to automatically detect human stress can benefit artificial intelligent agents involved in affective computing and human-computer interaction. Stress and emotion are both human affective states, and stress has proven to have important implications on the regulation and expression of emotion. Although a series of methods have been established for multimodal stress detection, limited steps have been taken to explore the underlying inter-dependence between stress and emotion. In this work, we investigate the value of emotion recognition as an auxiliary task to improve stress detection. We propose MUSER {--} a transformer-based model architecture and a novel multi-task learning algorithm with speed-based dynamic sampling strategy. Evaluation on the Multimodal Stressed Emotion (MuSE) dataset shows that our model is effective for stress detection with both internal and external auxiliary tasks, and achieves state-of-the-art results.",https://aclanthology.org/2021.naacl-main.216,emotion,Yes,Yes,No
Emotion-Infused Models for Explainable Psychological Stress Detection,"Turcan, Elsbeth  and
Muresan, Smaranda  and
McKeown, Kathleen",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2021.naacl-main.230,"The problem of detecting psychological stress in online posts, and more broadly, of detecting people in distress or in need of help, is a sensitive application for which the ability to interpret models is vital. Here, we present work exploring the use of a semantically related task, emotion detection, for equally competent but more explainable and human-like psychological stress detection as compared to a black-box model. In particular, we explore the use of multi-task learning as well as emotion-based language model fine-tuning. With our emotion-infused models, we see comparable results to state-of-the-art BERT. Our analysis of the words used for prediction show that our emotion-infused models mirror psychological components of stress.",https://aclanthology.org/2021.naacl-main.230,emotion,No,Yes,Yes
{S}eq2{E}mo: A Sequence to Multi-Label Emotion Classification Model,"Huang, Chenyang  and
Trabelsi, Amine  and
Qin, Xuebin  and
Farruque, Nawshad  and
Mou, Lili  and
Za{\""\i}ane, Osmar",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2021.naacl-main.375,"Multi-label emotion classification is an important task in NLP and is essential to many applications. In this work, we propose a sequence-to-emotion (Seq2Emo) approach, which implicitly models emotion correlations in a bi-directional decoder. Experiments on SemEval{'}18 and GoEmotions datasets show that our approach outperforms state-of-the-art methods (without using external data). In particular, Seq2Emo outperforms the binary relevance (BR) and classifier chain (CC) approaches in a fair setting.",https://aclanthology.org/2021.naacl-main.375,emotion,No,Yes,Yes
Multimodal End-to-End Sparse Model for Emotion Recognition,"Dai, Wenliang  and
Cahyawijaya, Samuel  and
Liu, Zihan  and
Fung, Pascale",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2021.naacl-main.417,"Existing works in multimodal affective computing tasks, such as emotion recognition and personality recognition, generally adopt a two-phase pipeline by first extracting feature representations for each single modality with hand crafted algorithms, and then performing end-to-end learning with extracted features. However, the extracted features are fixed and cannot be further fine-tuned on different target tasks, and manually finding feature extracting algorithms does not generalize or scale well to different tasks, which can lead to sub-optimal performance. In this paper, we develop a fully end-to-end model that connects the two phases and optimizes them jointly. In addition, we restructure the current datasets to enable the fully end-to-end training. Furthermore, to reduce the computational overhead brought by the end-to-end model, we introduce a sparse cross-modal attention mechanism for the feature extraction. Experimental results show that our fully end-to-end model significantly surpasses the current state-of-the-art models based on the two-phase pipeline. Moreover, by adding the sparse cross-modal attention, our model can maintain the performance with around half less computation in the feature extraction part of the model.",https://aclanthology.org/2021.naacl-main.417,emotion,No,Yes,No
Towards Sentiment and Emotion aided Multi-modal Speech Act Classification in {T}witter,"Saha, Tulika  and
Upadhyaya, Apoorva  and
Saha, Sriparna  and
Bhattacharyya, Pushpak",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,10.18653/v1/2021.naacl-main.456,"Speech Act Classification determining the communicative intent of an utterance has been investigated widely over the years as a standalone task. This holds true for discussion in any fora including social media platform such as Twitter. But the emotional state of the tweeter which has a considerable effect on the communication has not received the attention it deserves. Closely related to emotion is sentiment, and understanding of one helps understand the other. In this work, we firstly create a new multi-modal, emotion-TA ({`}TA{'} means tweet act, i.e., speech act in Twitter) dataset called \textit{EmoTA} collected from open-source Twitter dataset. We propose a Dyadic Attention Mechanism (DAM) based multi-modal, adversarial multi-tasking framework. DAM incorporates intra-modal and inter-modal attention to fuse multiple modalities and learns generalized features across all the tasks. Experimental results indicate that the proposed framework boosts the performance of the primary task, i.e., TA classification (TAC) by benefitting from the two secondary tasks, i.e., Sentiment and Emotion Analysis compared to its uni-modal and single task TAC (tweet act classification) variants.",https://aclanthology.org/2021.naacl-main.456,emotion,Yes,Yes,No
An Emotional Comfort Framework for Improving User Satisfaction in {E}-Commerce Customer Service Chatbots,"Song, Shuangyong  and
Wang, Chao  and
Chen, Haiqing  and
Chen, Huan",2021,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers,10.18653/v1/2021.naacl-industry.17,"E-commerce has grown substantially over the last several years, and chatbots for intelligent customer service are concurrently drawing attention. We presented AliMe Assist, a Chinese intelligent assistant designed for creating an innovative online shopping experience in E-commerce. Based on question answering (QA), AliMe Assist offers assistance service, customer service, and chatting service. According to the survey of user studies and the real online testing, emotional comfort of customers{'} negative emotions, which make up more than 5{\%} of whole number of customer visits on AliMe, is a key point for providing considerate service. In this paper, we propose a framework to obtain proper answer to customers{'} emotional questions. The framework takes emotion classification model as a core, and final answer selection is based on topic classification and text matching. Our experiments on real online systems show that the framework is very promising.",https://aclanthology.org/2021.naacl-industry.17,emotion,No,Yes,No
Multilingual and Multilabel Emotion Recognition using Virtual Adversarial Training,"Gupta, Vikram",2021,Proceedings of the 1st Workshop on Multilingual Representation Learning,10.18653/v1/2021.mrl-1.7,"Virtual Adversarial Training (VAT) has been effective in learning robust models under supervised and semi-supervised settings for both computer vision and NLP tasks. However, the efficacy of VAT for multilingual and multilabel emotion recognition has not been explored before. In this work, we explore VAT for multilabel emotion recognition with a focus on leveraging unlabelled data from different languages to improve the model performance. We perform extensive semi-supervised experiments on SemEval2018 multilabel and multilingual emotion recognition dataset and show performance gains of 6.2{\%} (Arabic), 3.8{\%} (Spanish) and 1.8{\%} (English) over supervised learning with same amount of labelled data (10{\%} of training data). We also improve the existing state-of-the-art by 7{\%}, 4.5{\%} and 1{\%} (Jaccard Index) for Spanish, Arabic and English respectively and perform probing experiments for understanding the impact of different layers of the contextual models.",https://aclanthology.org/2021.mrl-1.7,emotion,Yes,Yes,Yes
Meta-learning for Classifying Previously Unseen Data Source into Previously Unseen Emotional Categories,"Guibon, Ga{\""e}l  and
Labeau, Matthieu  and
Flamein, H{\'e}l{\`e}ne  and
Lefeuvre, Luce  and
Clavel, Chlo{\'e}",2021,Proceedings of the 1st Workshop on Meta Learning and Its Applications to Natural Language Processing,10.18653/v1/2021.metanlp-1.9,"In this paper, we place ourselves in a classification scenario in which the target classes and data type are not accessible during training. We use a meta-learning approach to determine whether or not meta-trained information from common social network data with fine-grained emotion labels can achieve competitive performance on messages labeled with different emotion categories. We leverage few-shot learning to match with the classification scenario and consider metric learning based meta-learning by setting up Prototypical Networks with a Transformer encoder, trained in an episodic fashion. This approach proves to be effective for capturing meta-information from a source emotional tag set to predict previously unseen emotional tags. Even though shifting the data type triggers an expected performance drop, our meta-learning approach achieves decent results when compared to the fully supervised one.",https://aclanthology.org/2021.metanlp-1.9,emotion,Yes,Yes,No
{COIN}: Conversational Interactive Networks for Emotion Recognition in Conversation,"Zhang, Haidong  and
Chai, Yekun",2021,Proceedings of the Third Workshop on Multimodal Artificial Intelligence,10.18653/v1/2021.maiworkshop-1.3,"Emotion recognition in conversation has received considerable attention recently because of its practical industrial applications. Existing methods tend to overlook the immediate mutual interaction between different speakers in the speaker-utterance level, or apply single speaker-agnostic RNN for utterances from different speakers. We propose COIN, a conversational interactive model to mitigate this problem by applying state mutual interaction within history contexts. In addition, we introduce a stacked global interaction module to capture the contextual and inter-dependency representation in a hierarchical manner. To improve the robustness and generalization during training, we generate adversarial examples by applying the minor perturbations on multimodal feature inputs, unveiling the benefits of adversarial examples for emotion detection. The proposed model empirically achieves the current state-of-the-art results on the IEMOCAP benchmark dataset.",https://aclanthology.org/2021.maiworkshop-1.3,emotion,Yes,Yes,No
Emotion Classification in {G}erman Plays with Transformer-based Language Models Pretrained on Historical and Contemporary Language,"Schmidt, Thomas  and
Dennerlein, Katrin  and
Wolff, Christian",2021,"Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",10.18653/v1/2021.latechclfl-1.8,"We present results of a project on emotion classification on historical German plays of Enlightenment, Storm and Stress, and German Classicism. We have developed a hierarchical annotation scheme consisting of 13 sub-emotions like suffering, love and joy that sum up to 6 main and 2 polarity classes (positive/negative). We have conducted textual annotations on 11 German plays and have acquired over 13,000 emotion annotations by two annotators per play. We have evaluated multiple traditional machine learning approaches as well as transformer-based models pretrained on historical and contemporary language for a single-label text sequence emotion classification for the different emotion categories. The evaluation is carried out on three different instances of the corpus: (1) taking all annotations, (2) filtering overlapping annotations by annotators, (3) applying a heuristic for speech-based analysis. Best results are achieved on the filtered corpus with the best models being large transformer-based models pretrained on contemporary German language. For the polarity classification accuracies of up to 90{\%} are achieved. The accuracies become lower for settings with a higher number of classes, achieving 66{\%} for 13 sub-emotions. Further pretraining of a historical model with a corpus of dramatic texts led to no improvements.",https://aclanthology.org/2021.latechclfl-1.8,emotion,Yes,Yes,Yes
M{\'e}ta-apprentissage : classification de messages en cat{\'e}gories {\'e}motionnelles inconnues en entra{\^\i}nement (Meta-learning : Classifying Messages into Unseen Emotional Categories),"Guibon, Ga{\""e}l  and
Labeau, Matthieu  and
Flamein, H{\'e}l{\`e}ne  and
Lefeuvre, Luce  and
Clavel, Chlo{\'e}",2021,Actes de la 28e Conf{\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 : conf{\'e}rence principale,,"Dans cet article nous reproduisons un sc{\'e}nario d{'}apprentissage selon lequel les donn{\'e}es cibles ne sont pas accessibles et seules des donn{\'e}es connexes le sont. Nous utilisons une approche par m{\'e}ta-apprentissage afin de d{\'e}terminer si les m{\'e}ta-informations apprises {\`a} partir de messages issus de m{\'e}dias sociaux, finement annot{\'e}s en {\'e}motions, peuvent produire de bonnes performances une fois utilis{\'e}es sur des messages issus de conversations, {\'e}tiquet{\'e}s en {\'e}motions avec une granularit{\'e} diff{\'e}rente. Nous mettons {\`a} profit l{'}apprentissage sur quelques exemples (few-shot learning) pour la mise en place de ce sc{\'e}nario. Cette approche se montre efficace pour capturer les m{\'e}ta-informations d{'}un jeu d{'}{\'e}tiquettes {\'e}motionnelles pour pr{\'e}dire des {\'e}tiquettes jusqu{'}alors inconnues au mod{\`e}le. Bien que le fait de varier le type de donn{\'e}es engendre une baisse de performance, notre approche par m{\'e}ta-apprentissage atteint des r{\'e}sultats d{\'e}cents compar{\'e}s au r{\'e}f{\'e}rentiel d{'}apprentissage supervis{\'e}.",https://aclanthology.org/2021.jeptalnrecital-taln.19,emotion,No,Yes,No
{SEPRG}: Sentiment aware Emotion controlled Personalized Response Generation,"Firdaus, Mauajama  and
Jain, Umang  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2021,Proceedings of the 14th International Conference on Natural Language Generation,10.18653/v1/2021.inlg-1.39,"Social chatbots have gained immense popularity, and their appeal lies not just in their capacity to respond to the diverse requests from users, but also in the ability to develop an emotional connection with users. To further develop and promote social chatbots, we need to concentrate on increasing user interaction and take into account both the intellectual and emotional quotient in the conversational agents. Therefore, in this work, we propose the task of sentiment aware emotion controlled personalized dialogue generation giving the machine the capability to respond emotionally and in accordance with the persona of the user. As sentiment and emotions are highly co-related, we use the sentiment knowledge of the previous utterance to generate the correct emotional response in accordance with the user persona. We design a Transformer based Dialogue Generation framework, that generates responses that are sensitive to the emotion of the user and corresponds to the persona and sentiment as well. Moreover, the persona information is encoded by a different Transformer encoder, along with the dialogue history, is fed to the decoder for generating responses. We annotate the PersonaChat dataset with sentiment information to improve the response quality. Experimental results on the PersonaChat dataset show that the proposed framework significantly outperforms the existing baselines, thereby generating personalized emotional responses in accordance with the sentiment that provides better emotional connection and user satisfaction as desired in a social chatbot.",https://aclanthology.org/2021.inlg-1.39,emotion,Yes,Yes,No
Retrofitting of Pre-trained Emotion Words with {VAD}-dimensions and the {P}lutchik Emotions,"Kulkarni, Manasi  and
Bhattacharyya, Pushpak",2021,Proceedings of the 18th International Conference on Natural Language Processing (ICON),,"The word representations are based on distributional hypothesis according to which words that occur in the similar contexts, tend to have a similar meaning and appear closer in vector space. For example, the emotionally dissimilar words {''}joy{''} and {''}sadness{''} have higher cosine similarity. The existing pre-trained embedding models lack in emotional words interpretations. For creating our VAD-Emotion embeddings, we modify the pre-trained word embeddings with emotion information. This is a lexicons based approach that uses the Valence, Arousal and Dominance (VAD) values, and the Plutchik{'}s emotions to incorporate the emotion information in pre-trained word embeddings using post-training processing. This brings emotionally similar words nearer and emotionally dissimilar words away from each other in the proposed vector space. We demonstrate the performance of proposed embedding through NLP downstream task - Emotion Recognition.",https://aclanthology.org/2021.icon-main.64,emotion,No,Yes,Yes
{H}is{N}et: A Polarity Lexicon based on {W}ord{N}et for Emotion Analysis,"{\""O}z{\c{c}}elik, Merve  and
Ar{\i}can, Bilge Nas  and
Bakay, {\""O}zge  and
Sarm{\i}{\c{s}}, Elif  and
Ergelen, {\""O}zlem  and
Bayezit, Nilg{\""u}n G{\""u}ler  and
Y{\i}ld{\i}z, Olcay Taner",2021,Proceedings of the 11th Global Wordnet Conference,,"Dictionary-based methods in sentiment analysis have received scholarly attention recently, the most comprehensive examples of which can be found in English. However, many other languages lack polarity dictionaries, or the existing ones are small in size as in the case of SentiTurkNet, the first and only polarity dictionary in Turkish. Thus, this study aims to extend the content of SentiTurkNet by comparing the two available WordNets in Turkish, namely KeNet and TR-wordnet of BalkaNet. To this end, a current Turkish polarity dictionary has been created relying on 76,825 synsets matching KeNet, where each synset has been annotated with three polarity labels, which are positive, negative and neutral. Meanwhile, the comparison of KeNet and TR-wordnet of BalkaNet has revealed their weaknesses such as the repetition of the same senses, lack of necessary merges of the items belonging to the same synset and the presence of redundant narrower versions of synsets, which are discussed in light of their potential to the improvement of the current lexical databases of Turkish.",https://aclanthology.org/2021.gwc-1.18,emotion,Yes,No,No
Bidirectional Hierarchical Attention Networks based on Document-level Context for Emotion Cause Extraction,"Hu, Guimin  and
Lu, Guangming  and
Zhao, Yi",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.51,"Emotion cause extraction (ECE) aims to extract the causes behind the certain emotion in text. Some works related to the ECE task have been published and attracted lots of attention in recent years. However, these methods neglect two major issues: 1) pay few attentions to the effect of document-level context information on ECE, and 2) lack of sufficient exploration for how to effectively use the annotated emotion clause. For the first issue, we propose a bidirectional hierarchical attention network (BHA) corresponding to the specified candidate cause clause to capture the document-level context in a structured and dynamic manner. For the second issue, we design an emotional filtering module (EF) for each layer of the graph attention network, which calculates a gate score based on the emotion clause to filter the irrelevant information. Combining the BHA and EF, the EF-BHA can dynamically aggregate the contextual information from two directions and filters irrelevant information. The experimental results demonstrate that EF-BHA achieves the competitive performances on two public datasets in different languages (Chinese and English). Moreover, we quantify the effect of context on emotion cause extraction and provide the visualization of the interactions between candidate cause clauses and contexts.",https://aclanthology.org/2021.findings-emnlp.51,emotion,Yes,No,No
Improving Empathetic Response Generation by Recognizing Emotion Cause in Conversations,"Gao, Jun  and
Liu, Yuhan  and
Deng, Haolin  and
Wang, Wei  and
Cao, Yu  and
Du, Jiachen  and
Xu, Ruifeng",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.70,"Current approaches to empathetic response generation focus on learning a model to predict an emotion label and generate a response based on this label and have achieved promising results. However, the emotion cause, an essential factor for empathetic responding, is ignored. The emotion cause is a stimulus for human emotions. Recognizing the emotion cause is helpful to better understand human emotions so as to generate more empathetic responses. To this end, we propose a novel framework that improves empathetic response generation by recognizing emotion cause in conversations. Specifically, an emotion reasoner is designed to predict a context emotion label and a sequence of emotion cause-oriented labels, which indicate whether the word is related to the emotion cause. Then we devise both hard and soft gated attention mechanisms to incorporate the emotion cause into response generation. Experiments show that incorporating emotion cause information improves the performance of the model on both emotion recognition and response generation.",https://aclanthology.org/2021.findings-emnlp.70,emotion,No,Yes,No
"Past, Present, and Future: Conversational Emotion Recognition through Structural Modeling of Psychological Knowledge","Li, Jiangnan  and
Lin, Zheng  and
Fu, Peng  and
Wang, Weiping",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.104,"Conversational Emotion Recognition (CER) is a task to predict the emotion of an utterance in the context of a conversation. Although modeling the conversational context and interactions between speakers has been studied broadly, it is important to consider the speaker{'}s psychological state, which controls the action and intention of the speaker. The state-of-the-art method introduces CommonSense Knowledge (CSK) to model psychological states in a sequential way (forwards and backwards). However, it ignores the structural psychological interactions between utterances. In this paper, we propose a pSychological-Knowledge-Aware Interaction Graph (SKAIG). In the locally connected graph, the targeted utterance will be enhanced with the information of action inferred from the past context and intention implied by the future context. The utterance is self-connected to consider the present effect from itself. Furthermore, we utilize CSK to enrich edges with knowledge representations and process the SKAIG with a graph transformer. Our method achieves state-of-the-art and competitive performance on four popular CER datasets.",https://aclanthology.org/2021.findings-emnlp.104,emotion,No,Yes,No
Uncovering the Limits of Text-based Emotion Detection,"Alvarez-Gonzalez, Nurudin  and
Kaltenbrunner, Andreas  and
G{\'o}mez, Vicen{\c{c}}",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.219,"Identifying emotions from text is crucial for a variety of real world tasks. We consider the two largest now-available corpora for emotion classification: GoEmotions, with 58k messages labelled by readers, and Vent, with 33M writer-labelled messages. We design a benchmark and evaluate several feature spaces and learning algorithms, including two simple yet novel models on top of BERT that outperform previous strong baselines on GoEmotions. Through an experiment with human participants, we also analyze the differences between how writers express emotions and how readers perceive them. Our results suggest that emotions expressed by writers are harder to identify than emotions that readers perceive. We share a public web interface for researchers to explore our models.",https://aclanthology.org/2021.findings-emnlp.219,emotion,Yes,Yes,No
{D}ialogue{TRM}: Exploring Multi-Modal Emotional Dynamics in a Conversation,"Mao, Yuzhao  and
Liu, Guang  and
Wang, Xiaojie  and
Gao, Weiguo  and
Li, Xuan",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.229,"Emotion dynamics formulates principles explaining the emotional fluctuation during conversations. Recent studies explore the emotion dynamics from the self and inter-personal dependencies, however, ignoring the temporal and spatial dependencies in the situation of multi-modal conversations. To address the issue, we extend the concept of emotion dynamics to multi-modal settings and propose a Dialogue Transformer for simultaneously modeling the intra-modal and inter-modal emotion dynamics. Specifically, the intra-modal emotion dynamics is to not only capture the temporal dependency but also satisfy the context preference in every single modality. The inter-modal emotional dynamics aims at handling multi-grained spatial dependency across all modalities. Our models outperform the state-of-the-art with a margin of 4{\%}-16{\%} for most of the metrics on three benchmark datasets.",https://aclanthology.org/2021.findings-emnlp.229,emotion,Yes,Yes,No
Knowledge-Interactive Network with Sentiment Polarity Intensity-Aware Multi-Task Learning for Emotion Recognition in Conversations,"Xie, Yunhe  and
Yang, Kailai  and
Sun, Chengjie  and
Liu, Bingquan  and
Ji, Zhenzhou",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.245,"Emotion Recognition in Conversation (ERC) has gained much attention from the NLP community recently. Some models concentrate on leveraging commonsense knowledge or multi-task learning to help complicated emotional reasoning. However, these models neglect direct utterance-knowledge interaction. In addition, these models utilize emotion-indirect auxiliary tasks, which provide limited affective information for the ERC task. To address the above issues, we propose a Knowledge-Interactive Network with sentiment polarity intensity-aware multi-task learning, namely KI-Net, which leverages both commonsense knowledge and sentiment lexicon to augment semantic information. Specifically, we use a self-matching module for internal utterance-knowledge interaction. Considering correlations with the ERC task, a phrase-level Sentiment Polarity Intensity Prediction (SPIP) task is devised as an auxiliary task. Experiments show that all knowledge integration, self-matching and SPIP modules improve the model performance respectively on three datasets. Moreover, our KI-Net model shows 1.04{\%} performance improvement over the state-of-the-art model on the IEMOCAP dataset.",https://aclanthology.org/2021.findings-emnlp.245,emotion,Yes,Yes,Yes
A Discourse-Aware Graph Neural Network for Emotion Recognition in Multi-Party Conversation,"Sun, Yang  and
Yu, Nan  and
Fu, Guohong",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.252,"Emotion recognition in multi-party conversation (ERMC) is becoming increasingly popular as an emerging research topic in natural language processing. Prior research focuses on exploring sequential information but ignores the discourse structures of conversations. In this paper, we investigate the importance of discourse structures in handling informative contextual cues and speaker-specific features for ERMC. To this end, we propose a discourse-aware graph neural network (ERMC-DisGCN) for ERMC. In particular, we design a relational convolution to lever the self-speaker dependency of interlocutors to propagate contextual information. Furthermore, we exploit a gated convolution to select more informative cues for ERMC from dependent utterances. The experimental results show our method outperforms multiple baselines, illustrating that discourse structures are of great value to ERMC.",https://aclanthology.org/2021.findings-emnlp.252,emotion,No,Yes,Yes
Constructing Emotional Consensus and Utilizing Unpaired Data for Empathetic Dialogue Generation,"Shen, Lei  and
Zhang, Jinchao  and
Ou, Jiao  and
Zhao, Xiaofang  and
Zhou, Jie",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.268,"Researches on dialogue empathy aim to endow an agent with the capacity of accurate understanding and proper responding for emotions. Existing models for empathetic dialogue generation focus on the emotion flow in one direction, that is, from the context to response. We argue that conducting an empathetic conversation is a bidirectional process, where empathy occurs when the emotions of two interlocutors could converge on the same point, i.e., reaching an emotional consensus. Besides, we also find that the empathetic dialogue corpus is extremely limited, which further restricts the model performance. To address the above issues, we propose a dual-generative model, Dual-Emp, to simultaneously construct the emotional consensus and utilize some external unpaired data. Specifically, our model integrates a forward dialogue model, a backward dialogue model, and a discrete latent variable representing the emotional consensus into a unified architecture. Then, to alleviate the constraint of paired data, we extract unpaired emotional data from open-domain conversations and employ Dual-Emp to produce pseudo paired empathetic samples, which is more efficient and low-cost than the human annotation. Automatic and human evaluations demonstrate that our method outperforms competitive baselines in producing coherent and empathetic responses.",https://aclanthology.org/2021.findings-emnlp.268,emotion,Yes,Yes,No
Distilling Knowledge for Empathy Detection,"Hosseini, Mahshid  and
Caragea, Cornelia",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.314,"Empathy is the link between self and others. Detecting and understanding empathy is a key element for improving human-machine interaction. However, annotating data for detecting empathy at a large scale is a challenging task. This paper employs multi-task training with knowledge distillation to incorporate knowledge from available resources (emotion and sentiment) to detect empathy from the natural language in different domains. This approach yields better results on an existing news-related empathy dataset compared to strong baselines. In addition, we build a new dataset for empathy prediction with fine-grained empathy direction, seeking or providing empathy, from Twitter. We release our dataset for research purposes.",https://aclanthology.org/2021.findings-emnlp.314,empathy,Yes,Yes,No
{NICE}: Neural Image Commenting with Empathy,"Chen, Kezhen  and
Huang, Qiuyuan  and
McDuff, Daniel  and
Gao, Xiang  and
Palangi, Hamid  and
Wang, Jianfeng  and
Forbus, Kenneth  and
Gao, Jianfeng",2021,Findings of the Association for Computational Linguistics: EMNLP 2021,10.18653/v1/2021.findings-emnlp.380,"Emotion and empathy are examples of human qualities lacking in many human-machine interactions. The goal of our work is to generate engaging dialogue grounded in a user-shared image with increased emotion and empathy while minimizing socially inappropriate or offensive outputs. We release the Neural Image Commenting with Empathy (NICE) dataset consisting of almost two million images and the corresponding human-generated comments, a set of human annotations, and baseline performance on a range of models. In-stead of relying on manually labeled emotions, we also use automatically generated linguistic representations as a source of weakly supervised labels. Based on these annotations, we define two different tasks for the NICE dataset. Then, we propose a novel pre-training model - Modeling Affect Generation for Image Comments (MAGIC) - which aims to generate comments for images, conditioned on linguistic representations that capture style and affect, and to help generate more empathetic, emotional, engaging and socially appropriate comments. Using this model we achieve state-of-the-art performance on one of our NICE tasks. The experiments show that the approach can generate more human-like and engaging image comments.",https://aclanthology.org/2021.findings-emnlp.380,empathy,Yes,Yes,No
Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes,"Kim, Hyunwoo  and
Kim, Byeongchang  and
Kim, Gunhee",2021,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2021.emnlp-main.170,"Empathy is a complex cognitive ability based on the reasoning of others{'} affective states. In order to better understand others and express stronger empathy in dialogues, we argue that two issues must be tackled at the same time: (i) identifying which word is the cause for the other{'}s emotion from his or her utterance and (ii) reflecting those specific words in the response generation. However, previous approaches for recognizing emotion cause words in text require sub-utterance level annotations, which can be demanding. Taking inspiration from social cognition, we leverage a generative estimator to infer emotion cause words from utterances with no word-level label. Also, we introduce a novel method based on pragmatics to make dialogue models focus on targeted words in the input during generation. Our method is applicable to any dialogue models with no additional training on the fly. We show our approach improves multiple best-performing dialogue agents on generating more focused empathetic responses in terms of both automatic and human evaluation.",https://aclanthology.org/2021.emnlp-main.170,emotion,No,Yes,No
Emotion Inference in Multi-Turn Conversations with Addressee-Aware Module and Ensemble Strategy,"Li, Dayu  and
Zhu, Xiaodan  and
Li, Yang  and
Wang, Suge  and
Li, Deyu  and
Liao, Jian  and
Zheng, Jianxing",2021,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2021.emnlp-main.320,"Emotion inference in multi-turn conversations aims to predict the participant{'}s emotion in the next upcoming turn without knowing the participant{'}s response yet, and is a necessary step for applications such as dialogue planning. However, it is a severe challenge to perceive and reason about the future feelings of participants, due to the lack of utterance information from the future. Moreover, it is crucial for emotion inference to capture the characteristics of emotional propagation in conversations, such as persistence and contagiousness. In this study, we focus on investigating the task of emotion inference in multi-turn conversations by modeling the propagation of emotional states among participants in the conversation history, and propose an addressee-aware module to automatically learn whether the participant keeps the historical emotional state or is affected by others in the next upcoming turn. In addition, we propose an ensemble strategy to further enhance the model performance. Empirical studies on three different benchmark conversation datasets demonstrate the effectiveness of the proposed model over several strong baselines.",https://aclanthology.org/2021.emnlp-main.320,emotion,Yes,Yes,No
Dimensional Emotion Detection from Categorical Emotion,"Park, Sungjoon  and
Kim, Jiseon  and
Ye, Seonghyeon  and
Jeon, Jaeyeol  and
Park, Hee Young  and
Oh, Alice",2021,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2021.emnlp-main.358,"We present a model to predict fine-grained emotions along the continuous dimensions of valence, arousal, and dominance (VAD) with a corpus with categorical emotion annotations. Our model is trained by minimizing the EMD (Earth Mover{'}s Distance) loss between the predicted VAD score distribution and the categorical emotion distributions sorted along VAD, and it can simultaneously classify the emotion categories and predict the VAD scores for a given sentence. We use pre-trained RoBERTa-Large and fine-tune on three different corpora with categorical labels and evaluate on EmoBank corpus with VAD scores. We show that our approach reaches comparable performance to that of the state-of-the-art classifiers in categorical emotion classification and shows significant positive correlations with the ground truth VAD scores. Also, further training with supervision of VAD labels leads to improved performance especially when dataset is small. We also present examples of predictions of appropriate emotion words that are not part of the original annotations.",https://aclanthology.org/2021.emnlp-main.358,emotion,Yes,Yes,No
Few-Shot Emotion Recognition in Conversation with Sequential Prototypical Networks,"Guibon, Ga{\""e}l  and
Labeau, Matthieu  and
Flamein, H{\'e}l{\`e}ne  and
Lefeuvre, Luce  and
Clavel, Chlo{\'e}",2021,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2021.emnlp-main.549,"Several recent studies on dyadic human-human interactions have been done on conversations without specific business objectives. However, many companies might benefit from studies dedicated to more precise environments such as after sales services or customer satisfaction surveys. In this work, we place ourselves in the scope of a live chat customer service in which we want to detect emotions and their evolution in the conversation flow. This context leads to multiple challenges that range from exploiting restricted, small and mostly unlabeled datasets to finding and adapting methods for such context. We tackle these challenges by using Few-Shot Learning while making the hypothesis it can serve conversational emotion classification for different languages and sparse labels. We contribute by proposing a variation of Prototypical Networks for sequence labeling in conversation that we name ProtoSeq. We test this method on two datasets with different languages: daily conversations in English and customer service chat conversations in French. When applied to emotion classification in conversations, our method proved to be competitive even when compared to other ones.",https://aclanthology.org/2021.emnlp-main.549,emotion,No,Yes,No
Towards Label-Agnostic Emotion Embeddings,"Buechel, Sven  and
Modersohn, Luise  and
Hahn, Udo",2021,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2021.emnlp-main.728,"Research in emotion analysis is scattered across different label formats (e.g., polarity types, basic emotion categories, and affective dimensions), linguistic levels (word vs. sentence vs. discourse), and, of course, (few well-resourced but much more under-resourced) natural languages and text genres (e.g., product reviews, tweets, news). The resulting heterogeneity makes data and software developed under these conflicting constraints hard to compare and challenging to integrate. To resolve this unsatisfactory state of affairs we here propose a training scheme that learns a shared latent representation of emotion independent from different label formats, natural languages, and even disparate model architectures. Experiments on a wide range of datasets indicate that this approach yields the desired interoperability without penalizing prediction quality. Code and data are archived under DOI 10.5281/zenodo.5466068.",https://aclanthology.org/2021.emnlp-main.728,emotion,No,Yes,No
Guilt by Association: Emotion Intensities in Lexical Representations,"Raji, Shahab  and
de Melo, Gerard",2021,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/2021.emnlp-main.781,"What do linguistic models reveal about the emotions associated with words? In this study, we consider the task of estimating word-level emotion intensity scores for specific emotions, exploring unsupervised, supervised, and finally a self-supervised method of extracting emotional associations from pretrained vectors and models. Overall, we find that linguistic models carry substantial potential for inducing fine-grained emotion intensity scores, showing a far higher correlation with human ground truth ratings than state-of-the-art emotion lexicons based on labeled data.",https://aclanthology.org/2021.emnlp-main.781,emotion,Yes,Yes,No
{S}pan{E}mo: Casting Multi-label Emotion Classification as Span-prediction,"Alhuzali, Hassan  and
Ananiadou, Sophia",2021,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,10.18653/v1/2021.eacl-main.135,"Emotion recognition (ER) is an important task in Natural Language Processing (NLP), due to its high impact in real-world applications from health and well-being to author profiling, consumer analysis and security. Current approaches to ER, mainly classify emotions independently without considering that emotions can co-exist. Such approaches overlook potential ambiguities, in which multiple emotions overlap. We propose a new model {``}SpanEmo{''} casting multi-label emotion classification as span-prediction, which can aid ER models to learn associations between labels and words in a sentence. Furthermore, we introduce a loss function focused on modelling multiple co-existing emotions in the input sentence. Experiments performed on the SemEval2018 multi-label emotion data over three language sets (i.e., English, Arabic and Spanish) demonstrate our method{'}s effectiveness. Finally, we present different analyses that illustrate the benefits of our method in terms of improving the model performance and learning meaningful associations between emotion classes and words in the sentence.",https://aclanthology.org/2021.eacl-main.135,emotion,No,Yes,Yes
"Us vs. Them: A Dataset of Populist Attitudes, News Bias and Emotions","Huguet Cabot, Pere-Llu{\'\i}s  and
Abadi, David  and
Fischer, Agneta  and
Shutova, Ekaterina",2021,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,10.18653/v1/2021.eacl-main.165,"Computational modelling of political discourse tasks has become an increasingly important area of research in the field of natural language processing. Populist rhetoric has risen across the political sphere in recent years; however, due to its complex nature, computational approaches to it have been scarce. In this paper, we present the new Us vs. Them dataset, consisting of 6861 Reddit comments annotated for populist attitudes and the first large-scale computational models of this phenomenon. We investigate the relationship between populist mindsets and social groups, as well as a range of emotions typically associated with these. We set a baseline for two tasks associated with populist attitudes and present a set of multi-task learning models that leverage and demonstrate the importance of emotion and group identification as auxiliary tasks.",https://aclanthology.org/2021.eacl-main.165,emotion,Yes,Yes,Yes
{PHASE}: Learning Emotional Phase-aware Representations for Suicide Ideation Detection on Social Media,"Sawhney, Ramit  and
Joshi, Harshit  and
Flek, Lucie  and
Shah, Rajiv Ratn",2021,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,10.18653/v1/2021.eacl-main.205,"Recent psychological studies indicate that individuals exhibiting suicidal ideation increasingly turn to social media rather than mental health practitioners. Contextualizing the build-up of such ideation is critical for the identification of users at risk. In this work, we focus on identifying suicidal intent in tweets by augmenting linguistic models with emotional phases modeled from users{'} historical context. We propose PHASE, a time-and phase-aware framework that adaptively learns features from a user{'}s historical emotional spectrum on Twitter for preliminary screening of suicidal risk. Building on clinical studies, PHASE learns phase-like progressions in users{'} historical Plutchik-wheel-based emotions to contextualize suicidal intent. While outperforming state-of-the-art methods, we show the utility of temporal and phase-based emotional contextual cues for suicide ideation detection. We further discuss practical and ethical considerations.",https://aclanthology.org/2021.eacl-main.205,emotion,No,Yes,No
Modelling Context Emotions using Multi-task Learning for Emotion Controlled Dialog Generation,"Varshney, Deeksha  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2021,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,10.18653/v1/2021.eacl-main.255,"A recent topic of research in natural language generation has been the development of automatic response generation modules that can automatically respond to a user{'}s utterance in an empathetic manner. Previous research has tackled this task using neural generative methods by augmenting emotion classes with the input sequences. However, the outputs by these models may be inconsistent. We employ multi-task learning to predict the emotion label and to generate a viable response for a given utterance using a common encoder with multiple decoders. Our proposed encoder-decoder model consists of a self-attention based encoder and a decoder with dot product attention mechanism to generate response with a specified emotion. We use the focal loss to handle imbalanced data distribution, and utilize the consistency loss to allow coherent decoding by the decoders. Human evaluation reveals that our model produces more emotionally pertinent responses. In addition, our model outperforms multiple strong baselines on automatic evaluation measures such as F1 and BLEU scores, thus resulting in more fluent and adequate responses.",https://aclanthology.org/2021.eacl-main.255,emotion,No,Yes,No
{E}mpath{BERT}: A {BERT}-based Framework for Demographic-aware Empathy Prediction,"Guda, Bhanu Prakash Reddy  and
Garimella, Aparna  and
Chhaya, Niyati",2021,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,10.18653/v1/2021.eacl-main.268,"Affect preferences vary with user demographics, and tapping into demographic information provides important cues about the users{'} language preferences. In this paper, we utilize the user demographics and propose EmpathBERT, a demographic-aware framework for empathy prediction based on BERT. Through several comparative experiments, we show that EmpathBERT surpasses traditional machine learning and deep learning models, and illustrate the importance of user demographics, for predicting empathy and distress in user responses to stimulative news articles. We also highlight the importance of affect information in the responses by developing affect-aware models to predict user demographic attributes.",https://aclanthology.org/2021.eacl-main.268,empathy,No,Yes,No
Enhancing Cognitive Models of Emotions with Representation Learning,"Guo, Yuting  and
Choi, Jinho D.",2021,Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics,10.18653/v1/2021.cmcl-1.18,"We present a novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions. Our framework integrates a contextualized embedding encoder with a multi-head probing model that enables to interpret dynamically learned representations optimized for an emotion classification task. Our model is evaluated on the Empathetic Dialogue dataset and shows the state-of-the-art result for classifying 32 emotions. Our layer analysis can derive an emotion graph to depict hierarchical relations among the emotions. Our emotion representations can be used to generate an emotion wheel directly comparable to the one from Plutchik{'}s model, and also augment the values of missing emotions in the PAD emotional state model.",https://aclanthology.org/2021.cmcl-1.18,emotion,Yes,Yes,No
Demonstrating the Reliability of Self-Annotated Emotion Data,"Malko, Anton  and
Paris, Cecile  and
Duenser, Andreas  and
Kangas, Maria  and
Molla, Diego  and
Sparks, Ross  and
Wan, Stephen",2021,Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access,10.18653/v1/2021.clpsych-1.5,"Vent is a specialised iOS/Android social media platform with the stated goal to encourage people to post about their feelings and explicitly label them. In this paper, we study a snapshot of more than 100 million messages obtained from the developers of Vent, together with the labels assigned by the authors of the messages. We establish the quality of the self-annotated data by conducting a qualitative analysis, a vocabulary based analysis, and by training and testing an emotion classifier. We conclude that the self-annotated labels of our corpus are indeed indicative of the emotional contents expressed in the text and thus can support more detailed analyses of emotion expression on social media, such as emotion trajectories and factors influencing them.",https://aclanthology.org/2021.clpsych-1.5,emotion,Yes,Yes,No
Towards Low-Resource Real-Time Assessment of Empathy in Counselling,"Wu, Zixiu  and
Helaoui, Rim  and
Reforgiato Recupero, Diego  and
Riboni, Daniele",2021,Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access,10.18653/v1/2021.clpsych-1.22,"Gauging therapist empathy in counselling is an important component of understanding counselling quality. While session-level empathy assessment based on machine learning has been investigated extensively, it relies on relatively large amounts of well-annotated dialogue data, and real-time evaluation has been overlooked in the past. In this paper, we focus on the task of low-resource utterance-level binary empathy assessment. We train deep learning models on heuristically constructed empathy vs. non-empathy contrast in general conversations, and apply the models directly to therapeutic dialogues, assuming correlation between empathy manifested in those two domains. We show that such training yields poor performance in general, probe its causes, and examine the actual effect of learning from empathy contrast in general conversation.",https://aclanthology.org/2021.clpsych-1.22,empathy,Yes,Yes,No
{U}yghur Metaphor Detection Via Considering Emotional Consistency,"Qimeng, Yang  and
Long, Yu  and
Shengwei, Tian  and
Jinmiao, Song",2021,Proceedings of the 20th Chinese National Conference on Computational Linguistics,,Metaphor detection plays an important role in tasks such as machine translation and human-machine dialogue. As more users express their opinions on products or other topics on socialmedia through metaphorical expressions this task is particularly especially topical. Most of the research in this field focuses on English and there are few studies on minority languages thatlack language resources and tools. Moreover metaphorical expressions have different meaningsin different language environments. We therefore established a deep neural network (DNN)framework for Uyghur metaphor detection tasks. The proposed method can focus on the multi-level semantic information of the text from word embedding part of speech and location which makes the feature representation more complete. We also use the emotional information of words to learn the emotional consistency features of metaphorical words and their context. A qualitative analysis further confirms the need for broader emotional information in metaphor detection. Ourresults indicate the performance of Uyghur metaphor detection can be effectively improved withthe help of multi-attention and emotional information.,https://aclanthology.org/2021.ccl-1.80,emotion,No,Yes,No
Emotion Classification of {COVID}-19 {C}hinese Microblogs based on the Emotion Category Description,"Xianwei, Guo  and
Hua, Lai  and
Yan, Xiang  and
Zhengtao, Yu  and
Yuxin, Huang",2021,Proceedings of the 20th Chinese National Conference on Computational Linguistics,,Emotion classification of COVID-19 Chinese microblogs helps analyze the public opinion triggered by COVID-19. Existing methods only consider the features of the microblog itself with-out combining the semantics of emotion categories for modeling. Emotion classification of mi-croblogs is a process of reading the content of microblogs and combining the semantics of emo-tion categories to understand whether it contains a certain emotion. Inspired by this we proposean emotion classification model based on the emotion category description for COVID-19 Chi-nese microblogs. Firstly we expand all emotion categories into formalized category descriptions. Secondly based on the idea of question answering we construct a question for each microblogin the form of {`}What is the emotion expressed in the text X?{'} and regard all category descrip-tions as candidate answers. Finally we construct a question-and-answer pair and use it as the input of the BERT model to complete emotion classification. By integrating rich contextual andcategory semantics the model can better understand the emotion of microblogs. Experimentson the COVID-19 Chinese microblog dataset show that our approach outperforms many existinge motion classification methods including the BERT baseline.,https://aclanthology.org/2021.ccl-1.82,emotion,Yes,Yes,No
Multi-level Emotion Cause Analysis by Multi-head Attention Based Multi-task Learning,"Xiangju, Li  and
Shi, Feng  and
Yifei, Zhang  and
Daling, Wang",2021,Proceedings of the 20th Chinese National Conference on Computational Linguistics,,Emotion cause analysis (ECA) aims to identify the potential causes behind certain emotions intext. Lots of ECA models have been designed to extract the emotion cause at the clause level. However in many scenarios only extracting the cause clause is ambiguous. To ease the problemin this paper we introduce multi-level emotion cause analysis which focuses on identifying emotion cause clause (ECC) and emotion cause keywords (ECK) simultaneously. ECK is a more challenging task since it not only requires capturing the specific understanding of the role of eachword in the clause but also the relation between each word and emotion expression. We observethat ECK task can incorporate the contextual information from the ECC task while ECC taskcan be improved by learning the correlation between emotion cause keywords and emotion fromthe ECK task. To fulfill the goal of joint learning we propose a multi-head attention basedmulti-task learning method which utilizes a series of mechanisms including shared and privatefeature extractor multi-head attention emotion attention and label embedding to capture featuresand correlations between the two tasks. Experimental results show that the proposed method consistently outperforms the state-of-the-art methods on a benchmark emotion cause dataset.,https://aclanthology.org/2021.ccl-1.83,emotion,Yes,Yes,No
Personal Bias in Prediction of Emotions Elicited by Textual Opinions,"Milkowski, Piotr  and
Gruza, Marcin  and
Kanclerz, Kamil  and
Kazienko, Przemyslaw  and
Grimling, Damian  and
Kocon, Jan",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop,10.18653/v1/2021.acl-srw.26,"Analysis of emotions elicited by opinions, comments, or articles commonly exploits annotated corpora, in which the labels assigned to documents average the views of all annotators, or represent a majority decision. The models trained on such data are effective at identifying the general views of the population. However, their usefulness for predicting the emotions evoked by the textual content in a particular individual is limited. In this paper, we present a study performed on a dataset containing 7,000 opinions, each annotated by about 50 people with two dimensions: valence, arousal, and with intensity of eight emotions from Plutchik{'}s model. Our study showed that individual responses often significantly differed from the mean. Therefore, we proposed a novel measure to estimate this effect {--} Personal Emotional Bias (PEB). We also developed a new BERT-based transformer architecture to predict emotions from an individual human perspective. We found PEB a major factor for improving the quality of personalized reasoning. Both the method and measure may boost the quality of content recommendation systems and personalized solutions that protect users from hate speech or unwanted content, which are highly subjective in nature.",https://aclanthology.org/2021.acl-srw.26,emotion,Yes,Yes,No
e{MLM}: A New Pre-training Objective for Emotion Related Tasks,"Sosea, Tiberiu  and
Caragea, Cornelia",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),10.18653/v1/2021.acl-short.38,"BERT has been shown to be extremely effective on a wide variety of natural language processing tasks, including sentiment analysis and emotion detection. However, the proposed pretraining objectives of BERT do not induce any sentiment or emotion-specific biases into the model. In this paper, we present Emotion Masked Language Modelling, a variation of Masked Language Modelling aimed at improving the BERT language representation model for emotion detection and sentiment analysis tasks. Using the same pre-training corpora as the original model, Wikipedia and BookCorpus, our BERT variation manages to improve the downstream performance on 4 tasks from emotion detection and sentiment analysis by an average of 1.2{\%} F-1. Moreover, our approach shows an increased performance in our task-specific robustness tests.",https://aclanthology.org/2021.acl-short.38,emotion,No,Yes,Yes
Directed Acyclic Graph Network for Conversational Emotion Recognition,"Shen, Weizhou  and
Wu, Siyue  and
Yang, Yunyi  and
Quan, Xiaojun",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.123,"The modeling of conversational context plays a vital role in emotion recognition from conversation (ERC). In this paper, we put forward a novel idea of encoding the utterances with a directed acyclic graph (DAG) to better model the intrinsic structure within a conversation, and design a directed acyclic neural network, namely DAG-ERC, to implement this idea. In an attempt to combine the strengths of conventional graph-based neural models and recurrence-based neural models, DAG-ERC provides a more intuitive way to model the information flow between long-distance conversation background and nearby context. Extensive experiments are conducted on four ERC benchmarks with state-of-the-art models employed as baselines for comparison. The empirical results demonstrate the superiority of this new model and confirm the motivation of the directed acyclic graph architecture for ERC.",https://aclanthology.org/2021.acl-long.123,emotion,No,Yes,No
Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection,"Zhu, Lixing  and
Pergola, Gabriele  and
Gui, Lin  and
Zhou, Deyu  and
He, Yulan",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.125,"Emotion detection in dialogues is challenging as it often requires the identification of thematic topics underlying a conversation, the relevant commonsense knowledge, and the intricate transition patterns between the affective states. In this paper, we propose a Topic-Driven Knowledge-Aware Transformer to handle the challenges above. We firstly design a topic-augmented language model (LM) with an additional layer specialized for topic detection. The topic-augmented LM is then combined with commonsense statements derived from a knowledge base based on the dialogue contextual information. Finally, a transformer-based encoder-decoder architecture fuses the topical and commonsense information, and performs the emotion label sequence prediction. The model has been experimented on four datasets in dialogue emotion detection, demonstrating its superiority empirically over the existing state-of-the-art approaches. Quantitative and qualitative results show that the model can discover topics which help in distinguishing emotion categories.",https://aclanthology.org/2021.acl-long.125,emotion,No,Yes,Yes
Distributed Representations of Emotion Categories in Emotion Space,"Wang, Xiangyu  and
Zong, Chengqing",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.184,"Emotion category is usually divided into different ones by human beings, but it is indeed difficult to clearly distinguish and define the boundaries between different emotion categories. The existing studies working on emotion detection usually focus on how to improve the performance of model prediction, in which emotions are represented with one-hot vectors. However, emotion relations are ignored in one-hot representations. In this article, we first propose a general framework to learn the distributed representations for emotion categories in emotion space from a given emotion classification dataset. Furthermore, based on the soft labels predicted by the pre-trained neural network model, we derive a simple and effective algorithm. Experiments have validated that the proposed representations in emotion space can express emotion relations much better than word vectors in semantic space.",https://aclanthology.org/2021.acl-long.184,emotion,Yes,Yes,No
Missing Modality Imagination Network for Emotion Recognition with Uncertain Missing Modalities,"Zhao, Jinming  and
Li, Ruichen  and
Jin, Qin",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.203,"Multimodal fusion has been proved to improve emotion recognition performance in previous works. However, in real-world applications, we often encounter the problem of missing modality, and which modalities will be missing is uncertain. It makes the fixed multimodal fusion fail in such cases. In this work, we propose a unified model, Missing Modality Imagination Network (MMIN), to deal with the uncertain missing modality problem. MMIN learns robust joint multimodal representations, which can predict the representation of any missing modality given available modalities under different missing modality conditions. Comprehensive experiments on two benchmark datasets demonstrate that the unified MMIN model significantly improves emotion recognition performance under both uncertain missing-modality testing conditions and full-modality ideal testing condition. The code will be available at \url{https://github.com/AIM3-RUC/MMIN}.",https://aclanthology.org/2021.acl-long.203,emotion,Yes,Yes,No
Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion Cause Extraction,"Yan, Hanqi  and
Gui, Lin  and
Pergola, Gabriele  and
He, Yulan",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.261,"The Emotion Cause Extraction (ECE) task aims to identify clauses which contain emotion-evoking information for a particular emotion expressed in text. We observe that a widely-used ECE dataset exhibits a bias that the majority of annotated cause clauses are either directly before their associated emotion clauses or are the emotion clauses themselves. Existing models for ECE tend to explore such relative position information and suffer from the dataset bias. To investigate the degree of reliance of existing ECE models on clause relative positions, we propose a novel strategy to generate adversarial examples in which the relative position information is no longer the indicative feature of cause clauses. We test the performance of existing models on such adversarial examples and observe a significant performance drop. To address the dataset bias, we propose a novel graph-based method to explicitly model the emotion triggering paths by leveraging the commonsense knowledge to enhance the semantic dependencies between a candidate clause and an emotion clause. Experimental results show that our proposed approach performs on par with the existing state-of-the-art methods on the original ECE dataset, and is more robust against adversarial attacks compared to existing models.",https://aclanthology.org/2021.acl-long.261,emotion,Yes,Yes,No
Towards Emotional Support Dialog Systems,"Liu, Siyang  and
Zheng, Chujie  and
Demasi, Orianna  and
Sabour, Sahand  and
Li, Yu  and
Yu, Zhou  and
Jiang, Yong  and
Huang, Minlie",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.269,"Emotional support is a crucial ability for many conversation scenarios, including social interactions, mental health support, and customer service chats. Following reasonable procedures and using various support skills can help to effectively provide support. However, due to the lack of a well-designed task and corpora of effective emotional support conversations, research on building emotional support into dialog systems remains lacking. In this paper, we define the Emotional Support Conversation (ESC) task and propose an ESC Framework, which is grounded on the Helping Skills Theory. We construct an Emotion Support Conversation dataset (ESConv) with rich annotation (especially support strategy) in a help-seeker and supporter mode. To ensure a corpus of high-quality conversations that provide examples of effective emotional support, we take extensive effort to design training tutorials for supporters and several mechanisms for quality control during data collection. Finally, we evaluate state-of-the-art dialog models with respect to the ability to provide emotional support. Our results show the importance of support strategies in providing effective emotional support and the utility of ESConv in training more emotional support systems.",https://aclanthology.org/2021.acl-long.269,emotion,Yes,Yes,No
Supporting Cognitive and Emotional Empathic Writing of Students,"Wambsganss, Thiemo  and
Niklaus, Christina  and
S{\""o}llner, Matthias  and
Handschuh, Siegfried  and
Leimeister, Jan Marco",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.314,"We present an annotation approach to capturing emotional and cognitive empathy in student-written peer reviews on business models in German. We propose an annotation scheme that allows us to model emotional and cognitive empathy scores based on three types of review components. Also, we conducted an annotation study with three annotators based on 92 student essays to evaluate our annotation scheme. The obtained inter-rater agreement of =0.79 for the components and the multi-{\mbox{$\pi$}}=0.41 for the empathy scores indicate that the proposed annotation scheme successfully guides annotators to a substantial to moderate agreement. Moreover, we trained predictive models to detect the annotated empathy structures and embedded them in an adaptive writing support system for students to receive individual empathy feedback independent of an instructor, time, and location. We evaluated our tool in a peer learning exercise with 58 students and found promising results for perceived empathy skill learning, perceived feedback accuracy, and intention to use. Finally, we present our freely available corpus of 500 empathy-annotated, student-written peer reviews on business models and our annotation guidelines to encourage future research on the design and development of empathy support systems.",https://aclanthology.org/2021.acl-long.314,emotion_and_empathy,Yes,Yes,No
{MMGCN}: Multimodal Fusion via Deep Graph Convolution Network for Emotion Recognition in Conversation,"Hu, Jingwen  and
Liu, Yuchen  and
Zhao, Jinming  and
Jin, Qin",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.440,"Emotion recognition in conversation (ERC) is a crucial component in affective dialogue systems, which helps the system understand users{'} emotions and generate empathetic responses. However, most works focus on modeling speaker and contextual information primarily on the textual modality or simply leveraging multimodal information through feature concatenation. In order to explore a more effective way of utilizing both multimodal and long-distance contextual information, we propose a new model based on multimodal fused graph convolutional network, MMGCN, in this work. MMGCN can not only make use of multimodal dependencies effectively, but also leverage speaker information to model inter-speaker and intra-speaker dependency. We evaluate our proposed model on two public benchmark datasets, IEMOCAP and MELD, and the results prove the effectiveness of MMGCN, which outperforms other SOTA methods by a significant margin under the multimodal conversation setting.",https://aclanthology.org/2021.acl-long.440,emotion,Yes,Yes,No
{D}ialogue{CRN}: Contextual Reasoning Networks for Emotion Recognition in Conversations,"Hu, Dou  and
Wei, Lingwei  and
Huai, Xiaoyong",2021,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),10.18653/v1/2021.acl-long.547,"Emotion Recognition in Conversations (ERC) has gained increasing attention for developing empathetic machines. Recently, many approaches have been devoted to perceiving conversational context by deep learning models. However, these approaches are insufficient in understanding the context due to lacking the ability to extract and integrate emotional clues. In this work, we propose novel Contextual Reasoning Networks (DialogueCRN) to fully understand the conversational context from a cognitive perspective. Inspired by the Cognitive Theory of Emotion, we design multi-turn reasoning modules to extract and integrate emotional clues. The reasoning module iteratively performs an intuitive retrieving process and a conscious reasoning process, which imitates human unique cognitive thinking. Extensive experiments on three public benchmark datasets demonstrate the effectiveness and superiority of the proposed model.",https://aclanthology.org/2021.acl-long.547,emotion,Yes,Yes,No
Studying The Effect of Emotional and Moral Language on Information Contagion during the Charlottesville Event,"Mahajan, Khyati  and
Shaikh, Samira",2020,Proceedings of the Fourth Widening Natural Language Processing Workshop,10.18653/v1/2020.winlp-1.34,"We highlight the contribution of emotional and moral language towards information contagion online. We find that retweet count on Twitter is significantly predicted by the use of negative emotions with negative moral language. We find that a tweet is less likely to be retweeted (hence less engagement and less potential for contagion) when it has emotional language expressed as anger along with a specific type of moral language, known as authority-vice. Conversely, when sadness is expressed with authority-vice, the tweet is more likely to be retweeted. Our findings indicate how emotional and moral language can interact in predicting information contagion.",https://aclanthology.org/2020.winlp-1.34,emotion,No,No,No
Empathy-driven {A}rabic Conversational Chatbot,"Naous, Tarek  and
Hokayem, Christian  and
Hajj, Hazem",2020,Proceedings of the Fifth Arabic Natural Language Processing Workshop,,"Conversational models have witnessed a significant research interest in the last few years with the advancements in sequence generation models. A challenging aspect in developing human-like conversational models is enabling the sense of empathy in bots, making them infer emotions from the person they are interacting with. By learning to develop empathy, chatbot models are able to provide human-like, empathetic responses, thus making the human-machine interaction close to human-human interaction. Recent advances in English use complex encoder-decoder language models that require large amounts of empathetic conversational data. However, research has not produced empathetic bots for Arabic. Furthermore, there is a lack of Arabic conversational data labeled with empathy. To address these challenges, we create an Arabic conversational dataset that comprises empathetic responses. However, the dataset is not large enough to develop very complex encoder-decoder models. To address the limitation of data scale, we propose a special encoder-decoder composed of a Long Short-Term Memory (LSTM) Sequence-to-Sequence (Seq2Seq) with Attention. The experiments showed success of our proposed empathy-driven Arabic chatbot in generating empathetic responses with a perplexity of 38.6, an empathy score of 3.7, and a fluency score of 3.92.",https://aclanthology.org/2020.wanlp-1.6,empathy,Yes,Yes,Yes
Token Sequence Labeling vs. Clause Classification for {E}nglish Emotion Stimulus Detection,"Oberl{\""a}nder, Laura Ana Maria  and
Klinger, Roman",2020,Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics,,"Emotion stimulus detection is the task of finding the cause of an emotion in a textual description, similar to target or aspect detection for sentiment analysis. Previous work approached this in three ways, namely (1) as text classification into an inventory of predefined possible stimuli ({``}Is the stimulus category A or B?{''}), (2) as sequence labeling of tokens ({``}Which tokens describe the stimulus?{''}), and (3) as clause classification ({``}Does this clause contain the emotion stimulus?{''}). So far, setting (3) has been evaluated broadly on Mandarin and (2) on English, but no comparison has been performed. Therefore, we analyze whether clause classification or token sequence labeling is better suited for emotion stimulus detection in English. We propose an integrated framework which enables us to evaluate the two different approaches comparably, implement models inspired by state-of-the-art approaches in Mandarin, and test them on four English data sets from different domains. Our results show that token sequence labeling is superior on three out of four datasets, in both clause-based and token sequence-based evaluation. The only case in which clause classification performs better is one data set with a high density of clause annotations. Our error analysis further confirms quantitatively and qualitatively that clauses are not the appropriate stimulus unit in English.",https://aclanthology.org/2020.starsem-1.7,emotion,No,Yes,No
Challenges in Emotion Style Transfer: An Exploration with a Lexical Substitution Pipeline,"Helbig, David  and
Troiano, Enrica  and
Klinger, Roman",2020,Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media,10.18653/v1/2020.socialnlp-1.6,"We propose the task of emotion style transfer, which is particularly challenging, as emotions (here: anger, disgust, fear, joy, sadness, surprise) are on the fence between content and style. To understand the particular difficulties of this task, we design a transparent emotion style transfer pipeline based on three steps: (1) select the words that are promising to be substituted to change the emotion (with a brute-force approach and selection based on the attention mechanism of an emotion classifier), (2) find sets of words as candidates for substituting the words (based on lexical and distributional semantics), and (3) select the most promising combination of substitutions with an objective function which consists of components for content (based on BERT sentence embeddings), emotion (based on an emotion classifier), and fluency (based on a neural language model). This comparably straight-forward setup enables us to explore the task and understand in what cases lexical substitution can vary the emotional load of texts, how changes in content and style interact and if they are at odds. We further evaluate our pipeline quantitatively in an automated and an annotation study based on Tweets and find, indeed, that simultaneous adjustments of content and emotion are conflicting objectives: as we show in a qualitative analysis motivated by Scherer{'}s emotion component model, this is particularly the case for implicit emotion expressions based on cognitive appraisal or descriptions of bodily reactions.",https://aclanthology.org/2020.socialnlp-1.6,emotion,No,Yes,Yes
Speech-Emotion Detection in an {I}ndonesian Movie,"Fahmi, Fahmi  and
Jiwanggi, Meganingrum Arista  and
Adriani, Mirna",2020,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),,"The growing demand to develop an automatic emotion recognition system for the Human-Computer Interaction field had pushed some research in speech emotion detection. Although it is growing, there is still little research about automatic speech emotion detection in Bahasa Indonesia. Another issue is the lack of standard corpus for this research area in Bahasa Indonesia. This study proposed several approaches to detect speech-emotion in the dialogs of an Indonesian movie by classifying them into 4 different emotion classes i.e. happiness, sadness, anger, and neutral. There are two different speech data representations used in this study i.e. statistical and temporal/sequence representations. This study used Artificial Neural Network (ANN), Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM) variation, word embedding, and also the hybrid of three to perform the classification task. The best accuracies given by one-vs-rest scenario for each emotion class with speech-transcript pairs using hybrid of non-temporal and embedding approach are 1) happiness: 76.31{\%}; 2) sadness: 86.46{\%}; 3) anger: 82.14{\%}; and 4) neutral: 68.51{\%}. The multiclass classification resulted in 64.66{\%} of precision, 66.79{\%} of recall, and 64.83{\%} of F1-score.",https://aclanthology.org/2020.sltu-1.26,emotion,Yes,Yes,No
{T}urkish Emotion Voice Database ({T}ur{EV}-{DB}),"Canpolat, Salih Firat  and
Ormano{\u{g}}lu, Zuhal  and
Zeyrek, Deniz",2020,Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL),,"We introduce the Turkish Emotion-Voice Database (TurEV-DB) which involves a corpus of over 1700 tokens based on 82 words uttered by human subjects in four different emotions (\textit{angry, calm, happy, sad}). Three machine learning experiments are run on the corpus data to classify the emotions using a convolutional neural network (CNN) model and a support vector machine (SVM) model. We report the performance of the machine learning models, and for evaluation, compare machine learning results with the judgements of humans.",https://aclanthology.org/2020.sltu-1.52,emotion,Yes,Yes,No
Learning Word Groundings from Humans Facilitated by Robot Emotional Displays,"McNeill, David  and
Kennington, Casey",2020,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,10.18653/v1/2020.sigdial-1.13,"In working towards accomplishing a human-level acquisition and understanding of language, a robot must meet two requirements: the ability to learn words from interactions with its physical environment, and the ability to learn language from people in settings for language use, such as spoken dialogue. In a live interactive study, we test the hypothesis that emotional displays are a viable solution to the cold-start problem of how to communicate without relying on language the robot does not{--}indeed, cannot{--}yet know. We explain our modular system that can autonomously learn word groundings through interaction and show through a user study with 21 participants that emotional displays improve the quantity and quality of the inputs provided to the robot.",https://aclanthology.org/2020.sigdial-1.13,emotion,No,No,No
Contextualized Emotion Recognition in Conversation as Sequence Tagging,"Wang, Yan  and
Zhang, Jiayu  and
Ma, Jun  and
Wang, Shaojun  and
Xiao, Jing",2020,Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue,10.18653/v1/2020.sigdial-1.23,"Emotion recognition in conversation (ERC) is an important topic for developing empathetic machines in a variety of areas including social opinion mining, health-care and so on. In this paper, we propose a method to model ERC task as sequence tagging where a Conditional Random Field (CRF) layer is leveraged to learn the emotional consistency in the conversation. We employ LSTM-based encoders that capture self and inter-speaker dependency of interlocutors to generate contextualized utterance representations which are fed into the CRF layer. For capturing long-range global context, we use a multi-layer Transformer encoder to enhance the LSTM-based encoder. Experiments show that our method benefits from modeling the emotional consistency and outperforms the current state-of-the-art methods on multiple emotion classification datasets.",https://aclanthology.org/2020.sigdial-1.23,emotion,No,Yes,No
{DSC} {IIT}-{ISM} at {S}em{E}val-2020 Task 8: Bi-Fusion Techniques for Deep Meme Emotion Analysis,"Gupta, Pradyumna  and
Gupta, Himanshu  and
Sinha, Aman",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.111,"Memes have become an ubiquitous social media entity and the processing and analysis of such multimodal data is currently an active area of research. This paper presents our work on the Memotion Analysis shared task of SemEval 2020, which involves the sentiment and humor analysis of memes. We propose a system which uses different bimodal fusion techniques to leverage the inter-modal dependency for sentiment and humor classification tasks. Out of all our experiments, the best system improved the baseline with macro F1 scores of 0.357 on Sentiment Classification (Task A), 0.510 on Humor Classification (Task B) and 0.312 on Scales of Semantic Classes (Task C).",https://aclanthology.org/2020.semeval-1.111,emotion,No,Yes,No
{NUAA}-{QMUL} at {S}em{E}val-2020 Task 8: Utilizing {BERT} and {D}ense{N}et for {I}nternet Meme Emotion Analysis,"Guo, Xiaoyu  and
Ma, Jing  and
Zubiaga, Arkaitz",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.114,"This paper describes our contribution to SemEval 2020 Task 8: Memotion Analysis. Our system learns multi-modal embeddings from text and images in order to classify Internet memes by sentiment. Our model learns text embeddings using BERT and extracts features from images with DenseNet, subsequently combining both features through concatenation. We also compare our results with those produced by DenseNet, ResNet, BERT, and BERT-ResNet. Our results show that image classification models have the potential to help classifying memes, with DenseNet outperforming ResNet. Adding text features is however not always helpful for Memotion Analysis.",https://aclanthology.org/2020.semeval-1.114,emotion,No,Yes,No
{BERT} at {S}em{E}val-2020 Task 8: Using {BERT} to Analyse Meme Emotions,"Avvaru, Adithya  and
Vobilisetty, Sanath",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.144,"Sentiment analysis, being one of the most sought after research problems within Natural Language Processing (NLP) researchers. The range of problems being addressed by sentiment analysis is increasing. Till now, most of the research focuses on predicting sentiment, or sentiment categories like sarcasm, humor, offense and motivation on text data. But, there is very limited research that is focusing on predicting or analyzing the sentiment of internet memes. We try to address this problem as part of {``}Task 8 of SemEval 2020: Memotion Analysis{''}. We have participated in all the three tasks under Memotion Analysis. Our system built using state-of-the-art Transformer-based pre-trained Bidirectional Encoder Representations from Transformers (BERT) performed better compared to baseline models for the two tasks A and C and performed close to the baseline model for task B. In this paper, we present the data used, steps used by us for data cleaning and preparation, the fine-tuning process for BERT based model and finally predict the sentiment or sentiment categories. We found that the sequence models like Long Short Term Memory(LSTM) and its variants performed below par in predicting the sentiments. We also performed a comparative analysis with other Transformer based models like DistilBERT and XLNet.",https://aclanthology.org/2020.semeval-1.144,emotion,No,Yes,Yes
Hitachi at {S}em{E}val-2020 Task 8: Simple but Effective Modality Ensemble for Meme Emotion Recognition,"Morishita, Terufumi  and
Morio, Gaku  and
Horiguchi, Shota  and
Ozaki, Hiroaki  and
Miyoshi, Toshinori",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.149,"Users of social networking services often share their emotions via multi-modal content, usually images paired with text embedded in them. SemEval-2020 task 8, Memotion Analysis, aims at automatically recognizing these emotions of so-called internet memes. In this paper, we propose a simple but effective Modality Ensemble that incorporates visual and textual deep-learning models, which are independently trained, rather than providing a single multi-modal joint network. To this end, we first fine-tune four pre-trained visual models (i.e., Inception-ResNet, PolyNet, SENet, and PNASNet) and four textual models (i.e., BERT, GPT-2, Transformer-XL, and XLNet). Then, we fuse their predictions with ensemble methods to effectively capture cross-modal correlations. The experiments performed on dev-set show that both visual and textual features aided each other, especially in subtask-C, and consequently, our system ranked 2nd on subtask-C.",https://aclanthology.org/2020.semeval-1.149,emotion,No,Yes,No
{M}emo{SYS} at {S}em{E}val-2020 Task 8: Multimodal Emotion Analysis in Memes,"Bejan, Irina",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.155,"Internet memes are one of the most viral types of content in social media and are equally used in promoting hate speech. Towards a more broad understanding of memes, this paper describes the MemoSys system submitted in Task 8 of SemEval 2020, which aims to classify the sentiment of Internet memes and provide a minimum description of the type of humor it depicts (sarcastic, humorous, offensive, motivational) and its semantic scale. The solution presented covers four deep model architectures which are based on a joint fusion between the VGG16 pre-trained model for extracting visual information and the canonical BERT model or TF-IDF for text understanding. The system placed 5th of 36 participating systems in the task A, offering promising prospects to the use of transfer learning to approach Internet memes understanding.",https://aclanthology.org/2020.semeval-1.155,emotion,No,Yes,No
{B}ham{NLP} at {S}em{E}val-2020 Task 12: An Ensemble of Different Word Embeddings and Emotion Transfer Learning for {A}rabic Offensive Language Identification in Social Media,"Alharbi, Abdullah I.  and
Lee, Mark",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.200,"Social media platforms such as Twitter offer people an opportunity to publish short posts in which they can share their opinions and perspectives. While these applications can be valuable, they can also be exploited to promote negative opinions, insults, and hatred against a person, race, or group. These opinions can be spread to millions of people at the click of a mouse. As such, there is a need to develop mechanisms by which offensive language can be automatically detected in social media channels and managed in a timely manner. To help achieve this goal, SemEval 2020 offered a shared task (OffensEval 2020) that involved the detection of offensive text in Arabic. We propose an ensemble approach that combines different levels of word embedding models and transfers learning from other sources of emotion-related tasks. The proposed system ranked 9th out of the 52 entries within the Arabic Offensive language identification subtask.",https://aclanthology.org/2020.semeval-1.200,emotion,No,Yes,Yes
{S}oc{C}og{C}om at {S}em{E}val-2020 Task 11: Characterizing and Detecting Propaganda Using Sentence-Level Emotional Salience Features,"Krishnamurthy, Gangeshwar  and
Gupta, Raj Kumar  and
Yang, Yinping",2020,Proceedings of the Fourteenth Workshop on Semantic Evaluation,10.18653/v1/2020.semeval-1.235,"This paper describes a system developed for detecting propaganda techniques from news articles. We focus on examining how emotional salience features extracted from a news segment can help to characterize and predict the presence of propaganda techniques. Correlation analyses surfaced interesting patterns that, for instance, the {``}loaded language{''} and {``}slogan{''} techniques are negatively associated with valence and joy intensity but are positively associated with anger, fear and sadness intensity. In contrast, {``}flag waving{''} and {``}appeal to fear-prejudice{''} have the exact opposite pattern. Through predictive experiments, results further indicate that whereas BERT-only features obtained F1-score of 0.548, emotion intensity features and BERT hybrid features were able to obtain F1-score of 0.570, when a simple feedforward network was used as the classifier in both settings. On gold test data, our system obtained micro-averaged F1-score of 0.558 on overall detection efficacy over fourteen propaganda techniques. It performed relatively well in detecting {``}loaded language{''} (F1 = 0.772), {``}name calling and labeling{''} (F1 = 0.673), {``}doubt{''} (F1 = 0.604) and {``}flag waving{''} (F1 = 0.543).",https://aclanthology.org/2020.semeval-1.235,emotion,No,Yes,No
Contextual Augmentation of Pretrained Language Models for Emotion Recognition in Conversations,"Kim, Jonggu  and
Ko, Hyeonmok  and
Song, Seoha  and
Jang, Saebom  and
Hong, Jiyeon",2020,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",,"Since language model pretraining to learn contextualized word representations has been proposed, pretrained language models have made success in many natural language processing tasks. That is because it is helpful to use individual contextualized representations of self-attention layers as to initialize parameters for downstream tasks. Yet, unfortunately, use of pretrained language models for emotion recognition in conversations has not been studied enough. We firstly use ELECTRA which is a state-of-the-art pretrained language model and validate the performance on emotion recognition in conversations. Furthermore, we propose contextual augmentation of pretrained language models for emotion recognition in conversations, which is to consider not only previous utterances, but also conversation-related information such as speakers, speech acts and topics. We classify information based on what the information is related to, and propose position of words corresponding to the information in the entire input sequence. To validate the proposed method, we conduct experiments on the DailyDialog dataset which contains abundant annotated information of conversations. The experiments show that the proposed method achieves state-of-the-art F1 scores on the dataset and significantly improves the performance.",https://aclanthology.org/2020.peoples-1.7,emotion,Yes,Yes,Yes
Topic and Emotion Development among {D}utch {COVID}-19 {T}witter Communities in the early Pandemic,"Marinov, Boris  and
Spenader, Jennifer  and
Caselli, Tommaso",2020,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",,"The paper focuses on a large collection of Dutch tweets from the Netherlands to get an insight into the perception and reactions of users during the early months of the COVID-19 pandemic. We focused on five major user communities of users: government and health organizations, news media, politicians, the general public and conspiracy theory supporters, investigating differences among them in topic dominance and the expressions of emotions. Through topic modeling we monitor the evolution of the conversation about COVID-19 among these communities. Our results indicate that the national focus on COVID-19 shifted from the virus itself to its impact on the economy between February and April. Surprisingly, the overall emotional public response appears to be substantially positive and expressing trust, although differences can be observed in specific group of users.",https://aclanthology.org/2020.peoples-1.9,emotion,Yes,Yes,No
"Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine Learning to Infer the Emotions?","Oberl{\""a}nder, Laura Ana Maria  and
Reich, Kevin  and
Klinger, Roman",2020,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",,"Emotion recognition is predominantly formulated as text classification in which textual units are assigned to an emotion from a predefined inventory (e.g., fear, joy, anger, disgust, sadness, surprise, trust, anticipation). More recently, semantic role labeling approaches have been developed to extract structures from the text to answer questions like: {``}who is described to feel the emotion?{''} (experiencer), {``}what causes this emotion?{''} (stimulus), and at which entity is it directed?{''} (target). Though it has been shown that jointly modeling stimulus and emotion category prediction is beneficial for both subtasks, it remains unclear which of these semantic roles enables a classifier to infer the emotion. Is it the experiencer, because the identity of a person is biased towards a particular emotion (X is always happy)? Is it a particular target (everybody loves X) or a stimulus (doing X makes everybody sad)? We answer these questions by training emotion classification models on five available datasets annotated with at least one semantic role by masking the fillers of these roles in the text in a controlled manner and find that across multiple corpora, stimuli and targets carry emotion information, while the experiencer might be considered a confounder. Further, we analyze if informing the model about the position of the role improves the classification decision. Particularly on literature corpora we find that the role information improves the emotion classification.",https://aclanthology.org/2020.peoples-1.12,emotion,Yes,Yes,No
Learning Emotion from 100 Observations: Unexpected Robustness of Deep Learning under Strong Data Limitations,"Buechel, Sven  and
Sedoc, Jo{\~a}o  and
Schwartz, H. Andrew  and
Ungar, Lyle",2020,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",,"One of the major downsides of Deep Learning is its supposed need for vast amounts of training data. As such, these techniques appear ill-suited for NLP areas where annotated data is limited, such as less-resourced languages or emotion analysis, with its many nuanced and hard-to-acquire annotation formats. We conduct a questionnaire study indicating that indeed the vast majority of researchers in emotion analysis deems neural models inferior to traditional machine learning when training data is limited. In stark contrast to those survey results, we provide empirical evidence for English, Polish, and Portuguese that commonly used neural architectures can be trained on surprisingly few observations, outperforming n-gram based ridge regression on only 100 data points. Our analysis suggests that high-quality, pre-trained word embeddings are a main factor for achieving those results.",https://aclanthology.org/2020.peoples-1.13,emotion,Yes,Yes,Yes
Cross-lingual Emotion Intensity Prediction,"Navas Alejo, Irean  and
Badia, Toni  and
Barnes, Jeremy",2020,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",,"Emotion intensity prediction determines the degree or intensity of an emotion that the author expresses in a text, extending previous categorical approaches to emotion detection. While most previous work on this topic has concentrated on English texts, other languages would also benefit from fine-grained emotion classification, preferably without having to recreate the amount of annotated data available in English in each new language. Consequently, we explore cross-lingual transfer approaches for fine-grained emotion detection in Spanish and Catalan tweets. To this end we annotate a test set of Spanish and Catalan tweets using Best-Worst scaling. We compare six cross-lingual approaches, e.g., machine translation and cross-lingual embeddings, which have varying requirements for parallel data {--} from millions of parallel sentences to completely unsupervised. The results show that on this data, methods with low parallel-data requirements perform surprisingly better than methods that use more parallel data, which we explain through an in-depth error analysis. We make the dataset and the code available at \url{https://github.com/jerbarnes/fine-grained_cross-lingual_emotion}.",https://aclanthology.org/2020.peoples-1.14,emotion,Yes,Yes,No
"The {L}i{L}a{H} Emotion Lexicon of {C}roatian, {D}utch and {S}lovene","Ljube{\v{s}}i{\'c}, Nikola  and
Markov, Ilia  and
Fi{\v{s}}er, Darja  and
Daelemans, Walter",2020,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",,"In this paper, we present emotion lexicons of Croatian, Dutch and Slovene, based on manually corrected automatic translations of the English NRC Emotion lexicon. We evaluate the impact of the translation changes by measuring the change in supervised classification results of socially unacceptable utterances when lexicon information is used for feature construction. We further showcase the usage of the lexicons by calculating the difference in emotion distributions in texts containing and not containing socially unacceptable discourse, comparing them across four languages (English, Croatian, Dutch, Slovene) and two topics (migrants and LGBT). We show significant and consistent improvements in automatic classification across all languages and topics, as well as consistent (and expected) emotion distributions across all languages and topics, proving for the manually corrected lexicons to be a useful addition to the severely lacking area of emotion lexicons, the crucial resource for emotive analysis of text.",https://aclanthology.org/2020.peoples-1.15,emotion,No,Yes,No
Systematic Evaluation of a Framework for Unsupervised Emotion Recognition for Narrative Text,"Zad, Samira  and
Finlayson, Mark",2020,"Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events",10.18653/v1/2020.nuse-1.4,"Identifying emotions as expressed in text (a.k.a. text emotion recognition) has received a lot of attention over the past decade. Narratives often involve a great deal of emotional expression, and so emotion recognition on narrative text is of great interest to computational approaches to narrative understanding. Prior work by Kim et al. 2010 was the work with the highest reported emotion detection performance, on a corpus of fairy tales texts. Close inspection of that work, however, revealed significant reproducibility problems, and we were unable to reimplement Kim{'}s approach as described. As a consequence, we implemented a framework inspired by Kim{'}s approach, where we carefully evaluated the major design choices. We identify the highest-performing combination, which outperforms Kim{'}s reported performance by 7.6 $F_1$ points on average. Close inspection of the annotated data revealed numerous missing and incorrect emotion terms in the relevant lexicon, WordNetAffect (WNA; Strapparava and Valitutti, 2004), which allowed us to augment it in a useful way. More generally, this showed that numerous clearly emotive words and phrases are missing from WNA, which suggests that effort invested in augmenting or refining emotion ontologies could be useful for improving the performance of emotion recognition systems. We release our code and data to definitely enable future reproducibility of this work.",https://aclanthology.org/2020.nuse-1.4,emotion,Yes,Yes,No
Emotion Arcs of Student Narratives,"Somasundaran, Swapna  and
Chen, Xianyang  and
Flor, Michael",2020,"Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events",10.18653/v1/2020.nuse-1.12,"This paper studies emotion arcs in student narratives. We construct emotion arcs based on event affect and implied sentiments, which correspond to plot elements in the story. We show that student narratives can show elements of plot structure in their emotion arcs and that properties of these arcs can be useful indicators of narrative quality. We build a system and perform analysis to show that our arc-based features are complementary to previously studied sentiment features in this area.",https://aclanthology.org/2020.nuse-1.12,emotion,No,No,No
{I} miss you babe: Analyzing Emotion Dynamics During {COVID}-19 Pandemic,"Ng, Hui Xian Lynnette  and
Lee, Roy Ka-Wei  and
Awal, Md Rabiul",2020,Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science,10.18653/v1/2020.nlpcss-1.5,"With the world on a lockdown due to the COVID-19 pandemic, this paper studies emotions expressed on Twitter. Using a combined strategy of time series analysis of emotions augmented by tweet topics, this study provides an insight into emotion transitions during the pandemic. After tweets are annotated with dominant emotions and topics, a time-series emotion analysis is used to identify disgust and anger as the most commonly identified emotions. Through longitudinal analysis of each user, we construct emotion transition graphs, observing key transitions between disgust and anger, and self-transitions within anger and disgust emotional states. Observing user patterns through clustering of user longitudinal analyses reveals emotional transitions fall into four main clusters: (1) erratic motion over short period of time, (2) disgust -{\textgreater} anger, (3) optimism -{\textgreater} joy. (4) erratic motion over a prolonged period. Finally, we propose a method for predicting users subsequent topic, and by consequence their emotions, through constructing an Emotion Topic Hidden Markov Model, augmenting emotion transition states with topic information. Results suggests that the predictions fare better than baselines, spurring directions of predicting emotional states based on Twitter posts.",https://aclanthology.org/2020.nlpcss-1.5,emotion,Yes,Yes,No
Identifying Worry in {T}witter: Beyond Emotion Analysis,"Verma, Reyha  and
von der Weth, Christian  and
Vachery, Jithin  and
Kankanhalli, Mohan",2020,Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science,10.18653/v1/2020.nlpcss-1.9,"Identifying the worries of individuals and societies plays a crucial role in providing social support and enhancing policy decision-making. Due to the popularity of social media platforms such as Twitter, users share worries about personal issues (e.g., health, finances, relationships) and broader issues (e.g., changes in society, environmental concerns, terrorism) freely. In this paper, we explore and evaluate a wide range of machine learning models to predict worry on Twitter. While this task has been closely associated with emotion prediction, we argue and show that identifying worry needs to be addressed as a separate task given the unique challenges associated with it. We conduct a user study to provide evidence that social media posts express two basic kinds of worry {--} normative and pathological {--} as stated in psychology literature. In addition, we show that existing emotion detection techniques underperform, especially while capturing normative worry. Finally, we discuss the current limitations of our approach and propose future applications of the worry identification system.",https://aclanthology.org/2020.nlpcss-1.9,emotion,No,Yes,No
Measuring {Emotions} in the {COVID}-19 {Real} {World} {Worry} {Dataset},"Kleinberg, Bennett  and
van der Vegt, Isabelle  and
Mozes, Maximilian",2020,Proceedings of the 1st Workshop on {NLP} for {COVID-19} at {ACL} 2020,,"The COVID-19 pandemic is having a dramatic impact on societies and economies around the world. With various measures of lockdowns and social distancing in place, it becomes important to understand emotional responses on a large scale. In this paper, we present the first ground truth dataset of emotional responses to COVID-19. We asked participants to indicate their emotions and express these in text. This resulted in the Real World Worry Dataset of 5,000 texts (2,500 short + 2,500 long texts). Our analyses suggest that emotional responses correlated with linguistic measures. Topic modeling further revealed that people in the UK worry about their family and the economic situation. Tweet-sized texts functioned as a call for solidarity, while longer texts shed light on worries and concerns. Using predictive modeling approaches, we were able to approximate the emotional responses of participants from text within 14{\%} of their actual value. We encourage others to use the dataset and improve how we can use automated methods to learn about emotional responses and worries about an urgent problem.",https://aclanthology.org/2020.nlpcovid19-acl.11,emotion,Yes,Yes,No
Modulated Fusion using Transformer for Linguistic-Acoustic Emotion Recognition,"Delbrouck, Jean-Benoit  and
Tits, No{\'e}  and
Dupont, St{\'e}phane",2020,Proceedings of the First International Workshop on Natural Language Processing Beyond Text,10.18653/v1/2020.nlpbt-1.1,"This paper aims to bring a new lightweight yet powerful solution for the task of Emotion Recognition and Sentiment Analysis. Our motivation is to propose two architectures based on Transformers and modulation that combine the linguistic and acoustic inputs from a wide range of datasets to challenge, and sometimes surpass, the state-of-the-art in the field. To demonstrate the efficiency of our models, we carefully evaluate their performances on the IEMOCAP, MOSI, MOSEI and MELD dataset. The experiments can be directly replicated and the code is fully open for future researches.",https://aclanthology.org/2020.nlpbt-1.1,emotion,Yes,Yes,No
Emotional Speech Corpus for Persuasive Dialogue System,"Asai, Sara  and
Yoshino, Koichiro  and
Shinagawa, Seitaro  and
Sakti, Sakriani  and
Nakamura, Satoshi",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Expressing emotion is known as an efficient way to persuade one{'}s dialogue partner to accept one{'}s claim or proposal. Emotional expression in speech can express the speaker{'}s emotion more directly than using only emotion expression in the text, which will lead to a more persuasive dialogue. In this paper, we built a speech dialogue corpus in a persuasive scenario that uses emotional expressions to build a persuasive dialogue system with emotional expressions. We extended an existing text dialogue corpus by adding variations of emotional responses to cover different combinations of broad dialogue context and a variety of emotional states by crowd-sourcing. Then, we recorded emotional speech consisting of of collected emotional expressions spoken by a voice actor. The experimental results indicate that the collected emotional expressions with their speeches have higher emotional expressiveness for expressing the system{'}s emotion to users.",https://aclanthology.org/2020.lrec-1.62,emotion,Yes,No,No
{MPDD}: A Multi-Party Dialogue Dataset for Analysis of Emotions and Interpersonal Relationships,"Chen, Yi-Ting  and
Huang, Hen-Hsen  and
Chen, Hsin-Hsi",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"A dialogue dataset is an indispensable resource for building a dialogue system. Additional information like emotions and interpersonal relationships labeled on conversations enables the system to capture the emotion flow of the participants in the dialogue. However, there is no publicly available Chinese dialogue dataset with emotion and relation labels. In this paper, we collect the conversions from TV series scripts, and annotate emotion and interpersonal relationship labels on each utterance. This dataset contains 25,548 utterances from 4,142 dialogues. We also set up some experiments to observe the effects of the responded utterance on the current utterance, and the correlation between emotion and relation types in emotion and relation classification tasks.",https://aclanthology.org/2020.lrec-1.76,emotion,Yes,Yes,No
{EDA}: Enriching Emotional Dialogue Acts using an Ensemble of Neural Annotators,"Bothe, Chandrakant  and
Weber, Cornelius  and
Magg, Sven  and
Wermter, Stefan",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"The recognition of emotion and dialogue acts enriches conversational analysis and help to build natural dialogue systems. Emotion interpretation makes us understand feelings and dialogue acts reflect the intentions and performative functions in the utterances. However, most of the textual and multi-modal conversational emotion corpora contain only emotion labels but not dialogue acts. To address this problem, we propose to use a pool of various recurrent neural models trained on a dialogue act corpus, with and without context. These neural models annotate the emotion corpora with dialogue act labels, and an ensemble annotator extracts the final dialogue act label. We annotated two accessible multi-modal emotion corpora: IEMOCAP and MELD. We analyzed the co-occurrence of emotion and dialogue act labels and discovered specific relations. For example, Accept/Agree dialogue acts often occur with the Joy emotion, Apology with Sadness, and Thanking with Joy. We make the Emotional Dialogue Acts (EDA) corpus publicly available to the research community for further study and analysis.",https://aclanthology.org/2020.lrec-1.78,emotion,Yes,Yes,No
Relation between Degree of Empathy for Narrative Speech and Type of Responsive Utterance in Attentive Listening,"Ito, Koichiro  and
Murata, Masaki  and
Ohno, Tomohiro  and
Matsubara, Shigeki",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Nowadays, spoken dialogue agents such as communication robots and smart speakers listen to narratives of humans. In order for such an agent to be recognized as a listener of narratives and convey the attitude of attentive listening, it is necessary to generate responsive utterances. Moreover, responsive utterances can express empathy to narratives and showing an appropriate degree of empathy to narratives is significant for enhancing speaker{'}s motivation. The degree of empathy shown by responsive utterances is thought to depend on their type. However, the relation between responsive utterances and degrees of the empathy has not been explored yet. This paper describes the classification of responsive utterances based on the degree of empathy in order to explain that relation. In this research, responsive utterances are classified into five levels based on the effect of utterances and literature on attentive listening. Quantitative evaluations using 37,995 responsive utterances showed the appropriateness of the proposed classification.",https://aclanthology.org/2020.lrec-1.87,empathy,No,Yes,No
An {A}lgerian Corpus and an Annotation Platform for Opinion and Emotion Analysis,"Moudjari, Leila  and
Akli-Astouati, Karima  and
Benamara, Farah",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"In this paper, we address the lack of resources for opinion and emotion analysis related to North African dialects, targeting Algerian dialect. We present TWIFIL (TWItter proFILing) a collaborative annotation platform for crowdsourcing annotation of tweets at different levels of granularity. The plateform allowed the creation of the largest Algerian dialect dataset annotated for both sentiment (9,000 tweets), emotion (about 5,000 tweets) and extra-linguistic information including author profiling (age and gender). The annotation resulted also in the creation of the largest Algerien dialect subjectivity lexicon of about 9,000 entries which can constitute a valuable resources for the development of future NLP applications for Algerian dialect. To test the validity of the dataset, a set of deep learning experiments were conducted to classify a given tweet as positive, negative or neutral. We discuss our results and provide an error analysis to better identify classification errors.",https://aclanthology.org/2020.lrec-1.151,emotion,Yes,Yes,Yes
{E}mo{E}vent: A Multilingual Emotion Corpus based on different Events,"Plaza del Arco, Flor Miriam  and
Strapparava, Carlo  and
Urena Lopez, L. Alfonso  and
Martin, Maite",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"In recent years emotion detection in text has become more popular due to its potential applications in fields such as psychology, marketing, political science, and artificial intelligence, among others. While opinion mining is a well-established task with many standard data sets and well-defined methodologies, emotion mining has received less attention due to its complexity. In particular, the annotated gold standard resources available are not enough. In order to address this shortage, we present a multilingual emotion data set based on different events that took place in April 2019. We collected tweets from the Twitter platform. Then one of seven emotions, six Ekman{'}s basic emotions plus the {``}neutral or other emotions{''}, was labeled on each tweet by 3 Amazon MTurkers. A total of 8,409 in Spanish and 7,303 in English were labeled. In addition, each tweet was also labeled as offensive or no offensive. We report some linguistic statistics about the data set in order to observe the difference between English and Spanish speakers when they express emotions related to the same events. Moreover, in order to validate the effectiveness of the data set, we also propose a machine learning approach for automatically detecting emotions in tweets for both languages, English and Spanish.",https://aclanthology.org/2020.lrec-1.186,emotion,Yes,Yes,Yes
{M}u{SE}: a Multimodal Dataset of Stressed Emotion,"Jaiswal, Mimansa  and
Bara, Cristian-Paul  and
Luo, Yuanhang  and
Burzo, Mihai  and
Mihalcea, Rada  and
Provost, Emily Mower",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Endowing automated agents with the ability to provide support, entertainment and interaction with human beings requires sensing of the users{'} affective state. These affective states are impacted by a combination of emotion inducers, current psychological state, and various conversational factors. Although emotion classification in both singular and dyadic settings is an established area, the effects of these additional factors on the production and perception of emotion is understudied. This paper presents a new dataset, Multimodal Stressed Emotion (MuSE), to study the multimodal interplay between the presence of stress and expressions of affect. We describe the data collection protocol, the possible areas of use, and the annotations for the emotional content of the recordings. The paper also presents several baselines to measure the performance of multimodal features for emotion and stress classification.",https://aclanthology.org/2020.lrec-1.187,emotion,Yes,Yes,No
Annotation of Emotion Carriers in Personal Narratives,"Tammewar, Aniruddha  and
Cervone, Alessandra  and
Messner, Eva-Maria  and
Riccardi, Giuseppe",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"We are interested in the problem of understanding personal narratives (PN) - spoken or written - recollections of facts, events, and thoughts. For PNs, we define emotion carriers as the speech or text segments that best explain the emotional state of the narrator. Such segments may span from single to multiple words, containing for example verb or noun phrases. Advanced automatic understanding of PNs requires not only the prediction of the narrator{'}s emotional state but also to identify which events (e.g. the loss of a relative or the visit of grandpa) or people (e.g. the old group of high school mates) carry the emotion manifested during the personal recollection. This work proposes and evaluates an annotation model for identifying emotion carriers in spoken personal narratives. Compared to other text genres such as news and microblogs, spoken PNs are particularly challenging because a narrative is usually unstructured, involving multiple sub-events and characters as well as thoughts and associated emotions perceived by the narrator. In this work, we experiment with annotating emotion carriers in speech transcriptions from the Ulm State-of-Mind in Speech (USoMS) corpus, a dataset of PNs in German. We believe this resource could be used for experiments in the automatic extraction of emotion carriers from PN, a task that could provide further advancements in narrative understanding.",https://aclanthology.org/2020.lrec-1.189,emotion,Yes,Yes,No
{IIIT}-{H} {TEMD} Semi-Natural Emotional Speech Database from Professional Actors and Non-Actors,"Rambabu, Banothu  and
Botsa, Kishore Kumar  and
Paidi, Gangamohan  and
Gangashetty, Suryakanth V",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"A fundamental essence for emotional speech analysis towards emotion recognition is a good database. Database collected from natural scenarios consists of spontaneous emotions, but there are several issues in collection of such database. Other than the privacy and legal related concerns, there is no control over environment at the background. As it is difficult to collect data from natural scenarios, many research groups have collected data from semi-natural or designed procedures. In this paper, a new emotional speech database named IIIT-H TEMD (International Institute of Information Technology-Hyderabad Telugu Emotional Database) is collected using designed drama situations from actors and non-actors. Utterances are manually annotated using a hybrid strategy by giving the context to one of the listeners. As some of the data collection studies in the literature recommend for actors, analysis of actors data versus non-actors data is carried out for their significance. The total size of the dataset is about 5 hours, which makes it an useful resource for the emotional speech analysis.",https://aclanthology.org/2020.lrec-1.192,emotion,Yes,No,No
"{G}ood{N}ews{E}veryone: A Corpus of News Headlines Annotated with Emotions, Semantic Roles, and Reader Perception","Bostan, Laura Ana Maria  and
Kim, Evgeny  and
Klinger, Roman",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Most research on emotion analysis from text focuses on the task of emotion classification or emotion intensity regression. Fewer works address emotions as a phenomenon to be tackled with structured learning, which can be explained by the lack of relevant datasets. We fill this gap by releasing a dataset of 5000 English news headlines annotated via crowdsourcing with their associated emotions, the corresponding emotion experiencers and textual cues, related emotion causes and targets, as well as the reader{'}s perception of the emotion of the headline. This annotation task is comparably challenging, given the large number of classes and roles to be identified. We therefore propose a multiphase annotation procedure in which we first find relevant instances with emotional content and then annotate the more fine-grained aspects. Finally, we develop a baseline for the task of automatic prediction of semantic role structures and discuss the results. The corpus we release enables further research on emotion classification, emotion intensity prediction, emotion cause detection, and supports further qualitative studies.",https://aclanthology.org/2020.lrec-1.194,emotion,Yes,Yes,No
{K}orean-Specific Emotion Annotation Procedure Using {N}-Gram-Based Distant Supervision and {K}orean-Specific-Feature-Based Distant Supervision,"Lee, Young-Jun  and
Lim, Chae-Gyun  and
Choi, Ho-Jin",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Detecting emotions from texts is considerably important in an NLP task, but it has the limitation of the scarcity of manually labeled data. To overcome this limitation, many researchers have annotated unlabeled data with certain frequently used annotation procedures. However, most of these studies are focused mainly on English and do not consider the characteristics of the Korean language. In this paper, we present a Korean-specific annotation procedure, which consists of two parts, namely n-gram-based distant supervision and Korean-specific-feature-based distant supervision. We leverage the distant supervision with the n-gram and Korean emotion lexicons. Then, we consider the Korean-specific emotion features. Through experiments, we showed the effectiveness of our procedure by comparing with the KTEA dataset. Additionally, we constructed a large-scale emotion-labeled dataset, Korean Movie Review Emotion (KMRE) Dataset, using our procedure. In order to construct our dataset, we used a large-scale sentiment movie review corpus as the unlabeled dataset. Moreover, we used a Korean emotion lexicon provided by KTEA. We also performed an emotion classification task and a human evaluation on the KMRE dataset.",https://aclanthology.org/2020.lrec-1.199,emotion,Yes,Yes,Yes
Semi-Automatic Construction and Refinement of an Annotated Corpus for a Deep Learning Framework for Emotion Classification,"Xu, Jiajun  and
Masuda, Kyosuke  and
Nishizaki, Hiromitsu  and
Fukumoto, Fumiyo  and
Suzuki, Yoshimi",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"In the case of using a deep learning (machine learning) framework for emotion classification, one significant difficulty faced is the requirement of building a large, emotion corpus in which each sentence is assigned emotion labels. As a result, there is a high cost in terms of time and money associated with the construction of such a corpus. Therefore, this paper proposes a method of creating a semi-automatically constructed emotion corpus. For the purpose of this study sentences were mined from Twitter using some emotional seed words that were selected from a dictionary in which the emotion words were well-defined. Tweets were retrieved by one emotional seed word, and the retrieved sentences were assigned emotion labels based on the emotion category of the seed word. It was evident from the findings that the deep learning-based emotion classification model could not achieve high levels of accuracy in emotion classification because the semi-automatically constructed corpus had many errors when assigning emotion labels. In this paper, therefore, an approach for improving the quality of the emotion labels by automatically correcting the errors of emotion labels is proposed and tested. The experimental results showed that the proposed method worked well, and the classification accuracy rate was improved to 55.1{\%} from 44.9{\%} on the Twitter emotion classification task.",https://aclanthology.org/2020.lrec-1.200,emotion,Yes,Yes,No
"{CEASE}, a Corpus of Emotion Annotated Suicide notes in {E}nglish","Ghosh, Soumitra  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"A suicide note is usually written shortly before the suicide and it provides a chance to comprehend the self-destructive state of mind of the deceased. From a psychological point of view, suicide notes have been utilized for recognizing the motive behind the suicide. To the best of our knowledge, there is no openly accessible suicide note corpus at present, making it challenging for the researchers and developers to deep dive into the area of mental health assessment and suicide prevention. In this paper, we create a fine-grained emotion annotated corpus (CEASE) of suicide notes in English and develop various deep learning models to perform emotion detection on the curated dataset. The corpus consists of 2393 sentences from around 205 suicide notes collected from various sources. Each sentence is annotated with a particular emotion class from a set of 15 fine-grained emotion labels, namely (forgiveness, happiness{\_}peacefulness, love, pride, hopefulness, thankfulness, blame, anger, fear, abuse, sorrow, hopelessness, guilt, information, instructions). For the evaluation, we develop an ensemble architecture, where the base models correspond to three supervised deep learning models, namely Convolutional Neural Network (CNN), Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM). We obtain the highest test accuracy of 60.17{\%} and cross-validation accuracy of 60.32{\%}",https://aclanthology.org/2020.lrec-1.201,emotion,Yes,Yes,No
An Event-comment Social Media Corpus for Implicit Emotion Analysis,"Lee, Sophia Yat Mei  and
Lau, Helena Yan Ping",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"The classification of implicit emotions in text has always been a great challenge to emotion processing. Even though the majority of emotion expressed implicitly, most previous attempts at emotions have focused on the examination of explicit emotions. The poor performance of existing emotion identification and classification models can partly be attributed to the disregard of implicit emotions. In view of this, this paper presents the development of a Chinese event-comment social media emotion corpus. The corpus deals with both explicit and implicit emotions with more emphasis being placed on the implicit ones. This paper specifically describes the data collection and annotation of the corpus. An annotation scheme has been proposed for the annotation of emotion-related information including the emotion type, the emotion cause, the emotion reaction, the use of rhetorical question, the opinion target (i.e. the semantic role in an event that triggers an emotion), etc. Corpus data shows that the annotated items are of great value to the identification of implicit emotions. We believe that the corpus will be a useful resource for both explicit and implicit emotion classification and detection as well as event classification.",https://aclanthology.org/2020.lrec-1.203,emotion,Yes,Yes,No
An Emotional Mess! Deciding on a Framework for Building a {D}utch Emotion-Annotated Corpus,"De Bruyne, Luna  and
De Clercq, Orphee  and
Hoste, Veronique",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Seeing the myriad of existing emotion models, with the categorical versus dimensional opposition the most important dividing line, building an emotion-annotated corpus requires some well thought-out strategies concerning framework choice. In our work on automatic emotion detection in Dutch texts, we investigate this problem by means of two case studies. We find that the labels joy, love, anger, sadness and fear are well-suited to annotate texts coming from various domains and topics, but that the connotation of the labels strongly depends on the origin of the texts. Moreover, it seems that information is lost when an emotional state is forcedly classified in a limited set of categories, indicating that a bi-representational format is desirable when creating an emotion corpus.",https://aclanthology.org/2020.lrec-1.204,emotion,Yes,Yes,No
"{PO}-{EMO}: Conceptualization, Annotation, and Modeling of Aesthetic Emotions in {G}erman and {E}nglish Poetry","Haider, Thomas  and
Eger, Steffen  and
Kim, Evgeny  and
Klinger, Roman  and
Menninghaus, Winfried",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Most approaches to emotion analysis of social media, literature, news, and other domains focus exclusively on basic emotion categories as defined by Ekman or Plutchik. However, art (such as literature) enables engagement in a broader range of more complex and subtle emotions. These have been shown to also include mixed emotional responses. We consider emotions in poetry as they are elicited in the reader, rather than what is expressed in the text or intended by the author. Thus, we conceptualize a set of aesthetic emotions that are predictive of aesthetic appreciation in the reader, and allow the annotation of multiple labels per line to capture mixed emotions within their context. We evaluate this novel setting in an annotation experiment both with carefully trained experts and via crowdsourcing. Our annotation with experts leads to an acceptable agreement of k = .70, resulting in a consistent dataset for future large scale analysis. Finally, we conduct first emotion classification experiments based on BERT, showing that identifying aesthetic emotions is challenging in our data, with up to .52 F1-micro on the German subset. Data and resources are available at \url{https://github.com/tnhaider/poetry-emotion}.",https://aclanthology.org/2020.lrec-1.205,emotion,Yes,Yes,No
Learning Word Ratings for Empathy and Distress from Document-Level User Responses,"Sedoc, Jo{\~a}o  and
Buechel, Sven  and
Nachmany, Yehonathan  and
Buffone, Anneke  and
Ungar, Lyle",2020,Proceedings of the Twelfth Language Resources and Evaluation Conference,,"Despite the excellent performance of black box approaches to modeling sentiment and emotion, lexica (sets of informative words and associated weights) that characterize different emotions are indispensable to the NLP community because they allow for interpretable and robust predictions. Emotion analysis of text is increasing in popularity in NLP; however, manually creating lexica for psychological constructs such as empathy has proven difficult. This paper automatically creates empathy word ratings from document-level ratings. The underlying problem of learning word ratings from higher-level supervision has to date only been addressed in an ad hoc fashion and has not used deep learning methods. We systematically compare a number of approaches to learning word ratings from higher-level supervision against a Mixed-Level Feed Forward Network (MLFFN), which we find performs best, and use the MLFFN to create the first-ever empathy lexicon. We then use Signed Spectral Clustering to gain insights into the resulting words. The empathy and distress lexica are publicly available at: \url{http://www.wwbp.org/lexica.html}.",https://aclanthology.org/2020.lrec-1.206,empathy,No,Yes,Yes
Towards a Multi-Dataset for Complex Emotions Learning Based on Deep Neural Networks,"Belainine, Billal  and
Sadat, Fatiha  and
Boukadoum, Mounir  and
Lounis, Hakim",2020,Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources,,"In sentiment analysis, several researchers have used emoji and hashtags as specific forms of training and supervision. Some emotions, such as fear and disgust, are underrepresented in the text of social media. Others, such as anticipation, are absent. This research paper proposes a new dataset for complex emotion detection using a combination of several existing corpora in order to represent and interpret complex emotions based on the Plutchik{'}s theory. Our experiments and evaluations confirm that using Transfer Learning (TL) with a rich emotional corpus, facilitates the detection of complex emotions in a four-dimensional space. In addition, the incorporation of the rule on the reverse emotions in the model{'}s architecture brings a significant improvement in terms of precision, recall, and F-score.",https://aclanthology.org/2020.lincr-1.7,emotion,Yes,Yes,No
Annotating Errors and Emotions in Human-Chatbot Interactions in {I}talian,"Sanguinetti, Manuela  and
Mazzei, Alessandro  and
Patti, Viviana  and
Scalerandi, Marco  and
Mana, Dario  and
Simeoni, Rossana",2020,Proceedings of the 14th Linguistic Annotation Workshop,,"This paper describes a novel annotation scheme specifically designed for a customer-service context where written interactions take place between a given user and the chatbot of an Italian telecommunication company. More specifically, the scheme aims to detect and highlight two aspects: the presence of errors in the conversation on both sides (i.e. customer and chatbot) and the {``}emotional load{''} of the conversation. This can be inferred from the presence of emotions of some kind (especially negative ones) in the customer messages, and from the possible empathic responses provided by the agent. The dataset annotated according to this scheme is currently used to develop the prototype of a rule-based Natural Language Generation system aimed at improving the chatbot responses and the customer experience overall.",https://aclanthology.org/2020.law-1.14,emotion,Yes,No,No
L{'}expression des {\'e}motions dans les textes pour enfants : constitution d{'}un corpus annot{\'e} (Expressing emotions in texts for children: constitution of an annotated corpus),"{\'E}tienne, Aline  and
Battistelli, Delphine  and
Lecorv{\'e}, Gw{\'e}nol{\'e}",2020,"Actes de la 6e conf{\'e}rence conjointe Journ{\'e}es d'{\'E}tudes sur la Parole (JEP, 33e {\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\'e}dition), Rencontre des {\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\'E}CITAL, 22e {\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",,"Cet article pr{\'e}sente une typologie de divers modes d{'}expression linguistique des {\'e}motions, le sch{\'e}ma d{'}annotation sous Glozz qui impl{\'e}mente cette typologie et un corpus de textes journalistiques pour enfants annot{\'e} {\`a} l{'}aide de ce sch{\'e}ma. Ces travaux pr{\'e}liminaires s{'}ins{\`e}rent dans le contexte d{'}une {\'e}tude relative au d{\'e}veloppement des capacit{\'e}s langagi{\`e}res des enfants, en particulier de leur capacit{\'e} {\`a} comprendre un texte selon des crit{\`e}res {\'e}motionnels.",https://aclanthology.org/2020.jeptalnrecital-taln.19,emotion,Yes,No,No
Annotated Corpus of Tweets in {E}nglish from Various Domains for Emotion Detection,"Ghosh, Soumitra  and
Ekbal, Asif  and
Bhattacharyya, Pushpak  and
Saha, Sriparna  and
Tyagi, Vipin  and
Kumar, Alka  and
Srivastava, Shikha  and
Kumar, Nitish",2020,Proceedings of the 17th International Conference on Natural Language Processing (ICON),,"Emotion recognition is a very well-attended problem in Natural Language Processing (NLP). Most of the existing works on emotion recognition focus on the general domain and in some cases to specific domains like fairy tales, blogs, weather, Twitter etc. But emotion analysis systems in the domains of security, social issues, technology, politics, sports, etc. are very rare. In this paper, we create a benchmark setup for emotion recognition in these specialised domains. First, we construct a corpus of 18,921 tweets in English annotated with Paul Ekman{'}s six basic emotions (Anger, Disgust, Fear, Happiness, Sadness, Surprise) and a non-emotive class Others. Thereafter, we propose a deep neural framework to perform emotion recognition in an end-to-end setting. We build various models based on Convolutional Neural Network (CNN), Bi-directional Long Short Term Memory (Bi-LSTM), Bi-directional Gated Recurrent Unit (Bi-GRU). We propose a Hierarchical Attention-based deep neural network for Emotion Detection (HAtED). We also develop multiple systems by considering different sets of emotion classes for each system and report the detailed comparative analysis of the results. Experiments show the hierarchical attention-based model achieves best results among the considered baselines with accuracy of 69{\%}.",https://aclanthology.org/2020.icon-main.62,emotion,Yes,Yes,Yes
{EST}e{R}: Combining Word Co-occurrences and Word Associations for Unsupervised Emotion Detection,"Gollapalli, Sujatha Das  and
Rozenshtein, Polina  and
Ng, See-Kiong",2020,Findings of the Association for Computational Linguistics: EMNLP 2020,10.18653/v1/2020.findings-emnlp.93,"Accurate detection of emotions in user- generated text was shown to have several applications for e-commerce, public well-being, and disaster management. Currently, the state-of-the-art performance for emotion detection in text is obtained using complex, deep learning models trained on domain-specific, labeled data. In this paper, we propose ESTeR , an unsupervised model for identifying emotions using a novel similarity function based on random walks on graphs. Our model combines large-scale word co-occurrence information with word-associations from lexicons avoiding not only the dependence on labeled datasets, but also an explicit mapping of words to latent spaces used in emotion-enriched word embeddings. Our similarity function can also be computed efficiently. We study a range of datasets including recent tweets related to COVID-19 to illustrate the superior performance of our model and report insights on public emotions during the on-going pandemic.",https://aclanthology.org/2020.findings-emnlp.93,emotion,Yes,Yes,No
Condolence and Empathy in Online Communities,"Zhou, Naitian  and
Jurgens, David",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.45,"Offering condolence is a natural reaction to hearing someone{'}s distress. Individuals frequently express distress in social media, where some communities can provide support. However, not all condolence is equal{---}trite responses offer little actual support despite their good intentions. Here, we develop computational tools to create a massive dataset of 11.4M expressions of distress and 2.8M corresponding offerings of condolence in order to examine the dynamics of condolence online. Our study reveals widespread disparity in what types of distress receive supportive condolence rather than just engagement. Building on studies from social psychology, we analyze the language of condolence and develop a new dataset for quantifying the empathy in a condolence using appraisal theory. Finally, we demonstrate that the features of condolence individuals find most helpful online differ substantially in their features from those seen in interpersonal settings.",https://aclanthology.org/2020.emnlp-main.45,empathy,Yes,No,No
"Hashtags, Emotions, and Comments: A Large-Scale Dataset to Understand Fine-Grained Social Emotions to Online Topics","Ding, Keyang  and
Li, Jing  and
Zhang, Yuji",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.106,"This paper studies social emotions to online discussion topics. While most prior work focus on emotions from writers, we investigate readers{'} responses and explore the public feelings to an online topic. A large-scale dataset is collected from Chinese microblog Sina Weibo with over 13 thousand trending topics, emotion votes in 24 fine-grained types from massive participants, and user comments to allow context understanding. In experiments, we examine baseline performance to predict a topic{'}s possible social emotions in a multilabel classification setting. The results show that a seq2seq model with user comment modeling performs the best, even surpassing human prediction. More analyses shed light on the effects of emotion types, topic description lengths, contexts from user comments, and the limited capacity of the existing models.",https://aclanthology.org/2020.emnlp-main.106,emotion,Yes,Yes,No
Conditional Causal Relationships between Emotions and Causes in Texts,"Chen, Xinhong  and
Li, Qing  and
Wang, Jianping",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.252,"The causal relationships between emotions and causes in text have recently received a lot of attention. Most of the existing works focus on the extraction of the causally related clauses from documents. However, none of these works has considered the possibility that the causal relationships among the extracted emotion and cause clauses may only be valid under a specific context, without which the extracted clauses may not be causally related. To address such an issue, we propose a new task of determining whether or not an input pair of emotion and cause has a valid causal relationship under different contexts, and construct a corresponding dataset via manual annotation and negative sampling based on an existing benchmark dataset. Furthermore, we propose a prediction aggregation module with low computational overhead to fine-tune the prediction results based on the characteristics of the input clauses. Experiments demonstrate the effectiveness and generality of our aggregation module.",https://aclanthology.org/2020.emnlp-main.252,emotion,Yes,No,No
Emotion-Cause Pair Extraction as Sequence Labeling Based on A Novel Tagging Scheme,"Yuan, Chaofa  and
Fan, Chuang  and
Bao, Jianzhu  and
Xu, Ruifeng",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.289,"The task of emotion-cause pair extraction deals with finding all emotions and the corresponding causes in unannotated emotion texts. Most recent studies are based on the likelihood of Cartesian product among all clause candidates, resulting in a high computational cost. Targeting this issue, we regard the task as a sequence labeling problem and propose a novel tagging scheme with coding the distance between linked components into the tags, so that emotions and the corresponding causes can be extracted simultaneously. Accordingly, an end-to-end model is presented to process the input texts from left to right, always with linear time complexity, leading to a speed up. Experimental results show that our proposed model achieves the best performance, outperforming the state-of-the-art method by 2.26{\%} (p{\textless}0.001) in F1 measure.",https://aclanthology.org/2020.emnlp-main.289,emotion,No,Yes,No
End-to-End Emotion-Cause Pair Extraction based on Sliding Window Multi-Label Learning,"Ding, Zixiang  and
Xia, Rui  and
Yu, Jianfei",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.290,"Emotion-cause pair extraction (ECPE) is a new task that aims to extract the potential pairs of emotions and their corresponding causes in a document. The existing methods first perform emotion extraction and cause extraction independently, and then perform emotion-cause pairing and filtering. However, the above methods ignore the fact that the cause and the emotion it triggers are inseparable, and the extraction of the cause without specifying the emotion is pathological, which greatly limits the performance of the above methods in the first step. To tackle these shortcomings, we propose two joint frameworks for ECPE: 1) multi-label learning for the extraction of the cause clauses corresponding to the specified emotion clause (CMLL) and 2) multi-label learning for the extraction of the emotion clauses corresponding to the specified cause clause (EMLL). The window of multi-label learning is centered on the specified emotion clause or cause clause and slides as their positions move. Finally, CMLL and EMLL are integrated to obtain the final result. We evaluate our model on a benchmark emotion cause corpus, the results show that our approach achieves the best performance among all compared systems on the ECPE task.",https://aclanthology.org/2020.emnlp-main.290,emotion,Yes,Yes,No
Multi-modal Multi-label Emotion Detection with Modality and Label Dependence,"Zhang, Dong  and
Ju, Xincheng  and
Li, Junhui  and
Li, Shoushan  and
Zhu, Qiaoming  and
Zhou, Guodong",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.291,"As an important research issue in the natural language processing community, multi-label emotion detection has been drawing more and more attention in the last few years. However, almost all existing studies focus on one modality (e.g., textual modality). In this paper, we focus on multi-label emotion detection in a multi-modal scenario. In this scenario, we need to consider both the dependence among different labels (label dependence) and the dependence between each predicting label and different modalities (modality dependence). Particularly, we propose a multi-modal sequence-to-set approach to effectively model both kinds of dependence in multi-modal multi-label emotion detection. The detailed evaluation demonstrates the effectiveness of our approach.",https://aclanthology.org/2020.emnlp-main.291,emotion,No,Yes,Yes
A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support,"Sharma, Ashish  and
Miner, Adam  and
Atkins, David  and
Althoff, Tim",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.425,"Empathy is critical to successful mental health support. Empathy measurement has predominantly occurred in synchronous, face-to-face settings, and may not translate to asynchronous, text-based contexts. Because millions of people use text-based platforms for mental health support, understanding empathy in these contexts is crucial. In this work, we present a computational approach to understanding how empathy is expressed in online mental health platforms. We develop a novel unifying theoretically-grounded framework for characterizing the communication of empathy in text-based conversations. We collect and share a corpus of 10k (post, response) pairs annotated using this empathy framework with supporting evidence for annotations (rationales). We develop a multi-task RoBERTa-based bi-encoder model for identifying empathy in conversations and extracting rationales underlying its predictions. Experiments demonstrate that our approach can effectively identify empathic conversations. We further apply this model to analyze 235k mental health interactions and show that users do not self-learn empathy over time, revealing opportunities for empathy training and feedback.",https://aclanthology.org/2020.emnlp-main.425,empathy,Yes,Yes,No
Modeling Protagonist Emotions for Emotion-Aware Storytelling,"Brahman, Faeze  and
Chaturvedi, Snigdha",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.426,"Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (EmoSup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.",https://aclanthology.org/2020.emnlp-main.426,emotion,No,Yes,No
Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations,"Ishiwatari, Taichi  and
Yasuda, Yuki  and
Miyazaki, Taro  and
Goto, Jun",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.597,"Interest in emotion recognition in conversations (ERC) has been increasing in various fields, because it can be used to analyze user behaviors and detect fake news. Many recent ERC methods use graph-based neural networks to take the relationships between the utterances of the speakers into account. In particular, the state-of-the-art method considers self- and inter-speaker dependencies in conversations by using relational graph attention networks (RGAT). However, graph-based neural networks do not take sequential information into account. In this paper, we propose relational position encodings that provide RGAT with sequential information reflecting the relational graph structure. Accordingly, our RGAT model can capture both the speaker dependency and the sequential information. Experiments on four ERC datasets show that our model is beneficial to recognizing emotions expressed in conversations. In addition, our approach empirically outperforms the state-of-the-art on all of the benchmark datasets.",https://aclanthology.org/2020.emnlp-main.597,emotion,Yes,Yes,No
{C}ancer{E}mo: A Dataset for Fine-Grained Emotion Detection,"Sosea, Tiberiu  and
Caragea, Cornelia",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.715,"Emotions are an important element of human nature, often affecting the overall wellbeing of a person. Therefore, it is no surprise that the health domain is a valuable area of interest for emotion detection, as it can provide medical staff or caregivers with essential information about patients. However, progress on this task has been hampered by the absence of large labeled datasets. To this end, we introduce CancerEmo, an emotion dataset created from an online health community and annotated with eight fine-grained emotions. We perform a comprehensive analysis of these emotions and develop deep learning models on the newly created dataset. Our best BERT model achieves an average F1 of 71{\%}, which we improve further using domain-specific pre-training.",https://aclanthology.org/2020.emnlp-main.715,emotion,Yes,Yes,No
{E}mo{T}ag1200: Understanding the Association between Emojis and Emotions,"Shoeb, Abu Awal Md  and
de Melo, Gerard",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.720,"Given the growing ubiquity of emojis in language, there is a need for methods and resources that shed light on their meaning and communicative role. One conspicuous aspect of emojis is their use to convey affect in ways that may otherwise be non-trivial to achieve. In this paper, we seek to explore the connection between emojis and emotions by means of a new dataset consisting of human-solicited association ratings. We additionally conduct experiments to assess to what extent such associations can be inferred from existing data in an unsupervised manner. Our experiments show that this succeeds when high-quality word-level information is available.",https://aclanthology.org/2020.emnlp-main.720,emotion,Yes,Yes,No
{MIME}: {MIM}icking Emotions for Empathetic Response Generation,"Majumder, Navonil  and
Hong, Pengfei  and
Peng, Shanshan  and
Lu, Jiankun  and
Ghosal, Deepanway  and
Gelbukh, Alexander  and
Mihalcea, Rada  and
Poria, Soujanya",2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),10.18653/v1/2020.emnlp-main.721,"Current approaches to empathetic response generation view the set of emotions expressed in the input text as a flat structure, where all the emotions are treated uniformly. We argue that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content. We show that the consideration of these polarity-based emotion clusters and emotional mimicry results in improved empathy and contextual relevance of the response as compared to the state-of-the-art. Also, we introduce stochasticity into the emotion mixture that yields emotionally more varied empathetic responses than the previous work. We demonstrate the importance of these factors to empathetic response generation using both automatic- and human-based evaluations. The implementation of MIME is publicly available at \url{https://github.com/declare-lab/MIME}.",https://aclanthology.org/2020.emnlp-main.721,emotion,No,No,No
Appraisal Theories for Emotion Classification in Text,"Hofmann, Jan  and
Troiano, Enrica  and
Sassenberg, Kai  and
Klinger, Roman",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.11,"Automatic emotion categorization has been predominantly formulated as text classification in which textual units are assigned to an emotion from a predefined inventory, for instance following the fundamental emotion classes proposed by Paul Ekman (fear, joy, anger, disgust, sadness, surprise) or Robert Plutchik (adding trust, anticipation). This approach ignores existing psychological theories to some degree, which provide explanations regarding the perception of events. For instance, the description that somebody discovers a snake is associated with fear, based on the appraisal as being an unpleasant and non-controllable situation. This emotion reconstruction is even possible without having access to explicit reports of a subjective feeling (for instance expressing this with the words {``}I am afraid.{''}). Automatic classification approaches therefore need to learn properties of events as latent variables (for instance that the uncertainty and the mental or physical effort associated with the encounter of a snake leads to fear). With this paper, we propose to make such interpretations of events explicit, following theories of cognitive appraisal of events, and show their potential for emotion classification when being encoded in classification models. Our results show that high quality appraisal dimension assignments in event descriptions lead to an improvement in the classification of discrete emotion categories. We make our corpus of appraisal-annotated emotion-associated event descriptions publicly available.",https://aclanthology.org/2020.coling-main.11,emotion,Yes,Yes,No
A Symmetric Local Search Network for Emotion-Cause Pair Extraction,"Cheng, Zifeng  and
Jiang, Zhiwei  and
Yin, Yafeng  and
Yu, Hua  and
Gu, Qing",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.12,"Emotion-cause pair extraction (ECPE) is a new task which aims at extracting the potential clause pairs of emotions and corresponding causes in a document. To tackle this task, a two-step method was proposed by previous study which first extracted emotion clauses and cause clauses individually, then paired the emotion and cause clauses, and filtered out the pairs without causality. Different from this method that separated the detection and the matching of emotion and cause into two steps, we propose a Symmetric Local Search Network (SLSN) model to perform the detection and matching simultaneously by local search. SLSN consists of two symmetric subnetworks, namely the emotion subnetwork and the cause subnetwork. Each subnetwork is composed of a clause representation learner and a local pair searcher. The local pair searcher is a specially-designed cross-subnetwork component which can extract the local emotion-cause pairs. Experimental results on the ECPE corpus demonstrate the superiority of our SLSN over existing state-of-the-art methods.",https://aclanthology.org/2020.coling-main.12,emotion,Yes,Yes,No
End-to-End Emotion-Cause Pair Extraction with Graph Convolutional Network,"Chen, Ying  and
Hou, Wenjun  and
Li, Shoushan  and
Wu, Caicong  and
Zhang, Xiaoqiang",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.17,"Emotion-cause pair extraction (ECPE), which aims at simultaneously extracting emotion-cause pairs that express emotions and their corresponding causes in a document, plays a vital role in understanding natural languages. Considering that most emotions usually have few causes mentioned in their contexts, we present a novel end-to-end Pair Graph Convolutional Network (PairGCN) to model pair-level contexts so that to capture the dependency information among local neighborhood candidate pairs. Moreover, in the graphical network, contexts are grouped into three types and each type of contexts is propagated by its own way. Experiments on a benchmark Chinese emotion-cause pair extraction corpus demonstrate the effectiveness of the proposed model.",https://aclanthology.org/2020.coling-main.17,emotion,Yes,Yes,No
A Unified Sequence Labeling Model for Emotion Cause Pair Extraction,"Chen, Xinhong  and
Li, Qing  and
Wang, Jianping",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.18,"Emotion-cause pair extraction (ECPE) aims at extracting emotions and causes as pairs from documents, where each pair contains an emotion clause and a set of cause clauses. Existing approaches address the task by first extracting emotion and cause clauses via two binary classifiers separately, and then training another binary classifier to pair them up. However, the extracted emotion-cause pairs of different emotion types cannot be distinguished from each other through simple binary classifiers, which limits the applicability of the existing approaches. Moreover, such two-step approaches may suffer from possible cascading errors. In this paper, to address the first problem, we assign emotion type labels to emotion and cause clauses so that emotion-cause pairs of different emotion types can be easily distinguished. As for the second problem, we reformulate the ECPE task as a unified sequence labeling task, which can extract multiple emotion-cause pairs in an end-to-end fashion. We propose an approach composed of a convolution neural network for encoding neighboring information and two Bidirectional Long-Short Term Memory networks for two auxiliary tasks. Experiment results demonstrate the feasibility and effectiveness of our approaches.",https://aclanthology.org/2020.coling-main.18,emotion,No,Yes,No
Emotion Classification by Jointly Learning to Lexiconize and Classify,"Zhou, Deyu  and
Wu, Shuangzhi  and
Wang, Qing  and
Xie, Jun  and
Tu, Zhaopeng  and
Li, Mu",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.288,"Emotion lexicons have been shown effective for emotion classification (Baziotis et al., 2018). Previous studies handle emotion lexicon construction and emotion classification separately. In this paper, we propose an emotional network (EmNet) to jointly learn sentence emotions and construct emotion lexicons which are dynamically adapted to a given context. The dynamic emotion lexicons are useful for handling words with multiple emotions based on different context, which can effectively improve the classification accuracy. We validate the approach on two representative architectures {--} LSTM and BERT, demonstrating its superiority on identifying emotions in Tweets. Our model outperforms several approaches proposed in previous studies and achieves new state-of-the-art on the benchmark Twitter dataset.",https://aclanthology.org/2020.coling-main.288,emotion,Yes,Yes,No
An Iterative Emotion Interaction Network for Emotion Recognition in Conversations,"Lu, Xin  and
Zhao, Yanyan  and
Wu, Yang  and
Tian, Yijian  and
Chen, Huipeng  and
Qin, Bing",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.360,"Emotion recognition in conversations (ERC) has received much attention recently in the natural language processing community. Considering that the emotions of the utterances in conversations are interactive, previous works usually implicitly model the emotion interaction between utterances by modeling dialogue context, but the misleading emotion information from context often interferes with the emotion interaction. We noticed that the gold emotion labels of the context utterances can provide explicit and accurate emotion interaction, but it is impossible to input gold labels at inference time. To address this problem, we propose an iterative emotion interaction network, which uses iteratively predicted emotion labels instead of gold emotion labels to explicitly model the emotion interaction. This approach solves the above problem, and can effectively retain the performance advantages of explicit modeling. We conduct experiments on two datasets, and our approach achieves state-of-the-art performance.",https://aclanthology.org/2020.coling-main.360,emotion,No,Yes,Yes
Summarize before Aggregate: A Global-to-local Heterogeneous Graph Inference Network for Conversational Emotion Recognition,"Sheng, Dongming  and
Wang, Dong  and
Shen, Ying  and
Zheng, Haitao  and
Liu, Haozhuang",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.367,"Conversational Emotion Recognition (CER) is a crucial task in Natural Language Processing (NLP) with wide applications. Prior works in CER generally focus on modeling emotion influences solely with utterance-level features, with little attention paid on phrase-level semantic connection between utterances. Phrases carry sentiments when they are referred to emotional events under certain topics, providing a global semantic connection between utterances throughout the entire conversation. In this work, we propose a two-stage Summarization and Aggregation Graph Inference Network (SumAggGIN), which seamlessly integrates inference for topic-related emotional phrases and local dependency reasoning over neighbouring utterances in a global-to-local fashion. Topic-related emotional phrases, which constitutes the global topic-related emotional connections, are recognized by our proposed heterogeneous Summarization Graph. Local dependencies, which captures short-term emotional effects between neighbouring utterances, are further injected via an Aggregation Graph to distinguish the subtle differences between utterances containing emotional phrases. The two steps of graph inference are tightly-coupled for a comprehensively understanding of emotional fluctuation. Experimental results on three CER benchmark datasets verify the effectiveness of our proposed model, which outperforms the state-of-the-art approaches.",https://aclanthology.org/2020.coling-main.367,emotion,Yes,Yes,Yes
{H}i{T}rans: A Transformer-Based Context- and Speaker-Sensitive Model for Emotion Detection in Conversations,"Li, Jingye  and
Ji, Donghong  and
Li, Fei  and
Zhang, Meishan  and
Liu, Yijiang",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.370,"Emotion detection in conversations (EDC) is to detect the emotion for each utterance in conversations that have multiple speakers. Different from the traditional non-conversational emotion detection, the model for EDC should be context-sensitive (e.g., understanding the whole conversation rather than one utterance) and speaker-sensitive (e.g., understanding which utterance belongs to which speaker). In this paper, we propose a transformer-based context- and speaker-sensitive model for EDC, namely HiTrans, which consists of two hierarchical transformers. We utilize BERT as the low-level transformer to generate local utterance representations, and feed them into another high-level transformer so that utterance representations could be sensitive to the global context of the conversation. Moreover, we exploit an auxiliary task to make our model speaker-sensitive, called pairwise utterance speaker verification (PUSV), which aims to classify whether two utterances belong to the same speaker. We evaluate our model on three benchmark datasets, namely EmoryNLP, MELD and IEMOCAP. Results show that our model outperforms previous state-of-the-art models.",https://aclanthology.org/2020.coling-main.370,emotion,Yes,Yes,No
Lost in Back-Translation: Emotion Preservation in Neural Machine Translation,"Troiano, Enrica  and
Klinger, Roman  and
Pad{\'o}, Sebastian",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.384,"Machine translation provides powerful methods to convert text between languages, and is therefore a technology enabling a multilingual world. An important part of communication, however, takes place at the non-propositional level (e.g., politeness, formality, emotions), and it is far from clear whether current MT methods properly translate this information. This paper investigates the specific hypothesis that the non-propositional level of emotions is at least partially lost in MT. We carry out a number of experiments in a back-translation setup and establish that (1) emotions are indeed partially lost during translation; (2) this tendency can be reversed almost completely with a simple re-ranking approach informed by an emotion classifier, taking advantage of diversity in the n-best list; (3) the re-ranking approach can also be applied to change emotions, obtaining a model for emotion style transfer. An in-depth qualitative analysis reveals that there are recurring linguistic changes through which emotions are toned down or amplified, such as change of modality.",https://aclanthology.org/2020.coling-main.384,emotion,No,Yes,No
Knowledge Aware Emotion Recognition in Textual Conversations via Multi-Task Incremental Transformer,"Zhang, Duzhen  and
Chen, Xiuyi  and
Xu, Shuang  and
Xu, Bo",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.392,"Emotion recognition in textual conversations (ERTC) plays an important role in a wide range of applications, such as opinion mining, recommender systems, and so on. ERTC, however, is a challenging task. For one thing, speakers often rely on the context and commonsense knowledge to express emotions; for another, most utterances contain neutral emotion in conversations, as a result, the confusion between a few non-neutral utterances and much more neutral ones restrains the emotion recognition performance. In this paper, we propose a novel Knowledge Aware Incremental Transformer with Multi-task Learning (KAITML) to address these challenges. Firstly, we devise a dual-level graph attention mechanism to leverage commonsense knowledge, which augments the semantic information of the utterance. Then we apply the Incremental Transformer to encode multi-turn contextual utterances. Moreover, we are the first to introduce multi-task learning to alleviate the aforementioned confusion and thus further improve the emotion recognition performance. Extensive experimental results show that our KAITML model outperforms the state-of-the-art models across five benchmark datasets.",https://aclanthology.org/2020.coling-main.392,emotion,Yes,Yes,No
"{MEISD}: A Multimodal Multi-Label Emotion, Intensity and Sentiment Dialogue Dataset for Emotion Recognition and Sentiment Analysis in Conversations","Firdaus, Mauajama  and
Chauhan, Hardik  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.393,"Emotion and sentiment classification in dialogues is a challenging task that has gained popularity in recent times. Humans tend to have multiple emotions with varying intensities while expressing their thoughts and feelings. Emotions in an utterance of dialogue can either be independent or dependent on the previous utterances, thus making the task complex and interesting. Multi-label emotion detection in conversations is a significant task that provides the ability to the system to understand the various emotions of the users interacting. Sentiment analysis in dialogue/conversation, on the other hand, helps in understanding the perspective of the user with respect to the ongoing conversation. Along with text, additional information in the form of audio and video assist in identifying the correct emotions with the appropriate intensity and sentiments in an utterance of a dialogue. Lately, quite a few datasets have been made available for dialogue emotion and sentiment classification, but these datasets are imbalanced in representing different emotions and consist of an only single emotion. Hence, we present at first a large-scale balanced Multimodal Multi-label Emotion, Intensity, and Sentiment Dialogue dataset (MEISD), collected from different TV series that has textual, audio and visual features, and then establish a baseline setup for further research.",https://aclanthology.org/2020.coling-main.393,emotion,Yes,Yes,No
Sentiment Analysis for Emotional Speech Synthesis in a News Dialogue System,"Takatsu, Hiroaki  and
Ando, Ryota  and
Matsuyama, Yoichi  and
Kobayashi, Tetsunori",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.440,"As smart speakers and conversational robots become ubiquitous, the demand for expressive speech synthesis has increased. In this paper, to control the emotional parameters of the speech synthesis according to certain dialogue contents, we construct a news dataset with emotion labels ({``}positive,{''} {``}negative,{''} or {``}neutral{''}) annotated for each sentence. We then propose a method to identify emotion labels using a model combining BERT and BiLSTM-CRF, and evaluate its effectiveness using the constructed dataset. The results showed that the classification model performance can be efficiently improved by preferentially annotating news articles with low confidence in the human-in-the-loop machine learning framework.",https://aclanthology.org/2020.coling-main.440,emotion,Yes,Yes,No
Exploiting Narrative Context and A Priori Knowledge of Categories in Textual Emotion Classification,"Tanabe, Hikari  and
Ogawa, Tetsuji  and
Kobayashi, Tetsunori  and
Hayashi, Yoshihiko",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.483,"Recognition of the mental state of a human character in text is a major challenge in natural language processing. In this study, we investigate the efficacy of the narrative context in recognizing the emotional states of human characters in text and discuss an approach to make use of a priori knowledge regarding the employed emotion category system. Specifically, we experimentally show that the accuracy of emotion classification is substantially increased by encoding the preceding context of the target sentence using a BERT-based text encoder. We also compare ways to incorporate a priori knowledge of emotion categories by altering the loss function used in training, in which our proposal of multi-task learning that jointly learns to classify positive/negative polarity of emotions is included. The experimental results suggest that, when using Plutchik{'}s Wheel of Emotions, it is better to jointly classify the basic emotion categories with positive/negative polarity rather than directly exploiting its characteristic structure in which eight basic categories are arranged in a wheel.",https://aclanthology.org/2020.coling-main.483,emotion,No,Yes,Yes
Cross-Lingual Emotion Lexicon Induction using Representation Alignment in Low-Resource Settings,"Ramachandran, Arun  and
de Melo, Gerard",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.517,"Emotion lexicons provide information about associations between words and emotions. They have proven useful in analyses of reviews, literary texts, and posts on social media, among other things. We evaluate the feasibility of deriving emotion lexicons cross-lingually, especially for low-resource languages, from existing emotion lexicons in resource-rich languages. For this, we start out from very small corpora to induce cross-lingually aligned vector spaces. Our study empirically analyses the effectiveness of the induced emotion lexicons by measuring translation precision and correlations with existing emotion lexicons, along with measurements on a downstream task of sentence emotion prediction.",https://aclanthology.org/2020.coling-main.517,emotion,No,No,No
{XED}: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,"{\""O}hman, Emily  and
P{\`a}mies, Marc  and
Kajava, Kaisla  and
Tiedemann, J{\""o}rg",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.575,"We introduce XED, a multilingual fine-grained emotion dataset. The dataset consists of human-annotated Finnish (25k) and English sentences (30k), as well as projected annotations for 30 additional languages, providing new resources for many low-resource languages. We use Plutchik{'}s core emotions to annotate the dataset with the addition of neutral to create a multilabel multiclass dataset. The dataset is carefully evaluated using language-specific BERT models and SVMs to show that XED performs on par with other similar datasets and is therefore a useful tool for sentiment analysis and emotion detection.",https://aclanthology.org/2020.coling-main.575,emotion,Yes,Yes,No
Creation of Corpus and analysis in Code-Mixed {K}annada-{E}nglish {T}witter data for Emotion Prediction,"Appidi, Abhinav Reddy  and
Srirangam, Vamshi Krishna  and
Suhas, Darsi  and
Shrivastava, Manish",2020,Proceedings of the 28th International Conference on Computational Linguistics,10.18653/v1/2020.coling-main.587,"Emotion prediction is a critical task in the field of Natural Language Processing (NLP). There has been a significant amount of work done in emotion prediction for resource-rich languages. There has been work done on code-mixed social media corpus but not on emotion prediction of Kannada-English code-mixed Twitter data. In this paper, we analyze the problem of emotion prediction on corpus obtained from code-mixed Kannada-English extracted from Twitter annotated with their respective {`}Emotion{'} for each tweet. We experimented with machine learning prediction models using features like Character N-Grams, Word N-Grams, Repetitive characters, and others on SVM and LSTM on our corpus, which resulted in an accuracy of 30{\%} and 32{\%} respectively.",https://aclanthology.org/2020.coling-main.587,emotion,Yes,Yes,Yes
A Transformer-based joint-encoding for Emotion Recognition and Sentiment Analysis,"Delbrouck, Jean-Benoit  and
Tits, No{\'e}  and
Brousmiche, Mathilde  and
Dupont, St{\'e}phane",2020,Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML),10.18653/v1/2020.challengehml-1.1,"Understanding expressed sentiment and emotions are two crucial factors in human multimodal language. This paper describes a Transformer-based joint-encoding (TBJE) for the task of Emotion Recognition and Sentiment Analysis. In addition to use the Transformer architecture, our approach relies on a modular co-attention and a glimpse layer to jointly encode one or more modalities. The proposed solution has also been submitted to the ACL20: Second Grand-Challenge on Multimodal Language to be evaluated on the CMU-MOSEI dataset. The code to replicate the presented experiments is open-source .",https://aclanthology.org/2020.challengehml-1.1,emotion,Yes,Yes,No
Multilogue-Net: A Context-Aware {RNN} for Multi-modal Emotion Detection and Sentiment Analysis in Conversation,"Shenoy, Aman  and
Sardana, Ashish",2020,Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML),10.18653/v1/2020.challengehml-1.3,"Sentiment Analysis and Emotion Detection in conversation is key in several real-world applications, with an increase in modalities available aiding a better understanding of the underlying emotions. Multi-modal Emotion Detection and Sentiment Analysis can be particularly useful, as applications will be able to use specific subsets of available modalities, as per the available data. Current systems dealing with Multi-modal functionality fail to leverage and capture - the context of the conversation through all modalities, the dependency between the listener(s) and speaker emotional states, and the relevance and relationship between the available modalities. In this paper, we propose an end to end RNN architecture that attempts to take into account all the mentioned drawbacks. Our proposed model, at the time of writing, out-performs the state of the art on a benchmark dataset on a variety of accuracy and regression metrics.",https://aclanthology.org/2020.challengehml-1.3,emotion,Yes,Yes,No
{CAN}-{GRU}: a Hierarchical Model for Emotion Recognition in Dialogue,"Jiang, Ting  and
Xu, Bing  and
Zhao, Tiejun  and
Li, Sheng",2020,Proceedings of the 19th Chinese National Conference on Computational Linguistics,,"Emotion recognition in dialogue systems has gained attention in the field of natural language processing recent years, because it can be applied in opinion mining from public conversational data on social media. In this paper, we propose a hierarchical model to recognize emotions in the dialogue. In the first layer, in order to extract textual features of utterances, we propose a convolutional self-attention network(CAN). Convolution is used to capture n-gram information and attention mechanism is used to obtain the relevant semantic information among words in the utterance. In the second layer, a GRU-based network helps to capture contextual information in the conversation. Furthermore, we discuss the effects of unidirectional and bidirectional networks. We conduct experiments on Friends dataset and EmotionPush dataset. The results show that our proposed model(CAN-GRU) and its variants achieve better performance than baselines.",https://aclanthology.org/2020.ccl-1.102,emotion,Yes,Yes,Yes
Attending the Emotions to Detect Online Abusive Language,"Safi Samghabadi, Niloofar  and
Hatami, Afsheen  and
Shafaei, Mahsa  and
Kar, Sudipta  and
Solorio, Thamar",2020,Proceedings of the Fourth Workshop on Online Abuse and Harms,10.18653/v1/2020.alw-1.10,"In recent years, abusive behavior has become a serious issue in online social networks. In this paper, we present a new corpus for the task of abusive language detection that is collected from a semi-anonymous online platform, and unlike the majority of other available resources, is not created based on a specific list of bad words. We also develop computational models to incorporate emotions into textual cues to improve aggression identification. We evaluate our proposed methods on a set of corpora related to the task and show promising results with respect to abusive language detection.",https://aclanthology.org/2020.alw-1.10,emotion,Yes,Yes,No
Convolutional and Recurrent Neural Networks for Spoken Emotion Recognition,"Keesing, Aaron  and
Watson, Ian  and
Witbrock, Michael",2020,Proceedings of the 18th Annual Workshop of the Australasian Language Technology Association,,"We test four models proposed in the speech emotion recognition (SER) literature on 15 public and academic licensed datasets in speaker-independent cross-validation. Results indicate differences in the performance of the models which is partly dependent on the dataset and features used. We also show that a standard utterance-level feature set still performs competitively with neural models on some datasets. This work serves as a starting point for future model comparisons, in addition to open-sourcing the testing code.",https://aclanthology.org/2020.alta-1.13,emotion,Yes,Yes,No
{CDL}: Curriculum Dual Learning for Emotion-Controllable Response Generation,"Shen, Lei  and
Feng, Yang",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.52,"Emotion-controllable response generation is an attractive and valuable task that aims to make open-domain conversations more empathetic and engaging. Existing methods mainly enhance the emotion expression by adding regularization terms to standard cross-entropy loss and thus influence the training process. However, due to the lack of further consideration of content consistency, the common problem of response generation tasks, safe response, is intensified. Besides, query emotions that can help model the relationship between query and response are simply ignored in previous models, which would further hurt the coherence. To alleviate these problems, we propose a novel framework named Curriculum Dual Learning (CDL) which extends the emotion-controllable response generation to a dual task to generate emotional responses and emotional queries alternatively. CDL utilizes two rewards focusing on emotion and content to improve the duality. Additionally, it applies curriculum learning to gradually generate high-quality responses based on the difficulties of expressing various emotions. Experimental results show that CDL significantly outperforms the baselines in terms of coherence, diversity, and relation to emotion factors.",https://aclanthology.org/2020.acl-main.52,emotion,No,Yes,No
Learning and Evaluating Emotion Lexicons for 91 Languages,"Buechel, Sven  and
R{\""u}cker, Susanna  and
Hahn, Udo",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.112,"Emotion lexicons describe the affective meaning of words and thus constitute a centerpiece for advanced sentiment and emotion analysis. Yet, manually curated lexicons are only available for a handful of languages, leaving most languages of the world without such a precious resource for downstream applications. Even worse, their coverage is often limited both in terms of the lexical units they contain and the emotional variables they feature. In order to break this bottleneck, we here introduce a methodology for creating almost arbitrarily large emotion lexicons for any target language. Our approach requires nothing but a source language emotion lexicon, a bilingual word translation model, and a target language embedding model. Fulfilling these requirements for 91 languages, we are able to generate representationally rich high-coverage lexicons comprising eight emotional variables with more than 100k lexical entries each. We evaluated the automatically generated lexicons against human judgment from 26 datasets, spanning 12 typologically diverse languages, and found that our approach produces results in line with state-of-the-art monolingual approaches to lexicon creation and even surpasses human reliability for some languages and variables. Code and data are available at \url{https://github.com/JULIELab/MEmoLon} archived under DOI 10.5281/zenodo.3779901.",https://aclanthology.org/2020.acl-main.112,emotion,No,Yes,No
"{ECPE}-2{D}: Emotion-Cause Pair Extraction based on Joint Two-Dimensional Representation, Interaction and Prediction","Ding, Zixiang  and
Xia, Rui  and
Yu, Jianfei",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.288,"In recent years, a new interesting task, called emotion-cause pair extraction (ECPE), has emerged in the area of text emotion analysis. It aims at extracting the potential pairs of emotions and their corresponding causes in a document. To solve this task, the existing research employed a two-step framework, which first extracts individual emotion set and cause set, and then pair the corresponding emotions and causes. However, such a pipeline of two steps contains some inherent flaws: 1) the modeling does not aim at extracting the final emotion-cause pair directly; 2) the errors from the first step will affect the performance of the second step. To address these shortcomings, in this paper we propose a new end-to-end approach, called ECPE-Two-Dimensional (ECPE-2D), to represent the emotion-cause pairs by a 2D representation scheme. A 2D transformer module and two variants, window-constrained and cross-road 2D transformers, are further proposed to model the interactions of different emotion-cause pairs. The 2D representation, interaction, and prediction are integrated into a joint framework. In addition to the advantages of joint modeling, the experimental results on the benchmark emotion cause corpus show that our approach improves the F1 score of the state-of-the-art from 61.28{\%} to 68.89{\%}.",https://aclanthology.org/2020.acl-main.288,emotion,Yes,Yes,No
Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction,"Wei, Penghui  and
Zhao, Jiahao  and
Mao, Wenji",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.289,"Emotion-cause pair extraction aims to extract all emotion clauses coupled with their cause clauses from a given document. Previous work employs two-step approaches, in which the first step extracts emotion clauses and cause clauses separately, and the second step trains a classifier to filter out negative pairs. However, such pipeline-style system for emotion-cause pair extraction is suboptimal because it suffers from error propagation and the two steps may not adapt to each other well. In this paper, we tackle emotion-cause pair extraction from a ranking perspective, i.e., ranking clause pair candidates in a document, and propose a one-step neural approach which emphasizes inter-clause modeling to perform end-to-end extraction. It models the interrelations between the clauses in a document to learn clause representations with graph attention, and enhances clause pair representations with kernel-based relative position embedding for effective ranking. Experimental results show that our approach significantly outperforms the current two-step systems, especially in the condition of extracting multiple pairs in one document.",https://aclanthology.org/2020.acl-main.289,emotion,No,Yes,No
Enhancing Cross-target Stance Detection with Transferable Semantic-Emotion Knowledge,"Zhang, Bowen  and
Yang, Min  and
Li, Xutao  and
Ye, Yunming  and
Xu, Xiaofei  and
Dai, Kuai",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.291,"Stance detection is an important task, which aims to classify the attitude of an opinionated text towards a given target. Remarkable success has been achieved when sufficient labeled training data is available. However, annotating sufficient data is labor-intensive, which establishes significant barriers for generalizing the stance classifier to the data with new targets. In this paper, we proposed a Semantic-Emotion Knowledge Transferring (SEKT) model for cross-target stance detection, which uses the external knowledge (semantic and emotion lexicons) as a bridge to enable knowledge transfer across different targets. Specifically, a semantic-emotion heterogeneous graph is constructed from external semantic and emotion lexicons, which is then fed into a graph convolutional network to learn multi-hop semantic connections between words and emotion tags. Then, the learned semantic-emotion graph representation, which serves as prior knowledge bridging the gap between the source and target domains, is fully integrated into the bidirectional long short-term memory (BiLSTM) stance classifier by adding a novel knowledge-aware memory unit to the BiLSTM cell. Extensive experiments on a large real-world dataset demonstrate the superiority of SEKT against the state-of-the-art baseline methods.",https://aclanthology.org/2020.acl-main.291,emotion,Yes,Yes,No
Transition-based Directed Graph Construction for Emotion-Cause Pair Extraction,"Fan, Chuang  and
Yuan, Chaofa  and
Du, Jiachen  and
Gui, Lin  and
Yang, Min  and
Xu, Ruifeng",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.342,"Emotion-cause pair extraction aims to extract all potential pairs of emotions and corresponding causes from unannotated emotion text. Most existing methods are pipelined framework, which identifies emotions and extracts causes separately, leading to a drawback of error propagation. Towards this issue, we propose a transition-based model to transform the task into a procedure of parsing-like directed graph construction. The proposed model incrementally generates the directed graph with labeled edges based on a sequence of actions, from which we can recognize emotions with the corresponding causes simultaneously, thereby optimizing separate subtasks jointly and maximizing mutual benefits of tasks interdependently. Experimental results show that our approach achieves the best performance, outperforming the state-of-the-art methods by 6.71{\%} (p{\textless}0.01) in F1 measure.",https://aclanthology.org/2020.acl-main.342,emotion,Yes,Yes,No
{G}o{E}motions: A Dataset of Fine-Grained Emotions,"Demszky, Dorottya  and
Movshovitz-Attias, Dana  and
Ko, Jeongwoo  and
Cowen, Alan  and
Nemade, Gaurav  and
Ravi, Sujith",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.372,"Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement.",https://aclanthology.org/2020.acl-main.372,emotion,Yes,Yes,No
Joint Modelling of Emotion and Abusive Language Detection,"Rajamanickam, Santhosh  and
Mishra, Pushkar  and
Yannakoudakis, Helen  and
Shutova, Ekaterina",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.394,"The rise of online communication platforms has been accompanied by some undesirable effects, such as the proliferation of aggressive and abusive behaviour online. Aiming to tackle this problem, the natural language processing (NLP) community has experimented with a range of techniques for abuse detection. While achieving substantial success, these methods have so far only focused on modelling the linguistic properties of the comments and the online communities of users, disregarding the emotional state of the users and how this might affect their language. The latter is, however, inextricably linked to abusive behaviour. In this paper, we present the first joint model of emotion and abusive language detection, experimenting in a multi-task learning framework that allows one task to inform the other. Our results demonstrate that incorporating affective features leads to significant improvements in abuse detection performance across datasets.",https://aclanthology.org/2020.acl-main.394,emotion,No,Yes,Yes
"Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis","Chauhan, Dushyant Singh  and
S R, Dhanush  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.401,"In this paper, we hypothesize that sarcasm is closely related to sentiment and emotion, and thereby propose a multi-task deep learning framework to solve all these three problems simultaneously in a multi-modal conversational scenario. We, at first, manually annotate the recently released multi-modal MUStARD sarcasm dataset with sentiment and emotion classes, both implicit and explicit. For multi-tasking, we propose two attention mechanisms, viz. Inter-segment Inter-modal Attention (Ie-Attention) and Intra-segment Inter-modal Attention (Ia-Attention). The main motivation of Ie-Attention is to learn the relationship between the different segments of the sentence across the modalities. In contrast, Ia-Attention focuses within the same segment of the sentence across the modalities. Finally, representations from both the attentions are concatenated and shared across the five classes (i.e., sarcasm, implicit sentiment, explicit sentiment, implicit emotion, explicit emotion) for multi-tasking. Experimental results on the extended version of the MUStARD dataset show the efficacy of our proposed approach for sarcasm detection over the existing state-of-the-art systems. The evaluation also shows that the proposed multi-task framework yields better performance for the primary task, i.e., sarcasm detection, with the help of two secondary tasks, emotion and sentiment analysis.",https://aclanthology.org/2020.acl-main.401,emotion,Yes,Yes,No
Towards Emotion-aided Multi-modal Dialogue Act Classification,"Saha, Tulika  and
Patra, Aditya  and
Saha, Sriparna  and
Bhattacharyya, Pushpak",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.402,"The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, facial expressions etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by emotions. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of \textit{both} multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset- multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multi-modality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants.",https://aclanthology.org/2020.acl-main.402,emotion,Yes,Yes,No
Modeling Label Semantics for Predicting Emotional Reactions,"Gaonkar, Radhika  and
Kwon, Heeyoung  and
Bastan, Mohaddeseh  and
Balasubramanian, Niranjan  and
Chambers, Nathanael",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.426,"Predicting how events induce emotions in the characters of a story is typically seen as a standard multi-label classification task, which usually treats labels as anonymous classes to predict. They ignore information that may be conveyed by the emotion labels themselves. We propose that the semantics of emotion labels can guide a model{'}s attention when representing the input story. Further, we observe that the emotions evoked by an event are often related: an event that evokes joy is unlikely to also evoke sadness. In this work, we explicitly model label classes via label embeddings, and add mechanisms that track label-label correlations both during training and inference. We also introduce a new semi-supervision strategy that regularizes for the correlations on unlabeled data. Our empirical evaluations show that modeling label semantics yields consistent benefits, and we advance the state-of-the-art on an emotion inference task.",https://aclanthology.org/2020.acl-main.426,emotion,No,Yes,No
Detecting Perceived Emotions in Hurricane Disasters,"Desai, Shrey  and
Caragea, Cornelia  and
Li, Junyi Jessy",2020,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/2020.acl-main.471,"Natural disasters (e.g., hurricanes) affect millions of people each year, causing widespread destruction in their wake. People have recently taken to social media websites (e.g., Twitter) to share their sentiments and feelings with the larger community. Consequently, these platforms have become instrumental in understanding and perceiving emotions at scale. In this paper, we introduce HurricaneEmo, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarse-grained emotion groups. Our best BERT model, even after task-guided pre-training which leverages unlabeled Twitter data, achieves only 68{\%} accuracy (averaged across all groups). HurricaneEmo serves not only as a challenging benchmark for models but also as a valuable resource for analyzing emotions in disaster-centric domains.",https://aclanthology.org/2020.acl-main.471,emotion,Yes,Yes,No
{FERN}et: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues,"Guo, Yingmei  and
Wu, Zhiyong  and
Xu, Mingxing",2020,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,,"Unlike non-conversation scenes, emotion recognition in dialogues (ERD) poses more complicated challenges due to its interactive nature and intricate contextual information. All present methods model historical utterances without considering the content of the target utterance. However, different parts of a historical utterance may contribute differently to emotion inference of different target utterances. Therefore we propose Fine-grained Extraction and Reasoning Network (FERNet) to generate target-specific historical utterance representations. The reasoning module effectively handles both local and global sequential dependencies to reason over context, and updates target utterance representations to more informed vectors. Experiments on two benchmarks show that our method achieves competitive performance compared with previous methods.",https://aclanthology.org/2020.aacl-main.5,emotion,No,Yes,No
Modality-Transferable Emotion Embeddings for Low-Resource Multimodal Emotion Recognition,"Dai, Wenliang  and
Liu, Zihan  and
Yu, Tiezheng  and
Fung, Pascale",2020,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,,"Despite the recent achievements made in the multi-modal emotion recognition task, two problems still exist and have not been well investigated: 1) the relationship between different emotion categories are not utilized, which leads to sub-optimal performance; and 2) current models fail to cope well with low-resource emotions, especially for unseen emotions. In this paper, we propose a modality-transferable model with emotion embeddings to tackle the aforementioned issues. We use pre-trained word embeddings to represent emotion categories for textual data. Then, two mapping functions are learned to transfer these embeddings into visual and acoustic spaces. For each modality, the model calculates the representation distance between the input sequence and target emotions and makes predictions based on the distances. By doing so, our model can directly adapt to the unseen emotions in any modality since we have their pre-trained embeddings and modality mapping functions. Experiments show that our model achieves state-of-the-art performance on most of the emotion categories. Besides, our model also outperforms existing baselines in the zero-shot and few-shot scenarios for unseen emotions.",https://aclanthology.org/2020.aacl-main.30,emotion,No,Yes,No
Prediction of User Emotion and Dialogue Success Using Audio Spectrograms and Convolutional Neural Networks,"Lykartsis, Athanasios  and
Kotti, Margarita",2019,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,10.18653/v1/W19-5939,"In this paper we aim to predict dialogue success and user satisfaction as well as emotion on a turn level. To achieve this, we investigate the use of spectrogram representations, extracted from audio files, in combination with several types of convolutional neural networks. The experiments were performed on the Let{'}s Go V2 database, comprising 5065 audio files and having labels for subjective and objective dialogue turn success, as well as the emotional state of the user. Results show that by using only audio, it is possible to predict turn success with very high accuracy for all three labels (90{\%}). The best performing input representation were 1s long mel-spectrograms in combination with a CNN with a bottleneck architecture. The resulting system has the potential to be used real-time. Our results significantly surpass the state of the art for dialogue success prediction based only on audio.",https://aclanthology.org/W19-5939,emotion,No,Yes,No
An Analysis of Emotion Communication Channels in Fan-Fiction: Towards Emotional Storytelling,"Kim, Evgeny  and
Klinger, Roman",2019,Proceedings of the Second Workshop on Storytelling,10.18653/v1/W19-3406,"Centrality of emotion for the stories told by humans is underpinned by numerous studies in literature and psychology. The research in automatic storytelling has recently turned towards emotional storytelling, in which characters{'} emotions play an important role in the plot development (Theune et al., 2004; y Perez, 2007; Mendez et al., 2016). However, these studies mainly use emotion to generate propositional statements in the form {``}A feels affection towards B{''} or {``}A confronts B{''}. At the same time, emotional behavior does not boil down to such propositional descriptions, as humans display complex and highly variable patterns in communicating their emotions, both verbally and non-verbally. In this paper, we analyze how emotions are expressed non-verbally in a corpus of fan fiction short stories. Our analysis shows that stories written by humans convey character emotions along various non-verbal channels. We find that some non-verbal channels, such as facial expressions and voice characteristics of the characters, are more strongly associated with joy, while gestures and body postures are more likely to occur with trust. Based on our analysis, we argue that automatic storytelling systems should take variability of emotion into account when generating descriptions of characters{'} emotions.",https://aclanthology.org/W19-3406,emotion,Yes,No,No
Modeling Word Emotion in Historical Language: Quantity Beats Supposed Stability in Seed Word Selection,"Hellrich, Johannes  and
Buechel, Sven  and
Hahn, Udo",2019,"Proceedings of the 3rd Joint {SIGHUM} Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",10.18653/v1/W19-2501,"To understand historical texts, we must be aware that language{---}including the emotional connotation attached to words{---}changes over time. In this paper, we aim at estimating the emotion which is associated with a given word in former language stages of English and German. Emotion is represented following the popular Valence-Arousal-Dominance (VAD) annotation scheme. While being more expressive than polarity alone, existing word emotion induction methods are typically not suited for addressing it. To overcome this limitation, we present adaptations of two popular algorithms to VAD. To measure their effectiveness in diachronic settings, we present the first gold standard for historical word emotions, which was created by scholars with proficiency in the respective language stages and covers both English and German. In contrast to claims in previous work, our findings indicate that hand-selecting small sets of seed words with supposedly stable emotional meaning is actually harm- rather than helpful.",https://aclanthology.org/W19-2501,emotion,No,Yes,No
Exploring Fine-Tuned Embeddings that Model Intensifiers for Emotion Analysis,"Bostan, Laura Ana Maria  and
Klinger, Roman",2019,"Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W19-1304,"Adjective phrases like {``}a little bit surprised{''}, {``}completely shocked{''}, or {``}not stunned at all{''} are not handled properly by current state-of-the-art emotion classification and intensity prediction systems. Based on this finding, we analyze differences between embeddings used by these systems in regard to their capability of handling such cases and argue that intensifiers in context of emotion words need special treatment, as is established for sentiment polarity classification, but not for more fine-grained emotion prediction. To resolve this issue, we analyze different aspects of a post-processing pipeline which enriches the word representations of such phrases. This includes expansion of semantic spaces at the phrase level and sub-word level followed by retrofitting to emotion lexicons. We evaluate the impact of these steps with {`}A La Carte and Bag-of-Substrings extensions based on pretrained GloVe,Word2vec, and fastText embeddings against a crowd-sourced corpus of intensity annotations for tweets containing our focus phrases. We show that the fastText-based models do not gain from handling these specific phrases under inspection. For Word2vec embeddings, we show that our post-processing pipeline improves the results by up to 8{\%} on a novel dataset densly populated with intensifiers while it does not decrease the performance on the established EmoInt dataset.",https://aclanthology.org/W19-1304,emotion,Yes,Yes,No
How do we feel when a robot dies? Emotions expressed on {T}witter before and after hitch{BOT}{'}s destruction,"Fraser, Kathleen C.  and
Zeller, Frauke  and
Smith, David Harris  and
Mohammad, Saif  and
Rudzicz, Frank",2019,"Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W19-1308,"In 2014, a chatty but immobile robot called hitchBOT set out to hitchhike across Canada. It similarly made its way across Germany and the Netherlands, and had begun a trip across the USA when it was destroyed by vandals. In this work, we analyze the emotions and sentiments associated with words in tweets posted before and after hitchBOT{'}s destruction to answer two questions: Were there any differences in the emotions expressed across the different countries visited by hitchBOT? And how did the public react to the demise of hitchBOT? Our analyses indicate that while there were few cross-cultural differences in sentiment towards hitchBOT, there was a significant negative emotional reaction to its destruction, suggesting that people had formed an emotional connection with hitchBOT and perceived its destruction as morally wrong. We discuss potential implications of anthropomorphism and emotional attachment to robots from the perspective of robot ethics.",https://aclanthology.org/W19-1308,emotion,No,No,No
Analyzing Incorporation of Emotion in Emoji Prediction,"Hayati, Shirley Anugrah  and
Muis, Aldrian Obaja",2019,"Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W19-1311,"In this work, we investigate the impact of incorporating emotion classes on the task of predicting emojis from Twitter texts. More specifically, we first show that there is a correlation between the emotion expressed in the text and the emoji choice of Twitter users. Based on this insight we propose a few simple methods to incorporate emotion information in traditional classifiers. Through automatic metrics, human evaluation, and error analysis, we show that the improvement obtained by incorporating emotion is significant and correlate better with human preferences compared to the baseline models. Through the human ratings that we obtained, we also argue for preference metric to better evaluate the usefulness of an emoji prediction system.",https://aclanthology.org/W19-1311,emotion,No,Yes,No
{S}em{E}val-2019 Task 3: {E}mo{C}ontext Contextual Emotion Detection in Text,"Chatterjee, Ankush  and
Narahari, Kedhar Nath  and
Joshi, Meghana  and
Agrawal, Puneet",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2005,"In this paper, we present the SemEval-2019 Task 3 - EmoContext: Contextual Emotion Detection in Text. Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. For instance, as humans, on reading {``}Why don{'}t you ever text me!{''} we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. However, the context of dialogue can prove helpful in detection of the emotion. In this task, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others. To facilitate the participation in this task, textual dialogues from user interaction with a conversational agent were taken and annotated for emotion classes after several data processing steps. A training data set of 30160 dialogues, and two evaluation data sets, Test1 and Test2, containing 2755 and 5509 dialogues respectively were released to the participants. A total of 311 teams made submissions to this task. The final leader-board was evaluated on Test2 data set, and the highest ranked submission achieved 79.59 micro-averaged F1 score. Our analysis of systems submitted to the task indicate that Bi-directional LSTM was the most common choice of neural architecture used, and most of the systems had the best performance for the Sad emotion class, and the worst for the Happy emotion class.",https://aclanthology.org/S19-2005,emotion,Yes,Yes,No
{ANA} at {S}em{E}val-2019 Task 3: Contextual Emotion detection in Conversations through hierarchical {LSTM}s and {BERT},"Huang, Chenyang  and
Trabelsi, Amine  and
Za{\""\i}ane, Osmar",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2006,"This paper describes the system submitted by ANA Team for the SemEval-2019 Task 3: EmoContext. We propose a novel Hierarchi- cal LSTMs for Contextual Emotion Detection (HRLCE) model. It classifies the emotion of an utterance given its conversational con- text. The results show that, in this task, our HRCLE outperforms the most recent state-of- the-art text classification framework: BERT. We combine the results generated by BERT and HRCLE to achieve an overall score of 0.7709 which ranked 5th on the final leader board of the competition among 165 Teams.",https://aclanthology.org/S19-2006,emotion,No,Yes,No
{B}rain{EE} at {S}em{E}val-2019 Task 3: Ensembling Linear Classifiers for Emotion Prediction,"Gratian, Vachagan",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2020,"The paper describes an ensemble of linear perceptrons trained for emotion classification as part of the SemEval-2019 shared-task 3. The model uses a matrix of probabilities to weight the activations of the base-classifiers and makes a final prediction using the sum rule. The base-classifiers are multi-class perceptrons utilizing character and word n-grams, part-of-speech tags and sentiment polarity scores. The results of our experiments indicate that the ensemble outperforms the base-classifiers, but only marginally. In the best scenario our model attains an F-Micro score of 0.672, whereas the base-classifiers attained scores ranging from 0.636 to 0.666.",https://aclanthology.org/S19-2020,emotion,No,Yes,No
{CA}i{RE}{\_}{HKUST} at {S}em{E}val-2019 Task 3: Hierarchical Attention for Dialogue Emotion Classification,"Winata, Genta Indra  and
Madotto, Andrea  and
Lin, Zhaojiang  and
Shin, Jamin  and
Xu, Yan  and
Xu, Peng  and
Fung, Pascale",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2021,"Detecting emotion from dialogue is a challenge that has not yet been extensively surveyed. One could consider the emotion of each dialogue turn to be independent, but in this paper, we introduce a hierarchical approach to classify emotion, hypothesizing that the current emotional state depends on previous latent emotions. We benchmark several feature-based classifiers using pre-trained word and emotion embeddings, state-of-the-art end-to-end neural network models, and Gaussian processes for automatic hyper-parameter search. In our experiments, hierarchical architectures consistently give significant improvements, and our best model achieves a 76.77{\%} F1-score on the test set.",https://aclanthology.org/S19-2021,emotion,Yes,Yes,No
{CECL} at {S}em{E}val-2019 Task 3: Using Surface Learning for Detecting Emotion in Textual Conversations,"Bestgen, Yves",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2022,"This paper describes the system developed by the Centre for English Corpus Linguistics for the SemEval-2019 Task 3: EmoContext. It aimed at classifying the emotion of a user utterance in a textual conversation as happy, sad, angry or other. It is based on a large number of feature types, mainly unigrams and bigrams, which were extracted by a SAS program. The usefulness of the different feature types was evaluated by means of Monte-Carlo resampling tests. As this system does not rest on any deep learning component, which is currently considered as the state-of-the-art approach, it can be seen as a possible point of comparison for such kind of systems.",https://aclanthology.org/S19-2022,emotion,Yes,Yes,No
{CL}a{C} Lab at {S}em{E}val-2019 Task 3: Contextual Emotion Detection Using a Combination of Neural Networks and {SVM},"Mohammadi, Elham  and
Amini, Hessam  and
Kosseim, Leila",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2023,"This paper describes our system at SemEval 2019, Task 3 (EmoContext), which focused on the contextual detection of emotions in a dataset of 3-round dialogues. For our final system, we used a neural network with pretrained ELMo word embeddings and POS tags as input, GRUs as hidden units, an attention mechanism to capture representations of the dialogues, and an SVM classifier which used the learned network representations to perform the task of multi-class classification. This system yielded a micro-averaged F1 score of 0.7072 for the three emotion classes, improving the baseline by approximately 12{\%}.",https://aclanthology.org/S19-2023,emotion,Yes,Yes,No
{CLARK} at {S}em{E}val-2019 Task 3: Exploring the Role of Context to Identify Emotion in a Short Conversation,"Cummings, Joseph  and
Wilson, Jason",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2024,"With text lacking valuable information avail-able in other modalities, context may provide useful information to better detect emotions. In this paper, we do a systematic exploration of the role of context in recognizing emotion in a conversation. We use a Naive Bayes model to show that inferring the mood of the conversation before classifying individual utterances leads to better performance. Additionally, we find that using context while train-ing the model significantly decreases performance. Our approach has the additional bene-fit that its performance rivals a baseline LSTM model while requiring fewer resources.",https://aclanthology.org/S19-2024,emotion,No,Yes,No
{CLP} at {S}em{E}val-2019 Task 3: Multi-Encoder in Hierarchical Attention Networks for Contextual Emotion Detection,"Li, Changjie  and
Xing, Yun",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2025,"In this paper, we describe the participation of team {''}CLP{''} in SemEval-2019 Task 3 {``}Con- textual Emotion Detection in Text{''} that aims to classify emotion of user utterance in tex- tual conversation. The submitted system is a deep learning architecture based on Hier- archical Attention Networks (HAN) and Em- bedding from Language Model (ELMo). The core of the architecture contains two represen- tation layers. The first one combines the out- puts of ELMo, hand-craft features and Bidi- rectional Long Short-Term Memory with At- tention (Bi-LSTM-Attention) to represent user utterance. The second layer use a Bi-LSTM- Attention encoder to represent the conversa- tion. Our system achieved F1 score of 0.7524 which outperformed the baseline model of the organizers by 0.1656.",https://aclanthology.org/S19-2025,emotion,No,Yes,Yes
{C}on{SSED} at {S}em{E}val-2019 Task 3: Configurable Semantic and Sentiment Emotion Detector,"Po{\'s}wiata, Rafa{\l}",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2027,"This paper describes our system participating in the SemEval-2019 Task 3: EmoContext: Contextual Emotion Detection in Text. The goal was to for a given textual dialogue, i.e. a user utterance along with two turns of context, identify the emotion of user utterance as one of the emotion classes: Happy, Sad, Angry or Others. Our system: ConSSED is a configurable combination of semantic and sentiment neural models. The official task submission achieved a micro-average F1 score of 75.31 which placed us 16th out of 165 participating systems.",https://aclanthology.org/S19-2027,emotion,No,Yes,No
{CX}-{ST}-{RNM} at {S}em{E}val-2019 Task 3: Fusion of Recurrent Neural Networks Based on Contextualized and Static Word Representations for Contextual Emotion Detection,"Pere{\l}kiewicz, Micha{\l}",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2028,"In this paper, I describe a fusion model combining contextualized and static word representations for approaching the EmoContext task in the SemEval 2019 competition. The model is based on two Recurrent Neural Networks, the first one is fed with a state-of-the-art ELMo deep contextualized word representation and the second one is fed with a static Word2Vec embedding augmented with 10-dimensional affective word feature vector. The proposed model is compared with two baseline models based on a static word representation and a contextualized word representation, separately. My approach achieved officially 0.7278 microaveraged F1 score on the test dataset, ranking 47th out of 165 participants.",https://aclanthology.org/S19-2028,emotion,Yes,Yes,No
{P}arallel{D}ots at {S}em{E}val-2019 Task 3: Domain Adaptation with feature embeddings for Contextual Emotion Analysis,"Jain, Akansha  and
Aggarwal, Ishita  and
Singh, Ankit",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2029,"This paper describes our proposed system {\&} experiments performed to detect contextual emotion in texts for SemEval 2019 Task 3. We exploit sentiment information, syntactic patterns {\&} semantic relatedness to capture diverse aspects of the text. Word level embeddings such as Glove, FastText, Emoji along with sentence level embeddings like Skip-Thought, DeepMoji {\&} Unsupervised Sentiment Neuron were used as input features to our architecture. We democratize the learning using ensembling of models with different parameters to produce the final output. This paper discusses comparative analysis of the significance of these embeddings and our approach for the task.",https://aclanthology.org/S19-2029,emotion,No,Yes,No
{E}-{LSTM} at {S}em{E}val-2019 Task 3: Semantic and Sentimental Features Retention for Emotion Detection in Text,"Patel, Harsh",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2030,"This paper discusses the solution to the problem statement of the SemEval19: EmoContext competition which is {''}Contextual Emotion Detection in Texts{''}. The paper includes the explanation of an architecture that I created by exploiting the embedding layers of Word2Vec and GloVe using LSTMs as memory unit cells which detects approximate emotion of chats between two people in the English language provided in the textual form. The set of emotions on which the model was trained was Happy, Sad, Angry and Others. The paper also includes an analysis of different conventional machine learning algorithms in comparison to E-LSTM.",https://aclanthology.org/S19-2030,emotion,No,Yes,No
{EL}i{RF}-{UPV} at {S}em{E}val-2019 Task 3: Snapshot Ensemble of Hierarchical Convolutional Neural Networks for Contextual Emotion Detection,"Gonz{\'a}lez, Jos{\'e}-{\'A}ngel  and
Hurtado, Llu{\'\i}s-F.  and
Pla, Ferran",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2031,This paper describes the approach developed by the ELiRF-UPV team at SemEval 2019 Task 3: Contextual Emotion Detection in Text. We have developed a Snapshot Ensemble of 1D Hierarchical Convolutional Neural Networks to extract features from 3-turn conversations in order to perform contextual emotion detection in text. This Snapshot Ensemble is obtained by averaging the models selected by a Genetic Algorithm that optimizes the evaluation measure. The proposed ensemble obtains better results than a single model and it obtains competitive and promising results on Contextual Emotion Detection in Text.,https://aclanthology.org/S19-2031,emotion,No,Yes,No
{E}mo{D}et at {S}em{E}val-2019 Task 3: Emotion Detection in Text using Deep Learning,"Al-Omari, Hani  and
Abdullah, Malak  and
Bassam, Nabeel",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2032,"Task 3, EmoContext, in the International Workshop SemEval 2019 provides training and testing datasets for the participant teams to detect emotion classes (Happy, Sad, Angry, or Others). This paper proposes a participating system (EmoDet) to detect emotions using deep learning architecture. The main input to the system is a combination of Word2Vec word embeddings and a set of semantic features (e.g. from AffectiveTweets Weka-package). The proposed system (EmoDet) ensembles a fully connected neural network architecture and LSTM neural network to obtain performance results that show substantial improvements (F1-Score 0.67) over the baseline model provided by Task 3 organizers (F1-score 0.58).",https://aclanthology.org/S19-2032,emotion,No,Yes,No
{EMOMINER} at {S}em{E}val-2019 Task 3: A Stacked {B}i{LSTM} Architecture for Contextual Emotion Detection in Text,"Chakravartula, Nikhil  and
Indurthi, Vijayasaradhi",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2033,"This paper describes our participation in the SemEval 2019 Task 3 - Contextual Emotion Detection in Text. This task aims to identify emotions, viz. happiness, anger, sadness in the context of a text conversation. Our system is a stacked Bidirectional LSTM, equipped with attention on top of word embeddings pre-trained on a large collection of Twitter data. In this paper, apart from describing our official submission, we elucidate how different deep learning models respond to this task.",https://aclanthology.org/S19-2033,emotion,Yes,Yes,No
{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations,"Smetanin, Sergey",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2034,"In this paper, we describe a deep-learning system for emotion detection in textual conversations that participated in SemEval-2019 Task 3 {``}EmoContext{''}. We designed a specific architecture of bidirectional LSTM which allows not only to learn semantic and sentiment feature representation, but also to capture user-specific conversation features. To fine-tune word embeddings using distant supervision we additionally collected a significant amount of emotional texts. The system achieved 72.59{\%} micro-average F1 score for emotion classes on the test dataset, thereby significantly outperforming the officially-released baseline. Word embeddings and the source code were released for the research community.",https://aclanthology.org/S19-2034,emotion,Yes,No,No
{EPITA}-{ADAPT} at {S}em{E}val-2019 Task 3: Detecting emotions in textual conversations using deep learning models combination,"Bouchekif, Abdessalam  and
Joshi, Praveen  and
Bouchekif, Latifa  and
Afli, Haithem",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2035,"Messaging platforms like WhatsApp, Facebook Messenger and Twitter have gained recently much popularity owing to their ability in connecting users in real-time. The content of these textual messages can be a useful resource for text mining to discover and unhide various aspects, including emotions. In this paper we present our submission for SemEval 2019 task {`}EmoContext{'}. The task consists of classifying a given textual dialogue into one of four emotion classes: Angry, Happy, Sad and Others. Our proposed system is based on the combination of different deep neural networks techniques. In particular, we use Recurrent Neural Networks (LSTM, B-LSTM, GRU, B-GRU), Convolutional Neural Network (CNN) and Transfer Learning (TL) methodes. Our final system, achieves an F1 score of 74.51{\%} on the subtask evaluation dataset.",https://aclanthology.org/S19-2035,emotion,Yes,Yes,No
Figure Eight at {S}em{E}val-2019 Task 3: Ensemble of Transfer Learning Methods for Contextual Emotion Detection,"Xiao, Joan",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2036,"This paper describes our transfer learning-based approach to contextual emotion detection as part of SemEval-2019 Task 3. We experiment with transfer learning using pre-trained language models (ULMFiT, OpenAI GPT, and BERT) and fine-tune them on this task. We also train a deep learning model from scratch using pre-trained word embeddings and BiLSTM architecture with attention mechanism. The ensembled model achieves competitive result, ranking ninth out of 165 teams. The result reveals that ULMFiT performs best due to its superior fine-tuning techniques. We propose improvements for future work.",https://aclanthology.org/S19-2036,emotion,No,Yes,Yes
{G}en{SMT} at {S}em{E}val-2019 Task 3: Contextual Emotion Detection in tweets using multi task generic approach,"Bogdan, Dumitru",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2037,"In this paper, we describe our participation in SemEval-2019 Task 3: EmoContext - A Shared Task on Contextual Emotion Detection in Text. We propose a three layer model with a generic, multi-purpose approach that without any task specific optimizations achieve competitive results (f1 score of 0.7096) in the EmoContext task. We describe our development strategy in detail along with an exposition of our results.",https://aclanthology.org/S19-2037,emotion,No,Yes,No
{GWU} {NLP} Lab at {S}em{E}val-2019 Task 3 : {E}mo{C}ontext: Effectiveness of{C}ontextual Information in Models for Emotion Detection in{S}entence-level at Multi-genre Corpus,"Tafreshi, Shabnam  and
Diab, Mona",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2038,"In this paper we present an emotion classifier models that submitted to the SemEval-2019 Task 3 : \textit{EmoContext}. Our approach is a Gated Recurrent Neural Network (GRU) model with attention layer is bootstrapped with contextual information and trained with a multigenre corpus, which is combination of several popular emotional data sets. We utilize different word embeddings to empirically select the most suited embedding to represent our features. Our aim is to build a robust emotion classifier that can generalize emotion detection, which is to learn emotion cues in a noisy training environment. To fulfill this aim we train our model with a multigenre emotion corpus, this way we leverage from having more training set. We achieved overall {\%}56.05 f1-score and placed 144. Given our aim and noisy training environment, the results are anticipated.",https://aclanthology.org/S19-2038,emotion,Yes,Yes,Yes
{IIT} {G}andhinagar at {S}em{E}val-2019 Task 3: Contextual Emotion Detection Using Deep Learning,"Pamnani, Arik  and
Goel, Rajat  and
Choudhari, Jayesh  and
Singh, Mayank",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2039,"Recent advancements in Internet and Mobile infrastructure have resulted in the development of faster and efficient platforms of communication. These platforms include speech, facial and text-based conversational mediums. Majority of these are text-based messaging platforms. Development of Chatbots that automatically understand latent emotions in the textual message is a challenging task. In this paper, we present an automatic emotion detection system that aims to detect the emotion of a person textually conversing with a chatbot. We explore deep learning techniques such as CNN and LSTM based neural networks and outperformed the baseline score by 14{\%}. The trained model and code are kept in public domain.",https://aclanthology.org/S19-2039,emotion,No,Yes,No
{KGPC}hamps at {S}em{E}val-2019 Task 3: A deep learning approach to detect emotions in the dialog utterances.,"Patro, Jasabanta  and
Choudhary, Nitin  and
Chittora, Kalpit  and
Mukherjee, Animesh",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2040,"This paper describes our approach to solve \textit{Semeval task 3: EmoContext}; where, given a textual dialogue i.e. a user utterance along with two turns of context, we have to classify the emotion associated with the utterance as one of the following emotion classes: \textit{Happy, Sad, Angry} or \textit{Others}. To solve this problem, we experiment with different deep learning models ranging from simple bidirectional LSTM (Long and short term memory) model to comparatively complex attention model. We also experiment with word embedding conceptnet along with word embedding generated from bi-directional LSTM taking input characters. We fine-tune different parameters and hyper-parameters associated with each of our models and report the value of evaluating measure i.e. micro precision along with class wise precision, recall and F1-score of each system. We report the bidirectional LSTM model, along with the input word embedding as the concatenation of word embedding generated from bidirectional LSTM for word characters and conceptnet embedding, as the best performing model with a highest micro-F1 score of 0.7261. We also report class wise precision, recall, and f1-score of best performing model along with other models that we have experimented with.",https://aclanthology.org/S19-2040,emotion,No,Yes,No
{KSU} at {S}em{E}val-2019 Task 3: Hybrid Features for Emotion Recognition in Textual Conversation,"Alswaidan, Nourah  and
Menai, Mohamed El Bachir",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2041,"We proposed a model to address emotion recognition in textual conversation based on using automatically extracted features and human engineered features. The proposed model utilizes a fast gated-recurrent-unit backed by CuDNN, and a convolutional neural network to automatically extract features. The human engineered features take the frequency-inverse document frequency of semantic meaning and mood tags extracted from SinticNet.",https://aclanthology.org/S19-2041,emotion,No,Yes,No
{LIRMM}-Advanse at {S}em{E}val-2019 Task 3: Attentive Conversation Modeling for Emotion Detection and Classification,"Ragheb, Waleed  and
Az{\'e}, J{\'e}r{\^o}me  and
Bringay, Sandra  and
Servajean, Maximilien",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2042,This paper addresses the problem of modeling textual conversations and detecting emotions. Our proposed model makes use of 1) deep transfer learning rather than the classical shallow methods of word embedding; 2) self-attention mechanisms to focus on the most important parts of the texts and 3) turn-based conversational modeling for classifying the emotions. The approach does not rely on any hand-crafted features or lexicons. Our model was evaluated on the data provided by the SemEval-2019 shared task on contextual emotion detection in text. The model shows very competitive results.,https://aclanthology.org/S19-2042,emotion,No,Yes,No
{M}oon{G}rad at {S}em{E}val-2019 Task 3: Ensemble {B}i{RNN}s for Contextual Emotion Detection in Dialogues,"Bothe, Chandrakant  and
Wermter, Stefan",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2044,"When reading {``}I don{'}t want to talk to you any more{''}, we might interpret this as either an angry or a sad emotion in the absence of context. Often, the utterances are shorter, and given a short utterance like {``}Me too!{''}, it is difficult to interpret the emotion without context. The lack of prosodic or visual information makes it a challenging problem to detect such emotions only with text. However, using contextual information in the dialogue is gaining importance to provide a context-aware recognition of linguistic features such as emotion, dialogue act, sentiment etc. The SemEval 2019 Task 3 EmoContext competition provides a dataset of three-turn dialogues labeled with the three emotion classes, i.e. Happy, Sad and Angry, and in addition with Others as none of the aforementioned emotion classes. We develop an ensemble of the recurrent neural model with character- and word-level features as an input to solve this problem. The system performs quite well, achieving a microaveraged F1 score (F1) of 0.7212 for the three emotion classes.",https://aclanthology.org/S19-2044,emotion,Yes,Yes,No
{NL}-{FIIT} at {S}em{E}val-2019 Task 3: Emotion Detection From Conversational Triplets Using Hierarchical Encoders,"Farkas, Michal  and
Lacko, Peter",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2046,"In this paper, we present our system submission for the EmoContext, the third task of the SemEval 2019 workshop. Our solution is a hierarchical recurrent neural network with ELMo embeddings and regularization through dropout and Gaussian noise. We have mainly experimented with two main model architectures: simple and hierarchical LSTM network. We have also examined ensembling of the models and various variants of an ensemble. We have achieved microF1 score of 0.7481, which is significantly higher than baseline and currently the 19th best submission.",https://aclanthology.org/S19-2046,emotion,No,Yes,No
{NTUA}-{ISL}ab at {S}em{E}val-2019 Task 3: Determining emotions in contextual conversations with deep learning,"Potamias, Rolandos Alexandros  and
Siolas, Georgios",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2047,"Sentiment analysis (SA) in texts is a well-studied Natural Language Processing task, which in nowadays gains popularity due to the explosion of social media, and the subsequent accumulation of huge amounts of related data. However, capturing emotional states and the sentiment polarity of written excerpts requires knowledge on the events triggering them. Towards this goal, we present a computational end-to-end context-aware SA methodology, which was competed in the context of the SemEval-2019 / EmoContext task (Task 3). The proposed system is founded on the combination of two neural architectures, a deep recurrent neural network, structured by an attentive Bidirectional LSTM, and a deep dense network (DNN). The system achieved 0.745 micro f1-score, and ranked 26/165 (top 20{\%}) teams among the official task submissions.",https://aclanthology.org/S19-2047,emotion,No,Yes,Yes
ntuer at {S}em{E}val-2019 Task 3: Emotion Classification with Word and Sentence Representations in {RCNN},"Zhong, Peixiang  and
Miao, Chunyan",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2048,"In this paper we present our model on the task of emotion detection in textual conversations in SemEval-2019. Our model extends the Recurrent Convolutional Neural Network (RCNN) by using external fine-tuned word representations and DeepMoji sentence representations. We also explored several other competitive pre-trained word and sentence representations including ELMo, BERT and InferSent but found inferior performance. In addition, we conducted extensive sensitivity analysis, which empirically shows that our model is relatively robust to hyper-parameters. Our model requires no handcrafted features or emotion lexicons but achieved good performance with a micro-F1 score of 0.7463.",https://aclanthology.org/S19-2048,emotion,No,Yes,No
{PKUSE} at {S}em{E}val-2019 Task 3: Emotion Detection with Emotion-Oriented Neural Attention Network,"Ma, Luyao  and
Zhang, Long  and
Ye, Wei  and
Hu, Wenhui",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2049,"This paper presents the system in SemEval-2019 Task 3, {``}EmoContext: Contextual Emotion Detection in Text{''}. We propose a deep learning architecture with bidirectional LSTM networks, augmented with an emotion-oriented attention network that is capable of extracting emotion information from an utterance. Experimental results show that our model outperforms its variants and the baseline. Overall, this system has achieved 75.57{\%} for the microaveraged F1 score.",https://aclanthology.org/S19-2049,emotion,No,Yes,No
{SINAI} at {S}em{E}val-2019 Task 3: Using affective features for emotion classification in textual conversations,"Plaza-del-Arco, Flor Miriam  and
Molina-Gonz{\'a}lez, M. Dolores  and
Martin, Maite  and
Ure{\~n}a-L{\'o}pez, L. Alfonso",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2053,"Detecting emotions in textual conversation is a challenging problem in absence of nonverbal cues typically associated with emotion, like fa- cial expression or voice modulations. How- ever, more and more users are using message platforms such as WhatsApp or Telegram. For this reason, it is important to develop systems capable of understanding human emotions in textual conversations. In this paper, we carried out different systems to analyze the emotions of textual dialogue from SemEval-2019 Task 3: EmoContext for English language. Our main contribution is the integration of emotional and sentimental features in the classification using the SVM algorithm.",https://aclanthology.org/S19-2053,emotion,No,Yes,No
{SSN}{\_}{NLP} at {S}em{E}val-2019 Task 3: Contextual Emotion Identification from Textual Conversation using {S}eq2{S}eq Deep Neural Network,"B., Senthil Kumar  and
D., Thenmozhi  and
Chandrabose, Aravindan  and
Sharavanan, Srinethe",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2055,"Emotion identification is a process of identifying the emotions automatically from text, speech or images. Emotion identification from textual conversations is a challenging problem due to absence of gestures, vocal intonation and facial expressions. It enables conversational agents, chat bots and messengers to detect and report the emotions to the user instantly for a healthy conversation by avoiding emotional cues and miscommunications. We have adopted a Seq2Seq deep neural network to identify the emotions present in the text sequences. Several layers namely embedding layer, encoding-decoding layer, softmax layer and a loss layer are used to map the sequences from textual conversations to the emotions namely Angry, Happy, Sad and Others. We have evaluated our approach on the EmoContext@SemEval2019 dataset and we have obtained the micro-averaged F1 scores as 0.595 and 0.6568 for the pre-evaluation dataset and final evaluation test set respectively. Our approach improved the base line score by 7{\%} for final evaluation test set.",https://aclanthology.org/S19-2055,emotion,Yes,Yes,Yes
"{SWAP} at {S}em{E}val-2019 Task 3: Emotion detection in conversations through Tweets, {CNN} and {LSTM} deep neural networks","Polignano, Marco  and
de Gemmis, Marco  and
Semeraro, Giovanni",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2056,"Emotion detection from user-generated contents is growing in importance in the area of natural language processing. The approach we proposed for the EmoContext task is based on the combination of a CNN and an LSTM using a concatenation of word embeddings. A stack of convolutional neural networks (CNN) is used for capturing the hierarchical hidden relations among embedding features. Meanwhile, a long short-term memory network (LSTM) is used for capturing information shared among words of the sentence. Each conversation has been formalized as a list of word embeddings, in particular during experimental runs pre-trained Glove and Google word embeddings have been evaluated. Surface lexical features have been also considered, but they have been demonstrated to be not usefully for the classification in this specific task. The final system configuration achieved a micro F1 score of 0.7089. The python code of the system is fully available at \url{https://github.com/marcopoli/EmoContext2019}",https://aclanthology.org/S19-2056,emotion,No,Yes,Yes
{S}ymanto{R}esearch at {S}em{E}val-2019 Task 3: Combined Neural Models for Emotion Classification in Human-Chatbot Conversations,"Basile, Angelo  and
Franco-Salvador, Marc  and
Pawar, Neha  and
{\v{S}}tajner, Sanja  and
Chinea Rios, Mara  and
Benajiba, Yassine",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2057,"In this paper, we present our participation to the EmoContext shared task on detecting emotions in English textual conversations between a human and a chatbot. We propose four neural systems and combine them to further improve the results. We show that our neural ensemble systems can successfully distinguish three emotions (SAD, HAPPY, and ANGRY) and separate them from the rest (OTHERS) in a highly-imbalanced scenario. Our best system achieved a 0.77 F1-score and was ranked fourth out of 165 submissions.",https://aclanthology.org/S19-2057,emotion,No,Yes,No
{TDB}ot at {S}em{E}val-2019 Task 3: Context Aware Emotion Detection Using A Conditioned Classification Approach,"Maity, Sourabh",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2058,"With the system description it is shown how to use the context information while detecting the emotion in a dialogue. Some guidelines about how to handle emojis was also laid out. While developing this system I realized the importance of pre-processing in conversational text data, or in general NLP related tasks; it can not be over emphasized.",https://aclanthology.org/S19-2058,emotion,No,Yes,Yes
{THU}{\_}{NGN} at {S}em{E}val-2019 Task 3: Dialog Emotion Classification using Attentional {LSTM}-{CNN},"Ge, Suyu  and
Qi, Tao  and
Wu, Chuhan  and
Huang, Yongfeng",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2059,"With the development of the Internet, dialog systems are widely used in online platforms to provide personalized services for their users. It is important to understand the emotions through conversations to improve the quality of dialog systems. To facilitate the researches on dialog emotion recognition, the SemEval-2019 Task 3 named EmoContext is proposed. This task aims to classify the emotions of user utterance along with two short turns of dialogues into four categories. In this paper, we propose an attentional LSTM-CNN model to participate in this shared task. We use a combination of convolutional neural networks and long-short term neural networks to capture both local and long-distance contextual information in conversations. In addition, we apply attention mechanism to recognize and attend to important words within conversations. Besides, we propose to use ensemble strategies by combing the variants of our model with different pre-trained word embeddings via weighted voting. Our model achieved 0.7542 micro-F1 score in the final test data, ranking 15{\^{}}th out of 165 teams.",https://aclanthology.org/S19-2059,emotion,No,Yes,No
{THU}-{HCSI} at {S}em{E}val-2019 Task 3: Hierarchical Ensemble Classification of Contextual Emotion in Conversation,"Liang, Xihao  and
Ma, Ye  and
Xu, Mingxing",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2060,"In this paper, we describe our hierarchical ensemble system designed for the SemEval-2019 task3, EmoContext. In our system, three sets of classifiers are trained for different sub-targets and the predicted labels of these base classifiers are combined through three steps of voting to make the final prediction. Effective details for developing base classifiers are highlighted.",https://aclanthology.org/S19-2060,emotion,No,Yes,No
{T}okyo{T}ech{\_}{NLP} at {S}em{E}val-2019 Task 3: Emotion-related Symbols in Emotion Detection,"Yang, Zhishen  and
Vijlbrief, Sam  and
Okazaki, Naoaki",2019,Proceedings of the 13th International Workshop on Semantic Evaluation,10.18653/v1/S19-2061,"This paper presents our contextual emotion detection system in approaching the SemEval2019 shared task 3: EmoContext: Contextual Emotion Detection in Text. This system cooperates with an emotion detection neural network method (Poria et al., 2017), emoji2vec (Eisner et al., 2016) embedding, word2vec embedding (Mikolov et al., 2013), and our proposed emoticon and emoji preprocessing method. The experimental results demonstrate the usefulness of our emoticon and emoji prepossessing method, and representations of emoticons and emoji contribute model{'}s emotion detection.",https://aclanthology.org/S19-2061,emotion,No,Yes,Yes
Sentiment and Emotion Based Representations for Fake Reviews Detection,"Melleng, Alimuddin  and
Jurek-Loughrey, Anna  and
P, Deepak",2019,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),10.26615/978-954-452-056-4_087,"Fake reviews are increasingly prevalent across the Internet. They can be unethical as well as harmful. They can affect businesses and mislead individual customers. As the opinions on the Web are increasingly used the detection of fake reviews has become more and more critical. In this study, we explore the effectiveness of sentiment and emotions based representations for the task of building machine learning models for fake review detection. We perform empirical studies over three real world datasets and demonstrate that improved data representation can be achieved by combining sentiment and emotion extraction methods, as well as by performing sentiment and emotion analysis on a part-by-part basis by segmenting the reviews.",https://aclanthology.org/R19-1087,emotion,No,Yes,No
Neural Feature Extraction for Contextual Emotion Detection,"Mohammadi, Elham  and
Amini, Hessam  and
Kosseim, Leila",2019,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),10.26615/978-954-452-056-4_091,"This paper describes a new approach for the task of contextual emotion detection. The approach is based on a neural feature extractor, composed of a recurrent neural network with an attention mechanism, followed by a classifier, that can be neural or SVM-based. We evaluated the model with the dataset of the task 3 of SemEval 2019 (EmoContext), which includes short 3-turn conversations, tagged with 4 emotion classes. The best performing setup was achieved using ELMo word embeddings and POS tags as input, bidirectional GRU as hidden units, and an SVM as the final classifier. This configuration reached 69.93{\%} in terms of micro-average F1 score on the main 3 emotion classes, a score that outperformed the baseline system by 11.25{\%}.",https://aclanthology.org/R19-1091,emotion,Yes,Yes,No
{E}mo{T}ag {--} Towards an Emotion-Based Analysis of Emojis,"Shoeb, Abu Awal Md  and
Raji, Shahab  and
de Melo, Gerard",2019,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),10.26615/978-954-452-056-4_126,"Despite being a fairly recent phenomenon, emojis have quickly become ubiquitous. Besides their extensive use in social media, they are now also invoked in customer surveys and feedback forms. Hence, there is a need for techniques to understand their sentiment and emotion. In this work, we provide a method to quantify the emotional association of basic emotions such as anger, fear, joy, and sadness for a set of emojis. We collect and process a unique corpus of 20 million emoji-centric tweets, such that we can capture rich emoji semantics using a comparably small dataset. We evaluate the induced emotion profiles of emojis with regard to their ability to predict word affect intensities as well as sentiment scores.",https://aclanthology.org/R19-1126,emotion,Yes,No,No
Adversarial Attention Modeling for Multi-dimensional Emotion Regression,"Zhu, Suyang  and
Li, Shoushan  and
Zhou, Guodong",2019,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/P19-1045,"In this paper, we propose a neural network-based approach, namely Adversarial Attention Network, to the task of multi-dimensional emotion regression, which automatically rates multiple emotion dimension scores for an input text. Especially, to determine which words are valuable for a particular emotion dimension, an attention layer is trained to weight the words in an input sequence. Furthermore, adversarial training is employed between two attention layers to learn better word weights via a discriminator. In particular, a shared attention layer is incorporated to learn public word weights between two emotion dimensions. Empirical evaluation on the EMOBANK corpus shows that our approach achieves notable improvements in r-values on both EMOBANK Reader{'}s and Writer{'}s multi-dimensional emotion regression tasks in all domains over the state-of-the-art baselines.",https://aclanthology.org/P19-1045,emotion,Yes,Yes,No
{MELD}: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations,"Poria, Soujanya  and
Hazarika, Devamanyu  and
Majumder, Navonil  and
Naik, Gautam  and
Cambria, Erik  and
Mihalcea, Rada",2019,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/P19-1050,"Emotion recognition in conversations is a challenging task that has recently gained popularity due to its potential applications. Until now, however, a large-scale multimodal multi-party emotional conversational database containing more than two speakers per dialogue was missing. Thus, we propose the Multimodal EmotionLines Dataset (MELD), an extension and enhancement of EmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual and textual modalities. We propose several strong multimodal baselines and show the importance of contextual and multimodal information for emotion recognition in conversations. The full dataset is available for use at \url{http://affective-meld.github.io}.",https://aclanthology.org/P19-1050,emotion,Yes,No,No
Multimodal and Multi-view Models for Emotion Recognition,"Aguilar, Gustavo  and
Rozgic, Viktor  and
Wang, Weiran  and
Wang, Chao",2019,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/P19-1095,"Studies on emotion recognition (ER) show that combining lexical and acoustic information results in more robust and accurate models. The majority of the studies focus on settings where both modalities are available in training and evaluation. However, in practice, this is not always the case; getting ASR output may represent a bottleneck in a deployment pipeline due to computational complexity or privacy-related constraints. To address this challenge, we study the problem of efficiently combining acoustic and lexical modalities during training while still providing a deployable acoustic model that does not require lexical inputs. We first experiment with multimodal models and two attention mechanisms to assess the extent of the benefits that lexical information can provide. Then, we frame the task as a multi-view learning problem to induce semantic information from a multimodal model into our acoustic-only network using a contrastive loss function. Our multimodal model outperforms the previous state of the art on the USC-IEMOCAP dataset reported on lexical and acoustic information. Additionally, our multi-view-trained acoustic network significantly surpasses models that have been exclusively trained with acoustic features.",https://aclanthology.org/P19-1095,emotion,Yes,Yes,No
Emotion-Cause Pair Extraction: A New Task to Emotion Analysis in Texts,"Xia, Rui  and
Ding, Zixiang",2019,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/P19-1096,"Emotion cause extraction (ECE), the task aimed at extracting the potential causes behind certain emotions in text, has gained much attention in recent years due to its wide applications. However, it suffers from two shortcomings: 1) the emotion must be annotated before cause extraction in ECE, which greatly limits its applications in real-world scenarios; 2) the way to first annotate emotion and then extract the cause ignores the fact that they are mutually indicative. In this work, we propose a new task: emotion-cause pair extraction (ECPE), which aims to extract the potential pairs of emotions and corresponding causes in a document. We propose a 2-step approach to address this new ECPE task, which first performs individual emotion extraction and cause extraction via multi-task learning, and then conduct emotion-cause pairing and filtering. The experimental results on a benchmark emotion cause corpus prove the feasibility of the ECPE task as well as the effectiveness of our approach.",https://aclanthology.org/P19-1096,emotion,Yes,No,No
Generating Responses with a Specific Emotion in Dialog,"Song, Zhenqiao  and
Zheng, Xiaoqing  and
Liu, Lu  and
Xu, Mu  and
Huang, Xuanjing",2019,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/P19-1359,"It is desirable for dialog systems to have capability to express specific emotions during a conversation, which has a direct, quantifiable impact on improvement of their usability and user satisfaction. After a careful investigation of real-life conversation data, we found that there are at least two ways to express emotions with language. One is to describe emotional states by explicitly using strong emotional words; another is to increase the intensity of the emotional experiences by implicitly combining neutral words in distinct ways. We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure for a post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework. Experimental results showed EmoDS performed better than the baselines in BLEU, diversity and the quality of emotional expression.",https://aclanthology.org/P19-1359,emotion,No,No,No
Crowdsourcing and Validating Event-focused Emotion Corpora for {G}erman and {E}nglish,"Troiano, Enrica  and
Pad{\'o}, Sebastian  and
Klinger, Roman",2019,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,10.18653/v1/P19-1391,"Sentiment analysis has a range of corpora available across multiple languages. For emotion analysis, the situation is more limited, which hinders potential research on crosslingual modeling and the development of predictive models for other languages. In this paper, we fill this gap for German by constructing deISEAR, a corpus designed in analogy to the well-established English ISEAR emotion dataset. Motivated by Scherer{'}s appraisal theory, we implement a crowdsourcing experiment which consists of two steps. In step 1, participants create descriptions of emotional events for a given emotion. In step 2, five annotators assess the emotion expressed by the texts. We show that transferring an emotion classification model from the original English ISEAR to the German crowdsourced deISEAR via machine translation does not, on average, cause a performance drop.",https://aclanthology.org/P19-1391,emotion,Yes,Yes,No
Emotion Impacts Speech Recognition Performance,"Munot, Rushab  and
Nenkova, Ani",2019,Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,10.18653/v1/N19-3003,"It has been established that the performance of speech recognition systems depends on multiple factors including the lexical content, speaker identity and dialect. Here we use three English datasets of acted emotion to demonstrate that emotional content also impacts the performance of commercial systems. On two of the corpora, emotion is a bigger contributor to recognition errors than speaker identity and on two, neutral speech is recognized considerably better than emotional speech. We further evaluate the commercial systems on spontaneous interactions that contain portions of emotional speech. We propose and validate on the acted datasets, a method that allows us to evaluate the overall impact of emotion on recognition even when manual transcripts are not available. Using this method, we show that emotion in natural spontaneous dialogue is a less prominent but still significant factor in recognition accuracy.",https://aclanthology.org/N19-3003,emotion,No,No,No
Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis,"Akhtar, Md Shad  and
Chauhan, Dushyant  and
Ghosal, Deepanway  and
Poria, Soujanya  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2019,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",10.18653/v1/N19-1034,"Related tasks often have inter-dependence on each other and perform better when solved in a joint framework. In this paper, we present a deep multi-task learning framework that jointly performs sentiment and emotion analysis both. The multi-modal inputs (i.e. text, acoustic and visual frames) of a video convey diverse and distinctive information, and usually do not have equal contribution in the decision making. We propose a context-level inter-modal attention framework for simultaneously predicting the sentiment and expressed emotions of an utterance. We evaluate our proposed approach on CMU-MOSEI dataset for multi-modal sentiment and emotion analysis. Evaluation results suggest that multi-task learning framework offers improvement over the single-task framework. The proposed approach reports new state-of-the-art performance for both sentiment analysis and emotion analysis.",https://aclanthology.org/N19-1034,emotion,Yes,No,No
{H}i{GRU}: {H}ierarchical Gated Recurrent Units for Utterance-Level Emotion Recognition,"Jiao, Wenxiang  and
Yang, Haiqin  and
King, Irwin  and
Lyu, Michael R.",2019,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",10.18653/v1/N19-1037,"In this paper, we address three challenges in utterance-level emotion recognition in dialogue systems: (1) the same word can deliver different emotions in different contexts; (2) some emotions are rarely seen in general dialogues; (3) long-range contextual information is hard to be effectively captured. We therefore propose a hierarchical Gated Recurrent Unit (HiGRU) framework with a lower-level GRU to model the word-level inputs and an upper-level GRU to capture the contexts of utterance-level embeddings. Moreover, we promote the framework to two variants, Hi-GRU with individual features fusion (HiGRU-f) and HiGRU with self-attention and features fusion (HiGRU-sf), so that the word/utterance-level individual inputs and the long-range contextual information can be sufficiently utilized. Experiments on three dialogue emotion datasets, IEMOCAP, Friends, and EmotionPush demonstrate that our proposed Hi-GRU models attain at least 8.7{\%}, 7.5{\%}, 6.0{\%} improvement over the state-of-the-art methods on each dataset, respectively. Particularly, by utilizing only the textual feature in IEMOCAP, our HiGRU models gain at least 3.8{\%} improvement over the state-of-the-art conversational memory network (CMN) with the trimodal features of text, video, and audio.",https://aclanthology.org/N19-1037,emotion,Yes,Yes,No
"Frowning {F}rodo, Wincing {L}eia, and a Seriously Great Friendship: Learning to Classify Emotional Relationships of Fictional Characters","Kim, Evgeny  and
Klinger, Roman",2019,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",10.18653/v1/N19-1067,"The development of a fictional plot is centered around characters who closely interact with each other forming dynamic social networks. In literature analysis, such networks have mostly been analyzed without particular relation types or focusing on roles which the characters take with respect to each other. We argue that an important aspect for the analysis of stories and their development is the emotion between characters. In this paper, we combine these aspects into a unified framework to classify emotional relationships of fictional characters. We formalize it as a new task and describe the annotation of a corpus, based on fan-fiction short stories. The extraction pipeline which we propose consists of character identification (which we treat as given by an oracle here) and the relation classification. For the latter, we provide results using several approaches previously proposed for relation identification with neural methods. The best result of 0.45 F1 is achieved with a GRU with character position indicators on the task of predicting undirected emotion relations in the associated social network graph.",https://aclanthology.org/N19-1067,emotion,Yes,Yes,No
Multi-Channel Convolutional Neural Network for {T}witter Emotion and Sentiment Recognition,"Islam, Jumayel  and
Mercer, Robert E.  and
Xiao, Lu",2019,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",10.18653/v1/N19-1137,"The advent of micro-blogging sites has paved the way for researchers to collect and analyze huge volumes of data in recent years. Twitter, being one of the leading social networking sites worldwide, provides a great opportunity to its users for expressing their states of mind via short messages which are called tweets. The urgency of identifying emotions and sentiments conveyed through tweets has led to several research works. It provides a great way to understand human psychology and impose a challenge to researchers to analyze their content easily. In this paper, we propose a novel use of a multi-channel convolutional neural architecture which can effectively use different emotion and sentiment indicators such as hashtags, emoticons and emojis that are present in the tweets and improve the performance of emotion and sentiment identification. We also investigate the incorporation of different lexical features in the neural network model and its effect on the emotion and sentiment identification task. We analyze our model on some standard datasets and compare its effectiveness with existing techniques.",https://aclanthology.org/N19-1137,emotion,No,Yes,No
Detecting Depression in Social Media using Fine-Grained Emotions,"Arag{\'o}n, Mario Ezra  and
L{\'o}pez-Monroy, Adrian Pastor  and
Gonz{\'a}lez-Gurrola, Luis Carlos  and
Montes-y-G{\'o}mez, Manuel",2019,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",10.18653/v1/N19-1151,"Nowadays social media platforms are the most popular way for people to share information, from work issues to personal matters. For example, people with health disorders tend to share their concerns for advice, support or simply to relieve suffering. This provides a great opportunity to proactively detect these users and refer them as soon as possible to professional help. We propose a new representation called Bag of Sub-Emotions (BoSE), which represents social media documents by a set of fine-grained emotions automatically generated using a lexical resource of emotions and subword embeddings. The proposed representation is evaluated in the task of depression detection. The results are encouraging; the usage of fine-grained emotions improved the results from a representation based on the core emotions and obtained competitive results in comparison to state of the art approaches.",https://aclanthology.org/N19-1151,emotion,No,No,No
Improving Multi-label Emotion Classification by Integrating both General and Domain-specific Knowledge,"Ying, Wenhao  and
Xiang, Rong  and
Lu, Qin",2019,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),10.18653/v1/D19-5541,"Deep learning based general language models have achieved state-of-the-art results in many popular tasks such as sentiment analysis and QA tasks. Text in domains like social media has its own salient characteristics. Domain knowledge should be helpful in domain relevant tasks. In this work, we devise a simple method to obtain domain knowledge and further propose a method to integrate domain knowledge with general knowledge based on deep language models to improve performance of emotion classification. Experiments on Twitter data show that even though a deep language model fine-tuned by a target domain data has attained comparable results to that of previous state-of-the-art models, this fine-tuned model can still benefit from our extracted domain knowledge to obtain more improvement. This highlights the importance of making use of domain knowledge in domain-specific applications.",https://aclanthology.org/D19-5541,emotion,No,Yes,Yes
A Time Series Analysis of Emotional Loading in Central Bank Statements,"Buechel, Sven  and
Junker, Simon  and
Schlaak, Thore  and
Michelsen, Claus  and
Hahn, Udo",2019,Proceedings of the Second Workshop on Economics and Natural Language Processing,10.18653/v1/D19-5103,"We examine the affective content of central bank press statements using emotion analysis. Our focus is on two major international players, the European Central Bank (ECB) and the US Federal Reserve Bank (Fed), covering a time span from 1998 through 2019. We reveal characteristic patterns in the emotional dimensions of valence, arousal, and dominance and find{---}despite the commonly established attitude that emotional wording in central bank communication should be avoided{---}a correlation between the state of the economy and particularly the dominance dimension in the press releases under scrutiny and, overall, an impact of the president in office.",https://aclanthology.org/D19-5103,emotion,No,No,No
{D}ialogue{GCN}: A Graph Convolutional Neural Network for Emotion Recognition in Conversation,"Ghosal, Deepanway  and
Majumder, Navonil  and
Poria, Soujanya  and
Chhaya, Niyati  and
Gelbukh, Alexander",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1015,"Emotion recognition in conversation (ERC) has received much attention, lately, from researchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources. In this paper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC. We leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition. Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods. We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets.",https://aclanthology.org/D19-1015,emotion,Yes,Yes,No
Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations,"Zhong, Peixiang  and
Wang, Di  and
Miao, Chunyan",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1016,"Messages in human conversations inherently convey emotions. The task of detecting emotions in textual conversations leads to a wide range of applications such as opinion mining in social networks. However, enabling machines to analyze emotions in conversations is challenging, partly because humans often rely on the context and commonsense knowledge to express emotions. In this paper, we address these challenges by proposing a Knowledge-Enriched Transformer (KET), where contextual utterances are interpreted using hierarchical self-attention and external commonsense knowledge is dynamically leveraged using a context-aware affective graph attention mechanism. Experiments on multiple textual conversation datasets demonstrate that both context and commonsense knowledge are consistently beneficial to the emotion detection performance. In addition, the experimental results show that our KET model outperforms the state-of-the-art models on most of the tested datasets in F1 score.",https://aclanthology.org/D19-1016,emotion,No,Yes,No
Interpretable Relevant Emotion Ranking with Event-Driven Attention,"Yang, Yang  and
Zhou, Deyu  and
He, Yulan  and
Zhang, Meng",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1017,"Multiple emotions with different intensities are often evoked by events described in documents. Oftentimes, such event information is hidden and needs to be discovered from texts. Unveiling the hidden event information can help to understand how the emotions are evoked and provide explainable results. However, existing studies often ignore the latent event information. In this paper, we proposed a novel interpretable relevant emotion ranking model with the event information incorporated into a deep learning architecture using the event-driven attentions. Moreover, corpus-level event embeddings and document-level event distributions are introduced respectively to consider the global events in corpus and the document-specific events simultaneously. Experimental results on three real-world corpora show that the proposed approach performs remarkably better than the state-of-the-art emotion detection approaches and multi-label approaches. Moreover, interpretable results can be obtained to shed light on the events which trigger certain emotions.",https://aclanthology.org/D19-1017,emotion,Yes,Yes,No
Modelling the interplay of metaphor and emotion through multitask learning,"Dankers, Verna  and
Rei, Marek  and
Lewis, Martha  and
Shutova, Ekaterina",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1227,"Metaphors allow us to convey emotion by connecting physical experiences and abstract concepts. The results of previous research in linguistics and psychology suggest that metaphorical phrases tend to be more emotionally evocative than their literal counterparts. In this paper, we investigate the relationship between metaphor and emotion within a computational framework, by proposing the first joint model of these phenomena. We experiment with several multitask learning architectures for this purpose, involving both hard and soft parameter sharing. Our results demonstrate that metaphor identification and emotion prediction mutually benefit from joint learning and our models advance the state of the art in both of these tasks.",https://aclanthology.org/D19-1227,emotion,No,Yes,No
Text Emotion Distribution Learning from Small Sample: A Meta-Learning Approach,"Zhao, Zhenjie  and
Ma, Xiaojuan",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1408,"Text emotion distribution learning (EDL) aims to develop models that can predict the intensity values of a sentence across a set of emotion categories. Existing methods based on supervised learning require a large amount of well-labelled training data, which is difficult to obtain due to inconsistent perception of fine-grained emotion intensity. In this paper, we propose a meta-learning approach to learn text emotion distributions from a small sample. Specifically, we propose to learn low-rank sentence embeddings by tensor decomposition to capture their contextual semantic similarity, and use K-nearest neighbors (KNNs) of each sentence in the embedding space to generate sample clusters. We then train a meta-learner that can adapt to new data with only a few training samples on the clusters, and further fit the meta-learner on KNNs of a testing sample for EDL. In this way, we effectively augment the learning ability of a model on the small sample. To demonstrate the performance, we compare the proposed approach with state-of-the-art EDL methods on a widely used EDL dataset: SemEval 2007 Task 14 (Strapparava and Mihalcea, 2007). Results show the superiority of our method on small-sample emotion distribution learning.",https://aclanthology.org/D19-1408,emotion,Yes,Yes,No
Emotion Detection with Neural Personal Discrimination,"Zhou, Xiabing  and
Wang, Zhongqing  and
Li, Shoushan  and
Zhou, Guodong  and
Zhang, Min",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1552,"There have been a recent line of works to automatically predict the emotions of posts in social media. Existing approaches consider the posts individually and predict their emotions independently. Different from previous researches, we explore the dependence among relevant posts via the authors{'} backgrounds, since the authors with similar backgrounds, e.g., gender, location, tend to express similar emotions. However, such personal attributes are not easy to obtain in most social media websites, and it is hard to capture attributes-aware words to connect similar people. Accordingly, we propose a Neural Personal Discrimination (NPD) approach to address above challenges by determining personal attributes from posts, and connecting relevant posts with similar attributes to jointly learn their emotions. In particular, we employ adversarial discriminators to determine the personal attributes, with attention mechanisms to aggregate attributes-aware words. In this way, social correlationship among different posts can be better addressed. Experimental results show the usefulness of personal attributes, and the effectiveness of our proposed NPD approach in capturing such personal attributes with significant gains over the state-of-the-art models.",https://aclanthology.org/D19-1552,emotion,No,Yes,No
A Knowledge Regularized Hierarchical Approach for Emotion Cause Analysis,"Fan, Chuang  and
Yan, Hongyu  and
Du, Jiachen  and
Gui, Lin  and
Bing, Lidong  and
Yang, Min  and
Xu, Ruifeng  and
Mao, Ruibin",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1563,"Emotion cause analysis, which aims to identify the reasons behind emotions, is a key topic in sentiment analysis. A variety of neural network models have been proposed recently, however, these previous models mostly focus on the learning architecture with local textual information, ignoring the discourse and prior knowledge, which play crucial roles in human text comprehension. In this paper, we propose a new method to extract emotion cause with a hierarchical neural model and knowledge-based regularizations, which aims to incorporate discourse context information and restrain the parameters by sentiment lexicon and common knowledge. The experimental results demonstrate that our proposed method achieves the state-of-the-art performance on two public datasets in different languages (Chinese and English), outperforming a number of competitive baselines by at least 2.08{\%} in F-measure.",https://aclanthology.org/D19-1563,emotion,No,Yes,No
Context-aware Interactive Attention for Multi-modal Sentiment and Emotion Analysis,"Chauhan, Dushyant Singh  and
Akhtar, Md Shad  and
Ekbal, Asif  and
Bhattacharyya, Pushpak",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1566,"In recent times, multi-modal analysis has been an emerging and highly sought-after field at the intersection of natural language processing, computer vision, and speech processing. The prime objective of such studies is to leverage the diversified information, (e.g., textual, acoustic and visual), for learning a model. The effective interaction among these modalities often leads to a better system in terms of performance. In this paper, we introduce a recurrent neural network based approach for the multi-modal sentiment and emotion analysis. The proposed model learns the inter-modal interaction among the participating modalities through an auto-encoder mechanism. We employ a context-aware attention module to exploit the correspondence among the neighboring utterances. We evaluate our proposed approach for five standard multi-modal affect analysis datasets. Experimental results suggest the efficacy of the proposed model for both sentiment and emotion analysis over various existing state-of-the-art systems.",https://aclanthology.org/D19-1566,emotion,No,Yes,Yes
{DENS}: A Dataset for Multi-class Emotion Analysis,"Liu, Chen  and
Osama, Muhammad  and
De Andrade, Anderson",2019,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),10.18653/v1/D19-1656,"We introduce a new dataset for multi-class emotion analysis from long-form narratives in English. The Dataset for Emotions of Narrative Sequences (DENS) was collected from both classic literature available on Project Gutenberg and modern online narratives avail- able on Wattpad, annotated using Amazon Mechanical Turk. A number of statistics and baseline benchmarks are provided for the dataset. Of the tested techniques, we find that the fine-tuning of a pre-trained BERT model achieves the best results, with an average micro-F1 score of 60.4{\%}. Our results show that the dataset provides a novel opportunity in emotion analysis that requires moving beyond existing sentence-level techniques.",https://aclanthology.org/D19-1656,emotion,Yes,Yes,No
Converting Sentiment Annotated Data to Emotion Annotated Data,"Kulkarni, Manasi  and
Bhattacharyya, Pushpak",2019,Proceedings of the 16th International Conference on Natural Language Processing,,"Existing supervised solutions for emotion classification demand large amount of emotion annotated data. Such resources may not be available for many languages. However, it is common to have sentiment annotated data available in these languages. The sentiment information (+1 or -1) is useful to segregate between positive emotions or negative emotions. In this paper, we propose an unsupervised approach for emotion recognition by taking advantage of the sentiment information. Given a sentence and its sentiment information, recognize the best possible emotion for it. For every sentence, the semantic relatedness between the words from sentence and a set of emotion-specific words is calculated using cosine similarity. An emotion vector representing the emotion score for each emotion category of Ekman{'}s model, is created. It is further improved with the dependency relations and the best possible emotion is predicted. The results show the significant improvement in f-score values for text with sentiment information as input over our baseline as text without sentiment information. We report the weighted f-score on three different datasets with the Ekman{'}s emotion model. This supports that by leveraging the sentiment value, better emotion annotated data can be created.",https://aclanthology.org/2019.icon-1.20,emotion,Yes,Yes,No
"Propagation of emotions, arousal and polarity in {W}ord{N}et using Heterogeneous Structured Synset Embeddings","Koco{\'n}, Jan  and
Janz, Arkadiusz",2019,Proceedings of the 10th Global Wordnet Conference,,"In this paper we present a novel method for emotive propagation in a wordnet based on a large emotive seed. We introduce a sense-level emotive lexicon annotated with polarity, arousal and emotions. The data were annotated as a part of a large study involving over 20,000 participants. A total of 30,000 lexical units in Polish WordNet were described with metadata, each unit received about 50 annotations concerning polarity, arousal and 8 basic emotions, marked on a multilevel scale. We present a preliminary approach to propagating emotive metadata to unlabeled lexical units based on the distribution of manual annotations using logistic regression and description of mixed synset embeddings based on our Heterogeneous Structured Synset Embeddings.",https://aclanthology.org/2019.gwc-1.43,emotion,Yes,No,No
Creating a Dataset for Multilingual Fine-grained Emotion-detection Using Gamification-based Annotation,"{\""O}hman, Emily  and
Kajava, Kaisla  and
Tiedemann, J{\""o}rg  and
Honkela, Timo",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6205,"This paper introduces a gamified framework for fine-grained sentiment analysis and emotion detection. We present a flexible tool, \textit{Sentimentator}, that can be used for efficient annotation based on crowd sourcing and a self-perpetuating gold standard. We also present a novel dataset with multi-dimensional annotations of emotions and sentiments in movie subtitles that enables research on sentiment preservation across languages and the creation of robust multilingual emotion detection tools. The tools and datasets are public and open-source and can easily be extended and applied for various purposes.",https://aclanthology.org/W18-6205,emotion,Yes,No,No
{IEST}: {WASSA}-2018 Implicit Emotions Shared Task,"Klinger, Roman  and
De Clercq, Orph{\'e}e  and
Mohammad, Saif  and
Balahur, Alexandra",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6206,"Past shared tasks on emotions use data with both overt expressions of emotions (\textit{I am so happy to see you!}) as well as subtle expressions where the emotions have to be inferred, for instance from event descriptions. Further, most datasets do not focus on the cause or the stimulus of the emotion. Here, for the first time, we propose a shared task where systems have to predict the emotions in a large automatically labeled dataset of tweets without access to words denoting emotions. Based on this intention, we call this the Implicit Emotion Shared Task (IEST) because the systems have to infer the emotion mostly from the context. Every tweet has an occurrence of an explicit emotion word that is masked. The tweets are collected in a manner such that they are likely to include a description of the cause of the emotion {--} the stimulus. Altogether, 30 teams submitted results which range from macro F1 scores of 21 {\%} to 71 {\%}. The baseline (Max-Ent bag of words and bigrams) obtains an F1 score of 60 {\%} which was available to the participants during the development phase. A study with human annotators suggests that automatic methods outperform human predictions, possibly by honing into subtle textual clues not used by humans. Corpora, resources, and results are available at the shared task website at \url{http://implicitemotions.wassa2018.com}.",https://aclanthology.org/W18-6206,emotion,Yes,No,No
{IIIDYT} at {IEST} 2018: Implicit Emotion Classification With Deep Contextualized Word Representations,"Balazs, Jorge  and
Marrese-Taylor, Edison  and
Matsuo, Yutaka",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6208,"In this paper we describe our system designed for the WASSA 2018 Implicit Emotion Shared Task (IEST), which obtained 2nd place out of 30 teams with a test macro F1 score of 0.710. The system is composed of a single pre-trained ELMo layer for encoding words, a Bidirectional Long-Short Memory Network BiLSTM for enriching word representations with context, a max-pooling operation for creating sentence representations from them, and a Dense Layer for projecting the sentence representations into label space. Our official submission was obtained by ensembling 6 of these models initialized with different random seeds. The code for replicating this paper is available at \url{https://github.com/jabalazs/implicit_emotion}.",https://aclanthology.org/W18-6208,emotion,No,Yes,No
{NTUA}-{SLP} at {IEST} 2018: Ensemble of Neural Transfer Methods for Implicit Emotion Classification,"Chronopoulou, Alexandra  and
Margatina, Aikaterini  and
Baziotis, Christos  and
Potamianos, Alexandros",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6209,"In this paper we present our approach to tackle the Implicit Emotion Shared Task (IEST) organized as part of WASSA 2018 at EMNLP 2018. Given a tweet, from which a certain word has been removed, we are asked to predict the emotion of the missing word. In this work, we experiment with neural Transfer Learning (TL) methods. Our models are based on LSTM networks, augmented with a self-attention mechanism. We use the weights of various pretrained models, for initializing specific layers of our networks. We leverage a big collection of unlabeled Twitter messages, for pretraining word2vec word embeddings and a set of diverse language models. Moreover, we utilize a sentiment analysis dataset for pretraining a model, which encodes emotion related information. The submitted model consists of an ensemble of the aforementioned TL models. Our team ranked 3rd out of 30 participants, achieving an F1 score of 0.703.",https://aclanthology.org/W18-6209,emotion,Yes,Yes,Yes
Leveraging Writing Systems Change for Deep Learning Based {C}hinese Emotion Analysis,"Xiang, Rong  and
Long, Yunfei  and
Lu, Qin  and
Xiong, Dan  and
Chen, I-Hsuan",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6214,"Social media text written in Chinese communities contains mixed scripts including major text written in Chinese, an ideograph-based writing system, and some minor text using Latin letters, an alphabet-based writing system. This phenomenon is called writing systems changes (WSCs). Past studies have shown that WSCs can be used to express emotions, particularly where the social and political environment is more conservative. However, because WSCs can break the syntax of the major text, it poses more challenges in Natural Language Processing (NLP) tasks like emotion classification. In this work, we present a novel deep learning based method to include WSCs as an effective feature for emotion analysis. The method first identifies all WSCs points. Then representation of the major text is learned through an LSTM model whereas the minor text is learned by a separate CNN model. Emotions in the minor text are further highlighted through an attention mechanism before emotion classification. Performance evaluation shows that incorporating WSCs features using deep learning models can improve performance measured by F1-scores compared to the state-of-the-art model.",https://aclanthology.org/W18-6214,emotion,No,Yes,Yes
The Role of Emotions in Native Language Identification,"Markov, Ilia  and
Nastase, Vivi  and
Strapparava, Carlo  and
Sidorov, Grigori",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6218,"We explore the hypothesis that emotion is one of the dimensions of language that surfaces from the native language into a second language. To check the role of emotions in native language identification (NLI), we model emotion information through polarity and emotion load features, and use document representations using these features to classify the native language of the author. The results indicate that emotion is relevant for NLI, even for high proficiency levels and across topics.",https://aclanthology.org/W18-6218,emotion,No,Yes,No
{UTFPR} at {IEST} 2018: Exploring Character-to-Word Composition for Emotion Analysis,"Paetzold, Gustavo",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6224,"We introduce the UTFPR system for the Implicit Emotions Shared Task of 2018: A compositional character-to-word recurrent neural network that does not exploit heavy and/or hard-to-obtain resources. We find that our approach can outperform multiple baselines, and offers an elegant and effective solution to the problem of orthographic variance in tweets.",https://aclanthology.org/W18-6224,emotion,No,Yes,No
{HUMIR} at {IEST}-2018: Lexicon-Sensitive and Left-Right Context-Sensitive {B}i{LSTM} for Implicit Emotion Recognition,"Naderalvojoud, Behzad  and
Ucan, Alaettin  and
Akcapinar Sezer, Ebru",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6225,"This paper describes the approaches used in HUMIR system for the WASSA-2018 shared task on the implicit emotion recognition. The objective of this task is to predict the emotion expressed by the target word that has been excluded from the given tweet. We suppose this task as a word sense disambiguation in which the target word is considered as a synthetic word that can express 6 emotions depending on the context. To predict the correct emotion, we propose a deep neural network model that uses two BiLSTM networks to represent the contexts in the left and right sides of the target word. The BiLSTM outputs achieved from the left and right contexts are considered as context-sensitive features. These features are used in a feed-forward neural network to predict the target word emotion. Besides this approach, we also combine the BiLSTM model with lexicon-based and emotion-based features. Finally, we employ all models in the final system using Bagging ensemble method. We achieved macro F-measure value of 68.8 on the official test set and ranked sixth out of 30 participants.",https://aclanthology.org/W18-6225,emotion,No,Yes,No
{NLP} at {IEST} 2018: {B}i{LSTM}-Attention and {LSTM}-Attention via Soft Voting in Emotion Classification,"Zhou, Qimin  and
Wu, Hao",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6226,"This paper describes our method that competed at WASSA2018 \textit{Implicit Emotion Shared Task}. The goal of this task is to classify the emotions of excluded words in tweets into six different classes: sad, joy, disgust, surprise, anger and fear. For this, we examine a BiLSTM architecture with attention mechanism (BiLSTM-Attention) and a LSTM architecture with attention mechanism (LSTM-Attention), and try different dropout rates based on these two models. We then exploit an ensemble of these methods to give the final prediction which improves the model performance significantly compared with the baseline model. The proposed method achieves 7th position out of 30 teams and outperforms the baseline method by 12.5{\%} in terms of \textit{macro F1}.",https://aclanthology.org/W18-6226,emotion,No,Yes,Yes
{SINAI} at {IEST} 2018: Neural Encoding of Emotional External Knowledge for Emotion Classification,"Plaza-del-Arco, Flor Miriam  and
Mart{\'\i}nez-C{\'a}mara, Eugenio  and
Martin, Maite  and
Ure{\~n}a- L{\'o}pez, L. Alfonso",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6227,"In this paper, we describe our participation in WASSA 2018 Implicit Emotion Shared Task (IEST 2018). We claim that the use of emotional external knowledge may enhance the performance and the capacity of generalization of an emotion classification system based on neural networks. Accordingly, we submitted four deep learning systems grounded in a sequence encoding layer. They mainly differ in the feature vector space and the recurrent neural network used in the sequence encoding layer. The official results show that the systems that used emotional external knowledge have a higher capacity of generalization, hence our claim holds.",https://aclanthology.org/W18-6227,emotion,No,Yes,No
{E}mo{NLP} at {IEST} 2018: An Ensemble of Deep Learning Models and Gradient Boosting Regression Tree for Implicit Emotion Prediction in Tweets,"Liu, Man",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6228,"This paper describes our system submitted to IEST 2018, a shared task (Klinger et al., 2018) to predict the emotion types. Six emotion types are involved: anger, joy, fear, surprise, disgust and sad. We perform three different approaches: feed forward neural network (FFNN), convolutional BLSTM (ConBLSTM) and Gradient Boosting Regression Tree Method (GBM). Word embeddings used in convolutional BLSTM are pre-trained on 470 million tweets which are filtered using the emotional words and emojis. In addition, broad sets of features (i.e. syntactic features, lexicon features, cluster features) are adopted to train GBM and FFNN. The three approaches are finally ensembled by the weighted average of predicted probabilities of each emotion label.",https://aclanthology.org/W18-6228,emotion,No,Yes,Yes
{HGSGNLP} at {IEST} 2018: An Ensemble of Machine Learning and Deep Neural Architectures for Implicit Emotion Classification in Tweets,"Wang, Wenting",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6229,"This paper describes our system designed for the WASSA-2018 Implicit Emotion Shared Task (IEST). The task is to predict the emotion category expressed in a tweet by removing the terms \textit{angry}, \textit{afraid}, \textit{happy}, \textit{sad}, \textit{surprised}, \textit{disgusted} and their synonyms. Our final submission is an ensemble of one supervised learning model and three deep neural network based models, where each model approaches the problem from essentially different directions. Our system achieves the macro F1 score of 65.8{\%}, which is a 5.9{\%} performance improvement over the baseline and is ranked 12 out of 30 participating teams.",https://aclanthology.org/W18-6229,emotion,No,Yes,No
{D}ata{SEARCH} at {IEST} 2018: Multiple Word Embedding based Models for Implicit Emotion Classification of Tweets with Deep Learning,"Senarath, Yasas  and
Thayasivam, Uthayasanker",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6230,"This paper describes an approach to solve implicit emotion classification with the use of pre-trained word embedding models to train multiple neural networks. The system described in this paper is composed of a sequential combination of Long Short-Term Memory and Convolutional Neural Network for feature extraction and Feedforward Neural Network for classification. In this paper, we successfully show that features extracted using multiple pre-trained embeddings can be used to improve the overall performance of the system with Emoji being one of the significant features. The evaluations show that our approach outperforms the baseline system by more than 8{\%} without using any external corpus or lexicon. This approach is ranked 8th in Implicit Emotion Shared Task (IEST) at WASSA-2018.",https://aclanthology.org/W18-6230,emotion,Yes,Yes,No
{NL}-{FIIT} at {IEST}-2018: Emotion Recognition utilizing Neural Networks and Multi-level Preprocessing,"Pecar, Samuel  and
Farkas, Michal  and
Simko, Marian  and
Lacko, Peter  and
Bielikova, Maria",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6231,"In this paper, we present neural models submitted to Shared Task on Implicit Emotion Recognition, organized as part of WASSA 2018. We propose a Bi-LSTM architecture with regularization through dropout and Gaussian noise. Our models use three different embedding layers: GloVe word embeddings trained on Twitter dataset, ELMo embeddings and also sentence embeddings. We see preprocessing as one of the most important parts of the task. We focused on handling emojis, emoticons, hashtags, and also various shortened word forms. In some cases, we proposed to remove some parts of the text, as they do not affect emotion of the original sentence. We also experimented with other modifications like category weights for learning and stacking multiple layers. Our model achieved a macro average F1 score of 65.55{\%}, significantly outperforming the baseline model produced by a simple logistic regression.",https://aclanthology.org/W18-6231,emotion,Yes,Yes,No
{UWB} at {IEST} 2018: Emotion Prediction in Tweets with Bidirectional Long Short-Term Memory Neural Network,"P{\v{r}}ib{\'a}{\v{n}}, Pavel  and
Mart{\'\i}nek, Ji{\v{r}}{\'\i}",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6232,"This paper describes our system created for the WASSA 2018 Implicit Emotion Shared Task. The goal of this task is to predict the emotion of a given tweet, from which a certain emotion word is removed. The removed word can be \textit{sad}, \textit{happy}, \textit{disgusted}, \textit{angry}, \textit{afraid} or a synonym of one of them. Our proposed system is based on deep-learning methods. We use Bidirectional Long Short-Term Memory (BiLSTM) with word embeddings as an input. Pre-trained DeepMoji model and pre-trained emoji2vec emoji embeddings are also used as additional inputs. Our System achieves 0.657 macro F1 score and our rank is 13th out of 30.",https://aclanthology.org/W18-6232,emotion,No,Yes,No
{USI}-{IR} at {IEST} 2018: Sequence Modeling and Pseudo-Relevance Feedback for Implicit Emotion Detection,"R{\'\i}ssola, Esteban  and
Giachanou, Anastasia  and
Crestani, Fabio",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6233,"This paper describes the participation of USI-IR in WASSA 2018 Implicit Emotion Shared Task. We propose a relevance feedback approach employing a sequential model (biLSTM) and word embeddings derived from a large collection of tweets. To this end, we assume that the top-\textit{k} predictions produce at a first classification step are correct (based on the model accuracy) and use them as new examples to re-train the network.",https://aclanthology.org/W18-6233,emotion,Yes,Yes,No
{E}moti{KLUE} at {IEST} 2018: Topic-Informed Classification of Implicit Emotions,"Proisl, Thomas  and
Heinrich, Philipp  and
Kabashi, Besim  and
Evert, Stefan",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6234,"EmotiKLUE is a submission to the Implicit Emotion Shared Task. It is a deep learning system that combines independent representations of the left and right contexts of the emotion word with the topic distribution of an LDA topic model. EmotiKLUE achieves a macro average \textit{F}score of 67.13{\%}, significantly outperforming the baseline produced by a simple ML classifier. Further enhancements after the evaluation period lead to an improved \textit{F}score of 68.10{\%}.",https://aclanthology.org/W18-6234,emotion,No,Yes,No
{B}rain{T} at {IEST} 2018: Fine-tuning Multiclass Perceptron For Implicit Emotion Classification,"Gratian, Vachagan  and
Haid, Marina",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6235,"We present \textit{BrainT}, a multi-class, averaged perceptron tested on implicit emotion prediction of tweets. We show that the dataset is linearly separable and explore ways in fine-tuning the baseline classifier. Our results indicate that the bag-of-words features benefit the model moderately and prediction can be improved with bigrams, trigrams, \textit{skip-one}-tetragrams and POS-tags. Furthermore, we find preprocessing of the n-grams, including stemming, lowercasing, stopword filtering, emoji and emoticon conversion generally not useful. The model is trained on an annotated corpus of 153,383 tweets and predictions on the test data were submitted to the WASSA-2018 Implicit Emotion Shared Task. BrainT attained a Macro F-score of 0.63.",https://aclanthology.org/W18-6235,emotion,Yes,Yes,No
Disney at {IEST} 2018: Predicting Emotions using an Ensemble,"Witon, Wojciech  and
Colombo, Pierre  and
Modi, Ashutosh  and
Kapadia, Mubbasir",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6236,"This paper describes our participating system in the WASSA 2018 shared task on emotion prediction. The task focuses on implicit emotion prediction in a tweet. In this task, keywords corresponding to the six emotion labels used (anger, fear, disgust, joy, sad, and surprise) have been removed from the tweet text, making emotion prediction implicit and the task challenging. We propose a model based on an ensemble of classifiers for prediction. Each classifier uses a sequence of Convolutional Neural Network (CNN) architecture blocks and uses ELMo (Embeddings from Language Model) as an input. Our system achieves a 66.2{\%} F1 score on the test set. The best performing system in the shared task has reported a 71.4{\%} F1 score.",https://aclanthology.org/W18-6236,emotion,No,Yes,Yes
Sentylic at {IEST} 2018: Gated Recurrent Neural Network and Capsule Network Based Approach for Implicit Emotion Detection,"Rathnayaka, Prabod  and
Abeysinghe, Supun  and
Samarajeewa, Chamod  and
Manchanayake, Isura  and
Walpola, Malaka",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6237,"In this paper, we present the system we have used for the Implicit WASSA 2018 Implicit Emotion Shared Task. The task is to predict the emotion of a tweet of which the explicit mentions of emotion terms have been removed. The idea is to come up with a model which has the ability to implicitly identify the emotion expressed given the context words. We have used a Gated Recurrent Neural Network (GRU) and a Capsule Network based model for the task. Pre-trained word embeddings have been utilized to incorporate contextual knowledge about words into the model. GRU layer learns latent representations using the input word embeddings. Subsequent Capsule Network layer learns high-level features from that hidden representation. The proposed model managed to achieve a macro-F1 score of 0.692.",https://aclanthology.org/W18-6237,emotion,No,Yes,No
{E}mo2{V}ec: Learning Generalized Emotion Representation by Multi-task Training,"Xu, Peng  and
Madotto, Andrea  and
Wu, Chien-Sheng  and
Park, Ji Ho  and
Fung, Pascale",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6243,"In this paper, we propose Emo2Vec which encodes emotional semantics into vectors. We train Emo2Vec by multi-task learning six different emotion-related tasks, including emotion/sentiment analysis, sarcasm classification, stress detection, abusive language classification, insult detection, and personality recognition. Our evaluation of Emo2Vec shows that it outperforms existing affect-related representations, such as Sentiment-Specific Word Embedding and DeepMoji embeddings with much smaller training corpora. When concatenated with GloVe, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using a simple logistic regression classifier.",https://aclanthology.org/W18-6243,emotion,No,Yes,No
{UBC}-{NLP} at {IEST} 2018: Learning Implicit Emotion With an Ensemble of Language Models,"Alhuzali, Hassan  and
Elaraby, Mohamed  and
Abdul-Mageed, Muhammad",2018,"Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W18-6250,"We describe UBC-NLP contribution to IEST-2018, focused at learning implicit emotion in Twitter data. Among the 30 participating teams, our system ranked the 4th (with 69.3{\%} \textit{F}-score). Post competition, we were able to score slightly higher than the 3rd ranking system (reaching 70.7{\%}). Our system is trained on top of a pre-trained language model (LM), fine-tuned on the data provided by the task organizers. Our best results are acquired by an average of an ensemble of language models. We also offer an analysis of system performance and the impact of training data size on the task. For example, we show that training our best model for only one epoch with {\textless} 40{\%} of the data enables better performance than the baseline reported by Klinger et al. (2018) for the task.",https://aclanthology.org/W18-6250,emotion,No,Yes,Yes
Unsupervised Counselor Dialogue Clustering for Positive Emotion Elicitation in Neural Dialogue System,"Lubis, Nurul  and
Sakti, Sakriani  and
Yoshino, Koichiro  and
Nakamura, Satoshi",2018,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,10.18653/v1/W18-5017,"Positive emotion elicitation seeks to improve user{'}s emotional state through dialogue system interaction, where a chat-based scenario is layered with an implicit goal to address user{'}s emotional needs. Standard neural dialogue system approaches still fall short in this situation as they tend to generate only short, generic responses. Learning from expert actions is critical, as these potentially differ from standard dialogue acts. In this paper, we propose using a hierarchical neural network for response generation that is conditioned on 1) expert{'}s action, 2) dialogue context, and 3) user emotion, encoded from user input. We construct a corpus of interactions between a counselor and 30 participants following a negative emotional exposure to learn expert actions and responses in a positive emotion elicitation scenario. Instead of relying on the expensive, labor intensive, and often ambiguous human annotations, we unsupervisedly cluster the expert{'}s responses and use the resulting labels to train the network. Our experiments and evaluation show that the proposed approach yields lower perplexity and generates a larger variety of responses.",https://aclanthology.org/W18-5017,emotion,Yes,Yes,No
An Analysis of the Effect of Emotional Speech Synthesis on Non-Task-Oriented Dialogue System,"Chiba, Yuya  and
Nose, Takashi  and
Kase, Taketo  and
Yamanaka, Mai  and
Ito, Akinori",2018,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,10.18653/v1/W18-5044,"This paper explores the effect of emotional speech synthesis on a spoken dialogue system when the dialogue is non-task-oriented. Although the use of emotional speech responses have been shown to be effective in a limited domain, e.g., scenario-based and counseling dialogue, the effect is still not clear in the non-task-oriented dialogue such as voice chatting. For this purpose, we constructed a simple dialogue system with example- and rule-based dialogue management. In the system, two types of emotion labeling with emotion estimation are adopted, i.e., system-driven and user-cooperative emotion labeling. We conducted a dialogue experiment where subjects evaluate the subjective quality of the system and the dialogue from the multiple aspects such as richness of the dialogue and impression of the agent. We then analyze and discuss the results and show the advantage of using appropriate emotions for the expressive speech responses in the non-task-oriented system.",https://aclanthology.org/W18-5044,emotion,No,No,No
{S}ocial{NLP} 2018 {E}motion{X} Challenge Overview: Recognizing Emotions in Dialogues,"Hsu, Chao-Chun  and
Ku, Lun-Wei",2018,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,10.18653/v1/W18-3505,"This paper describes an overview of the Dialogue Emotion Recognition Challenge, EmotionX, at the Sixth SocialNLP Workshop, which recognizes the emotion of each utterance in dialogues. This challenge offers the EmotionLines dataset as the experimental materials. The EmotionLines dataset contains conversations from Friends TV show transcripts (Friends) and real chatting logs (EmotionPush), where every dialogue utterance is labeled with emotions. Organizers provide baseline results. 18 teams registered in this challenge and 5 of them submitted their results successfully. The best team achieves the unweighted accuracy 62.48 and 62.5 on EmotionPush and Friends, respectively. In this paper we present the task definition, test collection, the evaluation results of the groups that participated in this challenge, and their approach.",https://aclanthology.org/W18-3505,emotion,Yes,No,Yes
{E}motion{X}-{DLC}: Self-Attentive {B}i{LSTM} for Detecting Sequential Emotions in Dialogues,"Luo, Linkai  and
Yang, Haiqin  and
Chin, Francis Y. L.",2018,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,10.18653/v1/W18-3506,"In this paper, we propose a self-attentive bidirectional long short-term memory (SA-BiLSTM) network to predict multiple emotions for the EmotionX challenge. The BiLSTM exhibits the power of modeling the word dependencies, and extracting the most relevant features for emotion classification. Building on top of BiLSTM, the self-attentive network can model the contextual dependencies between utterances which are helpful for classifying the ambiguous emotions. We achieve 59.6 and 55.0 unweighted accuracy scores in the Friends and the EmotionPush test sets, respectively.",https://aclanthology.org/W18-3506,emotion,No,Yes,No
{E}motion{X}-{AR}: {CNN}-{DCNN} autoencoder based Emotion Classifier,"Khosla, Sopan",2018,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,10.18653/v1/W18-3507,"In this paper, we model emotions in EmotionLines dataset using a convolutional-deconvolutional autoencoder (CNN-DCNN) framework. We show that adding a joint reconstruction loss improves performance. Quantitative evaluation with jointly trained network, augmented with linguistic features, reports best accuracies for emotion prediction; namely joy, sadness, anger, and neutral emotion in text.",https://aclanthology.org/W18-3507,emotion,Yes,Yes,No
{E}motion{X}-{S}mart{D}ubai{\_}{NLP}: Detecting User Emotions In Social Media Text,"AlBalooshi, Hessa  and
Rahmanian, Shahram  and
Venkatesh Kumar, Rahul",2018,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,10.18653/v1/W18-3508,"This paper describes the working note on {``}EmotionX{''} shared task. It is hosted by SocialNLP 2018. The objective of this task is to detect the emotions, based on each speaker{'}s utterances that are in English. Taking this as multiclass text classification problem, we have experimented to develop a model to classify the target class. The primary challenge in this task is to detect the emotions in short messages, communicated through social media. This paper describes the participation of SmartDubai{\_}NLP team in EmotionX shared task and our investigation to detect the emotions from utterance using Neural networks and Natural language understanding.",https://aclanthology.org/W18-3508,emotion,No,Yes,Yes
{E}motion{X}-Area66: Predicting Emotions in Dialogues using Hierarchical Attention Network with Sequence Labeling,"Saxena, Rohit  and
Bhat, Savita  and
Pedanekar, Niranjan",2018,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,10.18653/v1/W18-3509,"This paper presents our system submitted to the EmotionX challenge. It is an emotion detection task on dialogues in the EmotionLines dataset. We formulate this as a hierarchical network where network learns data representation at both utterance level and dialogue level. Our model is inspired by Hierarchical Attention network (HAN) and uses pre-trained word embeddings as features. We formulate emotion detection in dialogues as a sequence labeling problem to capture the dependencies among labels. We report the performance accuracy for four emotions (anger, joy, neutral and sadness). The model achieved unweighted accuracy of 55.38{\%} on Friends test dataset and 56.73{\%} on EmotionPush test dataset. We report an improvement of 22.51{\%} in Friends dataset and 36.04{\%} in EmotionPush dataset over baseline results.",https://aclanthology.org/W18-3509,emotion,Yes,Yes,No
{E}motion{X}-{JTML}: Detecting emotions with Attention,"Torres, Johnny",2018,Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media,10.18653/v1/W18-3510,"This paper addresses the problem of automatic recognition of emotions in conversational text datasets for the EmotionX challenge. Emotion is a human characteristic expressed through several modalities (e.g., auditory, visual, tactile). Trying to detect emotions only from the text becomes a difficult task even for humans. This paper evaluates several neural architectures based on Attention Models, which allow extracting relevant parts of the context within a conversation to identify the emotion associated with each utterance. Empirical results in the validation datasets demonstrate the effectiveness of the approach compared to the reference models for some instances, and other cases show better results with simpler models.",https://aclanthology.org/W18-3510,emotion,No,Yes,No
Recognizing Emotions in Video Using Multimodal {DNN} Feature Fusion,"Williams, Jennifer  and
Kleinegesse, Steven  and
Comanescu, Ramona  and
Radu, Oana",2018,Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-{HML}),10.18653/v1/W18-3302,"We present our system description of input-level multimodal fusion of audio, video, and text for recognition of emotions and their intensities for the 2018 First Grand Challenge on Computational Modeling of Human Multimodal Language. Our proposed approach is based on input-level feature fusion with sequence learning from Bidirectional Long-Short Term Memory (BLSTM) deep neural networks (DNNs). We show that our fusion approach outperforms unimodal predictors. Our system performs 6-way simultaneous classification and regression, allowing for overlapping emotion labels in a video segment. This leads to an overall binary accuracy of 90{\%}, overall 4-class accuracy of 89.2{\%} and an overall mean-absolute-error (MAE) of 0.12. Our work shows that an early fusion technique can effectively predict the presence of multi-label emotions as well as their coarse-grained intensities. The presented multimodal approach creates a simple and robust baseline on this new Grand Challenge dataset. Furthermore, we provide a detailed analysis of emotion intensity distributions as output from our DNN, as well as a related discussion concerning the inherent difficulty of this task.",https://aclanthology.org/W18-3302,emotion,Yes,Yes,No
Multimodal Relational Tensor Network for Sentiment and Emotion Classification,"Sahay, Saurav  and
Kumar, Shachi H  and
Xia, Rui  and
Huang, Jonathan  and
Nachman, Lama",2018,Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-{HML}),10.18653/v1/W18-3303,"Understanding Affect from video segments has brought researchers from the language, audio and video domains together. Most of the current multimodal research in this area deals with various techniques to fuse the modalities, and mostly treat the segments of a video independently. Motivated by the work of (Zadeh et al., 2017) and (Poria et al., 2017), we present our architecture, Relational Tensor Network, where we use the inter-modal interactions within a segment (intra-segment) and also consider the sequence of segments in a video to model the inter-segment inter-modal interactions. We also generate rich representations of text and audio modalities by leveraging richer audio and linguistic context alongwith fusing fine-grained knowledge based polarity scores from text. We present the results of our model on CMU-MOSEI dataset and show that our model outperforms many baselines and state of the art methods for sentiment classification and emotion recognition.",https://aclanthology.org/W18-3303,emotion,Yes,Yes,No
Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data,"Choi, Woo Yong  and
Song, Kyu Ye  and
Lee, Chan Woo",2018,Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-{HML}),10.18653/v1/W18-3304,"Emotion recognition has become a popular topic of interest, especially in the field of human computer interaction. Previous works involve unimodal analysis of emotion, while recent efforts focus on multimodal emotion recognition from vision and speech. In this paper, we propose a new method of learning about the hidden representations between just speech and text data using convolutional attention networks. Compared to the shallow model which employs simple concatenation of feature vectors, the proposed attention model performs much better in classifying emotion from speech and text data contained in the CMU-MOSEI dataset.",https://aclanthology.org/W18-3304,emotion,Yes,Yes,No
{ASR}-based Features for Emotion Recognition: A Transfer Learning Approach,"Tits, No{\'e}  and
El Haddad, Kevin  and
Dutoit, Thierry",2018,Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-{HML}),10.18653/v1/W18-3307,"During the last decade, the applications of signal processing have drastically improved with deep learning. However areas of affecting computing such as emotional speech synthesis or emotion recognition from spoken language remains challenging. In this paper, we investigate the use of a neural Automatic Speech Recognition (ASR) as a feature extractor for emotion recognition. We show that these features outperform the eGeMAPS feature set to predict the valence and arousal emotional dimensions, which means that the audio-to-text mapping learned by the ASR system contains information related to the emotional dimensions in spontaneous speech. We also examine the relationship between first layers (closer to speech) and last layers (closer to text) of the ASR and valence/arousal.",https://aclanthology.org/W18-3307,emotion,No,Yes,No
Social and Emotional Correlates of Capitalization on {T}witter,"Chan, Sophia  and
Fyshe, Alona",2018,"Proceedings of the Second Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media",10.18653/v1/W18-1102,"Social media text is replete with unusual capitalization patterns. We posit that capitalizing a token like THIS performs two expressive functions: it marks a person socially, and marks certain parts of an utterance as more salient than others. Focusing on gender and sentiment, we illustrate using a corpus of tweets that capitalization appears in more negative than positive contexts, and is used more by females compared to males. Yet we find that both genders use capitalization in a similar way when expressing sentiment.",https://aclanthology.org/W18-1102,emotion,Yes,No,No
Enabling Deep Learning of Emotion With First-Person Seed Expressions,"Alhuzali, Hassan  and
Abdul-Mageed, Muhammad  and
Ungar, Lyle",2018,"Proceedings of the Second Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media",10.18653/v1/W18-1104,"The computational treatment of emotion in natural language text remains relatively limited, and Arabic is no exception. This is partly due to lack of labeled data. In this work, we describe and manually validate a method for the automatic acquisition of emotion labeled data and introduce a newly developed data set for Modern Standard and Dialectal Arabic emotion detection focused at Robert Plutchik{'}s 8 basic emotion types. Using a hybrid supervision method that exploits first person emotion seeds, we show how we can acquire promising results with a deep gated recurrent neural network. Our best model reaches 70{\%} \textit{F}-score, significantly (i.e., 11{\%}, $p < 0.05$) outperforming a competitive baseline. Applying our method and data on an external dataset of 4 emotions released around the same time we finalized our work, we acquire 7{\%} absolute gain in $F$-score over a linear SVM classifier trained on gold data, thus validating our approach.",https://aclanthology.org/W18-1104,emotion,Yes,Yes,No
{E}mo{W}ord{N}et: Automatic Expansion of Emotion Lexicon Using {E}nglish {W}ord{N}et,"Badaro, Gilbert  and
Jundi, Hussein  and
Hajj, Hazem  and
El-Hajj, Wassim",2018,Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics,10.18653/v1/S18-2009,"Nowadays, social media have become a platform where people can easily express their opinions and emotions about any topic such as politics, movies, music, electronic products and many others. On the other hand, politicians, companies, and businesses are interested in analyzing automatically people{'}s opinions and emotions. In the last decade, a lot of efforts has been put into extracting sentiment polarity from texts. Recently, the focus has expanded to also cover emotion recognition from texts. In this work, we expand an existing emotion lexicon, DepecheMood, by leveraging semantic knowledge from English WordNet (EWN). We create an expanded lexicon, EmoWordNet, consisting of 67K terms aligned with EWN, almost 1.8 times the size of DepecheMood. We also evaluate EmoWordNet in an emotion recognition task using SemEval 2007 news headlines dataset and we achieve an improvement compared to the use of DepecheMood. EmoWordNet is publicly available to speed up research in the field on \url{http://oma-project.com}.",https://aclanthology.org/S18-2009,emotion,Yes,No,No
{NLPZZX} at {S}em{E}val-2018 Task 1: Using Ensemble Method for Emotion and Sentiment Intensity Determination,"Zhang, Zhengxin  and
Zhou, Qimin  and
Wu, Hao",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1015,"In this paper, we put forward a system that competed at SemEval-2018 Task 1: {``}Affect in Tweets{''}. Our system uses a simple yet effective ensemble method which combines several neural network components. We participate in two subtasks for English tweets: EI-reg and V-reg. For two subtasks, different combinations of neural components are examined. For EI-reg, our system achieves an accuracy of 0.727 in Pearson Correlation Coefficient (all instances) and an accuracy of 0.555 in Pearson Correlation Coefficient (0.5-1). For V-reg, the achieved accuracy scores are respectively 0.835 and 0.670",https://aclanthology.org/S18-1015,emotion,No,Yes,No
{LT}3 at {S}em{E}val-2018 Task 1: A classifier chain to detect emotions in tweets,"De Bruyne, Luna  and
De Clercq, Orph{\'e}e  and
Hoste, V{\'e}ronique",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1016,"This paper presents an emotion classification system for English tweets, submitted for the SemEval shared task on Affect in Tweets, subtask 5: Detecting Emotions. The system combines lexicon, n-gram, style, syntactic and semantic features. For this multi-class multi-label problem, we created a classifier chain. This is an ensemble of eleven binary classifiers, one for each possible emotion category, where each model gets the predictions of the preceding models as additional features. The predicted labels are combined to get a multi-label representation of the predictions. Our system was ranked eleventh among thirty five participating teams, with a Jaccard accuracy of 52.0{\%} and macro- and micro-average F1-scores of 49.3{\%} and 64.0{\%}, respectively.",https://aclanthology.org/S18-1016,emotion,No,Yes,No
{SINAI} at {S}em{E}val-2018 Task 1: Emotion Recognition in Tweets,"Plaza-del-Arco, Flor Miriam  and
Jim{\'e}nez-Zafra, Salud Mar{\'\i}a  and
Martin, Maite  and
Ure{\~n}a-L{\'o}pez, L. Alfonso",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1017,"Emotion classification is a new task that combines several disciplines including Artificial Intelligence and Psychology, although Natural Language Processing is perhaps the most challenging area. In this paper, we describe our participation in SemEval-2018 Task1: Affect in Tweets. In particular, we have participated in EI-oc, EI-reg and E-c subtasks for English and Spanish languages.",https://aclanthology.org/S18-1017,emotion,No,Yes,Yes
{UWB} at {S}em{E}val-2018 Task 1: Emotion Intensity Detection in Tweets,"P{\v{r}}ib{\'a}{\v{n}}, Pavel  and
Hercig, Tom{\'a}{\v{s}}  and
Lenc, Ladislav",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1018,"This paper describes our system created for the SemEval-2018 Task 1: Affect in Tweets (AIT-2018). We participated in both the regression and the ordinal classification subtasks for emotion intensity detection in English, Arabic, and Spanish. For the regression subtask we use the AffectiveTweets system with added features using various word embeddings, lexicons, and LDA. For the ordinal classification we additionally use our Brainy system with features using parse tree, POS tags, and morphological features. The most beneficial features apart from word and character n-grams include word embeddings, POS count and morphological features.",https://aclanthology.org/S18-1018,emotion,No,Yes,No
{A}ttn{C}onvnet at {S}em{E}val-2018 Task 1: Attention-based Convolutional Neural Networks for Multi-label Emotion Classification,"Kim, Yanghoon  and
Lee, Hwanhee  and
Jung, Kyomin",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1019,"In this paper, we propose an attention-based classifier that predicts multiple emotions of a given sentence. Our model imitates human{'}s two-step procedure of sentence understanding and it can effectively represent and classify sentences. With emoji-to-meaning preprocessing and extra lexicon utilization, we further improve the model performance. We train and evaluate our model with data provided by SemEval-2018 task 1-5, each sentence of which has several labels among 11 given emotions. Our model achieves 5th/1st rank in English/Spanish respectively.",https://aclanthology.org/S18-1019,emotion,No,Yes,No
Tw-{S}t{AR} at {S}em{E}val-2018 Task 1: Preprocessing Impact on Multi-label Emotion Classification,"Mulki, Hala  and
Bechikh Ali, Chedi  and
Haddad, Hatem  and
Babao{\u{g}}lu, Ismail",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1024,"In this paper, we describe our contribution in SemEval-2018 contest. We tackled task 1 {``}Affect in Tweets{''}, subtask E-c {``}Detecting Emotions (multi-label classification){''}. A multilabel classification system Tw-StAR was developed to recognize the emotions embedded in Arabic, English and Spanish tweets. To handle the multi-label classification problem via traditional classifiers, we employed the binary relevance transformation strategy while a TF-IDF scheme was used to generate the tweets{'} features. We investigated using single and combinations of several preprocessing tasks to further improve the performance. The results showed that specific combinations of preprocessing tasks could significantly improve the evaluation measures. This has been later emphasized by the official results as our system ranked 3rd for both Arabic and Spanish datasets and 14th for the English dataset.",https://aclanthology.org/S18-1024,emotion,Yes,Yes,No
{E}mo{I}ntens Tracker at {S}em{E}val-2018 Task 1: Emotional Intensity Levels in {\#}Tweets,"Turcu, Ramona-Andreea  and
Amarandei, Sandra Maria  and
Flescan-Lovin-Arseni, Iuliana-Alexandra  and
Gifu, Daniela  and
Trandabat, Diana",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1026,"The Affect in Tweets{''} task is centered on emotions categorization and evaluation matrix using multi-language tweets (English and Spanish). In this research, SemEval Affect dataset was preprocessed, categorized, and evaluated accordingly (precision, recall, and accuracy). The system described in this paper is based on the implementation of supervised machine learning (Naive Bayes, KNN and SVM), deep learning (NN Tensor Flow model), and decision trees algorithms.",https://aclanthology.org/S18-1026,emotion,Yes,Yes,No
{E}i{TAKA} at {S}em{E}val-2018 Task 1: An Ensemble of N-Channels {C}onv{N}et and {XG}boost Regressors for Emotion Analysis of Tweets,"Jabreel, Mohammed  and
Moreno, Antonio",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1029,"This paper describes our system that has been used in Task1 Affect in Tweets. We combine two different approaches. The first one called N-Stream ConvNets, which is a deep learning approach where the second one is XGboost regressor based on a set of embedding and lexicons based features. Our system was evaluated on the testing sets of the tasks outperforming all other approaches for the Arabic version of valence intensity regression task and valence ordinal classification task.",https://aclanthology.org/S18-1029,emotion,No,Yes,No
Yuan at {S}em{E}val-2018 Task 1: Tweets Emotion Intensity Prediction using Ensemble Recurrent Neural Network,"Wang, Min  and
Zhou, Xiaobing",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1031,We perform the LSTM and BiLSTM model for the emotion intensity prediction. We only join the third subtask in Task 1:Affect in Tweets. Our system rank 6th among all the teams.,https://aclanthology.org/S18-1031,emotion,No,Yes,No
{ECNU} at {S}em{E}val-2018 Task 1: Emotion Intensity Prediction Using Effective Features and Machine Learning Models,"Xu, Huimin  and
Lan, Man  and
Wu, Yuanbin",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1035,"This paper describes our submissions to SemEval 2018 task 1. The task is affect intensity prediction in tweets, including five subtasks. We participated in all subtasks of English tweets. We extracted several traditional NLP, sentiment lexicon, emotion lexicon and domain specific features from tweets, adopted supervised machine learning algorithms to perform emotion intensity prediction.",https://aclanthology.org/S18-1035,emotion,No,Yes,Yes
{EMA} at {S}em{E}val-2018 Task 1: Emotion Mining for {A}rabic,"Badaro, Gilbert  and
El Jundi, Obeida  and
Khaddaj, Alaa  and
Maarouf, Alaa  and
Kain, Raslan  and
Hajj, Hazem  and
El-Hajj, Wassim",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1036,"While significant progress has been achieved for Opinion Mining in Arabic (OMA), very limited efforts have been put towards the task of Emotion mining in Arabic. In fact, businesses are interested in learning a fine-grained representation of how users are feeling towards their products or services. In this work, we describe the methods used by the team Emotion Mining in Arabic (EMA), as part of the SemEval-2018 Task 1 for Affect Mining for Arabic tweets. EMA participated in all 5 subtasks. For the five tasks, several preprocessing steps were evaluated and eventually the best system included diacritics removal, elongation adjustment, replacement of emojis by the corresponding Arabic word, character normalization and light stemming. Moreover, several features were evaluated along with different classification and regression techniques. For the 5 subtasks, word embeddings feature turned out to perform best along with Ensemble technique. EMA achieved the 1st place in subtask 5, and 3rd place in subtasks 1 and 3.",https://aclanthology.org/S18-1036,emotion,No,Yes,No
{C}rystal{F}eel at {S}em{E}val-2018 Task 1: Understanding and Detecting Emotion Intensity using Affective Lexicons,"Gupta, Raj Kumar  and
Yang, Yinping",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1038,"While sentiment and emotion analysis has received a considerable amount of research attention, the notion of understanding and detecting the intensity of emotions is relatively less explored. This paper describes a system developed for predicting emotion intensity in tweets. Given a Twitter message, CrystalFeel uses features derived from parts-of-speech, n-grams, word embedding, and multiple affective lexicons including Opinion Lexicon, SentiStrength, AFFIN, NRC Emotion {\&} Hash Emotion, and our in-house developed EI Lexicons to predict the degree of the intensity associated with fear, anger, sadness, and joy in the tweet. We found that including the affective lexicons-based features allowed the system to obtain strong prediction performance, while revealing interesting emotion word-level and message-level associations. On gold test data, CrystalFeel obtained Pearson correlations of 0.717 on average emotion intensity and of 0.816 on sentiment intensity.",https://aclanthology.org/S18-1038,emotion,No,Yes,No
{P}lus{E}mo2{V}ec at {S}em{E}val-2018 Task 1: Exploiting emotion knowledge from emoji and {\#}hashtags,"Park, Ji Ho  and
Xu, Peng  and
Fung, Pascale",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1039,This paper describes our system that has been submitted to SemEval-2018 Task 1: Affect in Tweets (AIT) to solve five subtasks. We focus on modeling both sentence and word level representations of emotion inside texts through large distantly labeled corpora with emojis and hashtags. We transfer the emotional knowledge by exploiting neural network models as feature extractors and use these representations for traditional machine learning models such as support vector regression (SVR) and logistic regression to solve the competition tasks. Our system is placed among the Top3 for all subtasks we participated.,https://aclanthology.org/S18-1039,emotion,Yes,Yes,No
{UG}18 at {S}em{E}val-2018 Task 1: Generating Additional Training Data for Predicting Emotion Intensity in {S}panish,"Kuijper, Marloes  and
van Lenthe, Mike  and
van Noord, Rik",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1041,"The present study describes our submission to SemEval 2018 Task 1: Affect in Tweets. Our Spanish-only approach aimed to demonstrate that it is beneficial to automatically generate additional training data by (i) translating training data from other languages and (ii) applying a semi-supervised learning method. We find strong support for both approaches, with those models outperforming our regular models in all subtasks. However, creating a stepwise ensemble of different models as opposed to simply averaging did not result in an increase in performance. We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc) in the four Spanish subtasks we participated in.",https://aclanthology.org/S18-1041,emotion,No,Yes,No
{DMCB} at {S}em{E}val-2018 Task 1: Transfer Learning of Sentiment Classification Using Group {LSTM} for Emotion Intensity prediction,"Kim, Youngmin  and
Lee, Hyunju",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1044,"This paper describes a system attended in the SemEval-2018 Task 1 {``}Affect in tweets{''} that predicts emotional intensities. We use Group LSTM with an attention model and transfer learning with sentiment classification data as a source data (SemEval 2017 Task 4a). A transfer model structure consists of a source domain and a target domain. Additionally, we try a new dropout that is applied to LSTMs in the Group LSTM. Our system ranked 8th at the subtask 1a (emotion intensity regression). We also show various results with different architectures in the source, target and transfer models.",https://aclanthology.org/S18-1044,emotion,No,Yes,No
{D}eep{M}iner at {S}em{E}val-2018 Task 1: Emotion Intensity Recognition Using Deep Representation Learning,"Naderi, Habibeh  and
Haji Soleimani, Behrouz  and
Mohammad, Saif  and
Kiritchenko, Svetlana  and
Matwin, Stan",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1045,"In this paper, we propose a regression system to infer the emotion intensity of a tweet. We develop a multi-aspect feature learning mechanism to capture the most discriminative semantic features of a tweet as well as the emotion information conveyed by each word in it. We combine six types of feature groups: (1) a tweet representation learned by an LSTM deep neural network on the training data, (2) a tweet representation learned by an LSTM network on a large corpus of tweets that contain emotion words (a distant supervision corpus), (3) word embeddings trained on the distant supervision corpus and averaged over all words in a tweet, (4) word and character n-grams, (5) features derived from various sentiment and emotion lexicons, and (6) other hand-crafted features. As part of the word embedding training, we also learn the distributed representations of multi-word expressions (MWEs) and negated forms of words. An SVR regressor is then trained over the full set of features. We evaluate the effectiveness of our ensemble feature sets on the SemEval-2018 Task 1 datasets and achieve a Pearson correlation of 72{\%} on the task of tweet emotion intensity prediction.",https://aclanthology.org/S18-1045,emotion,Yes,Yes,No
{SSN} {MLRG}1 at {S}em{E}val-2018 Task 1: Emotion and Sentiment Intensity Detection Using Rule Based Feature Selection,"S, Angel Deborah  and
S, Rajalakshmi  and
Rajendram, S Milton  and
T T, Mirnalinee",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1048,"The system developed by the SSN MLRG1 team for Semeval-2018 task 1 on affect in tweets uses rule based feature selection and one-hot encoding to generate the input feature vector. Multilayer Perceptron was used to build the model for emotion intensity ordinal classification, sentiment analysis ordinal classification and emotion classfication subtasks. Support Vector Machine was used to build the model for emotion intensity regression and sentiment intensity regression subtasks.",https://aclanthology.org/S18-1048,emotion,No,Yes,No
{T}eam{CEN} at {S}em{E}val-2018 Task 1: Global Vectors Representation in Emotion Detection,"George, Anon  and
Ganesh H. B., Barathi  and
Kumar M, Anand  and
K P, Soman",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1050,"Emotions are a way of expressing human sentiments. In the modern era, social media is a platform where we convey our emotions. These emotions can be joy, anger, sadness and fear. Understanding the emotions from the written sentences is an interesting part in knowing about the writer. In the amount of digital language shared through social media, a considerable amount of data reflects the sentiment or emotion towards some product, person and organization. Since these texts are from users with diverse social aspects, these texts can be used to enrich the application related to the business intelligence. More than the sentiment, identification of intensity of the sentiment will enrich the performance of the end application. In this paper we experimented the intensity prediction as a text classification problem that evaluates the distributed representation text using aggregated sum and dimensionality reduction of the glove vectors of the words present in the respective texts .",https://aclanthology.org/S18-1050,emotion,No,Yes,No
{IIT} {D}elhi at {S}em{E}val-2018 Task 1 : Emotion Intensity Prediction,"Kotakonda, Bhaskar  and
Gowda, Prashanth  and
Lall, Brejesh",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1051,"This paper discusses the experiments performed for predicting the emotion intensity in tweets using a generalized supervised learning approach. We extract 3 kind of features from each of the tweets - one denoting the sentiment and emotion metrics obtained from different sentiment lexicons, one denoting the semantic representation of the word using dense representations like Glove, Word2vec and finally the syntactic information through POS N-grams, Word clusters, etc. We provide a comparative analysis of the significance of each of these features individually and in combination tested over standard regressors avaliable in scikit-learn. We apply an ensemble of these models to choose the best combination over cross validation.",https://aclanthology.org/S18-1051,emotion,No,Yes,No
Mutux at {S}em{E}val-2018 Task 1: Exploring Impacts of Context Information On Emotion Detection,"Du, Pan  and
Nie, Jian-Yun",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1052,"This paper describes MuTuX, our system that is designed for task 1-5a, emotion classification analysis of tweets on SemEval2018. The system aims at exploring the potential of context information of terms for emotion analysis. A Recurrent Neural Network is adopted to capture the context information of terms in tweets. Only term features and the sequential relations are used in our system. The results submitted ranks 16th out of 35 systems on the task of emotion detection in English-language tweets.",https://aclanthology.org/S18-1052,emotion,No,Yes,No
{T}eam{UNCC} at {S}em{E}val-2018 Task 1: Emotion Detection in {E}nglish and {A}rabic Tweets using Deep Learning,"Abdullah, Malak  and
Shaikh, Samira",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1053,"Task 1 in the International Workshop SemEval 2018, Affect in Tweets, introduces five subtasks (El-reg, El-oc, V-reg, V-oc, and E-c) to detect the intensity of emotions in English, Arabic, and Spanish tweets. This paper describes TeamUNCC{'}s system to detect emotions in English and Arabic tweets. Our approach is novel in that we present the same architecture for all the five subtasks in both English and Arabic. The main input to the system is a combination of word2vec and doc2vec embeddings and a set of psycholinguistic features (e.g. from AffectTweets Weka-package). We apply a fully connected neural network architecture and obtain performance results that show substantial improvements in Spearman correlation scores over the baseline models provided by Task 1 organizers, (ranging from 0.03 to 0.23). TeamUNCC{'}s system ranks third in subtask El-oc and fourth in other subtasks for Arabic tweets.",https://aclanthology.org/S18-1053,emotion,No,Yes,No
psy{ML} at {S}em{E}val-2018 Task 1: Transfer Learning for Sentiment and Emotion Analysis,"Gee, Grace  and
Wang, Eugene",2018,Proceedings of the 12th International Workshop on Semantic Evaluation,10.18653/v1/S18-1056,"In this paper, we describe the first attempt to perform transfer learning from sentiment to emotions. Our system employs Long Short-Term Memory (LSTM) networks, including bidirectional LSTM (biLSTM) and LSTM with attention mechanism. We perform transfer learning by first pre-training the LSTM networks on sentiment data before concatenating the penultimate layers of these networks into a single vector as input to new dense layers. For the E-c subtask, we utilize a novel approach to train models for correlated emotion classes. Our system performs 4/48, 3/39, 8/38, 4/37, 4/35 on all English subtasks EI-reg, EI-oc, V-reg, V-oc, E-c of SemEval 2018 Task 1: Affect in Tweets.",https://aclanthology.org/S18-1056,emotion,No,Yes,No
{M}oji{T}alk: Generating Emotional Responses at Scale,"Zhou, Xianda  and
Wang, William Yang",2018,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/P18-1104,"Generating emotional language is a key step towards building empathetic natural language processing agents. However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels. Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult. In this paper, we take a more radical approach: we exploit the idea of leveraging Twitter data that are naturally labeled with emojis. We collect a large corpus of Twitter conversations that include emojis in the response and assume the emojis convey the underlying emotions of the sentence. We investigate several conditional variational autoencoders training on these conversations, which allow us to use emojis to control the emotion of the generated text. Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate high-quality abstractive conversation responses in accordance with designated emotions.",https://aclanthology.org/P18-1104,emotion,Yes,Yes,Yes
Corpus Creation and Emotion Prediction for {H}indi-{E}nglish Code-Mixed Social Media Text,"Vijay, Deepanshu  and
Bohra, Aditya  and
Singh, Vinay  and
Akhtar, Syed Sarfaraz  and
Shrivastava, Manish",2018,Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Student Research Workshop,10.18653/v1/N18-4018,"Emotion Prediction is a Natural Language Processing (NLP) task dealing with detection and classification of emotions in various monolingual and bilingual texts. While some work has been done on code-mixed social media text and in emotion prediction separately, our work is the first attempt which aims at identifying the emotion associated with Hindi-English code-mixed social media text. In this paper, we analyze the problem of emotion identification in code-mixed content and present a Hindi-English code-mixed corpus extracted from twitter and annotated with the associated emotion. For every tweet in the dataset, we annotate the source language of all the words present, and also the causal language of the expressed emotion. Finally, we propose a supervised classification system which uses various machine learning techniques for detecting the emotion associated with the text using a variety of character level, word level, and lexicon based features.",https://aclanthology.org/N18-4018,emotion,Yes,Yes,Yes
Automatic Dialogue Generation with Expressed Emotions,"Huang, Chenyang  and
Za{\""\i}ane, Osmar  and
Trabelsi, Amine  and
Dziri, Nouha",2018,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",10.18653/v1/N18-2008,"Despite myriad efforts in the literature designing neural dialogue generation systems in recent years, very few consider putting restrictions on the response itself. They learn from collections of past responses and generate one based on a given utterance without considering, speech act, desired style or emotion to be expressed. In this research, we address the problem of forcing the dialogue generation to express emotion. We present three models that either concatenate the desired emotion with the source input during the learning, or push the emotion in the decoder. The results, evaluated with an emotion tagger, are encouraging with all three models, but present better outcome and promise with our model that adds the emotion vector in the decoder.",https://aclanthology.org/N18-2008,emotion,No,Yes,No
Letting Emotions Flow: Success Prediction by Modeling the Flow of Emotions in Books,"Maharjan, Suraj  and
Kar, Sudipta  and
Montes, Manuel  and
Gonz{\'a}lez, Fabio A.  and
Solorio, Thamar",2018,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",10.18653/v1/N18-2042,"Books have the power to make us feel happiness, sadness, pain, surprise, or sorrow. An author{'}s dexterity in the use of these emotions captivates readers and makes it difficult for them to put the book down. In this paper, we model the flow of emotions over a book using recurrent neural networks and quantify its usefulness in predicting success in books. We obtained the best weighted F1-score of 69{\%} for predicting books{'} success in a multitask setting (simultaneously predicting success and genre of books).",https://aclanthology.org/N18-2042,emotion,No,Yes,No
Relevant Emotion Ranking from Text Constrained with Emotion Relationships,"Zhou, Deyu  and
Yang, Yang  and
He, Yulan",2018,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",10.18653/v1/N18-1052,"Text might contain or invoke multiple emotions with varying intensities. As such, emotion detection, to predict multiple emotions associated with a given text, can be cast into a multi-label classification problem. We would like to go one step further so that a ranked list of relevant emotions are generated where top ranked emotions are more intensely associated with text compared to lower ranked emotions, whereas the rankings of irrelevant emotions are not important. A novel framework of relevant emotion ranking is proposed to tackle the problem. In the framework, the objective loss function is designed elaborately so that both emotion prediction and rankings of only relevant emotions can be achieved. Moreover, we observe that some emotions co-occur more often while other emotions rarely co-exist. Such information is incorporated into the framework as constraints to improve the accuracy of emotion detection. Experimental results on two real-world corpora show that the proposed framework can effectively deal with emotion detection and performs remarkably better than the state-of-the-art emotion detection approaches and multi-label learning methods.",https://aclanthology.org/N18-1052,emotion,No,Yes,No
Word Emotion Induction for Multiple Languages as a Deep Multi-Task Learning Problem,"Buechel, Sven  and
Hahn, Udo",2018,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",10.18653/v1/N18-1173,"Predicting the emotional value of lexical items is a well-known problem in sentiment analysis. While research has focused on polarity for quite a long time, meanwhile this early focus has been shifted to more expressive emotion representation models (such as Basic Emotions or Valence-Arousal-Dominance). This change resulted in a proliferation of heterogeneous formats and, in parallel, often small-sized, non-interoperable resources (lexicons and corpus annotations). In particular, the limitations in size hampered the application of deep learning methods in this area because they typically require large amounts of input data. We here present a solution to get around this language data bottleneck by rephrasing word emotion induction as a multi-task learning problem. In this approach, the prediction of each independent emotion dimension is considered as an individual task and hidden layers are shared between these dimensions. We investigate whether multi-task learning is more advantageous than single-task learning for emotion prediction by comparing our model against a wide range of alternative emotion and polarity induction methods featuring 9 typologically diverse languages and a total of 15 conditions. Our model turns out to outperform each one of them. Against all odds, the proposed deep learning approach yields the largest gain on the smallest data sets, merely composed of one thousand samples.",https://aclanthology.org/N18-1173,emotion,Yes,Yes,No
Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos,"Hazarika, Devamanyu  and
Poria, Soujanya  and
Zadeh, Amir  and
Cambria, Erik  and
Morency, Louis-Philippe  and
Zimmermann, Roger",2018,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",10.18653/v1/N18-1193,"Emotion recognition in conversations is crucial for the development of empathetic machines. Present methods mostly ignore the role of inter-speaker dependency relations while classifying emotions in conversations. In this paper, we address recognizing utterance-level emotions in dyadic conversational videos. We propose a deep neural framework, termed Conversational Memory Network (CMN), which leverages contextual information from the conversation history. In particular, CMN uses multimodal approach comprising audio, visual and textual features with gated recurrent units to model past utterances of each speaker into memories. These memories are then merged using attention-based hops to capture inter-speaker dependencies. Experiments show a significant improvement of 3  4{\%} in accuracy over the state of the art.",https://aclanthology.org/N18-1193,emotion,No,Yes,No
Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition,"Beard, Rory  and
Das, Ritwik  and
Ng, Raymond W. M.  and
Gopalakrishnan, P. G. Keerthana  and
Eerens, Luka  and
Swietojanski, Pawel  and
Miksik, Ondrej",2018,Proceedings of the 22nd Conference on Computational Natural Language Learning,10.18653/v1/K18-1025,"Natural human communication is nuanced and inherently multi-modal. Humans possess specialised sensoria for processing vocal, visual, and linguistic, and para-linguistic information, but form an intricately fused percept of the multi-modal data stream to provide a holistic representation. Analysis of emotional content in face-to-face communication is a cognitive task to which humans are particularly attuned, given its sociological importance, and poses a difficult challenge for machine emulation due to the subtlety and expressive variability of cross-modal cues. Inspired by the empirical success of recent so-called End-To-End Memory Networks and related works, we propose an approach based on recursive multi-attention with a shared external memory updated over multiple gated iterations of analysis. We evaluate our model across several large multi-modal datasets and show that global contextualised memory with gated memory update can effectively achieve emotion recognition.",https://aclanthology.org/K18-1025,emotion,No,Yes,No
Joint Learning for Emotion Classification and Emotion Cause Detection,"Chen, Ying  and
Hou, Wenjun  and
Cheng, Xiyao  and
Li, Shoushan",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1066,"We present a neural network-based joint approach for emotion classification and emotion cause detection, which attempts to capture mutual benefits across the two sub-tasks of emotion analysis. Considering that emotion classification and emotion cause detection need different kinds of features (affective and event-based separately), we propose a joint encoder which uses a unified framework to extract features for both sub-tasks and a joint model trainer which simultaneously learns two models for the two sub-tasks separately. Our experiments on Chinese microblogs show that the joint approach is very promising.",https://aclanthology.org/D18-1066,emotion,No,Yes,No
A Syntactically Constrained Bidirectional-Asynchronous Approach for Emotional Conversation Generation,"Li, Jingyuan  and
Sun, Xiao",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1071,"Traditional neural language models tend to generate generic replies with poor logic and no emotion. In this paper, a syntactically constrained bidirectional-asynchronous approach for emotional conversation generation (E-SCBA) is proposed to address this issue. In our model, pre-generated emotion keywords and topic keywords are asynchronously introduced into the process of decoding. It is much different from most existing methods which generate replies from the first word to the last. Through experiments, the results indicate that our approach not only improves the diversity of replies, but gains a boost on both logic and emotion compared with baselines.",https://aclanthology.org/D18-1071,emotion,No,Yes,Yes
Improving Multi-label Emotion Classification via Sentiment Classification with Dual Attention Transfer Network,"Yu, Jianfei  and
Marujo, Lu{\'\i}s  and
Jiang, Jing  and
Karuturi, Pradeep  and
Brendel, William",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1137,"In this paper, we target at improving the performance of multi-label emotion classification with the help of sentiment classification. Specifically, we propose a new transfer learning architecture to divide the sentence representation into two different feature spaces, which are expected to respectively capture the general sentiment words and the other important emotion-specific words via a dual attention mechanism. Experimental results on two benchmark datasets demonstrate the effectiveness of our proposed method.",https://aclanthology.org/D18-1137,emotion,Yes,Yes,No
Fine-Grained Emotion Detection in Health-Related Online Posts,"Khanpour, Hamed  and
Caragea, Cornelia",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1147,"Detecting fine-grained emotions in online health communities provides insightful information about patients{'} emotional states. However, current computational approaches to emotion detection from health-related posts focus only on identifying messages that contain emotions, with no emphasis on the emotion type, using a set of handcrafted features. In this paper, we take a step further and propose to detect fine-grained emotion types from health-related posts and show how high-level and abstract features derived from deep neural networks combined with lexicon-based features can be employed to detect emotions.",https://aclanthology.org/D18-1147,emotion,No,Yes,No
{ICON}: Interactive Conversational Memory Network for Multimodal Emotion Detection,"Hazarika, Devamanyu  and
Poria, Soujanya  and
Mihalcea, Rada  and
Cambria, Erik  and
Zimmermann, Roger",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1280,"Emotion recognition in conversations is crucial for building empathetic machines. Present works in this domain do not explicitly consider the inter-personal influences that thrive in the emotional dynamics of dialogues. To this end, we propose Interactive COnversational memory Network (ICON), a multimodal emotion detection framework that extracts multimodal features from conversational videos and hierarchically models the self- and inter-speaker emotional influences into global memories. Such memories generate contextual summaries which aid in predicting the emotional orientation of utterance-videos. Our model outperforms state-of-the-art networks on multiple classification and regression tasks in two benchmark datasets.",https://aclanthology.org/D18-1280,emotion,Yes,Yes,No
An Interpretable Neural Network with Topical Information for Relevant Emotion Ranking,"Yang, Yang  and
Zhou, Deyu  and
He, Yulan",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1379,"Text might express or evoke multiple emotions with varying intensities. As such, it is crucial to predict and rank multiple relevant emotions by their intensities. Moreover, as emotions might be evoked by hidden topics, it is important to unveil and incorporate such topical information to understand how the emotions are evoked. We proposed a novel interpretable neural network approach for relevant emotion ranking. Specifically, motivated by transfer learning, the neural network is initialized to make the hidden layer approximate the behavior of topic models. Moreover, a novel error function is defined to optimize the whole neural network for relevant emotion ranking. Experimental results on three real-world corpora show that the proposed approach performs remarkably better than the state-of-the-art emotion detection approaches and multi-label learning methods. Moreover, the extracted emotion-associated topic words indeed represent emotion-evoking events and are in line with our common-sense knowledge.",https://aclanthology.org/D18-1379,emotion,No,Yes,No
{CARER}: Contextualized Affect Representations for Emotion Recognition,"Saravia, Elvis  and
Liu, Hsien-Chi Toby  and
Huang, Yen-Hao  and
Wu, Junlin  and
Chen, Yi-Shin",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1404,"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.",https://aclanthology.org/D18-1404,emotion,No,Yes,No
A Co-Attention Neural Network Model for Emotion Cause Analysis with Emotional Context Awareness,"Li, Xiangju  and
Song, Kaisong  and
Feng, Shi  and
Wang, Daling  and
Zhang, Yifei",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1506,"Emotion cause analysis has been a key topic in natural language processing. Existing methods ignore the contexts around the emotion word which can provide an emotion cause clue. Meanwhile, the clauses in a document play different roles on stimulating a certain emotion, depending on their content relevance. Therefore, we propose a co-attention neural network model for emotion cause analysis with emotional context awareness. The method encodes the clauses with a co-attention based bi-directional long short-term memory into high-level input representations, which are further fed into a convolutional layer for emotion cause analysis. Experimental results show that our approach outperforms the state-of-the-art baseline methods.",https://aclanthology.org/D18-1506,emotion,No,Yes,Yes
Modeling Empathy and Distress in Reaction to News Stories,"Buechel, Sven  and
Buffone, Anneke  and
Slaff, Barry  and
Ungar, Lyle  and
Sedoc, Jo{\~a}o",2018,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D18-1507,"Computational detection and understanding of empathy is an important factor in advancing human-computer interaction. Yet to date, text-based empathy prediction has the following major limitations: It underestimates the psychological complexity of the phenomenon, adheres to a weak notion of ground truth where empathic states are ascribed by third parties, and lacks a shared corpus. In contrast, this contribution presents the first publicly available gold standard for empathy prediction. It is constructed using a novel annotation methodology which reliably captures empathy assessments by the writer of a statement using multi-item scales. This is also the first computational work distinguishing between multiple forms of empathy, empathic concern, and personal distress, as recognized throughout psychology. Finally, we present experimental results for three different predictive models, of which a CNN performs the best.",https://aclanthology.org/D18-1507,empathy,Yes,Yes,No
{J}e{S}em{E}: Interleaving Semantics and Emotions in a Web Service for the Exploration of Language Change Phenomena,"Hellrich, Johannes  and
Buechel, Sven  and
Hahn, Udo",2018,Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations,,"We here introduce a substantially extended version of JeSemE, an interactive website for visually exploring computationally derived time-variant information on word meanings and lexical emotions assembled from five large diachronic text corpora. JeSemE is designed for scholars in the (digital) humanities as an alternative to consulting manually compiled, printed dictionaries for such information (if available at all). This tool uniquely combines state-of-the-art distributional semantics with a nuanced model of human emotions, two information streams we deem beneficial for a data-driven interpretation of texts in the humanities.",https://aclanthology.org/C18-2003,emotion,No,Yes,No
Learning Emotion-enriched Word Representations,"Agrawal, Ameeta  and
An, Aijun  and
Papagelis, Manos",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Most word representation learning methods are based on the distributional hypothesis in linguistics, according to which words that are used and occur in the same contexts tend to possess similar meanings. As a consequence, emotionally dissimilar words, such as {``}happy{''} and {``}sad{''} occurring in similar contexts would purport more similar meaning than emotionally similar words, such as {``}happy{''} and {``}joy{''}. This complication leads to rather undesirable outcome in predictive tasks that relate to affect (emotional state), such as emotion classification and emotion similarity. In order to address this limitation, we propose a novel method of obtaining emotion-enriched word representations, which projects emotionally similar words into neighboring spaces and emotionally dissimilar ones far apart. The proposed approach leverages distant supervision to automatically obtain a large training dataset of text documents and two recurrent neural network architectures for learning the emotion-enriched representations. Through extensive evaluation on two tasks, including emotion classification and emotion similarity, we demonstrate that the proposed representations outperform several competitive general-purpose and affective word representations.",https://aclanthology.org/C18-1081,emotion,Yes,Yes,No
Who Feels What and Why? Annotation of a Literature Corpus with Semantic Roles of Emotions,"Kim, Evgeny  and
Klinger, Roman",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Most approaches to emotion analysis in fictional texts focus on detecting the emotion expressed in text. We argue that this is a simplification which leads to an overgeneralized interpretation of the results, as it does not take into account who experiences an emotion and why. Emotions play a crucial role in the interaction between characters and the events they are involved in. Until today, no specific corpora that capture such an interaction were available for literature. We aim at filling this gap and present a publicly available corpus based on Project Gutenberg, REMAN (Relational EMotion ANnotation), manually annotated for spans which correspond to emotion trigger phrases and entities/events in the roles of experiencers, targets, and causes of the emotion. We provide baseline results for the automatic prediction of these relational structures and show that emotion lexicons are not able to encompass the high variability of emotion expressions and demonstrate that statistical models benefit from joint modeling of emotions with its roles in all subtasks. The corpus that we provide enables future research on the recognition of emotions and associated entities in text. It supports qualitative literary studies and digital humanities. The corpus is available at \url{http://www.ims.uni-stuttgart.de/data/reman} .",https://aclanthology.org/C18-1114,emotion,Yes,Yes,No
An Analysis of Annotated Corpora for Emotion Classification in Text,"Bostan, Laura-Ana-Maria  and
Klinger, Roman",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Several datasets have been annotated and published for classification of emotions. They differ in several ways: (1) the use of different annotation schemata (e. g., discrete label sets, including joy, anger, fear, or sadness or continuous values including valence, or arousal), (2) the domain, and, (3) the file formats. This leads to several research gaps: supervised models often only use a limited set of available resources. Additionally, no previous work has compared emotion corpora in a systematic manner. We aim at contributing to this situation with a survey of the datasets, and aggregate them in a common file format with a common annotation schema. Based on this aggregation, we perform the first cross-corpus classification experiments in the spirit of future research enabled by this paper, in order to gain insight and a better understanding of differences of models inferred from the data. This work also simplifies the choice of the most appropriate resources for developing a model for a novel domain. One result from our analysis is that a subset of corpora is better classified with models trained on a different corpus. For none of the corpora, training on all data altogether is better than using a subselection of the resources. Our unified corpus is available at \url{http://www.ims.uni-stuttgart.de/data/unifyemotion}.",https://aclanthology.org/C18-1179,emotion,Yes,Yes,No
{F}olksonomication: Predicting Tags for Movies from Plot Synopses using Emotion Flow Encoded Neural Network,"Kar, Sudipta  and
Maharjan, Suraj  and
Solorio, Thamar",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Folksonomy of movies covers a wide range of heterogeneous information about movies, like the genre, plot structure, visual experiences, soundtracks, metadata, and emotional experiences from watching a movie. Being able to automatically generate or predict tags for movies can help recommendation engines improve retrieval of similar movies, and help viewers know what to expect from a movie in advance. In this work, we explore the problem of creating tags for movies from plot synopses. We propose a novel neural network model that merges information from synopses and emotion flows throughout the plots to predict a set of tags for movies. We compare our system with multiple baselines and found that the addition of emotion flows boosts the performance of the network by learning {\mbox{$\approx$}}18{\%} more tags than a traditional machine learning system.",https://aclanthology.org/C18-1244,emotion,No,Yes,No
Emotion Representation Mapping for Automatic Lexicon Construction (Mostly) Performs on Human Level,"Buechel, Sven  and
Hahn, Udo",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Emotion Representation Mapping (ERM) has the goal to convert existing emotion ratings from one representation format into another one, e.g., mapping Valence-Arousal-Dominance annotations for words or sentences into Ekman{'}s Basic Emotions and vice versa. ERM can thus not only be considered as an alternative to Word Emotion Induction (WEI) techniques for automatic emotion lexicon construction but may also help mitigate problems that come from the proliferation of emotion representation formats in recent years. We propose a new neural network approach to ERM that not only outperforms the previous state-of-the-art. Equally important, we present a refined evaluation methodology and gather strong evidence that our model yields results which are (almost) as reliable as human annotations, even in cross-lingual settings. Based on these results we generate new emotion ratings for 13 typologically diverse languages and claim that they have near-gold quality, at least.",https://aclanthology.org/C18-1245,emotion,No,Yes,No
Emotion Detection and Classification in a Multigenre Corpus with Joint Multi-Task Deep Learning,"Tafreshi, Shabnam  and
Diab, Mona",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Detection and classification of emotion categories expressed by a sentence is a challenging task due to subjectivity of emotion. To date, most of the models are trained and evaluated on single genre and when used to predict emotion in different genre their performance drops by a large margin. To address the issue of robustness, we model the problem within a joint multi-task learning framework. We train this model with a multigenre emotion corpus to predict emotions across various genre. Each genre is represented as a separate task, we use soft parameter shared layers across the various tasks. our experimental results show that this model improves the results across the various genres, compared to a single genre training in the same neural net architecture.",https://aclanthology.org/C18-1246,emotion,Yes,Yes,No
How emotional are you? Neural Architectures for Emotion Intensity Prediction in Microblogs,"Kulshreshtha, Devang  and
Goel, Pranav  and
Kumar Singh, Anil",2018,Proceedings of the 27th International Conference on Computational Linguistics,,"Social media based micro-blogging sites like Twitter have become a common source of real-time information (impacting organizations and their strategies, and are used for expressing emotions and opinions. Automated analysis of such content therefore rises in importance. To this end, we explore the viability of using deep neural networks on the specific task of emotion intensity prediction in tweets. We propose a neural architecture combining convolutional and fully connected layers in a non-sequential manner - done for the first time in context of natural language based tasks. Combined with lexicon-based features along with transfer learning, our model achieves state-of-the-art performance, outperforming the previous system by 0.044 or 4.4{\%} Pearson correlation on the WASSA{'}17 EmoInt shared task dataset. We investigate the performance of deep multi-task learning models trained for all emotions at once in a unified architecture and get encouraging results. Experiments performed on evaluating correlation between emotion pairs offer interesting insights into the relationship between them.",https://aclanthology.org/C18-1247,emotion,Yes,Yes,No
"Public Apologies in {I}ndia - Semantics, Sentiment and Emotion","Shukla, Sangeeta  and
Shukla, Rajita",2018,Proceedings of the 9th Global Wordnet Conference,,"This paper reports a pilot study related to public apologies in India, with reference to certain keywords found in them. The study is of importance as the choice of lexical items holds importance which goes beyond the surface meaning of the words. The analysis of the lexical items has been done using interlinked digital lexical resources which, in future, can lend this study to computational tasks related to opinion mining, sentiment analysis and document classification. The study attempts an in-depth psycholinguistic analysis of whether the apology conveys a sincerity of intent or is it a mere ritualistic exercise to control and repair damage.",https://aclanthology.org/2018.gwc-1.15,emotion,No,Yes,No
"Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus","Schuff, Hendrik  and
Barnes, Jeremy  and
Mohme, Julian  and
Pad{\'o}, Sebastian  and
Klinger, Roman",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5203,"There is a rich variety of data sets for sentiment analysis (viz., polarity and subjectivity classification). For the more challenging task of detecting discrete emotions following the definitions of Ekman and Plutchik, however, there are much fewer data sets, and notably no resources for the social media domain. This paper contributes to closing this gap by extending the \textit{SemEval 2016 stance and sentiment dataset}with emotion annotation. We (a) analyse annotation reliability and annotation merging; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment); (c) report modelling results as a baseline for future work.",https://aclanthology.org/W17-5203,emotion,Yes,Yes,No
{WASSA}-2017 Shared Task on Emotion Intensity,"Mohammad, Saif  and
Bravo-Marquez, Felipe",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5205,"We present the first shared task on detecting the intensity of emotion felt by the speaker of a tweet. We create the first datasets of tweets annotated for anger, fear, joy, and sadness intensities using a technique called best{--}worst scaling (BWS). We show that the annotations lead to reliable fine-grained intensity scores (rankings of tweets by intensity). The data was partitioned into training, development, and test sets for the competition. Twenty-two teams participated in the shared task, with the best system obtaining a Pearson correlation of 0.747 with the gold intensity scores. We summarize the machine learning setups, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful for the task. The emotion intensity dataset and the shared task are helping improve our understanding of how we convey more or less intense emotions through language.",https://aclanthology.org/W17-5205,emotion,Yes,Yes,No
"{IMS} at {E}mo{I}nt-2017: Emotion Intensity Prediction with Affective Norms, Automatically Extended Resources and Deep Learning","K{\""o}per, Maximilian  and
Kim, Evgeny  and
Klinger, Roman",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5206,"Our submission to the WASSA-2017 shared task on the prediction of emotion intensity in tweets is a supervised learning method with extended lexicons of affective norms. We combine three main information sources in a random forrest regressor, namely (1), manually created resources, (2) automatically extended lexicons, and (3) the output of a neural network (CNN-LSTM) for sentence regression. All three feature sets perform similarly well in isolation ({\mbox{$\approx$}} .67 macro average Pearson correlation). The combination achieves .72 on the official test set (ranked 2nd out of 22 participants). Our analysis reveals that performance is increased by providing cross-emotional intensity predictions. The automatic extension of lexicon features benefit from domain specific embeddings. Complementary ratings for affective norms increase the impact of lexicon features. Our resources (ratings for 1.6 million twitter specific words) and our implementation is publicly available at \url{http://www.ims.uni-stuttgart.de/data/ims_emoint}.",https://aclanthology.org/W17-5206,emotion,No,Yes,No
Prayas at {E}mo{I}nt 2017: An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets,"Goel, Pranav  and
Kulshreshtha, Devang  and
Jain, Prayas  and
Shukla, Kaushal Kumar",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5207,"The paper describes the best performing system for EmoInt - a shared task to predict the intensity of emotions in tweets. Intensity is a real valued score, between 0 and 1. The emotions are classified as - anger, fear, joy and sadness. We apply three different deep neural network based models, which approach the problem from essentially different directions. Our final performance quantified by an average pearson correlation score of 74.7 and an average spearman correlation score of 73.5 is obtained using an ensemble of the three models. We outperform the baseline model of the shared task by 9.9{\%} and 9.4{\%} pearson and spearman correlation scores respectively.",https://aclanthology.org/W17-5207,emotion,No,Yes,No
Understanding human values and their emotional effect,"Balahur, Alexandra",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5214,"Emotions can be triggered by various factors. According to the Appraisal Theories (De Rivera, 1977; Frijda, 1986; Ortony et al., 1988; Johnson-Laird and Oatley, 1989) emotions are elicited and differentiated on the basis of the cognitive evaluation of the personal significance of a situation, object or event based on {``}appraisal criteria{''} (intrinsic characteristics of objects and events, significance of events to individual needs and goals, individual{'}s ability to cope with the consequences of the event, compatibility of event with social or personal standards, norms and values). These differences in values can trigger reactions such as anger, disgust (contempt), sadness, etc., because these behaviors are evaluated by the public as being incompatible with their social/personal standards, norms or values. Such arguments are frequently present both in mainstream media, as well as social media, building a society-wide view, attitude and emotional reaction towards refugees/immigrants. In this demo, I will talk about experiments to annotate and detect factual arguments that are linked to human needs/motivations from text and in consequence trigger emotion in the media audience and propose a new task for next year{'}s WASSA.",https://aclanthology.org/W17-5214,emotion,Yes,No,No
Modeling Temporal Progression of Emotional Status in Mental Health Forum: A Recurrent Neural Net Approach,"Halder, Kishaloy  and
Poddar, Lahari  and
Kan, Min-Yen",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5217,"Patients turn to Online Health Communities not only for information on specific conditions but also for emotional support. Previous research has indicated that the progression of emotional status can be studied through the linguistic patterns of an individual{'}s posts. We analyze a real-world dataset from the Mental Health section of HealthBoards.com. Estimated from the word usages in their posts, we find that the emotional progress across patients vary widely. We study the problem of predicting a patient{'}s emotional status in the future from her past posts and we propose a Recurrent Neural Network (RNN) based architecture to address it. We find that the future emotional status can be predicted with reasonable accuracy given her historical posts and participation features. Our evaluation results demonstrate the efficacy of our proposed architecture, by outperforming state-of-the-art approaches with over 0.13 reduction in Mean Absolute Error.",https://aclanthology.org/W17-5217,emotion,Yes,Yes,No
{G}rad{A}scent at {E}mo{I}nt-2017: Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection,"Lakomkin, Egor  and
Bothe, Chandrakant  and
Wermter, Stefan",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5222,"The WASSA 2017 EmoInt shared task has the goal to predict emotion intensity values of tweet messages. Given the text of a tweet and its emotion category (anger, joy, fear, and sadness), the participants were asked to build a system that assigns emotion intensity values. Emotion intensity estimation is a challenging problem given the short length of the tweets, the noisy structure of the text and the lack of annotated data. To solve this problem, we developed an ensemble of two neural models, processing input on the character. and word-level with a lexicon-driven system. The correlation scores across all four emotions are averaged to determine the bottom-line competition metric, and our system ranks place forth in full intensity range and third in 0.5-1 range of intensity among 23 systems at the time of writing (June 2017).",https://aclanthology.org/W17-5222,emotion,Yes,Yes,No
{NUIG} at {E}mo{I}nt-2017: {B}i{LSTM} and {SVR} Ensemble to Detect Emotion Intensity,"Andryushechkin, Vladimir  and
Wood, Ian  and
O{'} Neill, James",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5223,"This paper describes the entry NUIG in the WASSA 2017 (8th Workshop on Computational Approaches to Subjectivity, Sentiment {\&} Social Media Analysis) shared task on emotion recognition. The NUIG system used an SVR (SVM regression) and BLSTM ensemble, utilizing primarily n-grams (for SVR features) and tweet word embeddings (for BLSTM features). Experiments were carried out on several other candidate features, some of which were added to the SVR model. Parameter selection for the SVR model was run as a grid search whilst parameters for the BLSTM model were selected through a non-exhaustive ad-hoc search.",https://aclanthology.org/W17-5223,emotion,No,Yes,No
{PLN}-{PUCRS} at {E}mo{I}nt-2017: Psycholinguistic features for emotion intensity prediction in tweets,"Santos, Henrique  and
Vieira, Renata",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5225,"Linguistic Inquiry and Word Count (LIWC) is a rich dictionary that map words into several psychological categories such as Affective, Social, Cognitive, Perceptual and Biological processes. In this work, we have used LIWC psycholinguistic categories to train regression models and predict emotion intensity in tweets for the EmoInt-2017 task. Results show that LIWC features may boost emotion intensity prediction on the basis of a low dimension set.",https://aclanthology.org/W17-5225,emotion,No,Yes,No
Seernet at {E}mo{I}nt-2017: Tweet Emotion Intensity Estimator,"Duppada, Venkatesh  and
Hiray, Sushant",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5228,"The paper describes experiments on estimating emotion intensity in tweets using a generalized regressor system. The system combines various independent feature extractors, trains them on general regressors and finally combines the best performing models to create an ensemble. The proposed system stood 3rd out of 22 systems in leaderboard of WASSA-2017 Shared Task on Emotion Intensity.",https://aclanthology.org/W17-5228,emotion,No,Yes,No
{IITP} at {E}mo{I}nt-2017: Measuring Intensity of Emotions using Sentence Embeddings and Optimized Features,"Akhtar, Md Shad  and
Sawant, Palaash  and
Ekbal, Asif  and
Pawar, Jyoti  and
Bhattacharyya, Pushpak",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5229,"This paper describes the system that we submitted as part of our participation in the shared task on Emotion Intensity (EmoInt-2017). We propose a Long short term memory (LSTM) based architecture cascaded with Support Vector Regressor (SVR) for intensity prediction. We also employ Particle Swarm Optimization (PSO) based feature selection algorithm for obtaining an optimized feature set for training and evaluation. System evaluation shows interesting results on the four emotion datasets i.e. anger, fear, joy and sadness. In comparison to the other participating teams our system was ranked 5th in the competition.",https://aclanthology.org/W17-5229,emotion,No,Yes,No
{NSE}mo at {E}mo{I}nt-2017: An Ensemble to Predict Emotion Intensity in Tweets,"Madisetty, Sreekanth  and
Desarkar, Maunendra Sankar",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5230,"In this paper, we describe a method to predict emotion intensity in tweets. Our approach is an ensemble of three regression methods. The first method uses content-based features (hashtags, emoticons, elongated words, etc.). The second method considers word n-grams and character n-grams for training. The final method uses lexicons, word embeddings, word n-grams, character n-grams for training the model. An ensemble of these three methods gives better performance than individual methods. We applied our method on WASSA emotion dataset. Achieved results are as follows: average Pearson correlation is 0.706, average Spearman correlation is 0.696, average Pearson correlation for gold scores in range 0.5 to 1 is 0.539, and average Spearman correlation for gold scores in range 0.5 to 1 is 0.514.",https://aclanthology.org/W17-5230,emotion,Yes,Yes,No
{E}mo{A}tt at {E}mo{I}nt-2017: Inner attention sentence embedding for Emotion Intensity,"Marrese-Taylor, Edison  and
Matsuo, Yutaka",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5232,"In this paper we describe a deep learning system that has been designed and built for the WASSA 2017 Emotion Intensity Shared Task. We introduce a representation learning approach based on inner attention on top of an RNN. Results show that our model offers good capabilities and is able to successfully identify emotion-bearing words to predict intensity without leveraging on lexicons, obtaining the 13t place among 22 shared task competitors.",https://aclanthology.org/W17-5232,emotion,No,Yes,No
{YZU}-{NLP} at {E}mo{I}nt-2017: Determining Emotion Intensity Using a Bi-directional {LSTM}-{CNN} Model,"He, Yuanye  and
Yu, Liang-Chih  and
Lai, K. Robert  and
Liu, Weiyi",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5233,"The EmoInt-2017 task aims to determine a continuous numerical value representing the intensity to which an emotion is expressed in a tweet. Compared to classification tasks that identify 1 among n emotions for a tweet, the present task can provide more fine-grained (real-valued) sentiment analysis. This paper presents a system that uses a bi-directional LSTM-CNN model to complete the competition task. Combining bi-directional LSTM and CNN, the prediction process considers both global information in a tweet and local important information. The proposed method ranked sixth among twenty-one teams in terms of Pearson Correlation Coefficient.",https://aclanthology.org/W17-5233,emotion,No,Yes,Yes
{DMG}roup at {E}mo{I}nt-2017: Emotion Intensity Using Ensemble Method,"Jiang, Song  and
Han, Xiaotian",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5234,"In this paper, we present a novel ensemble learning architecture for emotion intensity analysis, particularly a novel framework of ensemble method. The ensemble method has two stages and each stage includes several single machine learning models. In stage1, we employ both linear and nonlinear regression models to obtain a more diverse emotion intensity representation. In stage2, we use two regression models including linear regression and XGBoost. The result of stage1 serves as the input of stage2, so the two different type models (linear and non-linear) in stage2 can describe the input in two opposite aspects. We also added a method for analyzing and splitting multi-words hashtags and appending them to the emotion intensity corpus before feeding it to our model. Our model achieves 0.571 Pearson-measure for the average of four emotions.",https://aclanthology.org/W17-5234,emotion,Yes,Yes,No
"{UW}at-Emote at {E}mo{I}nt-2017: Emotion Intensity Detection using Affect Clues, Sentiment Polarity and Word Embeddings","John, Vineet  and
Vechtomova, Olga",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5235,"This paper describes the UWaterloo affect prediction system developed for EmoInt-2017. We delve into our feature selection approach for affect intensity, affect presence, sentiment intensity and sentiment presence lexica alongside pre-trained word embeddings, which are utilized to extract emotion intensity signals from tweets in an ensemble learning approach. The system employs emotion specific model training, and utilizes distinct models for each of the emotion corpora in isolation. Our system utilizes gradient boosted regression as the primary learning technique to predict the final emotion intensities.",https://aclanthology.org/W17-5235,emotion,No,Yes,No
{LIPN}-{UAM} at {E}mo{I}nt-2017:Combination of Lexicon-based features and Sentence-level Vector Representations for Emotion Intensity Determination,"Buscaldi, Davide  and
Priego, Belem",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5236,"This paper presents the combined LIPN-UAM participation in the WASSA 2017 Shared Task on Emotion Intensity. In particular, the paper provides some highlights on the Tweetaneuse system that was presented to the shared task. We combined lexicon-based features with sentence-level vector representations to implement a random forest regressor.",https://aclanthology.org/W17-5236,emotion,No,No,No
deep{C}yb{E}r{N}et at {E}mo{I}nt-2017: Deep Emotion Intensities in Tweets,"R, Vinayakumar  and
B, Premjith  and
S, Sachin Kumar  and
KP, Soman  and
Poornachandran, Prabaharan",2017,"Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",10.18653/v1/W17-5237,"This working note presents the methodology used in deepCybErNet submission to the shared task on Emotion Intensities in Tweets (EmoInt) WASSA-2017. The goal of the task is to predict a real valued score in the range [0-1] for a particular tweet with an emotion type. To do this, we used Bag-of-Words and embedding based on recurrent network architecture. We have developed two systems and experiments are conducted on the Emotion Intensity shared Task 1 data base at WASSA-2017. A system which uses word embedding based on recurrent network architecture has achieved highest 5 fold cross-validation accuracy. This has used embedding with recurrent network to extract optimal features at tweet level and logistic regression for prediction. These methods are highly language independent and experimental results shows that the proposed methods are apt for predicting a real valued score in than range [0-1] for a given tweet with its emotion type.",https://aclanthology.org/W17-5237,emotion,No,Yes,No
Video Highlights Detection and Summarization with Lag-Calibration based on Concept-Emotion Mapping of Crowdsourced Time-Sync Comments,"Ping, Qing  and
Chen, Chaomei",2017,Proceedings of the Workshop on New Frontiers in Summarization,10.18653/v1/W17-4501,"With the prevalence of video sharing, there are increasing demands for automatic video digestion such as highlight detection. Recently, platforms with crowdsourced time-sync video comments have emerged worldwide, providing a good opportunity for highlight detection. However, this task is non-trivial: (1) time-sync comments often lag behind their corresponding shot; (2) time-sync comments are semantically sparse and noisy; (3) to determine which shots are highlights is highly subjective. The present paper aims to tackle these challenges by proposing a framework that (1) uses concept-mapped lexical-chains for lag-calibration; (2) models video highlights based on comment intensity and combination of emotion and concept concentration of each shot; (3) summarize each detected highlight using improved SumBasic with emotion and concept mapping. Experiments on large real-world datasets show that our highlight detection method and summarization method both outperform other benchmarks with considerable margins.",https://aclanthology.org/W17-4501,emotion,No,Yes,No
Predicting News Values from Headline Text and Emotions,"di Buono, Maria Pia  and
{\v{S}}najder, Jan  and
Dalbelo Ba{\v{s}}i{\'c}, Bojana  and
Glava{\v{s}}, Goran  and
Tutek, Martin  and
Milic-Frayling, Natasa",2017,Proceedings of the 2017 {EMNLP} Workshop: Natural Language Processing meets Journalism,10.18653/v1/W17-4201,"We present a preliminary study on predicting news values from headline text and emotions. We perform a multivariate analysis on a dataset manually annotated with news values and emotions, discovering interesting correlations among them. We then train two competitive machine learning models {--} an SVM and a CNN {--} to predict news values from headline text and emotions as features. We find that, while both models yield a satisfactory performance, some news values are more difficult to detect than others, while some profit more from including emotion information.",https://aclanthology.org/W17-4201,emotion,Yes,Yes,No
Investigating the Relationship between Literary Genres and Emotional Plot Development,"Kim, Evgeny  and
Pad{\'o}, Sebastian  and
Klinger, Roman",2017,"Proceedings of the Joint {SIGHUM} Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",10.18653/v1/W17-2203,"Literary genres are commonly viewed as being defined in terms of content and stylistic features. In this paper, we focus on one particular class of lexical features, namely emotion information, and investigate the hypothesis that emotion-related information correlates with particular genres. Using genre classification as a testbed, we compare a model that computes lexicon-based emotion scores globally for complete stories with a model that tracks emotion arcs through stories on a subset of Project Gutenberg with five genres. Our main findings are: (a), the global emotion model is competitive with a large-vocabulary bag-of-words genre classifier (80{\%}F1); (b), the emotion arc model shows a lower performance (59 {\%} F1) but shows complementary behavior to the global model, as indicated by a very good performance of an oracle model (94 {\%} F1) and an improved performance of an ensemble model (84 {\%} F1); (c), genres differ in the extent to which stories follow the same emotional arcs, with particularly uniform behavior for anger (mystery) and fear (adventures, romance, humor, science fiction).",https://aclanthology.org/W17-2203,emotion,No,Yes,No
Readers vs. Writers vs. Texts: Coping with Different Perspectives of Text Understanding in Emotion Annotation,"Buechel, Sven  and
Hahn, Udo",2017,Proceedings of the 11th Linguistic Annotation Workshop,10.18653/v1/W17-0801,"We here examine how different perspectives of understanding written discourse, like the reader{'}s, the writer{'}s or the text{'}s point of view, affect the quality of emotion annotations. We conducted a series of annotation experiments on two corpora, a popular movie review corpus and a genre- and domain-balanced corpus of standard English. We found statistical evidence that the writer{'}s perspective yields superior annotation quality overall. However, the quality one perspective yields compared to the other(s) seems to depend on the domain the utterance originates from. Our data further suggest that the popular movie review data set suffers from an atypical bimodal distribution which may decrease model performance when used as a training resource.",https://aclanthology.org/W17-0801,emotion,Yes,Yes,No
Emotion Intensities in Tweets,"Mohammad, Saif  and
Bravo-Marquez, Felipe",2017,Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*{SEM} 2017),10.18653/v1/S17-1007,"This paper examines the task of detecting intensity of emotion from text. We create the first datasets of tweets annotated for anger, fear, joy, and sadness intensities. We use a technique called best{--}worst scaling (BWS) that improves annotation consistency and obtains reliable fine-grained scores. We show that emotion-word hashtags often impact emotion intensity, usually conveying a more intense emotion. Finally, we create a benchmark regression system and conduct experiments to determine: which features are useful for detecting emotion intensity; and, the extent to which two emotions are similar in terms of how they manifest in language.",https://aclanthology.org/S17-1007,emotion,Yes,No,No
Gradient Emotional Analysis,"Simeonova, Lilia",2017,Proceedings of the Student Research Workshop Associated with {RANLP} 2017,10.26615/issn.1314-9156.2017_006,"Over the past few years a lot of research has been done on sentiment analysis, however, the emotional analysis, being so subjective, is not a well examined dis-cipline. The main focus of this proposal is to categorize a given sentence in two dimensions - sentiment and arousal. For this purpose two techniques will be com-bined {--} Machine Learning approach and Lexicon-based approach. The first di-mension will give the sentiment value {--} positive versus negative. This will be re-solved by using Na{\""\i}ve Bayes Classifier. The second and more interesting dimen-sion will determine the level of arousal. This will be achieved by evaluation of given a phrase or sentence based on lexi-con with affective ratings for 14 thousand English words.",https://doi.org/10.26615/issn.1314-9156.2017_006,emotion,No,Yes,No
Towards the Improvement of Automatic Emotion Pre-annotation with Polarity and Subjective Information,"Canales, Lea  and
Daelemans, Walter  and
Boldrini, Ester  and
Mart{\'\i}nez-Barco, Patricio",2017,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",10.26615/978-954-452-049-6_022,"Emotion detection has a high potential positive impact on the benefit of business, society, politics or education. Given this, the main objective of our research is to contribute to the resolution of one of the most important challenges in textual emotion detection: emotional corpora annotation. This will be tackled by proposing a semi-automatic methodology. It consists in two main phases: (1) an automatic process to pre-annotate the unlabelled sentences with a reduced number of emotional categories; and (2) a manual process of refinement where human annotators will determine which is the dominant emotion between the pre-defined set. Our objective in this paper is to show the pre-annotation process, as well as to evaluate the usability of subjective and polarity information in this process. The evaluation performed confirms clearly the benefits of employing the polarity and subjective information on emotion detection and thus endorses the relevance of our approach.",https://doi.org/10.26615/978-954-452-049-6_022,emotion,Yes,No,No
{E}mo{N}et: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks,"Abdul-Mageed, Muhammad  and
Ungar, Lyle",2017,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/P17-1067,"Accurate detection of emotion from natural language has applications ranging from building emotional chatbots to better understanding individuals and their lives. However, progress on emotion detection has been hampered by the absence of large labeled datasets. In this work, we build a very large dataset for fine-grained emotions and develop deep learning models on it. We achieve a new state-of-the-art on 24 fine-grained types of emotions (with an average accuracy of 87.58{\%}). We also extend the task beyond emotion types to model Robert Plutick{'}s 8 primary emotion dimensions, acquiring a superior accuracy of 95.68{\%}.",https://aclanthology.org/P17-1067,emotion,Yes,Yes,No
Understanding and Predicting Empathic Behavior in Counseling Therapy,"P{\'e}rez-Rosas, Ver{\'o}nica  and
Mihalcea, Rada  and
Resnicow, Kenneth  and
Singh, Satinder  and
An, Lawrence",2017,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),10.18653/v1/P17-1131,"Counselor empathy is associated with better outcomes in psychology and behavioral counseling. In this paper, we explore several aspects pertaining to counseling interaction dynamics and their relation to counselor empathy during motivational interviewing encounters. Particularly, we analyze aspects such as participants{'} engagement, participants{'} verbal and nonverbal accommodation, as well as topics being discussed during the conversation, with the final goal of identifying linguistic and acoustic markers of counselor empathy. We also show how we can use these findings alongside other raw linguistic and acoustic features to build accurate counselor empathy classifiers with accuracies of up to 80{\%}.",https://aclanthology.org/P17-1131,empathy,No,No,No
Modelling Representation Noise in Emotion Analysis using {G}aussian Processes,"Beck, Daniel",2017,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),,Emotion Analysis is the task of modelling latent emotions present in natural language. Labelled datasets for this task are scarce so learning good input text representations is not trivial. Using averaged word embeddings is a simple way to leverage unlabelled corpora to build text representations but this approach can be prone to noise either coming from the embedding themselves or the averaging procedure. In this paper we propose a model for Emotion Analysis using Gaussian Processes and kernels that are better suitable for functions that exhibit noisy behaviour. Empirical evaluations in a emotion prediction task show that our model outperforms commonly used baselines for regression.,https://aclanthology.org/I17-2024,emotion,No,Yes,No
Reusing Neural Speech Representations for Auditory Emotion Recognition,"Lakomkin, Egor  and
Weber, Cornelius  and
Magg, Sven  and
Wermter, Stefan",2017,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),,"Acoustic emotion recognition aims to categorize the affective state of the speaker and is still a difficult task for machine learning models. The difficulties come from the scarcity of training data, general subjectivity in emotion perception resulting in low annotator agreement, and the uncertainty about which features are the most relevant and robust ones for classification. In this paper, we will tackle the latter problem. Inspired by the recent success of transfer learning methods we propose a set of architectures which utilize neural representations inferred by training on large speech databases for the acoustic emotion recognition task. Our experiments on the IEMOCAP dataset show {\textasciitilde}10{\%} relative improvements in the accuracy and F1-score over the baseline recurrent neural network which is trained end-to-end for emotion recognition.",https://aclanthology.org/I17-1043,emotion,Yes,Yes,No
Automatically augmenting an emotion dataset improves classification using audio,"Lakomkin, Egor  and
Weber, Cornelius  and
Wermter, Stefan",2017,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",,"In this work, we tackle a problem of speech emotion classification. One of the issues in the area of affective computation is that the amount of annotated data is very limited. On the other hand, the number of ways that the same emotion can be expressed verbally is enormous due to variability between speakers. This is one of the factors that limits performance and generalization. We propose a simple method that extracts audio samples from movies using textual sentiment analysis. As a result, it is possible to automatically construct a larger dataset of audio samples with positive, negative emotional and neutral speech. We show that pretraining recurrent neural network on such a dataset yields better results on the challenging EmotiW corpus. This experiment shows a potential benefit of combining textual sentiment analysis with vocal information.",https://aclanthology.org/E17-2031,emotion,Yes,Yes,No
Predicting Emotional Word Ratings using Distributional Representations and Signed Clustering,"Sedoc, Jo{\~a}o  and
Preo{\c{t}}iuc-Pietro, Daniel  and
Ungar, Lyle",2017,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",,"Inferring the emotional content of words is important for text-based sentiment analysis, dialogue systems and psycholinguistics, but word ratings are expensive to collect at scale and across languages or domains. We develop a method that automatically extends word-level ratings to unrated words using signed clustering of vector space word representations along with affect ratings. We use our method to determine a word{'}s valence and arousal, which determine its position on the circumplex model of affect, the most popular dimensional model of emotion. Our method achieves superior out-of-sample word rating prediction on both affective dimensions across three different languages when compared to state-of-the-art word similarity based methods. Our method can assist building word ratings for new languages and improve downstream tasks such as sentiment analysis and emotion detection.",https://aclanthology.org/E17-2090,emotion,No,Yes,No
{E}mo{B}ank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis,"Buechel, Sven  and
Hahn, Udo",2017,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",,"We describe EmoBank, a corpus of 10k English sentences balancing multiple genres, which we annotated with dimensional emotion metadata in the Valence-Arousal-Dominance (VAD) representation format. EmoBank excels with a bi-perspectival and bi-representational design. On the one hand, we distinguish between writer{'}s and reader{'}s emotions, on the other hand, a subset of the corpus complements dimensional VAD annotations with categorical ones based on Basic Emotions. We find evidence for the supremacy of the reader{'}s perspective in terms of IAA and rating intensity, and achieve close-to-human performance when mapping between dimensional and categorical formats.",https://aclanthology.org/E17-2092,emotion,Yes,No,No
{M}ood{S}wipe: A Soft Keyboard that Suggests {M}essage{B}ased on User-Specified Emotions,"Huang, Chieh-Yang  and
Labetoulle, Tristan  and
Huang, Ting-Hao  and
Chen, Yi-Pei  and
Chen, Hung-Chen  and
Srivastava, Vallari  and
Ku, Lun-Wei",2017,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,10.18653/v1/D17-2013,"We present MoodSwipe, a soft keyboard that suggests text messages given the user-specified emotions utilizing the real dialog data. The aim of MoodSwipe is to create a convenient user interface to enjoy the technology of emotion classification and text suggestion, and at the same time to collect labeled data automatically for developing more advanced technologies. While users select the MoodSwipe keyboard, they can type as usual but sense the emotion conveyed by their text and receive suggestions for their message as a benefit. In MoodSwipe, the detected emotions serve as the medium for suggested texts, where viewing the latter is the incentive to correcting the former. We conduct several experiments to show the superiority of the emotion classification models trained on the dialog data, and further to verify good emotion cues are important context for text suggestion.",https://aclanthology.org/D17-2013,emotion,Yes,Yes,No
A Question Answering Approach for Emotion Cause Extraction,"Gui, Lin  and
Hu, Jiannan  and
He, Yulan  and
Xu, Ruifeng  and
Lu, Qin  and
Du, Jiachen",2017,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D17-1167,"Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text. It is a much more difficult task compared to emotion classification. Inspired by recent advances in using deep memory networks for question answering (QA), we propose a new approach which considers emotion cause identification as a reading comprehension task in QA. Inspired by convolutional neural networks, we propose a new mechanism to store relevant context in different memory slots to model context information. Our proposed approach can extract both word level sequence features and lexical features. Performance evaluation shows that our method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01{\%} in F-measure.",https://aclanthology.org/D17-1167,emotion,Yes,Yes,No
"Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm","Felbo, Bjarke  and
Mislove, Alan  and
S{\o}gaard, Anders  and
Rahwan, Iyad  and
Lehmann, Sune",2017,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,10.18653/v1/D17-1169,"NLP tasks are often limited by scarcity of manually annotated data. In social media sentiment analysis and related tasks, researchers have therefore used binarized emoticons and specific hashtags as forms of distant supervision. Our paper shows that by extending the distant supervision to a more diverse set of noisy labels, the models can learn richer representations. Through emoji prediction on a dataset of 1246 million tweets containing one of 64 common emojis we obtain state-of-the-art performance on 8 benchmark datasets within emotion, sentiment and sarcasm detection using a single pretrained model. Our analyses confirm that the diversity of our emotional labels yield a performance improvement over previous distant supervision approaches.",https://aclanthology.org/D17-1169,emotion,Yes,Yes,Yes
The Effect of Gender and Age Differences on the Recognition of Emotions from Facial Expressions,"Schneevogt, Daniela  and
Paggio, Patrizia",2016,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",,"Recent studies have demonstrated gender and cultural differences in the recognition of emotions in facial expressions. However, most studies were conducted on American subjects. In this paper, we explore the generalizability of several findings to a non-American culture in the form of Danish subjects. We conduct an emotion recognition task followed by two stereotype questionnaires with different genders and age groups. While recent findings (Krems et al., 2015) suggest that women are biased to see anger in neutral facial expressions posed by females, in our sample both genders assign higher ratings of anger to all emotions expressed by females. Furthermore, we demonstrate an effect of gender on the fear-surprise-confusion observed by Tomkins and McCarter (1964); females overpredict fear, while males overpredict surprise.",https://aclanthology.org/W16-4302,emotion,No,No,No
Distant supervision for emotion detection using {F}acebook reactions,"Pool, Chris  and
Nissim, Malvina",2016,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",,"We exploit the Facebook reaction feature in a distant supervised fashion to train a support vector machine classifier for emotion detection, using several feature combinations and combining different Facebook pages. We test our models on existing benchmarks for emotion detection and show that employing only information that is derived completely automatically, thus without relying on any handcrafted lexicon as it{'}s usually done, we can achieve competitive results. The results also show that there is large room for improvement, especially by gearing the collection of Facebook pages, with a view to the target domain.",https://aclanthology.org/W16-4304,emotion,Yes,Yes,No
Innovative Semi-Automatic Methodology to Annotate Emotional Corpora,"Canales, Lea  and
Strapparava, Carlo  and
Boldrini, Ester  and
Mart{\'\i}nez-Barco, Patricio",2016,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",,"Detecting depression or personality traits, tutoring and student behaviour systems, or identifying cases of cyber-bulling are a few of the wide range of the applications, in which the automatic detection of emotion is a crucial element. Emotion detection has the potential of high impact by contributing the benefit of business, society, politics or education. Given this context, the main objective of our research is to contribute to the resolution of one of the most important challenges in textual emotion detection task: the problems of emotional corpora annotation. This will be tackled by proposing of a new semi-automatic methodology. Our innovative methodology consists in two main phases: (1) an automatic process to pre-annotate the unlabelled sentences with a reduced number of emotional categories; and (2) a refinement manual process where human annotators will determine which is the predominant emotion between the emotional categories selected in the phase 1. Our proposal in this paper is to show and evaluate the pre-annotation process to analyse the feasibility and the benefits by the methodology proposed. The results obtained are promising and allow obtaining a substantial improvement of annotation time and cost and confirm the usefulness of our pre-annotation process to improve the annotation task.",https://aclanthology.org/W16-4310,emotion,Yes,No,No
Social and linguistic behavior and its correlation to trait empathy,"Litvak, Marina  and
Otterbacher, Jahna  and
Ang, Chee Siang  and
Atkins, David",2016,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",,"A growing body of research exploits social media behaviors to gauge psychological character-istics, though trait empathy has received little attention. Because of its intimate link to the abil-ity to relate to others, our research aims to predict participants{'} levels of empathy, given their textual and friending behaviors on Facebook. Using Poisson regression, we compared the vari-ance explained in Davis{'} Interpersonal Reactivity Index (IRI) scores on four constructs (em-pathic concern, personal distress, fantasy, perspective taking), by two classes of variables: 1) post content and 2) linguistic style. Our study lays the groundwork for a greater understanding of empathy{'}s role in facilitating interactions on social media.",https://aclanthology.org/W16-4314,empathy,No,No,No
"Microblog Emotion Classification by Computing Similarity in Text, Time, and Space","Summa, Anja  and
Resch, Bernd  and
Strube, Michael",2016,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",,"Most work in NLP analysing microblogs focuses on textual content thus neglecting temporal and spatial information. We present a new interdisciplinary method for emotion classification that combines linguistic, temporal, and spatial information into a single metric. We create a graph of labeled and unlabeled tweets that encodes the relations between neighboring tweets with respect to their emotion labels. Graph-based semi-supervised learning labels all tweets with an emotion.",https://aclanthology.org/W16-4317,emotion,Yes,Yes,Yes
Feelings from the {P}ast{---}{A}dapting Affective Lexicons for Historical Emotion Analysis,"Buechel, Sven  and
Hellrich, Johannes  and
Hahn, Udo",2016,Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities ({LT}4{DH}),,"We here describe a novel methodology for measuring affective language in historical text by expanding an affective lexicon and jointly adapting it to prior language stages. We automatically construct a lexicon for word-emotion association of 18th and 19th century German which is then validated against expert ratings. Subsequently, this resource is used to identify distinct emotional patterns and trace long-term emotional trends in different genres of writing spanning several centuries.",https://aclanthology.org/W16-4008,emotion,No,No,No
Crowdsourcing-based Annotation of Emotions in {F}ilipino and {E}nglish Tweets,"Lapitan, Fermin Roberto  and
Batista-Navarro, Riza Theresa  and
Albacea, Eliezer",2016,Proceedings of the 6th Workshop on South and Southeast {A}sian Natural Language Processing ({WSSANLP}2016),,"The automatic analysis of emotions conveyed in social media content, e.g., tweets, has many beneficial applications. In the Philippines, one of the most disaster-prone countries in the world, such methods could potentially enable first responders to make timely decisions despite the risk of data deluge. However, recognising emotions expressed in Philippine-generated tweets, which are mostly written in Filipino, English or a mix of both, is a non-trivial task. In order to facilitate the development of natural language processing (NLP) methods that will automate such type of analysis, we have built a corpus of tweets whose predominant emotions have been manually annotated by means of crowdsourcing. Defining measures ensuring that only high-quality annotations were retained, we have produced a gold standard corpus of 1,146 emotion-labelled Filipino and English tweets. We validate the value of this manually produced resource by demonstrating that an automatic emotion-prediction method based on the use of a publicly available word-emotion association lexicon was unable to reproduce the labels assigned via crowdsourcing. While we are planning to make a few extensions to the corpus in the near future, its current version has been made publicly available in order to foster the development of emotion analysis methods based on advanced Filipino and English NLP.",https://aclanthology.org/W16-3708,emotion,Yes,No,Yes
"Could Speaker, Gender or Age Awareness be beneficial in Speech-based Emotion Recognition?","Sidorov, Maxim  and
Schmitt, Alexander  and
Semenkin, Eugene  and
Minker, Wolfgang",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"Emotion Recognition (ER) is an important part of dialogue analysis which can be used in order to improve the quality of Spoken Dialogue Systems (SDSs). The emotional hypothesis of the current response of an end-user might be utilised by the dialogue manager component in order to change the SDS strategy which could result in a quality enhancement. In this study additional speaker-related information is used to improve the performance of the speech-based ER process. The analysed information is the speaker identity, gender and age of a user. Two schemes are described here, namely, using additional information as an independent variable within the feature vector and creating separate emotional models for each speaker, gender or age-cluster independently. The performances of the proposed approaches were compared against the baseline ER system, where no additional information has been used, on a number of emotional speech corpora of German, English, Japanese and Russian. The study revealed that for some of the corpora the proposed approach significantly outperforms the baseline methods with a relative difference of up to 11.9{\%}.",https://aclanthology.org/L16-1010,emotion,No,Yes,No
Mirroring Facial Expressions and Emotions in Dyadic Conversations,"Navarretta, Costanza",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"This paper presents an investigation of mirroring facial expressions and the emotions which they convey in dyadic naturally occurring first encounters. Mirroring facial expressions are a common phenomenon in face-to-face interactions, and they are due to the mirror neuron system which has been found in both animals and humans. Researchers have proposed that the mirror neuron system is an important component behind many cognitive processes such as action learning and understanding the emotions of others. Preceding studies of the first encounters have shown that overlapping speech and overlapping facial expressions are very frequent. In this study, we want to determine whether the overlapping facial expressions are mirrored or are otherwise correlated in the encounters, and to what extent mirroring facial expressions convey the same emotion. The results of our study show that the majority of smiles and laughs, and one fifth of the occurrences of raised eyebrows are mirrored in the data. Moreover some facial traits in co-occurring expressions co-occur more often than it would be expected by chance. Finally, amusement, and to a lesser extent friendliness, are often emotions shared by both participants, while other emotions indicating individual affective states such as uncertainty and hesitancy are never showed by both participants, but co-occur with complementary emotions such as friendliness and support. Whether these tendencies are specific to this type of conversations or are more common should be investigated further.",https://aclanthology.org/L16-1075,emotion,No,No,No
{E}mo{T}weet-28: A Fine-Grained Emotion Corpus for Sentiment Analysis,"Liew, Jasy Suet Yan  and
Turtle, Howard R.  and
Liddy, Elizabeth D.",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"This paper describes EmoTweet-28, a carefully curated corpus of 15,553 tweets annotated with 28 emotion categories for the purpose of training and evaluating machine learning models for emotion classification. EmoTweet-28 is, to date, the largest tweet corpus annotated with fine-grained emotion categories. The corpus contains annotations for four facets of emotion: valence, arousal, emotion category and emotion cues. We first used small-scale content analysis to inductively identify a set of emotion categories that characterize the emotions expressed in microblog text. We then expanded the size of the corpus using crowdsourcing. The corpus encompasses a variety of examples including explicit and implicit expressions of emotions as well as tweets containing multiple emotions. EmoTweet-28 represents an important resource to advance the development and evaluation of more emotion-sensitive systems.",https://aclanthology.org/L16-1183,emotion,Yes,Yes,No
Emotion Corpus Construction Based on Selection from Hashtags,"Li, Minglei  and
Long, Yunfei  and
Qin, Lu  and
Li, Wenjie",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"The availability of labelled corpus is of great importance for supervised learning in emotion classification tasks. Because it is time-consuming to manually label text, hashtags have been used as naturally annotated labels to obtain a large amount of labelled training data from microblog. However, natural hashtags contain too much noise for it to be used directly in learning algorithms. In this paper, we design a three-stage semi-automatic method to construct an emotion corpus from microblogs. Firstly, a lexicon based voting approach is used to verify the hashtag automatically. Secondly, a SVM based classifier is used to select the data whose natural labels are consistent with the predicted labels. Finally, the remaining data will be manually examined to filter out the noisy data. Out of about 48K filtered Chinese microblogs, 39k microblogs are selected to form the final corpus with the Kappa value reaching over 0.92 for the automatic parts and over 0.81 for the manual part. The proportion of automatic selection reaches 54.1{\%}. Thus, the method can reduce about 44.5{\%} of manual workload for acquiring quality data. Experiment on a classifier trained on this corpus shows that it achieves comparable results compared to the manually annotated NLP{\&}CC2013 corpus.",https://aclanthology.org/L16-1291,emotion,Yes,Yes,Yes
Comparison of Emotional Understanding in Modality-Controlled Environments using Multimodal Online Emotional Communication Corpus,"Arimoto, Yoshiko  and
Okanoya, Kazuo",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"In online computer-mediated communication, speakers were considered to have experienced difficulties in catching their partner{'}s emotions and in conveying their own emotions. To explain why online emotional communication is so difficult and to investigate how this problem should be solved, multimodal online emotional communication corpus was constructed by recording approximately 100 speakers{'} emotional expressions and reactions in a modality-controlled environment. Speakers communicated over the Internet using video chat, voice chat or text chat; their face-to-face conversations were used for comparison purposes. The corpora incorporated emotional labels by evaluating the speaker{'}s dynamic emotional states and the measurements of the speaker{'}s facial expression, vocal expression and autonomic nervous system activity. For the initial study of this project, which used a large-scale emotional communication corpus, the accuracy of online emotional understanding was assessed to demonstrate the emotional labels evaluated by the speakers and to summarize the speaker{'}s answers on the questionnaire regarding the difference between an online chat and face-to-face conversations in which they actually participated. The results revealed that speakers have difficulty communicating their emotions in online communication environments, regardless of the type of communication modality and that inaccurate emotional understanding occurs more frequently in online computer-mediated communication than in face-to-face communication.",https://aclanthology.org/L16-1343,emotion,Yes,No,No
Construction of {J}apanese Audio-Visual Emotion Database and Its Application in Emotion Recognition,"Lubis, Nurul  and
Gomez, Randy  and
Sakti, Sakriani  and
Nakamura, Keisuke  and
Yoshino, Koichiro  and
Nakamura, Satoshi  and
Nakadai, Kazuhiro",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"Emotional aspects play a vital role in making human communication a rich and dynamic experience. As we introduce more automated system in our daily lives, it becomes increasingly important to incorporate emotion to provide as natural an interaction as possible. To achieve said incorporation, rich sets of labeled emotional data is prerequisite. However, in Japanese, existing emotion database is still limited to unimodal and bimodal corpora. Since emotion is not only expressed through speech, but also visually at the same time, it is essential to include multiple modalities in an observation. In this paper, we present the first audio-visual emotion corpora in Japanese, collected from 14 native speakers. The corpus contains 100 minutes of annotated and transcribed material. We performed preliminary emotion recognition experiments on the corpus and achieved an accuracy of 61.42{\%} for five classes of emotion.",https://aclanthology.org/L16-1346,emotion,Yes,No,No
Emotion Analysis on {T}witter: The Hidden Challenge,"Dini, Luca  and
Bittar, Andr{\'e}",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"In this paper, we present an experiment to detect emotions in tweets. Unlike much previous research, we draw the important distinction between the tasks of emotion detection in a closed world assumption (i.e. every tweet is emotional) and the complicated task of identifying emotional versus non-emotional tweets. Given an apparent lack of appropriately annotated data, we created two corpora for these tasks. We describe two systems, one symbolic and one based on machine learning, which we evaluated on our datasets. Our evaluation shows that a machine learning classifier performs best on emotion detection, while a symbolic approach is better for identifying relevant (i.e. emotional) tweets.",https://aclanthology.org/L16-1624,emotion,Yes,Yes,No
Accuracy of Automatic Cross-Corpus Emotion Labeling for Conversational Speech Corpus Commonization,"Mori, Hiroki  and
Nagaoka, Atsushi  and
Arimoto, Yoshiko",2016,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),,"There exists a major incompatibility in emotion labeling framework among emotional speech corpora, that is, category-based and dimension-based. Commonizing these requires inter-corpus emotion labeling according to both frameworks, but doing this by human annotators is too costly for most cases. This paper examines the possibility of automatic cross-corpus emotion labeling. In order to evaluate the effectiveness of the automatic labeling, a comprehensive emotion annotation for two conversational corpora, UUDB and OGVC, was performed. With a state-of-the-art machine learning technique, dimensional and categorical emotion estimation models were trained and tested against the two corpora. For the emotion dimension estimation, the automatic cross-corpus emotion labeling for the different corpus was effective for the dimensions of aroused-sleepy, dominant-submissive and interested-indifferent, showing only slight performance degradation against the result for the same corpus. On the other hand, the performance for the emotion category estimation was not sufficient.",https://aclanthology.org/L16-1634,emotion,Yes,Yes,No
{S}ensing Emotions in Text Messages: An Application and Deployment Study of {E}motion{P}ush,"Wang, Shih-Ming  and
Lee, Chun-Hui Scott  and
Lo, Yu-Chun  and
Huang, Ting-Hao  and
Ku, Lun-Wei",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",,"Instant messaging and push notifications play important roles in modern digital life. To enable robust sense-making and rich context awareness in computer mediated communications, we introduce EmotionPush, a system that automatically conveys the emotion of received text with a colored push notification on mobile devices. EmotionPush is powered by state-of-the-art emotion classifiers and is deployed for Facebook Messenger clients on Android. The study showed that the system is able to help users prioritize interactions.",https://aclanthology.org/C16-2030,emotion,No,No,No
"{Z}ara: A Virtual Interactive Dialogue System Incorporating Emotion, Sentiment and Personality Recognition","Fung, Pascale  and
Dey, Anik  and
Siddique, Farhad Bin  and
Lin, Ruixi  and
Yang, Yang  and
Bertero, Dario  and
Wan, Yan  and
Chan, Ricky Ho Yin  and
Wu, Chien-Sheng",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",,"Zara, or {`}Zara the Supergirl{'} is a virtual robot, that can exhibit empathy while interacting with an user, with the aid of its built in facial and emotion recognition, sentiment analysis, and speech module. At the end of the 5-10 minute conversation, Zara can give a personality analysis of the user based on all the user utterances. We have also implemented a real-time emotion recognition, using a CNN model that detects emotion from raw audio without feature extraction, and have achieved an average of 65.7{\%} accuracy on six different emotion classes, which is an impressive 4.5{\%} improvement from the conventional feature based SVM classification. Also, we have described a CNN based sentiment analysis module trained using out-of-domain data, that recognizes sentiment from the speech recognition transcript, which has a 74.8 F-measure when tested on human-machine dialogues.",https://aclanthology.org/C16-2058,emotion,No,Yes,No
How Interlocutors Coordinate with each other within Emotional Segments?,"Alam, Firoj  and
Chowdhury, Shammur Absar  and
Danieli, Morena  and
Riccardi, Giuseppe",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",,"In this paper, we aim to investigate the coordination of interlocutors behavior in different emotional segments. Conversational coordination between the interlocutors is the tendency of speakers to predict and adjust each other accordingly on an ongoing conversation. In order to find such a coordination, we investigated 1) lexical similarities between the speakers in each emotional segments, 2) correlation between the interlocutors using psycholinguistic features, such as linguistic styles, psychological process, personal concerns among others, and 3) relation of interlocutors turn-taking behaviors such as competitiveness. To study the degree of coordination in different emotional segments, we conducted our experiments using real dyadic conversations collected from call centers in which agent{'}s emotional state include empathy and customer{'}s emotional states include anger and frustration. Our findings suggest that the most coordination occurs between the interlocutors inside anger segments, where as, a little coordination was observed when the agent was empathic, even though an increase in the amount of non-competitive overlaps was observed. We found no significant difference between anger and frustration segment in terms of turn-taking behaviors. However, the length of pause significantly decreases in the preceding segment of anger where as it increases in the preceding segment of frustration.",https://aclanthology.org/C16-1070,emotion,No,No,No
Selective Co-occurrences for Word-Emotion Association,"Agrawal, Ameeta  and
An, Aijun",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",,"Emotion classification from text typically requires some degree of word-emotion association, either gathered from pre-existing emotion lexicons or calculated using some measure of semantic relatedness. Most emotion lexicons contain a fixed number of emotion categories and provide a rather limited coverage. Current measures of computing semantic relatedness, on the other hand, do not adapt well to the specific task of word-emotion association and therefore, yield average results. In this work, we propose an unsupervised method of learning word-emotion association from large text corpora, called Selective Co-occurrences (SECO), by leveraging the property of mutual exclusivity generally exhibited by emotions. Extensive evaluation, using just one seed word per emotion category, indicates the effectiveness of the proposed approach over three emotion lexicons and two state-of-the-art models of word embeddings on three datasets from different domains.",https://aclanthology.org/C16-1149,emotion,No,Yes,No
A Bilingual Attention Network for Code-switched Emotion Prediction,"Wang, Zhongqing  and
Zhang, Yue  and
Lee, Sophia  and
Li, Shoushan  and
Zhou, Guodong",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",,"Emotions in code-switching text can be expressed in either monolingual or bilingual forms. However, relatively little research has emphasized on code-switching text. In this paper, we propose a Bilingual Attention Network (BAN) model to aggregate the monolingual and bilingual informative words to form vectors from the document representation, and integrate the attention vectors to predict the emotion. The experiments show that the effectiveness of the proposed model. Visualization of the attention layers illustrates that the model selects qualitatively informative words.",https://aclanthology.org/C16-1153,emotion,No,Yes,No
Two-View Label Propagation to Semi-supervised Reader Emotion Classification,"Li, Shoushan  and
Xu, Jian  and
Zhang, Dong  and
Zhou, Guodong",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",,"In the literature, various supervised learning approaches have been adopted to address the task of reader emotion classification. However, the classification performance greatly suffers when the size of the labeled data is limited. In this paper, we propose a two-view label propagation approach to semi-supervised reader emotion classification by exploiting two views, namely source text and response text in a label propagation algorithm. Specifically, our approach depends on two word-document bipartite graphs to model the relationship among the samples in the two views respectively. Besides, the two bipartite graphs are integrated by linking each source text sample with its corresponding response text sample via a length-sensitive transition probability. In this way, our two-view label propagation approach to semi-supervised reader emotion classification largely alleviates the reliance on the strong sufficiency and independence assumptions of the two views, as required in co-training. Empirical evaluation demonstrates the effectiveness of our two-view label propagation approach to semi-supervised reader emotion classification.",https://aclanthology.org/C16-1249,emotion,Yes,Yes,No
Corpus Fusion for Emotion Classification,"Zhu, Suyang  and
Li, Shoushan  and
Chen, Ying  and
Zhou, Guodong",2016,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",,"Machine learning-based methods have obtained great progress on emotion classification. However, in most previous studies, the models are learned based on a single corpus which often suffers from insufficient labeled data. In this paper, we propose a corpus fusion approach to address emotion classification across two corpora which use different emotion taxonomies. The objective of this approach is to utilize the annotated data from one corpus to help the emotion classification on another corpus. An Integer Linear Programming (ILP) optimization is proposed to refine the classification results. Empirical studies show the effectiveness of the proposed approach to corpus fusion for emotion classification.",https://aclanthology.org/C16-1310,emotion,Yes,Yes,No
Computational Analysis of Affect and Emotion in Language,"Mohammad, Saif  and
Ovesdotter Alm, Cecilia",2015,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,,"Computational linguistics has witnessed a surge of interest in approaches to emotion and affect analysis, tackling problems that extend beyond sentiment analysis in depth and complexity. This area involves basic emotions (such as joy, sadness, and fear) as well as any of the hundreds of other emotions humans are capable of (such as optimism, frustration, and guilt), expanding into affective conditions, experiences, and activities. Leveraging linguistic data for computational affect and emotion inference enables opportunities to address a range of affect-related tasks, problems, and non-invasive applications that capture aspects essential to the human condition and individuals{'} cognitive processes. These efforts enable and facilitate human-centered computing experiences, as demonstrated by applications across clinical, socio-political, artistic, educational, and commercial domains. Efforts to computationally detect, characterize, and generate emotions or affect-related phenomena respond equally to technological needs for personalized, micro-level analytics and broad-coverage, macro-level inference, and they have involved both small and massive amounts of data.While this is an exciting area with numerous opportunities for members of the ACL community, a major obstacle is its intersection with other investigatory traditions, necessitating knowledge transfer. This tutorial comprehensively integrates relevant concepts and frameworks from linguistics, cognitive science, affective computing, and computational linguistics in order to equip researchers and practitioners with the adequate background and knowledge to work effectively on problems and tasks either directly involving, or benefiting from having an understanding of, affect and emotion analysis.There is a substantial body of work in traditional sentiment analysis focusing on positive and negative sentiment. This tutorial covers approaches and features that migrate well to affect analysis. We also discuss key differences from sentiment analysis, and their implications for analyzing affect and emotion.The tutorial begins with an introduction that highlights opportunities, key terminology, and interesting tasks and challenges (1). The body of the tutorial covers characteristics of emotive language use with emphasis on relevance for computational analysis (2); linguistic data{---}from conceptual analysis frameworks via useful existing resources to important annotation topics (3); computational approaches for lexical semantic emotion analysis (4); computational approaches for emotion and affect analysis in text (5); visualization methods (6); and a survey of application areas with affect-related problems (7). The tutorial concludes with an outline of future directions and a discussion with participants about the areas relevant to their respective tasks of interest (8).Besides attending the tutorial, tutorial participants receive electronic copies of tutorial slides, a complete reference list, as well as a categorized annotated bibliography that concentrates on seminal works, recent important publications, and other products and resources for researchers and developers.",https://aclanthology.org/D15-2008,emotion,Yes,No,Yes
"Toward a unifying model for Opinion, Sentiment and Emotion information extraction","Fraisse, Amel  and
Paroubek, Patrick",2014,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),,"This paper presents a logical formalization of a set 20 semantic categories related to opinion, emotion and sentiment. Our formalization is based on the BDI model (Belief, Desire and Intetion) and constitues a first step toward a unifying model for subjective information extraction. The separability of the subjective classes that we propose was assessed both formally and on two subjective reference corpora.",http://www.lrec-conf.org/proceedings/lrec2014/pdf/1010_Paper.pdf,emotion,No,Yes,No
Annotating Events in an Emotion Corpus,"Lee, Sophia  and
Li, Shoushan  and
Huang, Chu-Ren",2014,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),,"This paper presents the development of a Chinese event-based emotion corpus. It specifically describes the corpus design, collection and annotation. The proposed annotation scheme provides a consistent way of identifying some emotion-associated events (namely pre-events and post-events). Corpus data show that there are significant interactions between emotions and pre-events as well as that of between emotion and post-events. We believe that emotion as a pivot event underlies an innovative approach towards a linguistic model of emotion as well as automatic emotion detection and classification.",http://www.lrec-conf.org/proceedings/lrec2014/pdf/1222_Paper.pdf,emotion,Yes,Yes,No
Comparison of Gender- and Speaker-adaptive Emotion Recognition,"Sidorov, Maxim  and
Ultes, Stefan  and
Schmitt, Alexander",2014,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),,"Deriving the emotion of a human speaker is a hard task, especially if only the audio stream is taken into account. While state-of-the-art approaches already provide good results, adaptive methods have been proposed in order to further improve the recognition accuracy. A recent approach is to add characteristics of the speaker, e.g., the gender of the speaker. In this contribution, we argue that adding information unique for each speaker, i.e., by using speaker identification techniques, improves emotion recognition simply by adding this additional information to the feature vector of the statistical classification algorithm. Moreover, we compare this approach to emotion recognition adding only the speaker gender being a non-unique speaker attribute. We justify this by performing adaptive emotion recognition using both gender and speaker information on four different corpora of different languages containing acted and non-acted speech. The final results show that adding speaker information significantly outperforms both adding gender information and solely using a generic speaker-independent approach.",http://www.lrec-conf.org/proceedings/lrec2014/pdf/322_Paper.pdf,emotion,No,Yes,No
{E}milya: Emotional body expression in daily actions database,"Fourati, Nesrine  and
Pelachaud, Catherine",2014,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),,"The studies of bodily expression of emotion have been so far mostly focused on body movement patterns associated with emotional expression. Recently, there is an increasing interest on the expression of emotion in daily actions, called also non-emblematic movements (such as walking or knocking at the door). Previous studies were based on database limited to a small range of movement tasks or emotional states. In this paper, we describe our new database of emotional body expression in daily actions, where 11 actors express 8 emotions in 7 actions. We use motion capture technology to record body movements, but we recorded as well synchronized audio-visual data to enlarge the use of the database for different research purposes. We investigate also the matching between the expressed emotions and the perceived ones through a perceptive study. The first results of this study are discussed in this paper.",http://www.lrec-conf.org/proceedings/lrec2014/pdf/334_Paper.pdf,emotion,No,No,No
Speech-Based Emotion Recognition: Feature Selection by Self-Adaptive Multi-Criteria Genetic Algorithm,"Sidorov, Maxim  and
Brester, Christina  and
Minker, Wolfgang  and
Semenkin, Eugene",2014,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),,"Automated emotion recognition has a number of applications in Interactive Voice Response systems, call centers, etc. While employing existing feature sets and methods for automated emotion recognition has already achieved reasonable results, there is still a lot to do for improvement. Meanwhile, an optimal feature set, which should be used to represent speech signals for performing speech-based emotion recognition techniques, is still an open question. In our research, we tried to figure out the most essential features with self-adaptive multi-objective genetic algorithm as a feature selection technique and a probabilistic neural network as a classifier. The proposed approach was evaluated using a number of multi-languages databases (English, German), which were represented by 37- and 384-dimensional feature sets. According to the obtained results, the developed technique allows to increase the emotion recognition performance by up to 26.08 relative improvement in accuracy. Moreover, emotion recognition performance scores for all applied databases are improved.",http://www.lrec-conf.org/proceedings/lrec2014/pdf/341_Paper.pdf,emotion,No,Yes,No
{EMOVO} Corpus: an {I}talian Emotional Speech Database,"Costantini, Giovanni  and
Iaderola, Iacopo  and
Paoloni, Andrea  and
Todisco, Massimiliano",2014,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),,"This article describes the first emotional corpus, named EMOVO, applicable to Italian language,. It is a database built from the voices of up to 6 actors who played 14 sentences simulating 6 emotional states (disgust, fear, anger, joy, surprise, sadness) plus the neutral state. These emotions are the well-known Big Six found in most of the literature related to emotional speech. The recordings were made with professional equipment in the Fondazione Ugo Bordoni laboratories. The paper also describes a subjective validation test of the corpus, based on emotion-discrimination of two sentences carried out by two different groups of 24 listeners. The test was successful because it yielded an overall recognition accuracy of 80{\%}. It is observed that emotions less easy to recognize are joy and disgust, whereas the most easy to detect are anger, sadness and the neutral state.",http://www.lrec-conf.org/proceedings/lrec2014/pdf/591_Paper.pdf,emotion,Yes,No,No
Mining Sentiment Words from Microblogs for Predicting Writer-Reader Emotion Transition,"Tang, Yi-jie  and
Chen, Hsin-Hsi",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"The conversations between posters and repliers in microblogs form a valuable writer-reader emotion corpus. This paper adopts a log relative frequency ratio to investigate the linguistic features which affect emotion transitions, and applies the results to predict writers' and readers' emotions. A 4-class emotion transition predictor, a 2-class writer emotion predictor, and a 2-class reader emotion predictor are proposed and compared.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/117_Paper.pdf,emotion,Yes,No,No
{E}mpa{T}weet: Annotating and Detecting Emotions on {T}witter,"Roberts, Kirk  and
Roach, Michael A.  and
Johnson, Joseph  and
Guthrie, Josh  and
Harabagiu, Sanda M.",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"The rise of micro-blogging in recent years has resulted in significant access to emotion-laden text. Unlike emotion expressed in other textual sources (e.g., blogs, quotes in newswire, email, product reviews, or even clinical text), micro-blogs differ by (1) placing a strict limit on length, resulting radically in new forms of emotional expression, and (2) encouraging users to express their daily thoughts in real-time, often resulting in far more emotion statements than might normally occur. In this paper, we introduce a corpus collected from Twitter with annotated micro-blog posts (or tweets) annotated at the tweet-level with seven emotions: ANGER, DISGUST, FEAR, JOY, LOVE, SADNESS, and SURPRISE. We analyze how emotions are distributed in the data we annotated and compare it to the distributions in other emotion-annotated corpora. We also used the annotated corpus to train a classifier that automatically discovers the emotions in tweets. In addition, we present an analysis of the linguistic style used for expressing emotions our corpus. We hope that these observations will lead to the design of novel emotion detection techniques that account for linguistic style and psycholinguistic theories.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/201_Paper.pdf,emotion,Yes,Yes,No
A Multilingual Natural Stress Emotion Database,"Zuo, Xin  and
Li, Tian  and
Fung, Pascale",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"In this paper, we describe an ongoing effort in collecting and annotating a multilingual speech database of natural stress emotion from university students. The goal is to detect natural stress emotions and study the stress expression differences in different languages, which may help psychologists in the future. We designed a common questionnaire of stress-inducing and non-stress-inducing questions in English, Mandarin and Cantonese and collected a first ever, multilingual corpus of natural stress emotion. All of the students are native speakers of the corresponding language. We asked native language speakers to annotate recordings according to the participants' self-label states and obtained a very good kappa inter labeler agreement. We carried out human perception tests where listeners who do not understand Chinese were asked to detect stress emotion from the Mandarin Chinese database. Compared to the annotation labels, these human perceived emotions are of low accuracy, which shows a great necessity for natural stress detection research.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/594_Paper.pdf,emotion,Yes,No,No
A Parallel Corpus of Music and Lyrics Annotated with Emotions,"Strapparava, Carlo  and
Mihalcea, Rada  and
Battocchi, Alberto",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"In this paper, we introduce a novel parallel corpus of music and lyrics, annotated with emotions at line level. We first describe the corpus, consisting of 100 popular songs, each of them including a music component, provided in the MIDI format, as well as a lyrics component, made available as raw text. We then describe our work on enhancing this corpus with emotion annotations using crowdsourcing. We also present some initial experiments on emotion classification using the music and the lyrics representations of the songs, which lead to encouraging results, thus demonstrating the promise of using joint music-lyric models for song processing.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/730_Paper.pdf,emotion,Yes,Yes,No
Building a Multimodal Laughter Database for Emotion Recognition,"Suarez, Merlin Teodosia  and
Cu, Jocelynn  and
Maria, Madelene Sta.",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"Laughter is a significant paralinguistic cue that is largely ignored in multimodal affect analysis. In this work, we investigate how a multimodal laughter corpus can be constructed and annotated both with discrete and dimensional labels of emotions for acted and spontaneous laughter. Professional actors enacted emotions to produce acted clips, while spontaneous laughter was collected from volunteers. Experts annotated acted laughter clips, while volunteers who possess an acceptable empathic quotient score annotated spontaneous laughter clips. The data was pre-processed to remove noise from the environment, and then manually segmented starting from the onset of the expression until its offset. Our findings indicate that laughter carries distinct emotions, and that emotion in laughter is best recognized using audio information rather than facial information. This may be explained by emotion regulation, i.e. laughter is used to suppress or regulate certain emotions. Furthermore, contextual information plays a crucial role in understanding the kind of laughter and emotion in the enactment.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/779_Paper.pdf,emotion,Yes,No,No
Towards Emotion and Affect Detection in the Multimodal {LAST} {MINUTE} Corpus,"Frommer, J{\""o}rg  and
Michaelis, Bernd  and
R{\""o}sner, Dietmar  and
Wendemuth, Andreas  and
Friesen, Rafael  and
Haase, Matthias  and
Kunze, Manuela  and
Andrich, Rico  and
Lange, Julia  and
Panning, Axel  and
Siegert, Ingo",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"The LAST MINUTE corpus comprises multimodal recordings (e.g. video, audio, transcripts) from WOZ interactions in a mundane planning task (R{\""o}sner et al., 2011). It is one of the largest corpora with naturalistic data currently available. In this paper we report about first results from attempts to automatically and manually analyze the different modes with respect to emotions and affects exhibited by the subjects. We describe and discuss difficulties encountered due to the strong contrast between the naturalistic recordings and traditional databases with acted emotions.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/782_Paper.pdf,emotion,Yes,No,No
The {I}3{MEDIA} speech database: a trilingual annotated corpus for the analysis and synthesis of emotional speech,"Garrido, Juan Mar{\'\i}a  and
Laplaza, Yesika  and
Marquina, Montse  and
Pearman, Andrea  and
Escalada, Jos{\'e} Gregorio  and
Rodr{\'\i}guez, Miguel {\'A}ngel  and
Armenta, Ana",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"In this article the I3Media corpus is presented, a trilingual (Catalan, English, Spanish) speech database of neutral and emotional material collected for analysis and synthesis purposes. The corpus is actually made up of six different subsets of material: a neutral subcorpus, containing emotionless utterances; a dialog' subcorpus, containing typical call center utterances; an emotional' corpus, a set of sentences representative of pure emotional states; a football' subcorpus, including utterances imitating a football broadcasting situation; a SMS' subcorpus, including readings of SMS texts; and a paralinguistic elements' corpus, including recordings of interjections and paralinguistic sounds uttered in isolation. The corpus was read by professional speakers (male, in the case of Spanish and Catalan; female, in the case of the English corpus), carefully selected to meet criteria of language competence, voice quality and acting conditions. It is the result of a collaboration between the Speech Technology Group at Telef{\'o}nica Investigaci{\'o}n y Desarrollo (TID) and the Speech and Language Group at Barcelona Media Centre d'Innovaci{\'o} (BM), as part of the I3Media project.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/865_Paper.pdf,emotion,Yes,No,No
A hierarchical approach with feature selection for emotion recognition from speech,"Giannoulis, Panagiotis  and
Potamianos, Gerasimos",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"We examine speaker independent emotion classification from speech, reporting experiments on the Berlin database across six basic emotions. Our approach is novel in a number of ways: First, it is hierarchical, motivated by our belief that the most suitable feature set for classification is different for each pair of emotions. Further, it uses a large number of feature sets of different types, such as prosodic, spectral, glottal flow based, and AM-FM ones. Finally, it employs a two-stage feature selection strategy to achieve discriminative dimensionality reduction. The approach results to a classification rate of 85{\%}, comparable to the state-of-the-art on this dataset.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/917_Paper.pdf,emotion,Yes,Yes,No
Extending the {E}moti{N}et Knowledge Base to Improve the Automatic Detection of Implicitly Expressed Emotions from Text,"Balahur, Alexandra  and
Hermida, Jes{\'u}s M.",2012,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),,"Sentiment analysis is one of the recent, highly dynamic fields in Natural Language Processing. Although much research has been performed in this area, most existing approaches are based on word-level analysis of texts and are mostly able to detect only explicit expressions of sentiment. However, in many cases, emotions are not expressed by using words with an affective meaning (e.g. happy), but by describing real-life situations, which readers (based on their commonsense knowledge) detect as being related to a specific emotion. Given the challenges of detecting emotions from contexts in which no lexical clue is present, in this article we present a comparative analysis between the performance of well-established methods for emotion detection (supervised and lexical knowledge-based) and a method we extend, which is based on commonsense knowledge stored in the EmotiNet knowledge base. Our extensive comparative evaluations show that, in the context of this task, the approach based on EmotiNet is the most appropriate.",http://www.lrec-conf.org/proceedings/lrec2012/pdf/945_Paper.pdf,emotion,No,Yes,Yes
"Evaluation de la d{\'e}tection des {\'e}motions, des opinions ou des sentiments : dictature de la majorit{\'e} ou respect de la diversit{\'e} d{'}opinions ? (Evaluation of the detection of emotions, opinions or sentiments: majority dictatorship or respect for opinion diversity?)","Antoine, Jean-Yves  and
Le Tallec, Marc  and
Villaneau, Jeanne",2011,Actes de la 18e conf{\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,,"D{\'e}tection d{'}{\'e}motion, fouille d{'}opinion et analyse des sentiments sont g{\'e}n{\'e}ralement {\'e}valu{\'e}s par comparaison des r{\'e}ponses du syst{\`e}me concern{\'e} par rapport {\`a} celles contenues dans un corpus de r{\'e}f{\'e}rence. Les questions pos{\'e}es dans cet article concernent {\`a} la fois la d{\'e}finition de la r{\'e}f{\'e}rence et la fiabilit{\'e} des m{\'e}triques les plus fr{\'e}quemment utilis{\'e}es pour cette comparaison. Les exp{\'e}rimentations men{\'e}es pour {\'e}valuer le syst{\`e}me de d{\'e}tection d{'}{\'e}motions EmoLogus servent de base de r{\'e}flexion pour ces deux probl{\`e}mes. L{'}analyse des r{\'e}sultats d{'}EmoLogus et la comparaison entre les diff{\'e}rentes m{\'e}triques remettent en cause le choix du vote majoritaire comme r{\'e}f{\'e}rence. Par ailleurs elles montrent {\'e}galement la n{\'e}cessit{\'e} de recourir {\`a} des outils statistiques plus {\'e}volu{\'e}s que ceux g{\'e}n{\'e}ralement utilis{\'e}s pour obtenir des {\'e}valuations fiables de syst{\`e}mes qui travaillent sur des donn{\'e}es intrins{\`e}quement subjectives et incertaines.",https://aclanthology.org/2011.jeptalnrecital-court.1,emotion,Yes,No,No
Une proc{\'e}dure pour identifier les modifieurs de la valence affective d{'}un mot dans des textes (A procedure to identify modifiers of the word emotional valence in texts),"Boubel, No{\'e}mi  and
Bestgen, Yves",2011,Actes de la 18e conf{\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,,"Cette recherche s{'}inscrit dans le champ de la fouille d{'}opinion et, plus particuli{\`e}rement, dans celui de l{'}analyse de la polarit{\'e} d{'}une phrase ou d{'}un syntagme. Dans ce cadre, la prise en compte du contexte linguistique dans lequel apparaissent les mots porteurs de valence est particuli{\`e}rement importante. Nous proposons une m{\'e}thodologie pour extraire automatiquement de corpus de textes de telles expressions linguistiques. Cette approche s{'}appuie sur un corpus de textes, ou d{'}extraits de textes, dont la valence est connue, sur un lexique de valence construit {\`a} partir de ce corpus au moyen d{'}une proc{\'e}dure automatique et sur un analyseur syntaxique. Une {\'e}tude exploratoire, limit{\'e}e {\`a} la seule relation syntaxique associant un adverbe {\`a} un adjectif, laisse entrevoir les potentialit{\'e}s de l{'}approche.",https://aclanthology.org/2011.jeptalnrecital-court.23,emotion,Yes,No,No
Determining Reliability of Subjective and Multi-label Emotion Annotation through Novel Fuzzy Agreement Measure,"Bhowmick, Plaban Kr.  and
Basu, Anupam  and
Mitra, Pabitra",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"The paper presents a new fuzzy agreement measure {\$}{\textbackslash}gamma{\_}f{\$} for determining the agreement in multi-label and subjective annotation task. In this annotation framework, one data item may belong to a category or a class with a belief value denoting the degree of confidence of an annotator in assigning the data item to that category. We have provided a notion of disagreement based on the belief values provided by the annotators with respect to a category. The fuzzy agreement measure {\$}{\textbackslash}gamma{\_}f{\$} has been proposed by defining different fuzzy agreement sets based on the distribution of difference of belief values provided by the annotators. The fuzzy agreement has been computed by studying the average agreement over all the data items and annotators. Finally, we elaborate on the computation {\$}{\textbackslash}gamma{\_}f{\$} measure with a case study on emotion text data where a data item (sentence) may belong to more than one emotion category with varying belief values.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/67_Paper.pdf,emotion,No,No,No
Developing an Expressive Speech Labeling Tool Incorporating the Temporal Characteristics of Emotion,"Scherer, Stefan  and
Siegert, Ingo  and
Bigalke, Lutz  and
Meudt, Sascha",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"A lot of research effort has been spent on the development of emotion theories and modeling, however, their suitability and applicability to expressions in human computer interaction has not exhaustively been evaluated. Furthermore, investigations concerning the ability of the annotators to map certain expressions onto the developed emotion models is lacking proof. The proposed annotation tool, which incorporates the standard Geneva Emotional Wheel developed by Klaus Scherer and a novel temporal characteristic description feature, is aiming towards enabling the annotator to label expressions recorded in human computer interaction scenarios on an utterance level. Further, it is respecting key features of realistic and natural emotional expressions, such as their sequentiality, temporal characteristics, their mixed occurrences, and their expressivity or clarity of perception. Additionally, first steps towards evaluating the proposed tool, by analyzing utterance annotations taken from two expressive speech corpora, are undertaken and some future goals including the open source accessibility of the tool are given.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/101_Paper.pdf,emotion,No,Yes,No
Emotion Cause Events: Corpus Construction and Analysis,"Lee, Sophia Yat Mei  and
Chen, Ying  and
Li, Shoushan  and
Huang, Chu-Ren",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"Emotion processing has always been a great challenge. Given the fact that an emotion is triggered by cause events and that cause events are an integral part of emotion, this paper constructs a Chinese emotion cause corpus as a first step towards automatic inference of cause-emotion correlation. The corpus focuses on five primary emotions, namely happiness, sadness, fear, anger, and surprise. It is annotated with emotion cause events based on our proposed annotation scheme. Corpus data shows that most emotions are expressed with causes, and that causes mostly occur before the corresponding emotion verbs. We also examine the correlations between emotions and cause events in terms of linguistic cues: causative verbs, perception verbs, epistemic markers, conjunctions, prepositions, and others. Results show that each group of linguistic cues serves as an indicator marking the cause events in different structures of emotional constructions. We believe that the emotion cause corpus will be the useful resource for automatic emotion cause detection as well as emotion detection and classification.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/322_Paper.pdf,emotion,Yes,Yes,No
Building a System for Emotions Detection from Speech to Control an Affective Avatar,"Brendel, M{\'a}ty{\'a}s  and
Zaccarelli, Riccardo  and
Devillers, Laurence",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"In this paper we describe a corpus set together from two sub-corpora. The CINEMO corpus contains acted emotional expression obtained by playing dubbing exercises. This new protocol is a way to collect mood-induced data in large amount which show several complex and shaded emotions. JEMO is a corpus collected with an emotion-detection game and contains more prototypical emotions than CINEMO. We show how the two sub-corpora balance and enrich each other and result in a better performance. We built male and female emotion models and use Sequential Fast Forward Feature Selection to improve detection performances. After feature-selection we obtain good results even with our strict speaker independent testing method. The global corpus contains 88 speakers (38 females, 50 males). This study has been done within the scope of the ANR (National Research Agency) Affective Avatar project which deals with building a system of emotions detection for monitoring an Artificial Agent by voice.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/403_Paper.pdf,emotion,Yes,Yes,No
{CINEMO} {---} A {F}rench Spoken Language Resource for Complex Emotions: Facts and Baselines,"Schuller, Bj{\""o}rn  and
Zaccarelli, Riccardo  and
Rollet, Nicolas  and
Devillers, Laurence",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"The CINEMO corpus of French emotional speech provides a richly annotated resource to help overcome the apparent lack of learning and testing speech material for complex, i.e. blended or mixed emotions. The protocol for its collection was dubbing selected emotional scenes from French movies. 51 speakers are contained and the total speech time amounts to 2 hours and 13 minutes and 4k speech chunks after segmentation. Extensive labelling was carried out in 16 categories for major and minor emotions and in 6 continuous dimensions. In this contribution we give insight into the corpus statistics focusing in particular on the topic of complex emotions, and provide benchmark recognition results obtained in exemplary large feature space evaluations. In the result the labelling oft he collected speech clearly demonstrates that a complex handling of emotion seems needed. Further, the automatic recognition experiments provide evidence that the automatic recognition of blended emotions appears to be feasible.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/483_Paper.pdf,emotion,Yes,No,No
The Demo / Kemo Corpus: A Principled Approach to the Study of Cross-cultural Differences in the Vocal Expression and Perception of Emotion,"Goudbeek, Martijn  and
Broersma, Mirjam",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"This paper presents the Demo / Kemo corpus of Dutch and Korean emotional speech. The corpus has been specifically developed for the purpose of cross-linguistic comparison, and is more balanced than any similar corpus available so far: a) it contains expressions by both Dutch and Korean actors as well as judgments by both Dutch and Korean listeners; b) the same elicitation technique and recording procedure was used for recordings of both languages; c) the same nonsense sentence, which was constructed to be permissible in both languages, was used for recordings of both languages; and d) the emotions present in the corpus are balanced in terms of valence, arousal, and dominance. The corpus contains a comparatively large number of emotions (eight) uttered by a large number of speakers (eight Dutch and eight Korean). The counterbalanced nature of the corpus will enable a stricter investigation of language-specific versus universal aspects of emotional expression than was possible so far. Furthermore, given the carefully controlled phonetic content of the expressions, it allows for analysis of the role of specific phonetic features in emotional expression in Dutch and Korean.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/511_Paper.pdf,emotion,Yes,No,No
Automatic Annotation of Word Emotion in Sentences Based on {R}en-{CEC}ps,"Quan, Changqin  and
Ren, Fuji",2010,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),,"Textual information is an important communication medium contained rich expression of emotion, and emotion recognition on text has wide applications. Word emotion analysis is fundamental in the problem of textual emotion recognition. Through an analysis of the characteristics of word emotion expression, we use word emotion vector to describe the combined basic emotions in a word, which can be used to distinguish direct and indirect emotion words, express emotion ambiguity in words, and express multiple emotions in words. Based on Ren-CECps (a Chinese emotion corpus), we do an experiment to explore the role of emotion word for sentence emotion recognition and we find that the emotions of a simple sentence (sentence without negative words, conjunctions, or question mark) can be approximated by an addition of the word emotions. Then MaxEnt modeling is used to find which context features are effective for recognizing word emotion in sentences. The features of word, N-words, POS, Pre-N-words emotion, Pre-is-degree-word, Pre-is-negativeword, Pre-is-conjunction and their combination have been experimented. After that, we use the two metrics: Kappa coefficient of agreement and Voting agreement to measure the word annotation agreement of Ren-CECps. The experiments on above context features showed promising results compared with word emotion agreement on people's judgments.",http://www.lrec-conf.org/proceedings/lrec2010/pdf/662_Paper.pdf,emotion,Yes,Yes,No
On the Role of the {NIMITEK} Corpus in Developing an Emotion Adaptive Spoken Dialogue System,"Gnjatovi{\'c}, Milan  and
Roesner, Dietmar",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"This paper reports on the creation of the multimodal NIMITEK corpus of affected behavior in human-machine interaction and its role in the development of the NIMITEK prototype system. The NIMITEK prototype system is a spoken dialogue system for supporting users while they solve problems in a graphics system. The central feature of the system is adaptive dialogue management. The system dynamically defines a dialogue strategy according to the current state of the interaction (including also the emotional state of the user). Particular emphasis is devoted to the level of naturalness of interaction. We discuss that a higher level of naturalness can be achieved by combining a habitable natural language interface and an appropriate dialogue strategy. The role of the NIMITEK multimodal corpus in achieving these requirements is twofold: (1) in developing the model of attentional state on the level of users commands that facilitates processing of flexibly formulated commands, and (2) in defining the dialogue strategy that takes the emotional state of the user into account. Finally, we sketch the implemented prototype system and describe the incorporated dialogue management module. Whereas the prototype system itself is task-specific, the described underlying concepts are intended to be task-independent.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/149_paper.pdf,emotion,Yes,Yes,No
Emotion Recognition from Speech: Stress Experiment,"Scherer, Stefan  and
Hofmann, Hansj{\""o}rg  and
Lampmann, Malte  and
Pfeil, Martin  and
Rhinow, Steffen  and
Schwenker, Friedhelm  and
Palm, G{\""u}nther",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"The goal of this work is to introduce an architecture to automatically detect the amount of stress in the speech signal close to real time. For this an experimental setup to record speech rich in vocabulary and containing different stress levels is presented. Additionally, an experiment explaining the labeling process with a thorough analysis of the labeled data is presented. Fifteen subjects were asked to play an air controller simulation that gradually induced more stress by becoming more difficult to control. During this game the subjects were asked to answer questions, which were then labeled by a different set of subjects in order to receive a subjective target value for each of the answers. A recurrent neural network was used to measure the amount of stress contained in the utterances after training. The neural network estimated the amount of stress at a frequency of 25 Hz and outperformed the human baseline.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/336_paper.pdf,emotion,Yes,Yes,No
Coding Emotional Events in Audiovisual Corpora,"Devillers, Laurence  and
Martin, Jean-Claude",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"The modelling of realistic emotional behaviour is needed for various applications in multimodal human-machine interaction such as the design of emotional conversational agents (Martin et al., 2005) or of emotional detection systems (Devillers and Vidrascu, 2007). Yet, building such models requires appropriate definition of various levels for representing the emotions themselves but also some contextual information such as the events that elicit these emotions. This paper presents a coding scheme that has been defined following annotations of a corpus of TV interviews (EmoTV). Deciding which events triggered or may trigger which emotion is a challenge for building efficient emotion eliciting protocols. In this paper, we present the protocol that we defined for collecting another corpus of spontaneous human-human interactions recorded in laboratory conditions (EmoTaboo). We discuss the events that we designed for eliciting emotions. Part of this scheme for coding emotional event is being included in the specifications that are currently defined by a working group of the W3C (the W3C Emotion Incubator Working group). This group is investigating the feasibility of working towards a standard representation of emotions and related states in technological contexts.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/322_paper.pdf,emotion,Yes,Yes,No
Annotating Expressions of Opinion and Emotion in the {I}talian Content Annotation Bank,"Esuli, Andrea  and
Sebastiani, Fabrizio  and
Urciuoli, Ilaria",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"In this paper we describe the result of manually annotating I-CAB, the Italian Content Annotation Bank, by expressions of private state (EPSs), i.e., expressions that denote the presence of opinions, emotions, and other cognitive states. The aim of this effort was the generation of a standard resource for supporting the development of opinion extraction algorithms for Italian, and of a benchmark for testing such algorithms. To this end we have employed a previously existing annotation language (here dubbed WWC, from the initials of its proponents). We here describe the results of this annotation effort, including the results of a thorough inter-annotator agreement test. We conclude by discussing how WWC can be adapted to the specificities of a Romance language such as Italian.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/566_paper.pdf,emotion,Yes,No,No
Subjective Evaluation of an Emotional Speech Database for {B}asque,"Sainz, I{\~n}aki  and
Saratxaga, Ibon  and
Navas, Eva  and
Hern{\'a}ez, Inmaculada  and
Sanchez, Jon  and
Luengo, Iker  and
Odriozola, Igor",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"This paper describes the evaluation process of an emotional speech database recorded for standard Basque, in order to determine its adequacy for the analysis of emotional models and its use in speech synthesis. The corpus consists of seven hundred semantically neutral sentences that were recorded for the Big Six emotions and neutral style, by two professional actors. The test results show that every emotion is readily recognized far above chance level for both speakers. Therefore the database is a valid linguistic resource for the research and development purposes it was designed for.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/437_paper.pdf,emotion,Yes,Yes,No
Automatic Emotional Degree Labeling for Speakers{'} Anger Utterance during Natural {J}apanese Dialog,"Arimoto, Yoshiko  and
Ohno, Sumio  and
Iida, Hitoshi",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"This paper describes a method of automatic emotional degree labeling for speakers anger utterances during natural Japanese dialog. First, we explain how to record anger utterance naturally appeared in natural Japanese dialog. Manual emotional degree labeling was conducted in advance to grade the utterances by a 6 Likert scale to obtain a correct anger degree. Then experiments of automatic anger degree estimation were conducted to label an anger degree with each utterance by its acoustic features. Also estimation experiments were conducted with speaker-dependent datasets to find out any influence of individual emotional expression on automatic emotional degree labeling. As a result, almost all the speakers models show higher adjusted R square so that those models are superior to the speaker-independent model in those estimation capabilities. However, a residual between automatic emotional degree and manual emotional degree (0.73) is equivalent to those of speakers models. There still has a possibility to label utterances with the speaker-independent model.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/575_paper.pdf,emotion,No,Yes,No
A Real-World Emotional Speech Corpus for {M}odern {G}reek,"Kostoulas, Theodoros  and
Ganchev, Todor  and
Mporas, Iosif  and
Fakotakis, Nikos",2008,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),,"The present paper deals with the design and the annotation of a Greek real-world emotional speech corpus. The speech data consist of recordings collected during the interaction of na{\""\i}ve users with a smart-home dialogue system. Annotation of the speech data with respect to the uttered command and emotional state was performed. Initial experimentations towards recognizing negative emotional states were performed and the experimental results indicate the range of difficulties when dealing with real-world data.",http://www.lrec-conf.org/proceedings/lrec2008/pdf/664_paper.pdf,emotion,Yes,No,No
Designing and Recording an Emotional Speech Database for Corpus Based Synthesis in {B}asque,"Saratxaga, Ibon  and
Navas, Eva  and
Hern{\'a}ez, Inmaculada  and
Aholab, Iker",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"This paper describes an emotional speech database recorded for standard Basque. The database has been designed with the twofold purpose of being used for corpus based synthesis, and also of allowing the study of prosodic models for the emotions. The database is thus large, to get good corpus based synthesis quality and contains the same texts recorded in the six basic emotions plus the neutral style. The recordings were carried out by two professional dubbing actors, a man and a woman. The paper explains the whole creation process, beginning with the design stage, following with the corpus creation and the recording phases, and finishing with some learned lessons and hints.",http://www.lrec-conf.org/proceedings/lrec2006/pdf/19_pdf.pdf,emotion,Yes,Yes,No
Fear-type emotions of the {SAFE} Corpus: annotation issues,"Clavel, Chlo{\'e}  and
Vasilescu, Ioana  and
Devillers, Laurence  and
Ehrette, Thibaut  and
Richard, Ga{\""e}l",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"The present research focuses on annotation issues in the context of the acoustic detection of fear-type emotions for surveillance applications. The emotional speech material used for this study comes from the previously collected SAFE Database (Situation Analysis in a Fictional and Emotional Database) which consists of audio-visual sequences extracted from movie fictions. A generic annotation scheme was developed to annotate the various emotional manifestations contained in the corpus. The annotation was carried out by two labellers and the two annotations strategies are confronted. It emerges that the borderline between emotion and neutral vary according to the labeller. An acoustic validation by a third labeller allows at analysing the two strategies. Two human strategies are then observed: a first one, context-oriented which mixes audio and contextual (video) information in emotion categorization; and a second one, based mainly on audio information. The k-means clustering confirms the role of audio cues in human annotation strategies. It particularly helps in evaluating those strategies from the point of view of a detection system based on audio cues.",http://www.lrec-conf.org/proceedings/lrec2006/pdf/319_pdf.pdf,emotion,Yes,No,No
Improving Automatic Emotion Recognition from Speech via Gender Differentiaion,"Vogt, Thurid  and
Andr{\'e}, Elisabeth",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"Feature extraction is still a disputed issue for the recognition of emotions from speech. Differences in features for male and female speakers are a well-known problem and it is established that gender-dependent emotion recognizers perform better than gender-independent ones. We propose a way to improve the discriminative quality of gender-dependent features: The emotion recognition system is preceded by an automatic gender detection that decides upon which of two gender-dependent emotion classifiers is used to classify an utterance. This framework was tested on two different databases, one with emotional speech produced by actors and one with spontaneous emotional speech from a Wizard-of-Oz setting. Gender detection achieved an accuracy of about 90 {\%} and the combined gender and emotion recognition system improved the overall recognition rate of a gender-independent emotion recognition system by 2-4 {\%}.",http://www.lrec-conf.org/proceedings/lrec2006/pdf/392_pdf.pdf,emotion,No,No,No
Real life emotions in {F}rench and {E}nglish {TV} video clips: an integrated annotation protocol combining continuous and discrete approaches,"Devillers, L.  and
Cowie, R.  and
Martin, J-C.  and
Douglas-Cowie, E.  and
Abrilian, S.  and
McRorie, M.",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"A major barrier to the development of accurate and realistic models of human emotions is the absence of multi-cultural / multilingual databases of real-life behaviours and of a federative and reliable annotation protocol. QUB and LIMSI teams are working towards the definition of an integrated coding scheme combining their complementary approaches. This multilevel integrated scheme combines the dimensions that appear to be useful for the study of real-life emotions: verbal labels, abstract dimensions and contextual (appraisal based) annotations. This paper describes this integrated coding scheme, a protocol that was set-up for annotating French and English video clips of emotional interviews and the results (e.g. inter-coder agreement measures and subjective evaluation of the scheme).",http://www.lrec-conf.org/proceedings/lrec2006/pdf/411_pdf.pdf,emotion,No,Yes,No
Manual Annotation and Automatic Image Processing of Multimodal Emotional Behaviours: Validating the Annotation of {TV} Interviews,"Martin, J.-C.  and
Caridakis, G.  and
Devillers, L.  and
Karpouzis, K.  and
Abrilian, S.",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"There has been a lot of psychological researches on emotion and nonverbal communication. Yet, these studies were based mostly on acted basic emotions. This paper explores how manual annotation and image processing can cooperate towards the representation of spontaneous emotional behaviour in low resolution videos from TV. We describe a corpus of TV interviews and the manual annotations that have been defined. We explain the image processing algorithms that have been designed for the automatic estimation of movement quantity. Finally, we explore how image processing can be used for the validation of manual annotations.",http://www.lrec-conf.org/proceedings/lrec2006/pdf/465_pdf.pdf,emotion,Yes,No,No
Annotation of Emotions in Real-Life Video Interviews: Variability between Coders,"Abrilian, S.  and
Devillers, L.  and
Martin, J-C.",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"Research on emotional real-life data has to tackle the problem of their annotation. The annotation of emotional corpora raises the issue of how different coders perceive the same multimodal emotional behaviour. The long-term goal of this paper is to produce a guideline for the selection of annotators. The LIMSI team is working towards the definition of a coding scheme integrating emotion, context and multimodal annotations. We present the current defined coding scheme for emotion annotation, and the use of soft vectors for representing a mixture of emotions. This paper describes a perceptive test of emotion annotations and the results obtained with 40 different coders on a subset of complex real-life emotional segments selected from the EmoTV Corpus collected at LIMSI. The results of this first study validate previous annotations of emotion mixtures and highlight the difference of annotation between male and female coders.",http://www.lrec-conf.org/proceedings/lrec2006/pdf/531_pdf.pdf,emotion,Yes,No,No
Creation of a corpus of multimodal spontaneous expressions of emotions in Human-Machine Interaction,"Lechenadec, G.  and
Maffiolo, V.  and
Chateau, N.  and
Colletta, J.M.",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"This paper presents an experience in laboratory dealing with the constitution of a corpus of multimodal spontaneous expressions of emotions. The originality of this corpus resides in its characteristics (interactions between a virtual actor and humans learning a theater text), in its content (multimodal spontaneous expressions of emotions) and in its two sources of characterization (by the participant and by one of his/her close relation). The corpus collection is part of a study on the fusion of multimodal information (verbal, facial, gestural, postural, and physiological) to improve the detection and characterization of expressions of emotions in human-machine interaction (HMI).",http://www.lrec-conf.org/proceedings/lrec2006/pdf/599_pdf.pdf,emotion,Yes,No,No
Annotating Emotions in Meetings,"Reidsma, Dennis  and
Heylen, Dirk  and
Ordelman, Roeland",2006,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),,"We present the results of two trials testing procedures for the annotation of emotion and mental state of the AMI corpus. The first procedure is an adaptation of the FeelTrace method, focusing on a continuous labelling of emotion dimensions. The second method is centered around more discrete labeling of segments using categorical labels. The results reported are promising for this hard task.",http://www.lrec-conf.org/proceedings/lrec2006/pdf/626_pdf.pdf,emotion,Yes,No,No
{``}You Stupid Tin Box{''} - Children Interacting with the {AIBO} Robot: A Cross-linguistic Emotional Speech Corpus,"Batliner, A.  and
Hacker, C.  and
Steidl, S.  and
N{\""o}th, E.  and
D{'}Arcy, S.  and
Russell, M.  and
Wong, M.",2004,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),,"This paper deals with databases that combine different aspects: children's speech, emotional speech, human-robot communication, cross-linguistics, and read vs. spontaneous speech: in a Wizard-of-Oz scenario, German and English children had to instruct Sony's AIBO robot to fulfil specific tasks. In one experimental condition, strictly parallel for German and English, the AIBO behaved `disobedient' by following it's own script irrespective of the child's commands. By that, reactions of different children to the same sequence of AIBO's actions could be obtained. In addition, both the German and the English children were recorded reading texts. The data are transliterated orthographically; emotional user states and some other phenomena will be annotated. We report preliminary word recognition rates and classification results.",http://www.lrec-conf.org/proceedings/lrec2004/pdf/317.pdf,emotion,Yes,Yes,No
